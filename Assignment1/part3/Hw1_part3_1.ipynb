{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "54f45fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import argparse\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.optim.lr_scheduler import StepLR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "52c352ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CnnNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CnnNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, 3, 1)\n",
    "        self.dropout1 = nn.Dropout(0.25)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        self.fc1 = nn.Linear(2704, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        output = F.log_softmax(x, dim=1)\n",
    "        return output\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "efacf574",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train( model, device, train_loader, optimizer,loss_fn, epoch):\n",
    "    train_loss=0\n",
    "    model.train()\n",
    "    no_batches=0\n",
    "    correct = 0\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        #print(data.shape)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = loss_fn(output, target)\n",
    "        #train_loss.append(sum(loss.detach().cpu().numpy())/len(data))\n",
    "        train_loss+=loss.item()\n",
    "        no_batches+=1\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "        #if batch_idx % 10 == 0:\n",
    "        #    print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "        #        epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "        #        100. * batch_idx / len(train_loader), loss.item()))\n",
    "    print(\"Epoch:\", epoch, \"sum loss:\", train_loss, \"batches\", no_batches, \"loss:\", train_loss/no_batches,\n",
    "         \"accuracy:\", 100. * correct / len(train_loader.dataset))  \n",
    "    return train_loss/no_batches, 100. * correct / len(train_loader.dataset)\n",
    "\n",
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    loss_fn = nn.CrossEntropyLoss(reduction='sum')\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += loss_fn(output, target)  # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "    return test_loss, 100. * correct / len(test_loader.dataset)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9a287dac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torchvision.datasets.mnist.MNIST'>\n"
     ]
    }
   ],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "torch.manual_seed(1)\n",
    "\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "train_kwargs = {'batch_size': 512}\n",
    "test_kwargs = {'batch_size': 512}\n",
    "if use_cuda:\n",
    "    cuda_kwargs = {'num_workers': 1,\n",
    "                   'pin_memory': True,\n",
    "                   'shuffle': True}\n",
    "    train_kwargs.update(cuda_kwargs)\n",
    "    test_kwargs.update(cuda_kwargs)\n",
    "\n",
    "transform=transforms.Compose([\n",
    "        transforms.ToTensor()\n",
    "        #transforms.Normalize((0.1307,), (0.3081,))\n",
    "        ])\n",
    "dataset1 = datasets.MNIST('../data', train=True, download=True, transform=transform)\n",
    "dataset2 = datasets.MNIST('../data', train=False, transform=transform)\n",
    "print(type(dataset1))\n",
    "train_loader = torch.utils.data.DataLoader(dataset1,**train_kwargs)\n",
    "test_loader = torch.utils.data.DataLoader(dataset2, **test_kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6333413f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118\n",
      "60000\n",
      "60000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_data=[]\n",
    "train_labels=[]\n",
    "print(len(train_loader))\n",
    "for data, label in train_loader:\n",
    "    #data, label= dataset1[i]\n",
    "    for dt in data: \n",
    "        train_data.append(dt)\n",
    "    for lb in label:\n",
    "        train_labels.append(lb)\n",
    "print(len(train_data))    \n",
    "print(len(train_labels))\n",
    "print()\n",
    "#print(train_data[0])   \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "88a94d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.shuffle(train_labels)\n",
    "\n",
    "train_data_shuffle = []\n",
    "for i in range(len(train_data)):\n",
    "    train_data_shuffle.append([train_data[i], train_labels[i]])\n",
    "\n",
    "train_loader_shuffle = torch.utils.data.DataLoader(train_data_shuffle, shuffle=True, batch_size=512)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "59cce36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def returnModelAccAndLoss(model, device, train_loader, test_loader, optimizer, loss, epoch, scheduler):\n",
    "    train_loss=[]\n",
    "    test_loss=[]\n",
    "    accuracy_train=[]\n",
    "    accuracy_test=[]\n",
    "    #print(\"test_loader_size:\", len(test_loader.dataset))\n",
    "    for epoch in range(1, epoch+1):\n",
    "        tr_loss, tr_accuracy=train(model, device, train_loader, optimizer, loss, epoch)\n",
    "        train_loss.append(tr_loss)\n",
    "        accuracy_train.append(tr_accuracy)\n",
    "        tst_loss, tst_accuracy = test(model, device, test_loader)\n",
    "        test_loss.append(tst_loss)\n",
    "        accuracy_test.append(tst_accuracy)\n",
    "        scheduler.step()\n",
    "    return train_loss, accuracy_train, test_loss, accuracy_test\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bf869b0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 sum loss: 271.75069546699524 batches 118 loss: 2.3029719954830106 accuracy: 11.111666666666666\n",
      "\n",
      "Test set: Average loss: 2.3023, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Epoch: 2 sum loss: 271.5525965690613 batches 118 loss: 2.3012931912632313 accuracy: 11.236666666666666\n",
      "\n",
      "Test set: Average loss: 2.3022, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Epoch: 3 sum loss: 271.544873714447 batches 118 loss: 2.3012277433427712 accuracy: 11.236666666666666\n",
      "\n",
      "Test set: Average loss: 2.3022, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Epoch: 4 sum loss: 271.53723311424255 batches 118 loss: 2.301162992493581 accuracy: 11.236666666666666\n",
      "\n",
      "Test set: Average loss: 2.3022, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Epoch: 5 sum loss: 271.55051279067993 batches 118 loss: 2.3012755321244063 accuracy: 11.236666666666666\n",
      "\n",
      "Test set: Average loss: 2.3022, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Epoch: 6 sum loss: 271.5427701473236 batches 118 loss: 2.3012099165027426 accuracy: 11.236666666666666\n",
      "\n",
      "Test set: Average loss: 2.3022, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Epoch: 7 sum loss: 271.56027150154114 batches 118 loss: 2.3013582330639077 accuracy: 11.236666666666666\n",
      "\n",
      "Test set: Average loss: 2.3022, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Epoch: 8 sum loss: 271.538667678833 batches 118 loss: 2.3011751498206188 accuracy: 11.236666666666666\n",
      "\n",
      "Test set: Average loss: 2.3022, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Epoch: 9 sum loss: 271.53087282180786 batches 118 loss: 2.301109091710236 accuracy: 11.236666666666666\n",
      "\n",
      "Test set: Average loss: 2.3022, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Epoch: 10 sum loss: 271.5306553840637 batches 118 loss: 2.3011072490174893 accuracy: 11.236666666666666\n",
      "\n",
      "Test set: Average loss: 2.3022, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Epoch: 11 sum loss: 271.54026770591736 batches 118 loss: 2.301188709372181 accuracy: 11.236666666666666\n",
      "\n",
      "Test set: Average loss: 2.3022, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Epoch: 12 sum loss: 271.5377051830292 batches 118 loss: 2.3011669930765186 accuracy: 11.236666666666666\n",
      "\n",
      "Test set: Average loss: 2.3022, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Epoch: 13 sum loss: 271.53935265541077 batches 118 loss: 2.301180954706871 accuracy: 11.236666666666666\n",
      "\n",
      "Test set: Average loss: 2.3022, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Epoch: 14 sum loss: 271.5476610660553 batches 118 loss: 2.3012513649665705 accuracy: 11.236666666666666\n",
      "\n",
      "Test set: Average loss: 2.3022, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Epoch: 15 sum loss: 271.5471625328064 batches 118 loss: 2.301247140108529 accuracy: 11.236666666666666\n",
      "\n",
      "Test set: Average loss: 2.3022, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Epoch: 16 sum loss: 271.54490065574646 batches 118 loss: 2.3012279716588684 accuracy: 11.236666666666666\n",
      "\n",
      "Test set: Average loss: 2.3022, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Epoch: 17 sum loss: 271.55943179130554 batches 118 loss: 2.3013511168754706 accuracy: 11.236666666666666\n",
      "\n",
      "Test set: Average loss: 2.3022, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Epoch: 18 sum loss: 271.5386369228363 batches 118 loss: 2.3011748891765786 accuracy: 11.236666666666666\n",
      "\n",
      "Test set: Average loss: 2.3022, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Epoch: 19 sum loss: 271.5461483001709 batches 118 loss: 2.3012385449167025 accuracy: 11.236666666666666\n",
      "\n",
      "Test set: Average loss: 2.3022, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Epoch: 20 sum loss: 271.5454399585724 batches 118 loss: 2.3012325420218 accuracy: 11.236666666666666\n",
      "\n",
      "Test set: Average loss: 2.3022, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Epoch: 21 sum loss: 271.55115127563477 batches 118 loss: 2.301280943013854 accuracy: 11.236666666666666\n",
      "\n",
      "Test set: Average loss: 2.3022, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Epoch: 22 sum loss: 271.55435705184937 batches 118 loss: 2.301308110608893 accuracy: 11.236666666666666\n",
      "\n",
      "Test set: Average loss: 2.3022, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Epoch: 23 sum loss: 271.5589370727539 batches 118 loss: 2.301346924345372 accuracy: 11.236666666666666\n",
      "\n",
      "Test set: Average loss: 2.3022, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Epoch: 24 sum loss: 271.5385687351227 batches 118 loss: 2.301174311314599 accuracy: 11.236666666666666\n",
      "\n",
      "Test set: Average loss: 2.3022, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Epoch: 25 sum loss: 271.55075550079346 batches 118 loss: 2.301277588989775 accuracy: 11.236666666666666\n",
      "\n",
      "Test set: Average loss: 2.3022, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Epoch: 26 sum loss: 271.53754472732544 batches 118 loss: 2.301165633282419 accuracy: 11.236666666666666\n",
      "\n",
      "Test set: Average loss: 2.3022, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Epoch: 27 sum loss: 271.54449939727783 batches 118 loss: 2.3012245711633716 accuracy: 11.236666666666666\n",
      "\n",
      "Test set: Average loss: 2.3022, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Epoch: 28 sum loss: 271.5492432117462 batches 118 loss: 2.3012647729809 accuracy: 11.236666666666666\n",
      "\n",
      "Test set: Average loss: 2.3022, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Epoch: 29 sum loss: 271.5450623035431 batches 118 loss: 2.30122934155545 accuracy: 11.236666666666666\n",
      "\n",
      "Test set: Average loss: 2.3022, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Epoch: 30 sum loss: 271.535418510437 batches 118 loss: 2.3011476144952288 accuracy: 11.236666666666666\n",
      "\n",
      "Test set: Average loss: 2.3022, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Epoch: 31 sum loss: 271.5464005470276 batches 118 loss: 2.3012406826019287 accuracy: 11.236666666666666\n",
      "\n",
      "Test set: Average loss: 2.3022, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Epoch: 32 sum loss: 271.52985095977783 batches 118 loss: 2.301100431862524 accuracy: 11.236666666666666\n",
      "\n",
      "Test set: Average loss: 2.3022, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Epoch: 33 sum loss: 271.53389048576355 batches 118 loss: 2.3011346651335893 accuracy: 11.236666666666666\n",
      "\n",
      "Test set: Average loss: 2.3022, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Epoch: 34 sum loss: 271.5353560447693 batches 118 loss: 2.3011470851251636 accuracy: 11.236666666666666\n",
      "\n",
      "Test set: Average loss: 2.3022, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Epoch: 35 sum loss: 271.53193736076355 batches 118 loss: 2.30111811322681 accuracy: 11.236666666666666\n",
      "\n",
      "Test set: Average loss: 2.3022, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Epoch: 36 sum loss: 271.5486500263214 batches 118 loss: 2.301259745985775 accuracy: 11.236666666666666\n",
      "\n",
      "Test set: Average loss: 2.3022, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Epoch: 37 sum loss: 271.54588747024536 batches 118 loss: 2.3012363344936047 accuracy: 11.236666666666666\n",
      "\n",
      "Test set: Average loss: 2.3022, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Epoch: 38 sum loss: 271.55630373954773 batches 118 loss: 2.3013246079622687 accuracy: 11.236666666666666\n",
      "\n",
      "Test set: Average loss: 2.3022, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Epoch: 39 sum loss: 271.5502710342407 batches 118 loss: 2.301273483341023 accuracy: 11.236666666666666\n",
      "\n",
      "Test set: Average loss: 2.3022, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Epoch: 40 sum loss: 271.5394127368927 batches 118 loss: 2.301181463871972 accuracy: 11.236666666666666\n",
      "\n",
      "Test set: Average loss: 2.3022, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Epoch: 41 sum loss: 271.54151225090027 batches 118 loss: 2.3011992563635615 accuracy: 11.236666666666666\n",
      "\n",
      "Test set: Average loss: 2.3022, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Epoch: 42 sum loss: 271.5547626018524 batches 118 loss: 2.3013115474733254 accuracy: 11.236666666666666\n",
      "\n",
      "Test set: Average loss: 2.3022, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Epoch: 43 sum loss: 271.5491666793823 batches 118 loss: 2.3012641244015453 accuracy: 11.236666666666666\n",
      "\n",
      "Test set: Average loss: 2.3022, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Epoch: 44 sum loss: 271.55207228660583 batches 118 loss: 2.301288748191575 accuracy: 11.236666666666666\n",
      "\n",
      "Test set: Average loss: 2.3022, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Epoch: 45 sum loss: 271.5298824310303 batches 118 loss: 2.301100698568053 accuracy: 11.236666666666666\n",
      "\n",
      "Test set: Average loss: 2.3022, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Epoch: 46 sum loss: 271.55221366882324 batches 118 loss: 2.3012899463459595 accuracy: 11.236666666666666\n",
      "\n",
      "Test set: Average loss: 2.3022, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Epoch: 47 sum loss: 271.54707884788513 batches 118 loss: 2.3012464309142806 accuracy: 11.236666666666666\n",
      "\n",
      "Test set: Average loss: 2.3022, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Epoch: 48 sum loss: 271.54238057136536 batches 118 loss: 2.3012066150115706 accuracy: 11.236666666666666\n",
      "\n",
      "Test set: Average loss: 2.3022, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Epoch: 49 sum loss: 271.54303669929504 batches 118 loss: 2.3012121754177546 accuracy: 11.236666666666666\n",
      "\n",
      "Test set: Average loss: 2.3022, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Epoch: 50 sum loss: 271.53993487358093 batches 118 loss: 2.3011858887591603 accuracy: 11.236666666666666\n",
      "\n",
      "Test set: Average loss: 2.3022, Accuracy: 1135/10000 (11%)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 51 sum loss: 271.53859663009644 batches 118 loss: 2.3011745477126815 accuracy: 11.236666666666666\n",
      "\n",
      "Test set: Average loss: 2.3022, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Epoch: 52 sum loss: 271.53775119781494 batches 118 loss: 2.30116738303233 accuracy: 11.236666666666666\n",
      "\n",
      "Test set: Average loss: 2.3022, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Epoch: 53 sum loss: 271.54316997528076 batches 118 loss: 2.3012133048752608 accuracy: 11.236666666666666\n",
      "\n",
      "Test set: Average loss: 2.3022, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Epoch: 54 sum loss: 271.5411744117737 batches 118 loss: 2.301196393320116 accuracy: 11.236666666666666\n",
      "\n",
      "Test set: Average loss: 2.3022, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Epoch: 55 sum loss: 271.533567905426 batches 118 loss: 2.3011319314019154 accuracy: 11.236666666666666\n",
      "\n",
      "Test set: Average loss: 2.3022, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Epoch: 56 sum loss: 271.53621435165405 batches 118 loss: 2.3011543589123225 accuracy: 11.236666666666666\n",
      "\n",
      "Test set: Average loss: 2.3022, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Epoch: 57 sum loss: 271.54298663139343 batches 118 loss: 2.3012117511135037 accuracy: 11.236666666666666\n",
      "\n",
      "Test set: Average loss: 2.3022, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Epoch: 58 sum loss: 271.5499315261841 batches 118 loss: 2.301270606154102 accuracy: 11.236666666666666\n",
      "\n",
      "Test set: Average loss: 2.3022, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Epoch: 59 sum loss: 271.5553045272827 batches 118 loss: 2.301316140061718 accuracy: 11.236666666666666\n",
      "\n",
      "Test set: Average loss: 2.3022, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Epoch: 60 sum loss: 271.54831981658936 batches 118 loss: 2.301256947598215 accuracy: 11.236666666666666\n",
      "\n",
      "Test set: Average loss: 2.3022, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Epoch: 61 sum loss: 271.55711555480957 batches 118 loss: 2.3013314877526234 accuracy: 11.236666666666666\n",
      "\n",
      "Test set: Average loss: 2.3022, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Epoch: 62 sum loss: 271.5418508052826 batches 118 loss: 2.3012021254684965 accuracy: 11.236666666666666\n",
      "\n",
      "Test set: Average loss: 2.3022, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Epoch: 63 sum loss: 271.5438916683197 batches 118 loss: 2.3012194209179637 accuracy: 11.236666666666666\n",
      "\n",
      "Test set: Average loss: 2.3022, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Epoch: 64 sum loss: 271.5441973209381 batches 118 loss: 2.301222011194391 accuracy: 11.236666666666666\n",
      "\n",
      "Test set: Average loss: 2.3022, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Epoch: 65 sum loss: 271.53694701194763 batches 118 loss: 2.3011605678978615 accuracy: 11.236666666666666\n",
      "\n",
      "Test set: Average loss: 2.3022, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Epoch: 66 sum loss: 271.54265546798706 batches 118 loss: 2.301208944643958 accuracy: 11.236666666666666\n",
      "\n",
      "Test set: Average loss: 2.3022, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Epoch: 67 sum loss: 271.55278730392456 batches 118 loss: 2.3012948076603776 accuracy: 11.236666666666666\n",
      "\n",
      "Test set: Average loss: 2.3022, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Epoch: 68 sum loss: 271.54811811447144 batches 118 loss: 2.3012552382582325 accuracy: 11.236666666666666\n",
      "\n",
      "Test set: Average loss: 2.3022, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Epoch: 69 sum loss: 271.54582929611206 batches 118 loss: 2.301235841492475 accuracy: 11.236666666666666\n",
      "\n",
      "Test set: Average loss: 2.3022, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Epoch: 70 sum loss: 271.5335874557495 batches 118 loss: 2.301132097082623 accuracy: 11.236666666666666\n",
      "\n",
      "Test set: Average loss: 2.3022, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Epoch: 71 sum loss: 271.5456564426422 batches 118 loss: 2.301234376632561 accuracy: 11.236666666666666\n",
      "\n",
      "Test set: Average loss: 2.3022, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Epoch: 72 sum loss: 271.54957485198975 batches 118 loss: 2.3012675834914385 accuracy: 11.236666666666666\n",
      "\n",
      "Test set: Average loss: 2.3022, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Epoch: 73 sum loss: 271.54380655288696 batches 118 loss: 2.301218699600737 accuracy: 11.236666666666666\n",
      "\n",
      "Test set: Average loss: 2.3022, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Epoch: 74 sum loss: 271.54421830177307 batches 118 loss: 2.301222188998077 accuracy: 11.236666666666666\n",
      "\n",
      "Test set: Average loss: 2.3022, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Epoch: 75 sum loss: 271.52581429481506 batches 118 loss: 2.3010662228374157 accuracy: 11.236666666666666\n",
      "\n",
      "Test set: Average loss: 2.3022, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Epoch: 76 sum loss: 271.53086400032043 batches 118 loss: 2.301109016951868 accuracy: 11.236666666666666\n",
      "\n",
      "Test set: Average loss: 2.3022, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Epoch: 77 sum loss: 271.5381910800934 batches 118 loss: 2.301171110848249 accuracy: 11.236666666666666\n",
      "\n",
      "Test set: Average loss: 2.3022, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Epoch: 78 sum loss: 271.54112243652344 batches 118 loss: 2.3011959528518937 accuracy: 11.236666666666666\n",
      "\n",
      "Test set: Average loss: 2.3022, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Epoch: 79 sum loss: 271.53945684432983 batches 118 loss: 2.3011818376638122 accuracy: 11.236666666666666\n",
      "\n",
      "Test set: Average loss: 2.3022, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Epoch: 80 sum loss: 271.5425696372986 batches 118 loss: 2.301208217265242 accuracy: 11.236666666666666\n",
      "\n",
      "Test set: Average loss: 2.3022, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Epoch: 81 sum loss: 271.54321217536926 batches 118 loss: 2.3012136625031294 accuracy: 11.236666666666666\n",
      "\n",
      "Test set: Average loss: 2.3022, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Epoch: 82 sum loss: 271.5395312309265 batches 118 loss: 2.301182468058699 accuracy: 11.236666666666666\n",
      "\n",
      "Test set: Average loss: 2.3022, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Epoch: 83 sum loss: 271.53490710258484 batches 118 loss: 2.30114328053038 accuracy: 11.236666666666666\n",
      "\n",
      "Test set: Average loss: 2.3022, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Epoch: 84 sum loss: 271.5401165485382 batches 118 loss: 2.3011874283774425 accuracy: 11.236666666666666\n",
      "\n",
      "Test set: Average loss: 2.3022, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Epoch: 85 sum loss: 271.52265787124634 batches 118 loss: 2.3010394734851385 accuracy: 11.236666666666666\n",
      "\n",
      "Test set: Average loss: 2.3022, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Epoch: 86 sum loss: 271.53801345825195 batches 118 loss: 2.3011696055784063 accuracy: 11.236666666666666\n",
      "\n",
      "Test set: Average loss: 2.3022, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Epoch: 87 sum loss: 271.5464026927948 batches 118 loss: 2.3012407007863964 accuracy: 11.236666666666666\n",
      "\n",
      "Test set: Average loss: 2.3022, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Epoch: 88 sum loss: 271.5325062274933 batches 118 loss: 2.301122934131299 accuracy: 11.236666666666666\n",
      "\n",
      "Test set: Average loss: 2.3022, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Epoch: 89 sum loss: 271.5494508743286 batches 118 loss: 2.3012665328332935 accuracy: 11.236666666666666\n",
      "\n",
      "Test set: Average loss: 2.3022, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Epoch: 90 sum loss: 271.543417930603 batches 118 loss: 2.301215406191551 accuracy: 11.236666666666666\n",
      "\n",
      "Test set: Average loss: 2.3022, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Epoch: 91 sum loss: 271.5491621494293 batches 118 loss: 2.3012640860121127 accuracy: 11.236666666666666\n",
      "\n",
      "Test set: Average loss: 2.3022, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Epoch: 92 sum loss: 271.54255962371826 batches 118 loss: 2.3012081324043923 accuracy: 11.236666666666666\n",
      "\n",
      "Test set: Average loss: 2.3022, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Epoch: 93 sum loss: 271.5370743274689 batches 118 loss: 2.3011616468429565 accuracy: 11.236666666666666\n",
      "\n",
      "Test set: Average loss: 2.3022, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Epoch: 94 sum loss: 271.5333025455475 batches 118 loss: 2.3011296825893854 accuracy: 11.236666666666666\n",
      "\n",
      "Test set: Average loss: 2.3022, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Epoch: 95 sum loss: 271.53555393218994 batches 118 loss: 2.301148762137203 accuracy: 11.236666666666666\n",
      "\n",
      "Test set: Average loss: 2.3022, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Epoch: 96 sum loss: 271.5456507205963 batches 118 loss: 2.3012343281406467 accuracy: 11.236666666666666\n",
      "\n",
      "Test set: Average loss: 2.3022, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Epoch: 97 sum loss: 271.5494465827942 batches 118 loss: 2.3012664964643577 accuracy: 11.236666666666666\n",
      "\n",
      "Test set: Average loss: 2.3022, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Epoch: 98 sum loss: 271.53916931152344 batches 118 loss: 2.301179400945114 accuracy: 11.236666666666666\n",
      "\n",
      "Test set: Average loss: 2.3022, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Epoch: 99 sum loss: 271.53469371795654 batches 118 loss: 2.3011414721860723 accuracy: 11.236666666666666\n",
      "\n",
      "Test set: Average loss: 2.3022, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Epoch: 100 sum loss: 271.5492191314697 batches 118 loss: 2.3012645689107605 accuracy: 11.236666666666666\n",
      "\n",
      "Test set: Average loss: 2.3022, Accuracy: 1135/10000 (11%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "epoch=100\n",
    "model = CnnNet().to(device)\n",
    "optimizer = optim.Adadelta(model.parameters(), lr=1)\n",
    "scheduler = StepLR(optimizer, step_size=1, gamma=0.1)\n",
    "loss = nn.CrossEntropyLoss()\n",
    "train_loss_1, accuracy_train_1, test_loss_1, test_accuracy_1= returnModelAccAndLoss(model, device, train_loader_shuffle, test_loader, optimizer, loss, epoch, scheduler)\n",
    "\n",
    "#torch.save(model.state_dict(), \"mnist_cnn.pt\")\n",
    "  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7ddc1177",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt1=plt.figure(figsize=(10, 6))\n",
    "plt.plot(np.array(train_loss_1), 'r', label='training')\n",
    "plt.plot(np.array(test_loss_1), 'b', label='test')\n",
    "\n",
    "# naming the x axis\n",
    "plt.xlabel('Epochs')\n",
    "# naming the y axis\n",
    "plt.ylabel('Loss') \n",
    "plt.legend()\n",
    "plt.title(\"Loss function For MNIST\")\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b64187",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
