{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "607801d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from math import pi\n",
    "from collections import defaultdict\n",
    "from autograd_lib import autograd_lib\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c83dd792",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "class SineApproximator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SineApproximator, self).__init__()\n",
    "        self.regressor = nn.Sequential(nn.Linear(1, 190),\n",
    "                                       nn.ReLU(inplace=True),\n",
    "                                       nn.Linear(190, 1))\n",
    "    def forward(self, x):\n",
    "        output = self.regressor(x)\n",
    "        return output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "575d3099",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2500,)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "step = 0.1\n",
    "X = np.linspace(1e-4, 1, 2500) \n",
    "y = np.sin(5*np.pi*X) / (5*np.pi*X)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(X, y)\n",
    " \n",
    "# naming the x axis\n",
    "plt.xlabel('x - axis')\n",
    "# naming the y axis\n",
    "plt.ylabel('y - axis')\n",
    " \n",
    "# giving a title to my graph\n",
    "plt.title('My first graph!')\n",
    " \n",
    "# function to show the plot\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f6acf710",
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = 1e-4\n",
    "MAX_EPOCH = 20000\n",
    "BATCH_SIZE = 512\n",
    "\n",
    "X_train, X_val, y_train, y_val = map(torch.tensor, train_test_split(X, y, test_size=0.2))\n",
    "train_dataloader = DataLoader(TensorDataset(X_train.unsqueeze(1), y_train.unsqueeze(1)), batch_size=BATCH_SIZE,\n",
    "                              pin_memory=True, shuffle=True)\n",
    "val_dataloader = DataLoader(TensorDataset(X_val.unsqueeze(1), y_val.unsqueeze(1)), batch_size=BATCH_SIZE,\n",
    "                            pin_memory=True, shuffle=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6a46e7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to compute gradient norm\n",
    "def compute_gradient_norm(model, criterion, train, target):\n",
    "    model.train()\n",
    "    model.zero_grad()\n",
    "    output = model(train)\n",
    "    loss = criterion(output, target)\n",
    "    loss.backward()\n",
    "\n",
    "    grads = []\n",
    "    for p in model.regressor.children():\n",
    "        if isinstance(p, nn.Linear):\n",
    "            param_norm = p.weight.grad.norm(2).item()\n",
    "            grads.append(param_norm)\n",
    "\n",
    "    grad_mean = np.mean(grads) # compute mean of gradient norms\n",
    "\n",
    "    return grad_mean\n",
    "\n",
    "\n",
    "# helper function to save activations\n",
    "def save_activations(layer, A, _):\n",
    "    '''\n",
    "    A is the input of the layer, we use batch size of 6 here\n",
    "    layer 1: A has size of (6, 1)\n",
    "    layer 2: A has size of (6, 128)\n",
    "    '''\n",
    "    activations[layer] = A\n",
    "\n",
    "# helper function to compute Hessian matrix\n",
    "def compute_hess(layer, _, B):\n",
    "    '''\n",
    "    B is the backprop value of the layer\n",
    "    layer 1: B has size of (6, 128)\n",
    "    layer 2: B ahs size of (6, 1)\n",
    "    '''\n",
    "    A = activations[layer]\n",
    "    BA = torch.einsum('nl,ni->nli', B, A) # do batch-wise outer product\n",
    "\n",
    "    # full Hessian\n",
    "    hess[layer] += torch.einsum('nli,nkj->likj', BA, BA) # do batch-wise outer product, then sum over the batch\n",
    "    \n",
    "# function to compute the minimum ratio\n",
    "def compute_minimum_ratio(model, criterion, train, target):\n",
    "    model.zero_grad()\n",
    "    # compute Hessian matrix\n",
    "    # save the gradient of each layer\n",
    "    with autograd_lib.module_hook(save_activations):\n",
    "        output = model(train)\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "    # compute Hessian according to the gradient value stored in the previous step\n",
    "    with autograd_lib.module_hook(compute_hess):\n",
    "        autograd_lib.backward_hessian(output, loss='LeastSquares')\n",
    "\n",
    "    layer_hess = list(hess.values())\n",
    "    minimum_ratio = []\n",
    "\n",
    "    # compute eigenvalues of the Hessian matrix\n",
    "    for h in layer_hess:\n",
    "        size = h.shape[0] * h.shape[1]\n",
    "        h = h.reshape(size, size)\n",
    "        h_eig = torch.symeig(h).eigenvalues # torch.symeig() returns eigenvalues and eigenvectors of a real symmetric matrix\n",
    "        num_greater = torch.sum(h_eig > 0).item()\n",
    "        minimum_ratio.append(num_greater / len(h_eig))\n",
    "\n",
    "    ratio_mean = np.mean(minimum_ratio) # compute mean of minimum ratio\n",
    "\n",
    "    return ratio_mean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1dece66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def returnLossPredictedOp(model, train_dataloader, val_dataloader):\n",
    "    optimizer = optim.Adam(model.parameters(), lr=LR)\n",
    "    criterion = nn.MSELoss()\n",
    "    \n",
    "    # training loop\n",
    "    train_loss_list = list()\n",
    "    val_loss_list = list()\n",
    "    gradient_norm=[]\n",
    "    minimal_ratio=[]\n",
    "    for epoch in range(MAX_EPOCH):\n",
    "        print(\"epoch %d / %d\" % (epoch+1, MAX_EPOCH))\n",
    "        model.train()\n",
    "     \n",
    "        # training loop\n",
    "        temp_loss_list = list()\n",
    "        grdnt_norm=0\n",
    "        min_ratio=0\n",
    "        for X_train, y_train in train_dataloader:\n",
    "            X_train = X_train.type(torch.float32).to(device)\n",
    "            y_train = y_train.type(torch.float32).to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            score = model(X_train)\n",
    "            loss = criterion(input=score, target=y_train)\n",
    "            #loss.requires_grad = True\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            temp_loss_list.append(loss.detach().cpu().numpy())\n",
    "            grdnt_norm += compute_gradient_norm(model, criterion, X_train, y_train)\n",
    "            min_ratio += compute_minimum_ratio(model, criterion, X_train, y_train)\n",
    "\n",
    "        train_loss_list.append(np.average(temp_loss_list))\n",
    "        gradient_norm.append(np.average(grdnt_norm))\n",
    "        minimal_ratio.append(np.average(min_ratio))\n",
    "        print('gradient norm: {}, minimum ratio: {}'.format(gradient_norm[-1], minimal_ratio[-1]))\n",
    "        # validation\n",
    "        model.eval()\n",
    "\n",
    "        temp_loss_list = list()\n",
    "\n",
    "        for X_val, y_val in val_dataloader:\n",
    "            X_val = X_val.type(torch.float32).to(device)\n",
    "            y_val = y_val.type(torch.float32).to(device)\n",
    "\n",
    "            score = model(X_val)        \n",
    "            loss = criterion(input=score, target=y_val)\n",
    "\n",
    "            temp_loss_list.append(loss.detach().cpu().numpy())\n",
    "\n",
    "        val_loss_list.append(np.average(temp_loss_list))\n",
    "\n",
    "        print(\"\\ttrain loss: %.5f\" % train_loss_list[-1])\n",
    "        print(\"\\tval loss: %.5f\" % val_loss_list[-1])\n",
    "    \n",
    "    return train_loss_list, val_loss_list, gradient_norm, minimal_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f9baac2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 / 20000\n",
      "gradient norm: 5.86878989636898, minimum ratio: 2.3684210526315788\n",
      "\ttrain loss: 0.15900\n",
      "\tval loss: 0.15346\n",
      "epoch 2 / 20000\n",
      "gradient norm: 5.372600853443146, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.14903\n",
      "\tval loss: 0.14422\n",
      "epoch 3 / 20000\n",
      "gradient norm: 4.892411842942238, minimum ratio: 2.394736842105263\n",
      "\ttrain loss: 0.14008\n",
      "\tval loss: 0.13595\n",
      "epoch 4 / 20000\n",
      "gradient norm: 4.41388988122344, minimum ratio: 2.4000000000000004\n",
      "\ttrain loss: 0.13185\n",
      "\tval loss: 0.12864\n",
      "epoch 5 / 20000\n",
      "gradient norm: 3.9540716372430325, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.12444\n",
      "\tval loss: 0.12228\n",
      "epoch 6 / 20000\n",
      "gradient norm: 3.5135993771255016, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.11825\n",
      "\tval loss: 0.11684\n",
      "epoch 7 / 20000\n",
      "gradient norm: 3.0995533424429595, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.11300\n",
      "\tval loss: 0.11226\n",
      "epoch 8 / 20000\n",
      "gradient norm: 2.7266969489865005, minimum ratio: 2.4210526315789473\n",
      "\ttrain loss: 0.10873\n",
      "\tval loss: 0.10849\n",
      "epoch 9 / 20000\n",
      "gradient norm: 2.3733604687731713, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.10506\n",
      "\tval loss: 0.10539\n",
      "epoch 10 / 20000\n",
      "gradient norm: 2.0596143529983237, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.10193\n",
      "\tval loss: 0.10287\n",
      "epoch 11 / 20000\n",
      "gradient norm: 1.804497382370755, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.09972\n",
      "\tval loss: 0.10086\n",
      "epoch 12 / 20000\n",
      "gradient norm: 1.587166876066476, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.09767\n",
      "\tval loss: 0.09921\n",
      "epoch 13 / 20000\n",
      "gradient norm: 1.4024499910883605, minimum ratio: 2.4499999999999997\n",
      "\ttrain loss: 0.09597\n",
      "\tval loss: 0.09785\n",
      "epoch 14 / 20000\n",
      "gradient norm: 1.2571587613783777, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.09458\n",
      "\tval loss: 0.09671\n",
      "epoch 15 / 20000\n",
      "gradient norm: 1.146009873598814, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.09369\n",
      "\tval loss: 0.09572\n",
      "epoch 16 / 20000\n",
      "gradient norm: 1.0589313274249434, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.09259\n",
      "\tval loss: 0.09482\n",
      "epoch 17 / 20000\n",
      "gradient norm: 0.9984465716406703, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.09172\n",
      "\tval loss: 0.09400\n",
      "epoch 18 / 20000\n",
      "gradient norm: 0.9879550924524665, minimum ratio: 2.4499999999999997\n",
      "\ttrain loss: 0.09045\n",
      "\tval loss: 0.09320\n",
      "epoch 19 / 20000\n",
      "gradient norm: 0.9222892764955759, minimum ratio: 2.4421052631578943\n",
      "\ttrain loss: 0.08963\n",
      "\tval loss: 0.09244\n",
      "epoch 20 / 20000\n",
      "gradient norm: 0.9380354816094041, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.08943\n",
      "\tval loss: 0.09170\n",
      "epoch 21 / 20000\n",
      "gradient norm: 0.8739421600475907, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.08798\n",
      "\tval loss: 0.09096\n",
      "epoch 22 / 20000\n",
      "gradient norm: 0.8758456213399768, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.08724\n",
      "\tval loss: 0.09023\n",
      "epoch 23 / 20000\n",
      "gradient norm: 0.8552092183381319, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.08662\n",
      "\tval loss: 0.08951\n",
      "epoch 24 / 20000\n",
      "gradient norm: 0.8359830472618341, minimum ratio: 2.4157894736842103\n",
      "\ttrain loss: 0.08581\n",
      "\tval loss: 0.08881\n",
      "epoch 25 / 20000\n",
      "gradient norm: 0.8893623203039169, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.08518\n",
      "\tval loss: 0.08813\n",
      "epoch 26 / 20000\n",
      "gradient norm: 0.8054762054234743, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.08464\n",
      "\tval loss: 0.08744\n",
      "epoch 27 / 20000\n",
      "gradient norm: 0.8240309124812484, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.08400\n",
      "\tval loss: 0.08677\n",
      "epoch 28 / 20000\n",
      "gradient norm: 0.8310771379619837, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.08348\n",
      "\tval loss: 0.08612\n",
      "epoch 29 / 20000\n",
      "gradient norm: 0.7625990733504295, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.08259\n",
      "\tval loss: 0.08548\n",
      "epoch 30 / 20000\n",
      "gradient norm: 0.7791110463440418, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.08210\n",
      "\tval loss: 0.08486\n",
      "epoch 31 / 20000\n",
      "gradient norm: 0.7700671581551433, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.08127\n",
      "\tval loss: 0.08424\n",
      "epoch 32 / 20000\n",
      "gradient norm: 0.7878933632746339, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.08118\n",
      "\tval loss: 0.08364\n",
      "epoch 33 / 20000\n",
      "gradient norm: 0.7167796669527888, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.07987\n",
      "\tval loss: 0.08305\n",
      "epoch 34 / 20000\n",
      "gradient norm: 0.7276449911296368, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.07918\n",
      "\tval loss: 0.08248\n",
      "epoch 35 / 20000\n",
      "gradient norm: 0.6861380022019148, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.07875\n",
      "\tval loss: 0.08192\n",
      "epoch 36 / 20000\n",
      "gradient norm: 0.6969507718458772, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.07816\n",
      "\tval loss: 0.08137\n",
      "epoch 37 / 20000\n",
      "gradient norm: 0.7223510686308146, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.07761\n",
      "\tval loss: 0.08084\n",
      "epoch 38 / 20000\n",
      "gradient norm: 0.6703002164140344, minimum ratio: 2.4684210526315784\n",
      "\ttrain loss: 0.07731\n",
      "\tval loss: 0.08033\n",
      "epoch 39 / 20000\n",
      "gradient norm: 0.6525839110836387, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.07681\n",
      "\tval loss: 0.07983\n",
      "epoch 40 / 20000\n",
      "gradient norm: 0.6643246682360768, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.07635\n",
      "\tval loss: 0.07934\n",
      "epoch 41 / 20000\n",
      "gradient norm: 0.6495869439095259, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.07540\n",
      "\tval loss: 0.07885\n",
      "epoch 42 / 20000\n",
      "gradient norm: 0.625899386126548, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.07528\n",
      "\tval loss: 0.07839\n",
      "epoch 43 / 20000\n",
      "gradient norm: 0.6247817217372358, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.07445\n",
      "\tval loss: 0.07793\n",
      "epoch 44 / 20000\n",
      "gradient norm: 0.6233154819346964, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.07394\n",
      "\tval loss: 0.07748\n",
      "epoch 45 / 20000\n",
      "gradient norm: 0.6017065830528736, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.07361\n",
      "\tval loss: 0.07705\n",
      "epoch 46 / 20000\n",
      "gradient norm: 0.5745927873067558, minimum ratio: 2.492105263157895\n",
      "\ttrain loss: 0.07308\n",
      "\tval loss: 0.07663\n",
      "epoch 47 / 20000\n",
      "gradient norm: 0.5657697976566851, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.07300\n",
      "\tval loss: 0.07623\n",
      "epoch 48 / 20000\n",
      "gradient norm: 0.5491658663377166, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.07231\n",
      "\tval loss: 0.07583\n",
      "epoch 49 / 20000\n",
      "gradient norm: 0.5636013196781278, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.07199\n",
      "\tval loss: 0.07544\n",
      "epoch 50 / 20000\n",
      "gradient norm: 0.5473356028087437, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.07155\n",
      "\tval loss: 0.07506\n",
      "epoch 51 / 20000\n",
      "gradient norm: 0.5583193046040833, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.07107\n",
      "\tval loss: 0.07469\n",
      "epoch 52 / 20000\n",
      "gradient norm: 0.5122763738036156, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.07077\n",
      "\tval loss: 0.07434\n",
      "epoch 53 / 20000\n",
      "gradient norm: 0.5352034890092909, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.07031\n",
      "\tval loss: 0.07399\n",
      "epoch 54 / 20000\n",
      "gradient norm: 0.521163048222661, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.06972\n",
      "\tval loss: 0.07365\n",
      "epoch 55 / 20000\n",
      "gradient norm: 0.5363558861427009, minimum ratio: 2.447368421052631\n",
      "\ttrain loss: 0.06998\n",
      "\tval loss: 0.07332\n",
      "epoch 56 / 20000\n",
      "gradient norm: 0.500803810544312, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.06931\n",
      "\tval loss: 0.07300\n",
      "epoch 57 / 20000\n",
      "gradient norm: 0.4729585526511073, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.06870\n",
      "\tval loss: 0.07269\n",
      "epoch 58 / 20000\n",
      "gradient norm: 0.4614849085919559, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.06847\n",
      "\tval loss: 0.07238\n",
      "epoch 59 / 20000\n",
      "gradient norm: 0.4573565889149904, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.06817\n",
      "\tval loss: 0.07209\n",
      "epoch 60 / 20000\n",
      "gradient norm: 0.45633734529837966, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.06792\n",
      "\tval loss: 0.07180\n",
      "epoch 61 / 20000\n",
      "gradient norm: 0.4871991276741028, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.06765\n",
      "\tval loss: 0.07152\n",
      "epoch 62 / 20000\n",
      "gradient norm: 0.4704478164203465, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.06745\n",
      "\tval loss: 0.07125\n",
      "epoch 63 / 20000\n",
      "gradient norm: 0.5188265708275139, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.06713\n",
      "\tval loss: 0.07098\n",
      "epoch 64 / 20000\n",
      "gradient norm: 0.43146724347025156, minimum ratio: 2.4868421052631575\n",
      "\ttrain loss: 0.06701\n",
      "\tval loss: 0.07072\n",
      "epoch 65 / 20000\n",
      "gradient norm: 0.46726923529058695, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.06632\n",
      "\tval loss: 0.07046\n",
      "epoch 66 / 20000\n",
      "gradient norm: 0.40110952220857143, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.06617\n",
      "\tval loss: 0.07021\n",
      "epoch 67 / 20000\n",
      "gradient norm: 0.5279239756055176, minimum ratio: 2.4631578947368427\n",
      "\ttrain loss: 0.06590\n",
      "\tval loss: 0.06997\n",
      "epoch 68 / 20000\n",
      "gradient norm: 0.3993261307477951, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.06575\n",
      "\tval loss: 0.06974\n",
      "epoch 69 / 20000\n",
      "gradient norm: 0.4517632885836065, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.06549\n",
      "\tval loss: 0.06951\n",
      "epoch 70 / 20000\n",
      "gradient norm: 0.4082389622926712, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.06525\n",
      "\tval loss: 0.06928\n",
      "epoch 71 / 20000\n",
      "gradient norm: 0.4060520143248141, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.06512\n",
      "\tval loss: 0.06906\n",
      "epoch 72 / 20000\n",
      "gradient norm: 0.3654937343671918, minimum ratio: 2.4894736842105267\n",
      "\ttrain loss: 0.06478\n",
      "\tval loss: 0.06885\n",
      "epoch 73 / 20000\n",
      "gradient norm: 0.3995430856011808, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.06452\n",
      "\tval loss: 0.06864\n",
      "epoch 74 / 20000\n",
      "gradient norm: 0.3446951345540583, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.06432\n",
      "\tval loss: 0.06843\n",
      "epoch 75 / 20000\n",
      "gradient norm: 0.34346167417243123, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.06411\n",
      "\tval loss: 0.06823\n",
      "epoch 76 / 20000\n",
      "gradient norm: 0.42780725471675396, minimum ratio: 2.507894736842105\n",
      "\ttrain loss: 0.06403\n",
      "\tval loss: 0.06803\n",
      "epoch 77 / 20000\n",
      "gradient norm: 0.31720880372449756, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.06359\n",
      "\tval loss: 0.06783\n",
      "epoch 78 / 20000\n",
      "gradient norm: 0.3862859276123345, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.06362\n",
      "\tval loss: 0.06764\n",
      "epoch 79 / 20000\n",
      "gradient norm: 0.40546819823794067, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.06337\n",
      "\tval loss: 0.06745\n",
      "epoch 80 / 20000\n",
      "gradient norm: 0.30569224804639816, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.06301\n",
      "\tval loss: 0.06726\n",
      "epoch 81 / 20000\n",
      "gradient norm: 0.2992815636098385, minimum ratio: 2.5\n",
      "\ttrain loss: 0.06286\n",
      "\tval loss: 0.06708\n",
      "epoch 82 / 20000\n",
      "gradient norm: 0.3430896522477269, minimum ratio: 2.4736842105263155\n",
      "\ttrain loss: 0.06259\n",
      "\tval loss: 0.06690\n",
      "epoch 83 / 20000\n",
      "gradient norm: 0.3446821146644652, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.06250\n",
      "\tval loss: 0.06672\n",
      "epoch 84 / 20000\n",
      "gradient norm: 0.30212560086511075, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.06232\n",
      "\tval loss: 0.06654\n",
      "epoch 85 / 20000\n",
      "gradient norm: 0.40921012591570616, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.06201\n",
      "\tval loss: 0.06636\n",
      "epoch 86 / 20000\n",
      "gradient norm: 0.34304694505408406, minimum ratio: 2.518421052631579\n",
      "\ttrain loss: 0.06195\n",
      "\tval loss: 0.06619\n",
      "epoch 87 / 20000\n",
      "gradient norm: 0.35427078139036894, minimum ratio: 2.4842105263157896\n",
      "\ttrain loss: 0.06198\n",
      "\tval loss: 0.06602\n",
      "epoch 88 / 20000\n",
      "gradient norm: 0.33947046753019094, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.06143\n",
      "\tval loss: 0.06585\n",
      "epoch 89 / 20000\n",
      "gradient norm: 0.27239225478842854, minimum ratio: 2.5\n",
      "\ttrain loss: 0.06135\n",
      "\tval loss: 0.06568\n",
      "epoch 90 / 20000\n",
      "gradient norm: 0.2966800769791007, minimum ratio: 2.460526315789474\n",
      "\ttrain loss: 0.06131\n",
      "\tval loss: 0.06551\n",
      "epoch 91 / 20000\n",
      "gradient norm: 0.26342859864234924, minimum ratio: 2.507894736842105\n",
      "\ttrain loss: 0.06110\n",
      "\tval loss: 0.06534\n",
      "epoch 92 / 20000\n",
      "gradient norm: 0.31274618441239, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.06089\n",
      "\tval loss: 0.06518\n",
      "epoch 93 / 20000\n",
      "gradient norm: 0.300128175644204, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.06089\n",
      "\tval loss: 0.06502\n",
      "epoch 94 / 20000\n",
      "gradient norm: 0.2709882869385183, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.06065\n",
      "\tval loss: 0.06486\n",
      "epoch 95 / 20000\n",
      "gradient norm: 0.2811403004452586, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.06026\n",
      "\tval loss: 0.06469\n",
      "epoch 96 / 20000\n",
      "gradient norm: 0.24167136196047068, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.06033\n",
      "\tval loss: 0.06453\n",
      "epoch 97 / 20000\n",
      "gradient norm: 0.29900419106706977, minimum ratio: 2.4868421052631575\n",
      "\ttrain loss: 0.06004\n",
      "\tval loss: 0.06437\n",
      "epoch 98 / 20000\n",
      "gradient norm: 0.3676726242993027, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.05999\n",
      "\tval loss: 0.06421\n",
      "epoch 99 / 20000\n",
      "gradient norm: 0.2531608638819307, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.05982\n",
      "\tval loss: 0.06405\n",
      "epoch 100 / 20000\n",
      "gradient norm: 0.28541473508812487, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.05955\n",
      "\tval loss: 0.06389\n",
      "epoch 101 / 20000\n",
      "gradient norm: 0.2667028435971588, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.05933\n",
      "\tval loss: 0.06374\n",
      "epoch 102 / 20000\n",
      "gradient norm: 0.23574507562443614, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.05932\n",
      "\tval loss: 0.06358\n",
      "epoch 103 / 20000\n",
      "gradient norm: 0.23879219801165164, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.05930\n",
      "\tval loss: 0.06343\n",
      "epoch 104 / 20000\n",
      "gradient norm: 0.3092648533638567, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.05906\n",
      "\tval loss: 0.06328\n",
      "epoch 105 / 20000\n",
      "gradient norm: 0.3490122293587774, minimum ratio: 2.5078947368421054\n",
      "\ttrain loss: 0.05890\n",
      "\tval loss: 0.06312\n",
      "epoch 106 / 20000\n",
      "gradient norm: 0.3628609203733504, minimum ratio: 2.5078947368421054\n",
      "\ttrain loss: 0.05872\n",
      "\tval loss: 0.06298\n",
      "epoch 107 / 20000\n",
      "gradient norm: 0.21567950840108097, minimum ratio: 2.4842105263157896\n",
      "\ttrain loss: 0.05857\n",
      "\tval loss: 0.06283\n",
      "epoch 108 / 20000\n",
      "gradient norm: 0.23304762924090028, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.05840\n",
      "\tval loss: 0.06267\n",
      "epoch 109 / 20000\n",
      "gradient norm: 0.33180911210365593, minimum ratio: 2.494736842105263\n",
      "\ttrain loss: 0.05814\n",
      "\tval loss: 0.06252\n",
      "epoch 110 / 20000\n",
      "gradient norm: 0.24291449319571257, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.05778\n",
      "\tval loss: 0.06237\n",
      "epoch 111 / 20000\n",
      "gradient norm: 0.2706127574201673, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.05786\n",
      "\tval loss: 0.06222\n",
      "epoch 112 / 20000\n",
      "gradient norm: 0.39712643274106085, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.05762\n",
      "\tval loss: 0.06207\n",
      "epoch 113 / 20000\n",
      "gradient norm: 0.3236157977953553, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.05758\n",
      "\tval loss: 0.06192\n",
      "epoch 114 / 20000\n",
      "gradient norm: 0.27985302777960896, minimum ratio: 2.4842105263157896\n",
      "\ttrain loss: 0.05739\n",
      "\tval loss: 0.06177\n",
      "epoch 115 / 20000\n",
      "gradient norm: 0.22948195692151785, minimum ratio: 2.5\n",
      "\ttrain loss: 0.05741\n",
      "\tval loss: 0.06162\n",
      "epoch 116 / 20000\n",
      "gradient norm: 0.2926561366766691, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.05718\n",
      "\tval loss: 0.06147\n",
      "epoch 117 / 20000\n",
      "gradient norm: 0.2828552578575909, minimum ratio: 2.492105263157895\n",
      "\ttrain loss: 0.05691\n",
      "\tval loss: 0.06132\n",
      "epoch 118 / 20000\n",
      "gradient norm: 0.23507996508851647, minimum ratio: 2.513157894736842\n",
      "\ttrain loss: 0.05702\n",
      "\tval loss: 0.06118\n",
      "epoch 119 / 20000\n",
      "gradient norm: 0.32358858827501535, minimum ratio: 2.5\n",
      "\ttrain loss: 0.05684\n",
      "\tval loss: 0.06104\n",
      "epoch 120 / 20000\n",
      "gradient norm: 0.23366218688897789, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.05660\n",
      "\tval loss: 0.06089\n",
      "epoch 121 / 20000\n",
      "gradient norm: 0.27423118706792593, minimum ratio: 2.5\n",
      "\ttrain loss: 0.05652\n",
      "\tval loss: 0.06075\n",
      "epoch 122 / 20000\n",
      "gradient norm: 0.22668264107778668, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.05634\n",
      "\tval loss: 0.06060\n",
      "epoch 123 / 20000\n",
      "gradient norm: 0.45162287121638656, minimum ratio: 2.4842105263157896\n",
      "\ttrain loss: 0.05609\n",
      "\tval loss: 0.06047\n",
      "epoch 124 / 20000\n",
      "gradient norm: 0.30786143569275737, minimum ratio: 2.4868421052631584\n",
      "\ttrain loss: 0.05601\n",
      "\tval loss: 0.06032\n",
      "epoch 125 / 20000\n",
      "gradient norm: 0.2144572571851313, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.05593\n",
      "\tval loss: 0.06016\n",
      "epoch 126 / 20000\n",
      "gradient norm: 0.24484838917851448, minimum ratio: 2.518421052631579\n",
      "\ttrain loss: 0.05579\n",
      "\tval loss: 0.06002\n",
      "epoch 127 / 20000\n",
      "gradient norm: 0.22743841516785324, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.05555\n",
      "\tval loss: 0.05987\n",
      "epoch 128 / 20000\n",
      "gradient norm: 0.20058140298351645, minimum ratio: 2.528947368421053\n",
      "\ttrain loss: 0.05533\n",
      "\tval loss: 0.05972\n",
      "epoch 129 / 20000\n",
      "gradient norm: 0.24043299281038344, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.05529\n",
      "\tval loss: 0.05958\n",
      "epoch 130 / 20000\n",
      "gradient norm: 0.33072177437134087, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.05516\n",
      "\tval loss: 0.05942\n",
      "epoch 131 / 20000\n",
      "gradient norm: 0.2324429254513234, minimum ratio: 2.5078947368421054\n",
      "\ttrain loss: 0.05508\n",
      "\tval loss: 0.05928\n",
      "epoch 132 / 20000\n",
      "gradient norm: 0.24252409161999822, minimum ratio: 2.4868421052631575\n",
      "\ttrain loss: 0.05485\n",
      "\tval loss: 0.05914\n",
      "epoch 133 / 20000\n",
      "gradient norm: 0.24863213067874312, minimum ratio: 2.5131578947368425\n",
      "\ttrain loss: 0.05474\n",
      "\tval loss: 0.05900\n",
      "epoch 134 / 20000\n",
      "gradient norm: 0.2542838603258133, minimum ratio: 2.5\n",
      "\ttrain loss: 0.05453\n",
      "\tval loss: 0.05886\n",
      "epoch 135 / 20000\n",
      "gradient norm: 0.3044126301538199, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.05455\n",
      "\tval loss: 0.05871\n",
      "epoch 136 / 20000\n",
      "gradient norm: 0.2605337251443416, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.05438\n",
      "\tval loss: 0.05857\n",
      "epoch 137 / 20000\n",
      "gradient norm: 0.22378982696682215, minimum ratio: 2.5105263157894737\n",
      "\ttrain loss: 0.05419\n",
      "\tval loss: 0.05842\n",
      "epoch 138 / 20000\n",
      "gradient norm: 0.19266786170192063, minimum ratio: 2.526315789473684\n",
      "\ttrain loss: 0.05418\n",
      "\tval loss: 0.05828\n",
      "epoch 139 / 20000\n",
      "gradient norm: 0.20782553730532527, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.05384\n",
      "\tval loss: 0.05813\n",
      "epoch 140 / 20000\n",
      "gradient norm: 0.1936467932537198, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.05359\n",
      "\tval loss: 0.05799\n",
      "epoch 141 / 20000\n",
      "gradient norm: 0.2169745834544301, minimum ratio: 2.513157894736842\n",
      "\ttrain loss: 0.05369\n",
      "\tval loss: 0.05785\n",
      "epoch 142 / 20000\n",
      "gradient norm: 0.2950078484136611, minimum ratio: 2.5157894736842104\n",
      "\ttrain loss: 0.05353\n",
      "\tval loss: 0.05770\n",
      "epoch 143 / 20000\n",
      "gradient norm: 0.20490449387580156, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.05336\n",
      "\tval loss: 0.05755\n",
      "epoch 144 / 20000\n",
      "gradient norm: 0.1926077683456242, minimum ratio: 2.4842105263157896\n",
      "\ttrain loss: 0.05318\n",
      "\tval loss: 0.05741\n",
      "epoch 145 / 20000\n",
      "gradient norm: 0.1746828593313694, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.05311\n",
      "\tval loss: 0.05726\n",
      "epoch 146 / 20000\n",
      "gradient norm: 0.3262335271574557, minimum ratio: 2.5236842105263158\n",
      "\ttrain loss: 0.05290\n",
      "\tval loss: 0.05713\n",
      "epoch 147 / 20000\n",
      "gradient norm: 0.2927435589954257, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.05272\n",
      "\tval loss: 0.05699\n",
      "epoch 148 / 20000\n",
      "gradient norm: 0.2156851477921009, minimum ratio: 2.492105263157895\n",
      "\ttrain loss: 0.05277\n",
      "\tval loss: 0.05684\n",
      "epoch 149 / 20000\n",
      "gradient norm: 0.27250562654808164, minimum ratio: 2.5236842105263158\n",
      "\ttrain loss: 0.05249\n",
      "\tval loss: 0.05669\n",
      "epoch 150 / 20000\n",
      "gradient norm: 0.24641250749118626, minimum ratio: 2.531578947368421\n",
      "\ttrain loss: 0.05236\n",
      "\tval loss: 0.05655\n",
      "epoch 151 / 20000\n",
      "gradient norm: 0.3050824701786041, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.05226\n",
      "\tval loss: 0.05641\n",
      "epoch 152 / 20000\n",
      "gradient norm: 0.24572859634645283, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.05226\n",
      "\tval loss: 0.05627\n",
      "epoch 153 / 20000\n",
      "gradient norm: 0.18763739289715886, minimum ratio: 2.5131578947368425\n",
      "\ttrain loss: 0.05198\n",
      "\tval loss: 0.05613\n",
      "epoch 154 / 20000\n",
      "gradient norm: 0.25937685277312994, minimum ratio: 2.513157894736842\n",
      "\ttrain loss: 0.05196\n",
      "\tval loss: 0.05599\n",
      "epoch 155 / 20000\n",
      "gradient norm: 0.20832108915783465, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.05180\n",
      "\tval loss: 0.05585\n",
      "epoch 156 / 20000\n",
      "gradient norm: 0.24727888219058514, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.05159\n",
      "\tval loss: 0.05571\n",
      "epoch 157 / 20000\n",
      "gradient norm: 0.1801566993817687, minimum ratio: 2.4973684210526312\n",
      "\ttrain loss: 0.05142\n",
      "\tval loss: 0.05556\n",
      "epoch 158 / 20000\n",
      "gradient norm: 0.269106587395072, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.05139\n",
      "\tval loss: 0.05541\n",
      "epoch 159 / 20000\n",
      "gradient norm: 0.27172349323518574, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.05130\n",
      "\tval loss: 0.05528\n",
      "epoch 160 / 20000\n",
      "gradient norm: 0.20011820457875729, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.05106\n",
      "\tval loss: 0.05514\n",
      "epoch 161 / 20000\n",
      "gradient norm: 0.30775681766681373, minimum ratio: 2.492105263157895\n",
      "\ttrain loss: 0.05097\n",
      "\tval loss: 0.05500\n",
      "epoch 162 / 20000\n",
      "gradient norm: 0.2090536265168339, minimum ratio: 2.5131578947368425\n",
      "\ttrain loss: 0.05085\n",
      "\tval loss: 0.05487\n",
      "epoch 163 / 20000\n",
      "gradient norm: 0.32472811290062964, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.05064\n",
      "\tval loss: 0.05473\n",
      "epoch 164 / 20000\n",
      "gradient norm: 0.21492701163515449, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.05061\n",
      "\tval loss: 0.05459\n",
      "epoch 165 / 20000\n",
      "gradient norm: 0.18356490484438837, minimum ratio: 2.5157894736842104\n",
      "\ttrain loss: 0.05038\n",
      "\tval loss: 0.05445\n",
      "epoch 166 / 20000\n",
      "gradient norm: 0.23834168002940714, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.05022\n",
      "\tval loss: 0.05431\n",
      "epoch 167 / 20000\n",
      "gradient norm: 0.20448495633900166, minimum ratio: 2.5131578947368425\n",
      "\ttrain loss: 0.05016\n",
      "\tval loss: 0.05417\n",
      "epoch 168 / 20000\n",
      "gradient norm: 0.22689992864616215, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.04989\n",
      "\tval loss: 0.05402\n",
      "epoch 169 / 20000\n",
      "gradient norm: 0.19079304859042168, minimum ratio: 2.5184210526315787\n",
      "\ttrain loss: 0.04985\n",
      "\tval loss: 0.05389\n",
      "epoch 170 / 20000\n",
      "gradient norm: 0.2814774955622852, minimum ratio: 2.4842105263157896\n",
      "\ttrain loss: 0.04967\n",
      "\tval loss: 0.05376\n",
      "epoch 171 / 20000\n",
      "gradient norm: 0.23751285788603127, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.04972\n",
      "\tval loss: 0.05361\n",
      "epoch 172 / 20000\n",
      "gradient norm: 0.1782578609418124, minimum ratio: 2.513157894736842\n",
      "\ttrain loss: 0.04952\n",
      "\tval loss: 0.05347\n",
      "epoch 173 / 20000\n",
      "gradient norm: 0.18112000939436257, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.04943\n",
      "\tval loss: 0.05333\n",
      "epoch 174 / 20000\n",
      "gradient norm: 0.18860672321170568, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.04920\n",
      "\tval loss: 0.05319\n",
      "epoch 175 / 20000\n",
      "gradient norm: 0.3047545875888318, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.04909\n",
      "\tval loss: 0.05306\n",
      "epoch 176 / 20000\n",
      "gradient norm: 0.22891888325102627, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.04892\n",
      "\tval loss: 0.05292\n",
      "epoch 177 / 20000\n",
      "gradient norm: 0.18195498641580343, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.04883\n",
      "\tval loss: 0.05278\n",
      "epoch 178 / 20000\n",
      "gradient norm: 0.26504546171054244, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.04875\n",
      "\tval loss: 0.05264\n",
      "epoch 179 / 20000\n",
      "gradient norm: 0.23604153096675873, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.04846\n",
      "\tval loss: 0.05250\n",
      "epoch 180 / 20000\n",
      "gradient norm: 0.1878223018720746, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.04844\n",
      "\tval loss: 0.05237\n",
      "epoch 181 / 20000\n",
      "gradient norm: 0.19424152607098222, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.04837\n",
      "\tval loss: 0.05224\n",
      "epoch 182 / 20000\n",
      "gradient norm: 0.27617579069919884, minimum ratio: 2.492105263157895\n",
      "\ttrain loss: 0.04811\n",
      "\tval loss: 0.05211\n",
      "epoch 183 / 20000\n",
      "gradient norm: 0.1730902842245996, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.04808\n",
      "\tval loss: 0.05197\n",
      "epoch 184 / 20000\n",
      "gradient norm: 0.20345740485936403, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.04800\n",
      "\tval loss: 0.05183\n",
      "epoch 185 / 20000\n",
      "gradient norm: 0.2540969180408865, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.04778\n",
      "\tval loss: 0.05169\n",
      "epoch 186 / 20000\n",
      "gradient norm: 0.2169362767599523, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.04770\n",
      "\tval loss: 0.05156\n",
      "epoch 187 / 20000\n",
      "gradient norm: 0.28356869774870574, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.04760\n",
      "\tval loss: 0.05142\n",
      "epoch 188 / 20000\n",
      "gradient norm: 0.20999767491593957, minimum ratio: 2.4815789473684213\n",
      "\ttrain loss: 0.04742\n",
      "\tval loss: 0.05127\n",
      "epoch 189 / 20000\n",
      "gradient norm: 0.2591199241578579, minimum ratio: 2.4842105263157896\n",
      "\ttrain loss: 0.04740\n",
      "\tval loss: 0.05113\n",
      "epoch 190 / 20000\n",
      "gradient norm: 0.24420763598755002, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.04726\n",
      "\tval loss: 0.05099\n",
      "epoch 191 / 20000\n",
      "gradient norm: 0.31622562697157264, minimum ratio: 2.507894736842105\n",
      "\ttrain loss: 0.04678\n",
      "\tval loss: 0.05087\n",
      "epoch 192 / 20000\n",
      "gradient norm: 0.20640687877312303, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.04683\n",
      "\tval loss: 0.05073\n",
      "epoch 193 / 20000\n",
      "gradient norm: 0.2359261210076511, minimum ratio: 2.4578947368421056\n",
      "\ttrain loss: 0.04678\n",
      "\tval loss: 0.05060\n",
      "epoch 194 / 20000\n",
      "gradient norm: 0.2758282828144729, minimum ratio: 2.4736842105263155\n",
      "\ttrain loss: 0.04680\n",
      "\tval loss: 0.05047\n",
      "epoch 195 / 20000\n",
      "gradient norm: 0.3079918462317437, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.04667\n",
      "\tval loss: 0.05034\n",
      "epoch 196 / 20000\n",
      "gradient norm: 0.20857177814468741, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.04629\n",
      "\tval loss: 0.05020\n",
      "epoch 197 / 20000\n",
      "gradient norm: 0.18695851392112672, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.04623\n",
      "\tval loss: 0.05006\n",
      "epoch 198 / 20000\n",
      "gradient norm: 0.2799393138848245, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.04629\n",
      "\tval loss: 0.04992\n",
      "epoch 199 / 20000\n",
      "gradient norm: 0.1841408966574818, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.04605\n",
      "\tval loss: 0.04978\n",
      "epoch 200 / 20000\n",
      "gradient norm: 0.2309129936620593, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.04597\n",
      "\tval loss: 0.04965\n",
      "epoch 201 / 20000\n",
      "gradient norm: 0.25327221024781466, minimum ratio: 2.5131578947368425\n",
      "\ttrain loss: 0.04587\n",
      "\tval loss: 0.04951\n",
      "epoch 202 / 20000\n",
      "gradient norm: 0.1662755231373012, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.04564\n",
      "\tval loss: 0.04938\n",
      "epoch 203 / 20000\n",
      "gradient norm: 0.16983338352292776, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.04548\n",
      "\tval loss: 0.04925\n",
      "epoch 204 / 20000\n",
      "gradient norm: 0.28660372411832213, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.04548\n",
      "\tval loss: 0.04911\n",
      "epoch 205 / 20000\n",
      "gradient norm: 0.19869097112677991, minimum ratio: 2.5\n",
      "\ttrain loss: 0.04539\n",
      "\tval loss: 0.04898\n",
      "epoch 206 / 20000\n",
      "gradient norm: 0.22701300401240587, minimum ratio: 2.5\n",
      "\ttrain loss: 0.04502\n",
      "\tval loss: 0.04884\n",
      "epoch 207 / 20000\n",
      "gradient norm: 0.1914115115068853, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.04501\n",
      "\tval loss: 0.04870\n",
      "epoch 208 / 20000\n",
      "gradient norm: 0.264561640098691, minimum ratio: 2.526315789473684\n",
      "\ttrain loss: 0.04500\n",
      "\tval loss: 0.04857\n",
      "epoch 209 / 20000\n",
      "gradient norm: 0.19362672232091427, minimum ratio: 2.5157894736842104\n",
      "\ttrain loss: 0.04476\n",
      "\tval loss: 0.04844\n",
      "epoch 210 / 20000\n",
      "gradient norm: 0.19333072705194354, minimum ratio: 2.5078947368421054\n",
      "\ttrain loss: 0.04468\n",
      "\tval loss: 0.04830\n",
      "epoch 211 / 20000\n",
      "gradient norm: 0.19393435958772898, minimum ratio: 2.5\n",
      "\ttrain loss: 0.04450\n",
      "\tval loss: 0.04817\n",
      "epoch 212 / 20000\n",
      "gradient norm: 0.20944453217089176, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.04455\n",
      "\tval loss: 0.04803\n",
      "epoch 213 / 20000\n",
      "gradient norm: 0.15166890481486917, minimum ratio: 2.492105263157895\n",
      "\ttrain loss: 0.04436\n",
      "\tval loss: 0.04790\n",
      "epoch 214 / 20000\n",
      "gradient norm: 0.21825881116092205, minimum ratio: 2.5105263157894733\n",
      "\ttrain loss: 0.04408\n",
      "\tval loss: 0.04776\n",
      "epoch 215 / 20000\n",
      "gradient norm: 0.20516965258866549, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.04411\n",
      "\tval loss: 0.04763\n",
      "epoch 216 / 20000\n",
      "gradient norm: 0.1546131749637425, minimum ratio: 2.518421052631579\n",
      "\ttrain loss: 0.04410\n",
      "\tval loss: 0.04749\n",
      "epoch 217 / 20000\n",
      "gradient norm: 0.25750102289021015, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.04378\n",
      "\tval loss: 0.04735\n",
      "epoch 218 / 20000\n",
      "gradient norm: 0.21075624227523804, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.04356\n",
      "\tval loss: 0.04722\n",
      "epoch 219 / 20000\n",
      "gradient norm: 0.1774938153102994, minimum ratio: 2.492105263157895\n",
      "\ttrain loss: 0.04346\n",
      "\tval loss: 0.04708\n",
      "epoch 220 / 20000\n",
      "gradient norm: 0.1650422397069633, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.04340\n",
      "\tval loss: 0.04695\n",
      "epoch 221 / 20000\n",
      "gradient norm: 0.3137593260034919, minimum ratio: 2.513157894736842\n",
      "\ttrain loss: 0.04342\n",
      "\tval loss: 0.04682\n",
      "epoch 222 / 20000\n",
      "gradient norm: 0.230286288773641, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.04311\n",
      "\tval loss: 0.04670\n",
      "epoch 223 / 20000\n",
      "gradient norm: 0.21289452211931348, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.04300\n",
      "\tval loss: 0.04656\n",
      "epoch 224 / 20000\n",
      "gradient norm: 0.22593864472582936, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.04300\n",
      "\tval loss: 0.04642\n",
      "epoch 225 / 20000\n",
      "gradient norm: 0.24919194728136063, minimum ratio: 2.5\n",
      "\ttrain loss: 0.04286\n",
      "\tval loss: 0.04629\n",
      "epoch 226 / 20000\n",
      "gradient norm: 0.23281027702614665, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.04262\n",
      "\tval loss: 0.04615\n",
      "epoch 227 / 20000\n",
      "gradient norm: 0.1805078568868339, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.04258\n",
      "\tval loss: 0.04601\n",
      "epoch 228 / 20000\n",
      "gradient norm: 0.19684336427599192, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.04246\n",
      "\tval loss: 0.04587\n",
      "epoch 229 / 20000\n",
      "gradient norm: 0.15547014214098454, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.04238\n",
      "\tval loss: 0.04573\n",
      "epoch 230 / 20000\n",
      "gradient norm: 0.20341289322823286, minimum ratio: 2.5\n",
      "\ttrain loss: 0.04216\n",
      "\tval loss: 0.04560\n",
      "epoch 231 / 20000\n",
      "gradient norm: 0.19211933529004455, minimum ratio: 2.5236842105263158\n",
      "\ttrain loss: 0.04212\n",
      "\tval loss: 0.04547\n",
      "epoch 232 / 20000\n",
      "gradient norm: 0.1539532095193863, minimum ratio: 2.4842105263157896\n",
      "\ttrain loss: 0.04209\n",
      "\tval loss: 0.04535\n",
      "epoch 233 / 20000\n",
      "gradient norm: 0.25923561211675406, minimum ratio: 2.507894736842105\n",
      "\ttrain loss: 0.04183\n",
      "\tval loss: 0.04523\n",
      "epoch 234 / 20000\n",
      "gradient norm: 0.21664584055542946, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.04176\n",
      "\tval loss: 0.04509\n",
      "epoch 235 / 20000\n",
      "gradient norm: 0.14528185781091452, minimum ratio: 2.5\n",
      "\ttrain loss: 0.04159\n",
      "\tval loss: 0.04496\n",
      "epoch 236 / 20000\n",
      "gradient norm: 0.25343130389228463, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.04156\n",
      "\tval loss: 0.04483\n",
      "epoch 237 / 20000\n",
      "gradient norm: 0.20547016221098602, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.04128\n",
      "\tval loss: 0.04470\n",
      "epoch 238 / 20000\n",
      "gradient norm: 0.19207530794665217, minimum ratio: 2.5131578947368425\n",
      "\ttrain loss: 0.04123\n",
      "\tval loss: 0.04456\n",
      "epoch 239 / 20000\n",
      "gradient norm: 0.28011835855431855, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.04112\n",
      "\tval loss: 0.04444\n",
      "epoch 240 / 20000\n",
      "gradient norm: 0.19151650159619749, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.04103\n",
      "\tval loss: 0.04430\n",
      "epoch 241 / 20000\n",
      "gradient norm: 0.2236912241205573, minimum ratio: 2.4868421052631575\n",
      "\ttrain loss: 0.04084\n",
      "\tval loss: 0.04417\n",
      "epoch 242 / 20000\n",
      "gradient norm: 0.19979263516142964, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.04070\n",
      "\tval loss: 0.04404\n",
      "epoch 243 / 20000\n",
      "gradient norm: 0.3467260976321995, minimum ratio: 2.518421052631579\n",
      "\ttrain loss: 0.04074\n",
      "\tval loss: 0.04389\n",
      "epoch 244 / 20000\n",
      "gradient norm: 0.14291223604232073, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.04049\n",
      "\tval loss: 0.04377\n",
      "epoch 245 / 20000\n",
      "gradient norm: 0.29772532265633345, minimum ratio: 2.5236842105263158\n",
      "\ttrain loss: 0.04034\n",
      "\tval loss: 0.04366\n",
      "epoch 246 / 20000\n",
      "gradient norm: 0.2319330512546003, minimum ratio: 2.4868421052631575\n",
      "\ttrain loss: 0.04027\n",
      "\tval loss: 0.04354\n",
      "epoch 247 / 20000\n",
      "gradient norm: 0.25722477119416, minimum ratio: 2.5105263157894737\n",
      "\ttrain loss: 0.04021\n",
      "\tval loss: 0.04342\n",
      "epoch 248 / 20000\n",
      "gradient norm: 0.2538633970543742, minimum ratio: 2.518421052631579\n",
      "\ttrain loss: 0.04003\n",
      "\tval loss: 0.04327\n",
      "epoch 249 / 20000\n",
      "gradient norm: 0.2770661327522248, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.04006\n",
      "\tval loss: 0.04314\n",
      "epoch 250 / 20000\n",
      "gradient norm: 0.2339189148042351, minimum ratio: 2.518421052631579\n",
      "\ttrain loss: 0.03978\n",
      "\tval loss: 0.04300\n",
      "epoch 251 / 20000\n",
      "gradient norm: 0.19242663821205497, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.03966\n",
      "\tval loss: 0.04289\n",
      "epoch 252 / 20000\n",
      "gradient norm: 0.15883107902482152, minimum ratio: 2.536842105263158\n",
      "\ttrain loss: 0.03954\n",
      "\tval loss: 0.04277\n",
      "epoch 253 / 20000\n",
      "gradient norm: 0.2134164902381599, minimum ratio: 2.507894736842105\n",
      "\ttrain loss: 0.03950\n",
      "\tval loss: 0.04265\n",
      "epoch 254 / 20000\n",
      "gradient norm: 0.20090330461971462, minimum ratio: 2.5105263157894737\n",
      "\ttrain loss: 0.03923\n",
      "\tval loss: 0.04253\n",
      "epoch 255 / 20000\n",
      "gradient norm: 0.19129201071336865, minimum ratio: 2.5\n",
      "\ttrain loss: 0.03925\n",
      "\tval loss: 0.04239\n",
      "epoch 256 / 20000\n",
      "gradient norm: 0.21349025378003716, minimum ratio: 2.507894736842105\n",
      "\ttrain loss: 0.03914\n",
      "\tval loss: 0.04227\n",
      "epoch 257 / 20000\n",
      "gradient norm: 0.20835483679547906, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.03906\n",
      "\tval loss: 0.04214\n",
      "epoch 258 / 20000\n",
      "gradient norm: 0.18497015559114516, minimum ratio: 2.518421052631579\n",
      "\ttrain loss: 0.03888\n",
      "\tval loss: 0.04201\n",
      "epoch 259 / 20000\n",
      "gradient norm: 0.17433929536491632, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.03874\n",
      "\tval loss: 0.04189\n",
      "epoch 260 / 20000\n",
      "gradient norm: 0.18988079437986016, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.03873\n",
      "\tval loss: 0.04177\n",
      "epoch 261 / 20000\n",
      "gradient norm: 0.18079489143565297, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.03862\n",
      "\tval loss: 0.04165\n",
      "epoch 262 / 20000\n",
      "gradient norm: 0.18058082275092602, minimum ratio: 2.5105263157894737\n",
      "\ttrain loss: 0.03847\n",
      "\tval loss: 0.04153\n",
      "epoch 263 / 20000\n",
      "gradient norm: 0.1487492504529655, minimum ratio: 2.5105263157894737\n",
      "\ttrain loss: 0.03831\n",
      "\tval loss: 0.04140\n",
      "epoch 264 / 20000\n",
      "gradient norm: 0.20091931195929646, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.03828\n",
      "\tval loss: 0.04129\n",
      "epoch 265 / 20000\n",
      "gradient norm: 0.2377719422802329, minimum ratio: 2.5105263157894737\n",
      "\ttrain loss: 0.03811\n",
      "\tval loss: 0.04116\n",
      "epoch 266 / 20000\n",
      "gradient norm: 0.213870698120445, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.03795\n",
      "\tval loss: 0.04105\n",
      "epoch 267 / 20000\n",
      "gradient norm: 0.1555817467160523, minimum ratio: 2.518421052631579\n",
      "\ttrain loss: 0.03794\n",
      "\tval loss: 0.04092\n",
      "epoch 268 / 20000\n",
      "gradient norm: 0.15083348844200373, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.03779\n",
      "\tval loss: 0.04080\n",
      "epoch 269 / 20000\n",
      "gradient norm: 0.15200603497214615, minimum ratio: 2.492105263157895\n",
      "\ttrain loss: 0.03770\n",
      "\tval loss: 0.04068\n",
      "epoch 270 / 20000\n",
      "gradient norm: 0.1730036127846688, minimum ratio: 2.5131578947368425\n",
      "\ttrain loss: 0.03762\n",
      "\tval loss: 0.04055\n",
      "epoch 271 / 20000\n",
      "gradient norm: 0.1782810683362186, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.03749\n",
      "\tval loss: 0.04044\n",
      "epoch 272 / 20000\n",
      "gradient norm: 0.21192560577765107, minimum ratio: 2.5\n",
      "\ttrain loss: 0.03737\n",
      "\tval loss: 0.04031\n",
      "epoch 273 / 20000\n",
      "gradient norm: 0.16918352618813515, minimum ratio: 2.5\n",
      "\ttrain loss: 0.03731\n",
      "\tval loss: 0.04020\n",
      "epoch 274 / 20000\n",
      "gradient norm: 0.27212571119889617, minimum ratio: 2.5157894736842104\n",
      "\ttrain loss: 0.03711\n",
      "\tval loss: 0.04009\n",
      "epoch 275 / 20000\n",
      "gradient norm: 0.1404100637882948, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.03699\n",
      "\tval loss: 0.03997\n",
      "epoch 276 / 20000\n",
      "gradient norm: 0.1940714130178094, minimum ratio: 2.5157894736842104\n",
      "\ttrain loss: 0.03696\n",
      "\tval loss: 0.03985\n",
      "epoch 277 / 20000\n",
      "gradient norm: 0.1682436775881797, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.03687\n",
      "\tval loss: 0.03973\n",
      "epoch 278 / 20000\n",
      "gradient norm: 0.18214178294874728, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.03673\n",
      "\tval loss: 0.03961\n",
      "epoch 279 / 20000\n",
      "gradient norm: 0.17423572577536106, minimum ratio: 2.5\n",
      "\ttrain loss: 0.03664\n",
      "\tval loss: 0.03950\n",
      "epoch 280 / 20000\n",
      "gradient norm: 0.17263148166239262, minimum ratio: 2.5210526315789474\n",
      "\ttrain loss: 0.03658\n",
      "\tval loss: 0.03937\n",
      "epoch 281 / 20000\n",
      "gradient norm: 0.232176483143121, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.03636\n",
      "\tval loss: 0.03926\n",
      "epoch 282 / 20000\n",
      "gradient norm: 0.16440199594944715, minimum ratio: 2.5157894736842104\n",
      "\ttrain loss: 0.03630\n",
      "\tval loss: 0.03914\n",
      "epoch 283 / 20000\n",
      "gradient norm: 0.2616316375788301, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.03611\n",
      "\tval loss: 0.03903\n",
      "epoch 284 / 20000\n",
      "gradient norm: 0.22936106170527637, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.03604\n",
      "\tval loss: 0.03891\n",
      "epoch 285 / 20000\n",
      "gradient norm: 0.14962506177835166, minimum ratio: 2.5\n",
      "\ttrain loss: 0.03602\n",
      "\tval loss: 0.03880\n",
      "epoch 286 / 20000\n",
      "gradient norm: 0.16427627485245466, minimum ratio: 2.5\n",
      "\ttrain loss: 0.03591\n",
      "\tval loss: 0.03869\n",
      "epoch 287 / 20000\n",
      "gradient norm: 0.21129337092861533, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.03576\n",
      "\tval loss: 0.03858\n",
      "epoch 288 / 20000\n",
      "gradient norm: 0.1427018977701664, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.03569\n",
      "\tval loss: 0.03847\n",
      "epoch 289 / 20000\n",
      "gradient norm: 0.18466958682984114, minimum ratio: 2.5236842105263158\n",
      "\ttrain loss: 0.03552\n",
      "\tval loss: 0.03834\n",
      "epoch 290 / 20000\n",
      "gradient norm: 0.18299986189231277, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.03548\n",
      "\tval loss: 0.03823\n",
      "epoch 291 / 20000\n",
      "gradient norm: 0.16782802296802402, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.03532\n",
      "\tval loss: 0.03811\n",
      "epoch 292 / 20000\n",
      "gradient norm: 0.24057633709162474, minimum ratio: 2.528947368421053\n",
      "\ttrain loss: 0.03524\n",
      "\tval loss: 0.03799\n",
      "epoch 293 / 20000\n",
      "gradient norm: 0.15545258531346917, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.03518\n",
      "\tval loss: 0.03789\n",
      "epoch 294 / 20000\n",
      "gradient norm: 0.14250731701031327, minimum ratio: 2.5105263157894737\n",
      "\ttrain loss: 0.03496\n",
      "\tval loss: 0.03777\n",
      "epoch 295 / 20000\n",
      "gradient norm: 0.23209477635100484, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.03490\n",
      "\tval loss: 0.03766\n",
      "epoch 296 / 20000\n",
      "gradient norm: 0.22944804653525352, minimum ratio: 2.5289473684210524\n",
      "\ttrain loss: 0.03491\n",
      "\tval loss: 0.03755\n",
      "epoch 297 / 20000\n",
      "gradient norm: 0.2620478894095868, minimum ratio: 2.5210526315789474\n",
      "\ttrain loss: 0.03480\n",
      "\tval loss: 0.03743\n",
      "epoch 298 / 20000\n",
      "gradient norm: 0.22799470950849354, minimum ratio: 2.507894736842105\n",
      "\ttrain loss: 0.03464\n",
      "\tval loss: 0.03733\n",
      "epoch 299 / 20000\n",
      "gradient norm: 0.24273606343194842, minimum ratio: 2.515789473684211\n",
      "\ttrain loss: 0.03449\n",
      "\tval loss: 0.03722\n",
      "epoch 300 / 20000\n",
      "gradient norm: 0.19259092980064452, minimum ratio: 2.5\n",
      "\ttrain loss: 0.03446\n",
      "\tval loss: 0.03711\n",
      "epoch 301 / 20000\n",
      "gradient norm: 0.14049615478143096, minimum ratio: 2.5131578947368425\n",
      "\ttrain loss: 0.03430\n",
      "\tval loss: 0.03700\n",
      "epoch 302 / 20000\n",
      "gradient norm: 0.24317438155412674, minimum ratio: 2.513157894736842\n",
      "\ttrain loss: 0.03420\n",
      "\tval loss: 0.03687\n",
      "epoch 303 / 20000\n",
      "gradient norm: 0.17679401556961238, minimum ratio: 2.5131578947368416\n",
      "\ttrain loss: 0.03415\n",
      "\tval loss: 0.03676\n",
      "epoch 304 / 20000\n",
      "gradient norm: 0.20699391048401594, minimum ratio: 2.505263157894737\n",
      "\ttrain loss: 0.03402\n",
      "\tval loss: 0.03664\n",
      "epoch 305 / 20000\n",
      "gradient norm: 0.19069801783189178, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.03390\n",
      "\tval loss: 0.03653\n",
      "epoch 306 / 20000\n",
      "gradient norm: 0.1547112453263253, minimum ratio: 2.5236842105263158\n",
      "\ttrain loss: 0.03374\n",
      "\tval loss: 0.03643\n",
      "epoch 307 / 20000\n",
      "gradient norm: 0.17129856953397393, minimum ratio: 2.518421052631579\n",
      "\ttrain loss: 0.03372\n",
      "\tval loss: 0.03633\n",
      "epoch 308 / 20000\n",
      "gradient norm: 0.1940564215183258, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.03361\n",
      "\tval loss: 0.03623\n",
      "epoch 309 / 20000\n",
      "gradient norm: 0.16028755926527083, minimum ratio: 2.5\n",
      "\ttrain loss: 0.03352\n",
      "\tval loss: 0.03611\n",
      "epoch 310 / 20000\n",
      "gradient norm: 0.2498534661717713, minimum ratio: 2.5157894736842104\n",
      "\ttrain loss: 0.03333\n",
      "\tval loss: 0.03600\n",
      "epoch 311 / 20000\n",
      "gradient norm: 0.1697709287982434, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.03332\n",
      "\tval loss: 0.03588\n",
      "epoch 312 / 20000\n",
      "gradient norm: 0.14269742369651794, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.03323\n",
      "\tval loss: 0.03577\n",
      "epoch 313 / 20000\n",
      "gradient norm: 0.20352222537621856, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.03304\n",
      "\tval loss: 0.03566\n",
      "epoch 314 / 20000\n",
      "gradient norm: 0.16879502357915044, minimum ratio: 2.536842105263158\n",
      "\ttrain loss: 0.03295\n",
      "\tval loss: 0.03554\n",
      "epoch 315 / 20000\n",
      "gradient norm: 0.1548614171333611, minimum ratio: 2.5289473684210524\n",
      "\ttrain loss: 0.03294\n",
      "\tval loss: 0.03543\n",
      "epoch 316 / 20000\n",
      "gradient norm: 0.16959274280816317, minimum ratio: 2.5210526315789474\n",
      "\ttrain loss: 0.03275\n",
      "\tval loss: 0.03532\n",
      "epoch 317 / 20000\n",
      "gradient norm: 0.16934788157232106, minimum ratio: 2.528947368421053\n",
      "\ttrain loss: 0.03259\n",
      "\tval loss: 0.03522\n",
      "epoch 318 / 20000\n",
      "gradient norm: 0.21429170644842088, minimum ratio: 2.539473684210526\n",
      "\ttrain loss: 0.03256\n",
      "\tval loss: 0.03512\n",
      "epoch 319 / 20000\n",
      "gradient norm: 0.14047653949819505, minimum ratio: 2.5078947368421054\n",
      "\ttrain loss: 0.03246\n",
      "\tval loss: 0.03502\n",
      "epoch 320 / 20000\n",
      "gradient norm: 0.17352154245600104, minimum ratio: 2.5078947368421054\n",
      "\ttrain loss: 0.03239\n",
      "\tval loss: 0.03491\n",
      "epoch 321 / 20000\n",
      "gradient norm: 0.14527483796700835, minimum ratio: 2.513157894736842\n",
      "\ttrain loss: 0.03220\n",
      "\tval loss: 0.03481\n",
      "epoch 322 / 20000\n",
      "gradient norm: 0.15765876416116953, minimum ratio: 2.492105263157895\n",
      "\ttrain loss: 0.03216\n",
      "\tval loss: 0.03470\n",
      "epoch 323 / 20000\n",
      "gradient norm: 0.17984333168715239, minimum ratio: 2.5\n",
      "\ttrain loss: 0.03213\n",
      "\tval loss: 0.03459\n",
      "epoch 324 / 20000\n",
      "gradient norm: 0.19407809432595968, minimum ratio: 2.526315789473684\n",
      "\ttrain loss: 0.03197\n",
      "\tval loss: 0.03448\n",
      "epoch 325 / 20000\n",
      "gradient norm: 0.13533460535109043, minimum ratio: 2.4842105263157896\n",
      "\ttrain loss: 0.03188\n",
      "\tval loss: 0.03437\n",
      "epoch 326 / 20000\n",
      "gradient norm: 0.1320553917903453, minimum ratio: 2.507894736842105\n",
      "\ttrain loss: 0.03173\n",
      "\tval loss: 0.03426\n",
      "epoch 327 / 20000\n",
      "gradient norm: 0.18068914161995053, minimum ratio: 2.492105263157895\n",
      "\ttrain loss: 0.03160\n",
      "\tval loss: 0.03415\n",
      "epoch 328 / 20000\n",
      "gradient norm: 0.18445554887875915, minimum ratio: 2.5\n",
      "\ttrain loss: 0.03166\n",
      "\tval loss: 0.03405\n",
      "epoch 329 / 20000\n",
      "gradient norm: 0.1463011761661619, minimum ratio: 2.526315789473684\n",
      "\ttrain loss: 0.03145\n",
      "\tval loss: 0.03395\n",
      "epoch 330 / 20000\n",
      "gradient norm: 0.14932268019765615, minimum ratio: 2.518421052631579\n",
      "\ttrain loss: 0.03142\n",
      "\tval loss: 0.03385\n",
      "epoch 331 / 20000\n",
      "gradient norm: 0.2855488529894501, minimum ratio: 2.5157894736842104\n",
      "\ttrain loss: 0.03131\n",
      "\tval loss: 0.03373\n",
      "epoch 332 / 20000\n",
      "gradient norm: 0.2643146147020161, minimum ratio: 2.5236842105263158\n",
      "\ttrain loss: 0.03125\n",
      "\tval loss: 0.03363\n",
      "epoch 333 / 20000\n",
      "gradient norm: 0.14953454723581672, minimum ratio: 2.5342105263157895\n",
      "\ttrain loss: 0.03112\n",
      "\tval loss: 0.03354\n",
      "epoch 334 / 20000\n",
      "gradient norm: 0.13568957755342126, minimum ratio: 2.5105263157894737\n",
      "\ttrain loss: 0.03108\n",
      "\tval loss: 0.03344\n",
      "epoch 335 / 20000\n",
      "gradient norm: 0.21110573131591082, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.03093\n",
      "\tval loss: 0.03333\n",
      "epoch 336 / 20000\n",
      "gradient norm: 0.19896232220344245, minimum ratio: 2.518421052631579\n",
      "\ttrain loss: 0.03078\n",
      "\tval loss: 0.03322\n",
      "epoch 337 / 20000\n",
      "gradient norm: 0.2133210280444473, minimum ratio: 2.5289473684210524\n",
      "\ttrain loss: 0.03069\n",
      "\tval loss: 0.03313\n",
      "epoch 338 / 20000\n",
      "gradient norm: 0.2691182680428028, minimum ratio: 2.528947368421053\n",
      "\ttrain loss: 0.03064\n",
      "\tval loss: 0.03301\n",
      "epoch 339 / 20000\n",
      "gradient norm: 0.25896140141412616, minimum ratio: 2.5473684210526315\n",
      "\ttrain loss: 0.03060\n",
      "\tval loss: 0.03290\n",
      "epoch 340 / 20000\n",
      "gradient norm: 0.1439482900314033, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.03039\n",
      "\tval loss: 0.03281\n",
      "epoch 341 / 20000\n",
      "gradient norm: 0.18001422379165888, minimum ratio: 2.5315789473684207\n",
      "\ttrain loss: 0.03039\n",
      "\tval loss: 0.03272\n",
      "epoch 342 / 20000\n",
      "gradient norm: 0.2149729651864618, minimum ratio: 2.5105263157894733\n",
      "\ttrain loss: 0.03031\n",
      "\tval loss: 0.03262\n",
      "epoch 343 / 20000\n",
      "gradient norm: 0.16727329837158322, minimum ratio: 2.5473684210526315\n",
      "\ttrain loss: 0.03016\n",
      "\tval loss: 0.03252\n",
      "epoch 344 / 20000\n",
      "gradient norm: 0.24659801134839654, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.03010\n",
      "\tval loss: 0.03242\n",
      "epoch 345 / 20000\n",
      "gradient norm: 0.29841737914830446, minimum ratio: 2.5210526315789474\n",
      "\ttrain loss: 0.03002\n",
      "\tval loss: 0.03232\n",
      "epoch 346 / 20000\n",
      "gradient norm: 0.20982036390341818, minimum ratio: 2.5210526315789474\n",
      "\ttrain loss: 0.02991\n",
      "\tval loss: 0.03220\n",
      "epoch 347 / 20000\n",
      "gradient norm: 0.14915407309308648, minimum ratio: 2.507894736842105\n",
      "\ttrain loss: 0.02978\n",
      "\tval loss: 0.03209\n",
      "epoch 348 / 20000\n",
      "gradient norm: 0.25039956416003406, minimum ratio: 2.515789473684211\n",
      "\ttrain loss: 0.02973\n",
      "\tval loss: 0.03200\n",
      "epoch 349 / 20000\n",
      "gradient norm: 0.12039703992195427, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.02970\n",
      "\tval loss: 0.03190\n",
      "epoch 350 / 20000\n",
      "gradient norm: 0.2504377509467304, minimum ratio: 2.5026315789473688\n",
      "\ttrain loss: 0.02948\n",
      "\tval loss: 0.03180\n",
      "epoch 351 / 20000\n",
      "gradient norm: 0.15010037017054856, minimum ratio: 2.505263157894737\n",
      "\ttrain loss: 0.02945\n",
      "\tval loss: 0.03171\n",
      "epoch 352 / 20000\n",
      "gradient norm: 0.18243139097467065, minimum ratio: 2.5157894736842104\n",
      "\ttrain loss: 0.02934\n",
      "\tval loss: 0.03161\n",
      "epoch 353 / 20000\n",
      "gradient norm: 0.14330384996719658, minimum ratio: 2.507894736842105\n",
      "\ttrain loss: 0.02929\n",
      "\tval loss: 0.03152\n",
      "epoch 354 / 20000\n",
      "gradient norm: 0.15747382631525397, minimum ratio: 2.526315789473684\n",
      "\ttrain loss: 0.02916\n",
      "\tval loss: 0.03143\n",
      "epoch 355 / 20000\n",
      "gradient norm: 0.12814319226890802, minimum ratio: 2.518421052631579\n",
      "\ttrain loss: 0.02902\n",
      "\tval loss: 0.03132\n",
      "epoch 356 / 20000\n",
      "gradient norm: 0.20516700483858585, minimum ratio: 2.5210526315789474\n",
      "\ttrain loss: 0.02896\n",
      "\tval loss: 0.03122\n",
      "epoch 357 / 20000\n",
      "gradient norm: 0.1347638564184308, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.02894\n",
      "\tval loss: 0.03112\n",
      "epoch 358 / 20000\n",
      "gradient norm: 0.14018830354325473, minimum ratio: 2.507894736842105\n",
      "\ttrain loss: 0.02880\n",
      "\tval loss: 0.03101\n",
      "epoch 359 / 20000\n",
      "gradient norm: 0.18833902035839856, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.02873\n",
      "\tval loss: 0.03091\n",
      "epoch 360 / 20000\n",
      "gradient norm: 0.23060119012370706, minimum ratio: 2.507894736842105\n",
      "\ttrain loss: 0.02867\n",
      "\tval loss: 0.03083\n",
      "epoch 361 / 20000\n",
      "gradient norm: 0.13350743101909757, minimum ratio: 2.5105263157894737\n",
      "\ttrain loss: 0.02850\n",
      "\tval loss: 0.03073\n",
      "epoch 362 / 20000\n",
      "gradient norm: 0.14103687973693013, minimum ratio: 2.513157894736842\n",
      "\ttrain loss: 0.02851\n",
      "\tval loss: 0.03064\n",
      "epoch 363 / 20000\n",
      "gradient norm: 0.11405915371142328, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.02843\n",
      "\tval loss: 0.03055\n",
      "epoch 364 / 20000\n",
      "gradient norm: 0.14287295611575246, minimum ratio: 2.528947368421053\n",
      "\ttrain loss: 0.02824\n",
      "\tval loss: 0.03045\n",
      "epoch 365 / 20000\n",
      "gradient norm: 0.1275465355720371, minimum ratio: 2.513157894736842\n",
      "\ttrain loss: 0.02824\n",
      "\tval loss: 0.03035\n",
      "epoch 366 / 20000\n",
      "gradient norm: 0.17016213131137192, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.02808\n",
      "\tval loss: 0.03025\n",
      "epoch 367 / 20000\n",
      "gradient norm: 0.16317010042257607, minimum ratio: 2.531578947368421\n",
      "\ttrain loss: 0.02805\n",
      "\tval loss: 0.03016\n",
      "epoch 368 / 20000\n",
      "gradient norm: 0.3378724555950612, minimum ratio: 2.5289473684210524\n",
      "\ttrain loss: 0.02798\n",
      "\tval loss: 0.03009\n",
      "epoch 369 / 20000\n",
      "gradient norm: 0.1918442260939628, minimum ratio: 2.5105263157894737\n",
      "\ttrain loss: 0.02792\n",
      "\tval loss: 0.02999\n",
      "epoch 370 / 20000\n",
      "gradient norm: 0.20523191872052848, minimum ratio: 2.5078947368421054\n",
      "\ttrain loss: 0.02784\n",
      "\tval loss: 0.02988\n",
      "epoch 371 / 20000\n",
      "gradient norm: 0.15698887524195015, minimum ratio: 2.513157894736842\n",
      "\ttrain loss: 0.02774\n",
      "\tval loss: 0.02978\n",
      "epoch 372 / 20000\n",
      "gradient norm: 0.17953990842215717, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.02767\n",
      "\tval loss: 0.02969\n",
      "epoch 373 / 20000\n",
      "gradient norm: 0.13045952515676618, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.02757\n",
      "\tval loss: 0.02961\n",
      "epoch 374 / 20000\n",
      "gradient norm: 0.14304775511845946, minimum ratio: 2.5315789473684216\n",
      "\ttrain loss: 0.02746\n",
      "\tval loss: 0.02952\n",
      "epoch 375 / 20000\n",
      "gradient norm: 0.2480743257328868, minimum ratio: 2.5236842105263158\n",
      "\ttrain loss: 0.02744\n",
      "\tval loss: 0.02943\n",
      "epoch 376 / 20000\n",
      "gradient norm: 0.108405826613307, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.02725\n",
      "\tval loss: 0.02934\n",
      "epoch 377 / 20000\n",
      "gradient norm: 0.19016992044635117, minimum ratio: 2.526315789473684\n",
      "\ttrain loss: 0.02712\n",
      "\tval loss: 0.02924\n",
      "epoch 378 / 20000\n",
      "gradient norm: 0.19385132170282304, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.02715\n",
      "\tval loss: 0.02915\n",
      "epoch 379 / 20000\n",
      "gradient norm: 0.24192806193605065, minimum ratio: 2.4973684210526312\n",
      "\ttrain loss: 0.02702\n",
      "\tval loss: 0.02905\n",
      "epoch 380 / 20000\n",
      "gradient norm: 0.17240270297043025, minimum ratio: 2.5342105263157895\n",
      "\ttrain loss: 0.02691\n",
      "\tval loss: 0.02898\n",
      "epoch 381 / 20000\n",
      "gradient norm: 0.14661800605244935, minimum ratio: 2.5131578947368425\n",
      "\ttrain loss: 0.02686\n",
      "\tval loss: 0.02889\n",
      "epoch 382 / 20000\n",
      "gradient norm: 0.12850482086651027, minimum ratio: 2.5131578947368425\n",
      "\ttrain loss: 0.02684\n",
      "\tval loss: 0.02879\n",
      "epoch 383 / 20000\n",
      "gradient norm: 0.13357836846262217, minimum ratio: 2.536842105263158\n",
      "\ttrain loss: 0.02672\n",
      "\tval loss: 0.02870\n",
      "epoch 384 / 20000\n",
      "gradient norm: 0.2322510804515332, minimum ratio: 2.5289473684210524\n",
      "\ttrain loss: 0.02662\n",
      "\tval loss: 0.02861\n",
      "epoch 385 / 20000\n",
      "gradient norm: 0.1543980217538774, minimum ratio: 2.5315789473684207\n",
      "\ttrain loss: 0.02647\n",
      "\tval loss: 0.02851\n",
      "epoch 386 / 20000\n",
      "gradient norm: 0.23213049210608006, minimum ratio: 2.5105263157894737\n",
      "\ttrain loss: 0.02643\n",
      "\tval loss: 0.02843\n",
      "epoch 387 / 20000\n",
      "gradient norm: 0.10707736690528691, minimum ratio: 2.5236842105263158\n",
      "\ttrain loss: 0.02632\n",
      "\tval loss: 0.02834\n",
      "epoch 388 / 20000\n",
      "gradient norm: 0.14711805060505867, minimum ratio: 2.5236842105263158\n",
      "\ttrain loss: 0.02628\n",
      "\tval loss: 0.02825\n",
      "epoch 389 / 20000\n",
      "gradient norm: 0.2458389033563435, minimum ratio: 2.526315789473684\n",
      "\ttrain loss: 0.02620\n",
      "\tval loss: 0.02817\n",
      "epoch 390 / 20000\n",
      "gradient norm: 0.23254449293017387, minimum ratio: 2.515789473684211\n",
      "\ttrain loss: 0.02613\n",
      "\tval loss: 0.02808\n",
      "epoch 391 / 20000\n",
      "gradient norm: 0.13133194739930332, minimum ratio: 2.5289473684210524\n",
      "\ttrain loss: 0.02604\n",
      "\tval loss: 0.02799\n",
      "epoch 392 / 20000\n",
      "gradient norm: 0.12459934619255364, minimum ratio: 2.5289473684210524\n",
      "\ttrain loss: 0.02598\n",
      "\tval loss: 0.02791\n",
      "epoch 393 / 20000\n",
      "gradient norm: 0.2165330434218049, minimum ratio: 2.5078947368421054\n",
      "\ttrain loss: 0.02595\n",
      "\tval loss: 0.02783\n",
      "epoch 394 / 20000\n",
      "gradient norm: 0.15629328461363912, minimum ratio: 2.5078947368421054\n",
      "\ttrain loss: 0.02581\n",
      "\tval loss: 0.02773\n",
      "epoch 395 / 20000\n",
      "gradient norm: 0.1501030931249261, minimum ratio: 2.55\n",
      "\ttrain loss: 0.02571\n",
      "\tval loss: 0.02765\n",
      "epoch 396 / 20000\n",
      "gradient norm: 0.14375767577439547, minimum ratio: 2.526315789473684\n",
      "\ttrain loss: 0.02563\n",
      "\tval loss: 0.02756\n",
      "epoch 397 / 20000\n",
      "gradient norm: 0.28643990121781826, minimum ratio: 2.5\n",
      "\ttrain loss: 0.02558\n",
      "\tval loss: 0.02747\n",
      "epoch 398 / 20000\n",
      "gradient norm: 0.18680921057239175, minimum ratio: 2.5157894736842104\n",
      "\ttrain loss: 0.02547\n",
      "\tval loss: 0.02739\n",
      "epoch 399 / 20000\n",
      "gradient norm: 0.15236362139694393, minimum ratio: 2.507894736842105\n",
      "\ttrain loss: 0.02546\n",
      "\tval loss: 0.02732\n",
      "epoch 400 / 20000\n",
      "gradient norm: 0.12780843651853502, minimum ratio: 2.542105263157895\n",
      "\ttrain loss: 0.02538\n",
      "\tval loss: 0.02723\n",
      "epoch 401 / 20000\n",
      "gradient norm: 0.13347745733335614, minimum ratio: 2.5236842105263158\n",
      "\ttrain loss: 0.02526\n",
      "\tval loss: 0.02714\n",
      "epoch 402 / 20000\n",
      "gradient norm: 0.12078653392381966, minimum ratio: 2.552631578947368\n",
      "\ttrain loss: 0.02512\n",
      "\tval loss: 0.02705\n",
      "epoch 403 / 20000\n",
      "gradient norm: 0.21853289264254272, minimum ratio: 2.518421052631579\n",
      "\ttrain loss: 0.02518\n",
      "\tval loss: 0.02696\n",
      "epoch 404 / 20000\n",
      "gradient norm: 0.17101698485203087, minimum ratio: 2.5131578947368425\n",
      "\ttrain loss: 0.02503\n",
      "\tval loss: 0.02688\n",
      "epoch 405 / 20000\n",
      "gradient norm: 0.1470953286625445, minimum ratio: 2.528947368421053\n",
      "\ttrain loss: 0.02497\n",
      "\tval loss: 0.02681\n",
      "epoch 406 / 20000\n",
      "gradient norm: 0.18523396365344524, minimum ratio: 2.5315789473684207\n",
      "\ttrain loss: 0.02486\n",
      "\tval loss: 0.02673\n",
      "epoch 407 / 20000\n",
      "gradient norm: 0.13038183702155948, minimum ratio: 2.544736842105263\n",
      "\ttrain loss: 0.02483\n",
      "\tval loss: 0.02665\n",
      "epoch 408 / 20000\n",
      "gradient norm: 0.15377768175676465, minimum ratio: 2.5210526315789474\n",
      "\ttrain loss: 0.02472\n",
      "\tval loss: 0.02656\n",
      "epoch 409 / 20000\n",
      "gradient norm: 0.13970073289237916, minimum ratio: 2.5289473684210524\n",
      "\ttrain loss: 0.02460\n",
      "\tval loss: 0.02647\n",
      "epoch 410 / 20000\n",
      "gradient norm: 0.15971574652940035, minimum ratio: 2.507894736842105\n",
      "\ttrain loss: 0.02459\n",
      "\tval loss: 0.02638\n",
      "epoch 411 / 20000\n",
      "gradient norm: 0.16459316574037075, minimum ratio: 2.5210526315789474\n",
      "\ttrain loss: 0.02446\n",
      "\tval loss: 0.02631\n",
      "epoch 412 / 20000\n",
      "gradient norm: 0.10351564362645149, minimum ratio: 2.542105263157895\n",
      "\ttrain loss: 0.02437\n",
      "\tval loss: 0.02623\n",
      "epoch 413 / 20000\n",
      "gradient norm: 0.12449233373627067, minimum ratio: 2.5342105263157895\n",
      "\ttrain loss: 0.02434\n",
      "\tval loss: 0.02615\n",
      "epoch 414 / 20000\n",
      "gradient norm: 0.15865723113529384, minimum ratio: 2.5315789473684207\n",
      "\ttrain loss: 0.02428\n",
      "\tval loss: 0.02607\n",
      "epoch 415 / 20000\n",
      "gradient norm: 0.18891961919143796, minimum ratio: 2.513157894736842\n",
      "\ttrain loss: 0.02416\n",
      "\tval loss: 0.02599\n",
      "epoch 416 / 20000\n",
      "gradient norm: 0.11575315287336707, minimum ratio: 2.5315789473684207\n",
      "\ttrain loss: 0.02417\n",
      "\tval loss: 0.02591\n",
      "epoch 417 / 20000\n",
      "gradient norm: 0.1387908821925521, minimum ratio: 2.531578947368421\n",
      "\ttrain loss: 0.02405\n",
      "\tval loss: 0.02582\n",
      "epoch 418 / 20000\n",
      "gradient norm: 0.11903748544864357, minimum ratio: 2.513157894736842\n",
      "\ttrain loss: 0.02389\n",
      "\tval loss: 0.02573\n",
      "epoch 419 / 20000\n",
      "gradient norm: 0.11521969712339342, minimum ratio: 2.507894736842105\n",
      "\ttrain loss: 0.02391\n",
      "\tval loss: 0.02566\n",
      "epoch 420 / 20000\n",
      "gradient norm: 0.15541912405751646, minimum ratio: 2.5210526315789474\n",
      "\ttrain loss: 0.02381\n",
      "\tval loss: 0.02558\n",
      "epoch 421 / 20000\n",
      "gradient norm: 0.20000980119220912, minimum ratio: 2.515789473684211\n",
      "\ttrain loss: 0.02380\n",
      "\tval loss: 0.02550\n",
      "epoch 422 / 20000\n",
      "gradient norm: 0.09653705777600408, minimum ratio: 2.5105263157894737\n",
      "\ttrain loss: 0.02367\n",
      "\tval loss: 0.02543\n",
      "epoch 423 / 20000\n",
      "gradient norm: 0.10460097854956985, minimum ratio: 2.5315789473684207\n",
      "\ttrain loss: 0.02360\n",
      "\tval loss: 0.02535\n",
      "epoch 424 / 20000\n",
      "gradient norm: 0.1744747464545071, minimum ratio: 2.5236842105263158\n",
      "\ttrain loss: 0.02358\n",
      "\tval loss: 0.02528\n",
      "epoch 425 / 20000\n",
      "gradient norm: 0.21064083464443684, minimum ratio: 2.557894736842105\n",
      "\ttrain loss: 0.02353\n",
      "\tval loss: 0.02519\n",
      "epoch 426 / 20000\n",
      "gradient norm: 0.14501982810907066, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.02343\n",
      "\tval loss: 0.02510\n",
      "epoch 427 / 20000\n",
      "gradient norm: 0.20107232592999935, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.02331\n",
      "\tval loss: 0.02501\n",
      "epoch 428 / 20000\n",
      "gradient norm: 0.16536250105127692, minimum ratio: 2.5210526315789474\n",
      "\ttrain loss: 0.02324\n",
      "\tval loss: 0.02495\n",
      "epoch 429 / 20000\n",
      "gradient norm: 0.13665570667944849, minimum ratio: 2.5184210526315787\n",
      "\ttrain loss: 0.02310\n",
      "\tval loss: 0.02487\n",
      "epoch 430 / 20000\n",
      "gradient norm: 0.13728545606136322, minimum ratio: 2.5342105263157895\n",
      "\ttrain loss: 0.02309\n",
      "\tval loss: 0.02481\n",
      "epoch 431 / 20000\n",
      "gradient norm: 0.18263277364894748, minimum ratio: 2.518421052631579\n",
      "\ttrain loss: 0.02299\n",
      "\tval loss: 0.02472\n",
      "epoch 432 / 20000\n",
      "gradient norm: 0.11646626959554851, minimum ratio: 2.531578947368421\n",
      "\ttrain loss: 0.02292\n",
      "\tval loss: 0.02464\n",
      "epoch 433 / 20000\n",
      "gradient norm: 0.13812540657818317, minimum ratio: 2.5342105263157895\n",
      "\ttrain loss: 0.02288\n",
      "\tval loss: 0.02457\n",
      "epoch 434 / 20000\n",
      "gradient norm: 0.11501300591044128, minimum ratio: 2.536842105263158\n",
      "\ttrain loss: 0.02276\n",
      "\tval loss: 0.02449\n",
      "epoch 435 / 20000\n",
      "gradient norm: 0.111346973804757, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.02273\n",
      "\tval loss: 0.02441\n",
      "epoch 436 / 20000\n",
      "gradient norm: 0.15128225786611438, minimum ratio: 2.526315789473684\n",
      "\ttrain loss: 0.02269\n",
      "\tval loss: 0.02434\n",
      "epoch 437 / 20000\n",
      "gradient norm: 0.227605048334226, minimum ratio: 2.5210526315789474\n",
      "\ttrain loss: 0.02258\n",
      "\tval loss: 0.02426\n",
      "epoch 438 / 20000\n",
      "gradient norm: 0.10437993658706546, minimum ratio: 2.534210526315789\n",
      "\ttrain loss: 0.02255\n",
      "\tval loss: 0.02418\n",
      "epoch 439 / 20000\n",
      "gradient norm: 0.11975783039815724, minimum ratio: 2.507894736842105\n",
      "\ttrain loss: 0.02248\n",
      "\tval loss: 0.02411\n",
      "epoch 440 / 20000\n",
      "gradient norm: 0.12934041465632617, minimum ratio: 2.513157894736842\n",
      "\ttrain loss: 0.02241\n",
      "\tval loss: 0.02404\n",
      "epoch 441 / 20000\n",
      "gradient norm: 0.167792905587703, minimum ratio: 2.5289473684210524\n",
      "\ttrain loss: 0.02228\n",
      "\tval loss: 0.02396\n",
      "epoch 442 / 20000\n",
      "gradient norm: 0.2098097768612206, minimum ratio: 2.5078947368421054\n",
      "\ttrain loss: 0.02225\n",
      "\tval loss: 0.02389\n",
      "epoch 443 / 20000\n",
      "gradient norm: 0.16885323822498322, minimum ratio: 2.531578947368421\n",
      "\ttrain loss: 0.02223\n",
      "\tval loss: 0.02381\n",
      "epoch 444 / 20000\n",
      "gradient norm: 0.1930354218930006, minimum ratio: 2.5210526315789474\n",
      "\ttrain loss: 0.02209\n",
      "\tval loss: 0.02374\n",
      "epoch 445 / 20000\n",
      "gradient norm: 0.1516702447552234, minimum ratio: 2.5157894736842104\n",
      "\ttrain loss: 0.02203\n",
      "\tval loss: 0.02366\n",
      "epoch 446 / 20000\n",
      "gradient norm: 0.13135813199914992, minimum ratio: 2.518421052631579\n",
      "\ttrain loss: 0.02197\n",
      "\tval loss: 0.02360\n",
      "epoch 447 / 20000\n",
      "gradient norm: 0.13608463178388774, minimum ratio: 2.526315789473684\n",
      "\ttrain loss: 0.02194\n",
      "\tval loss: 0.02353\n",
      "epoch 448 / 20000\n",
      "gradient norm: 0.15102586359716952, minimum ratio: 2.518421052631579\n",
      "\ttrain loss: 0.02181\n",
      "\tval loss: 0.02346\n",
      "epoch 449 / 20000\n",
      "gradient norm: 0.15225885179825127, minimum ratio: 2.5105263157894737\n",
      "\ttrain loss: 0.02179\n",
      "\tval loss: 0.02338\n",
      "epoch 450 / 20000\n",
      "gradient norm: 0.10132005694322288, minimum ratio: 2.536842105263158\n",
      "\ttrain loss: 0.02174\n",
      "\tval loss: 0.02330\n",
      "epoch 451 / 20000\n",
      "gradient norm: 0.1428891725372523, minimum ratio: 2.5\n",
      "\ttrain loss: 0.02163\n",
      "\tval loss: 0.02322\n",
      "epoch 452 / 20000\n",
      "gradient norm: 0.14731402252800763, minimum ratio: 2.5157894736842104\n",
      "\ttrain loss: 0.02156\n",
      "\tval loss: 0.02315\n",
      "epoch 453 / 20000\n",
      "gradient norm: 0.15879663778468966, minimum ratio: 2.5368421052631582\n",
      "\ttrain loss: 0.02151\n",
      "\tval loss: 0.02308\n",
      "epoch 454 / 20000\n",
      "gradient norm: 0.1268144939094782, minimum ratio: 2.515789473684211\n",
      "\ttrain loss: 0.02141\n",
      "\tval loss: 0.02300\n",
      "epoch 455 / 20000\n",
      "gradient norm: 0.15239478647708893, minimum ratio: 2.521052631578947\n",
      "\ttrain loss: 0.02136\n",
      "\tval loss: 0.02293\n",
      "epoch 456 / 20000\n",
      "gradient norm: 0.1359887917060405, minimum ratio: 2.513157894736842\n",
      "\ttrain loss: 0.02132\n",
      "\tval loss: 0.02287\n",
      "epoch 457 / 20000\n",
      "gradient norm: 0.16622384102083743, minimum ratio: 2.539473684210526\n",
      "\ttrain loss: 0.02123\n",
      "\tval loss: 0.02279\n",
      "epoch 458 / 20000\n",
      "gradient norm: 0.09962148731574416, minimum ratio: 2.5236842105263158\n",
      "\ttrain loss: 0.02123\n",
      "\tval loss: 0.02272\n",
      "epoch 459 / 20000\n",
      "gradient norm: 0.1439842889085412, minimum ratio: 2.513157894736842\n",
      "\ttrain loss: 0.02112\n",
      "\tval loss: 0.02266\n",
      "epoch 460 / 20000\n",
      "gradient norm: 0.1717710541561246, minimum ratio: 2.534210526315789\n",
      "\ttrain loss: 0.02104\n",
      "\tval loss: 0.02258\n",
      "epoch 461 / 20000\n",
      "gradient norm: 0.1752218697220087, minimum ratio: 2.526315789473684\n",
      "\ttrain loss: 0.02100\n",
      "\tval loss: 0.02251\n",
      "epoch 462 / 20000\n",
      "gradient norm: 0.12973958952352405, minimum ratio: 2.518421052631579\n",
      "\ttrain loss: 0.02092\n",
      "\tval loss: 0.02244\n",
      "epoch 463 / 20000\n",
      "gradient norm: 0.16380589571781456, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.02084\n",
      "\tval loss: 0.02236\n",
      "epoch 464 / 20000\n",
      "gradient norm: 0.12550475052557886, minimum ratio: 2.5236842105263158\n",
      "\ttrain loss: 0.02081\n",
      "\tval loss: 0.02228\n",
      "epoch 465 / 20000\n",
      "gradient norm: 0.12215865938924253, minimum ratio: 2.5315789473684207\n",
      "\ttrain loss: 0.02072\n",
      "\tval loss: 0.02222\n",
      "epoch 466 / 20000\n",
      "gradient norm: 0.09351577330380678, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.02063\n",
      "\tval loss: 0.02216\n",
      "epoch 467 / 20000\n",
      "gradient norm: 0.09766893810592592, minimum ratio: 2.51578947368421\n",
      "\ttrain loss: 0.02058\n",
      "\tval loss: 0.02209\n",
      "epoch 468 / 20000\n",
      "gradient norm: 0.18057389673776925, minimum ratio: 2.531578947368421\n",
      "\ttrain loss: 0.02053\n",
      "\tval loss: 0.02203\n",
      "epoch 469 / 20000\n",
      "gradient norm: 0.11895645479671657, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.02045\n",
      "\tval loss: 0.02195\n",
      "epoch 470 / 20000\n",
      "gradient norm: 0.18941412423737347, minimum ratio: 2.5184210526315787\n",
      "\ttrain loss: 0.02039\n",
      "\tval loss: 0.02188\n",
      "epoch 471 / 20000\n",
      "gradient norm: 0.18397269118577242, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.02032\n",
      "\tval loss: 0.02182\n",
      "epoch 472 / 20000\n",
      "gradient norm: 0.11883371346630156, minimum ratio: 2.5157894736842104\n",
      "\ttrain loss: 0.02030\n",
      "\tval loss: 0.02174\n",
      "epoch 473 / 20000\n",
      "gradient norm: 0.10045948601327837, minimum ratio: 2.5078947368421054\n",
      "\ttrain loss: 0.02027\n",
      "\tval loss: 0.02167\n",
      "epoch 474 / 20000\n",
      "gradient norm: 0.1555666197091341, minimum ratio: 2.5368421052631582\n",
      "\ttrain loss: 0.02014\n",
      "\tval loss: 0.02160\n",
      "epoch 475 / 20000\n",
      "gradient norm: 0.10102057456970215, minimum ratio: 2.5105263157894737\n",
      "\ttrain loss: 0.02012\n",
      "\tval loss: 0.02154\n",
      "epoch 476 / 20000\n",
      "gradient norm: 0.12673117290250957, minimum ratio: 2.4973684210526312\n",
      "\ttrain loss: 0.02007\n",
      "\tval loss: 0.02147\n",
      "epoch 477 / 20000\n",
      "gradient norm: 0.1190305354539305, minimum ratio: 2.5315789473684207\n",
      "\ttrain loss: 0.01997\n",
      "\tval loss: 0.02140\n",
      "epoch 478 / 20000\n",
      "gradient norm: 0.17384858685545623, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.01991\n",
      "\tval loss: 0.02134\n",
      "epoch 479 / 20000\n",
      "gradient norm: 0.15769746550358832, minimum ratio: 2.4973684210526312\n",
      "\ttrain loss: 0.01986\n",
      "\tval loss: 0.02126\n",
      "epoch 480 / 20000\n",
      "gradient norm: 0.1873018452897668, minimum ratio: 2.5184210526315787\n",
      "\ttrain loss: 0.01979\n",
      "\tval loss: 0.02120\n",
      "epoch 481 / 20000\n",
      "gradient norm: 0.11040693148970604, minimum ratio: 2.526315789473684\n",
      "\ttrain loss: 0.01973\n",
      "\tval loss: 0.02114\n",
      "epoch 482 / 20000\n",
      "gradient norm: 0.13644009502604604, minimum ratio: 2.5210526315789474\n",
      "\ttrain loss: 0.01965\n",
      "\tval loss: 0.02108\n",
      "epoch 483 / 20000\n",
      "gradient norm: 0.15431500016711652, minimum ratio: 2.542105263157895\n",
      "\ttrain loss: 0.01964\n",
      "\tval loss: 0.02102\n",
      "epoch 484 / 20000\n",
      "gradient norm: 0.13062935206107795, minimum ratio: 2.5289473684210524\n",
      "\ttrain loss: 0.01960\n",
      "\tval loss: 0.02094\n",
      "epoch 485 / 20000\n",
      "gradient norm: 0.11932464432902634, minimum ratio: 2.5157894736842104\n",
      "\ttrain loss: 0.01947\n",
      "\tval loss: 0.02086\n",
      "epoch 486 / 20000\n",
      "gradient norm: 0.13392701325938106, minimum ratio: 2.505263157894737\n",
      "\ttrain loss: 0.01943\n",
      "\tval loss: 0.02080\n",
      "epoch 487 / 20000\n",
      "gradient norm: 0.14545585145242512, minimum ratio: 2.531578947368421\n",
      "\ttrain loss: 0.01939\n",
      "\tval loss: 0.02075\n",
      "epoch 488 / 20000\n",
      "gradient norm: 0.11446436611004174, minimum ratio: 2.5342105263157895\n",
      "\ttrain loss: 0.01929\n",
      "\tval loss: 0.02068\n",
      "epoch 489 / 20000\n",
      "gradient norm: 0.1663695154711604, minimum ratio: 2.5157894736842104\n",
      "\ttrain loss: 0.01929\n",
      "\tval loss: 0.02061\n",
      "epoch 490 / 20000\n",
      "gradient norm: 0.08658519107848406, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.01919\n",
      "\tval loss: 0.02055\n",
      "epoch 491 / 20000\n",
      "gradient norm: 0.13444679020904005, minimum ratio: 2.5157894736842104\n",
      "\ttrain loss: 0.01916\n",
      "\tval loss: 0.02049\n",
      "epoch 492 / 20000\n",
      "gradient norm: 0.14591046003624797, minimum ratio: 2.53421052631579\n",
      "\ttrain loss: 0.01908\n",
      "\tval loss: 0.02043\n",
      "epoch 493 / 20000\n",
      "gradient norm: 0.08905124175362289, minimum ratio: 2.536842105263158\n",
      "\ttrain loss: 0.01902\n",
      "\tval loss: 0.02036\n",
      "epoch 494 / 20000\n",
      "gradient norm: 0.10634447494521737, minimum ratio: 2.5315789473684207\n",
      "\ttrain loss: 0.01897\n",
      "\tval loss: 0.02029\n",
      "epoch 495 / 20000\n",
      "gradient norm: 0.11351751536130905, minimum ratio: 2.5236842105263158\n",
      "\ttrain loss: 0.01890\n",
      "\tval loss: 0.02023\n",
      "epoch 496 / 20000\n",
      "gradient norm: 0.1095520609524101, minimum ratio: 2.5105263157894737\n",
      "\ttrain loss: 0.01884\n",
      "\tval loss: 0.02017\n",
      "epoch 497 / 20000\n",
      "gradient norm: 0.12716665561310947, minimum ratio: 2.513157894736842\n",
      "\ttrain loss: 0.01874\n",
      "\tval loss: 0.02010\n",
      "epoch 498 / 20000\n",
      "gradient norm: 0.16701177530921996, minimum ratio: 2.5184210526315787\n",
      "\ttrain loss: 0.01871\n",
      "\tval loss: 0.02004\n",
      "epoch 499 / 20000\n",
      "gradient norm: 0.09940887591801584, minimum ratio: 2.5210526315789474\n",
      "\ttrain loss: 0.01867\n",
      "\tval loss: 0.01999\n",
      "epoch 500 / 20000\n",
      "gradient norm: 0.11541782412678003, minimum ratio: 2.513157894736842\n",
      "\ttrain loss: 0.01864\n",
      "\tval loss: 0.01993\n",
      "epoch 501 / 20000\n",
      "gradient norm: 0.17285534320399165, minimum ratio: 2.531578947368421\n",
      "\ttrain loss: 0.01856\n",
      "\tval loss: 0.01988\n",
      "epoch 502 / 20000\n",
      "gradient norm: 0.15349603747017682, minimum ratio: 2.5394736842105265\n",
      "\ttrain loss: 0.01847\n",
      "\tval loss: 0.01979\n",
      "epoch 503 / 20000\n",
      "gradient norm: 0.122593036852777, minimum ratio: 2.5\n",
      "\ttrain loss: 0.01843\n",
      "\tval loss: 0.01972\n",
      "epoch 504 / 20000\n",
      "gradient norm: 0.1344886110164225, minimum ratio: 2.5210526315789474\n",
      "\ttrain loss: 0.01836\n",
      "\tval loss: 0.01967\n",
      "epoch 505 / 20000\n",
      "gradient norm: 0.2121187977027148, minimum ratio: 2.515789473684211\n",
      "\ttrain loss: 0.01831\n",
      "\tval loss: 0.01960\n",
      "epoch 506 / 20000\n",
      "gradient norm: 0.1258181598968804, minimum ratio: 2.4868421052631575\n",
      "\ttrain loss: 0.01825\n",
      "\tval loss: 0.01955\n",
      "epoch 507 / 20000\n",
      "gradient norm: 0.13618289167061448, minimum ratio: 2.539473684210526\n",
      "\ttrain loss: 0.01824\n",
      "\tval loss: 0.01951\n",
      "epoch 508 / 20000\n",
      "gradient norm: 0.09888749499805272, minimum ratio: 2.5289473684210524\n",
      "\ttrain loss: 0.01816\n",
      "\tval loss: 0.01944\n",
      "epoch 509 / 20000\n",
      "gradient norm: 0.0972754789981991, minimum ratio: 2.518421052631579\n",
      "\ttrain loss: 0.01810\n",
      "\tval loss: 0.01938\n",
      "epoch 510 / 20000\n",
      "gradient norm: 0.13598730531521142, minimum ratio: 2.5289473684210524\n",
      "\ttrain loss: 0.01810\n",
      "\tval loss: 0.01931\n",
      "epoch 511 / 20000\n",
      "gradient norm: 0.10149808437563479, minimum ratio: 2.5131578947368416\n",
      "\ttrain loss: 0.01803\n",
      "\tval loss: 0.01925\n",
      "epoch 512 / 20000\n",
      "gradient norm: 0.14164238865487278, minimum ratio: 2.5236842105263153\n",
      "\ttrain loss: 0.01796\n",
      "\tval loss: 0.01918\n",
      "epoch 513 / 20000\n",
      "gradient norm: 0.0859533331822604, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.01789\n",
      "\tval loss: 0.01913\n",
      "epoch 514 / 20000\n",
      "gradient norm: 0.08173230406828225, minimum ratio: 2.5105263157894733\n",
      "\ttrain loss: 0.01780\n",
      "\tval loss: 0.01907\n",
      "epoch 515 / 20000\n",
      "gradient norm: 0.1325875110924244, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.01779\n",
      "\tval loss: 0.01903\n",
      "epoch 516 / 20000\n",
      "gradient norm: 0.08149960124865174, minimum ratio: 2.5289473684210524\n",
      "\ttrain loss: 0.01772\n",
      "\tval loss: 0.01896\n",
      "epoch 517 / 20000\n",
      "gradient norm: 0.1551301043946296, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.01767\n",
      "\tval loss: 0.01890\n",
      "epoch 518 / 20000\n",
      "gradient norm: 0.163787673227489, minimum ratio: 2.5184210526315787\n",
      "\ttrain loss: 0.01761\n",
      "\tval loss: 0.01884\n",
      "epoch 519 / 20000\n",
      "gradient norm: 0.19672913034446537, minimum ratio: 2.544736842105263\n",
      "\ttrain loss: 0.01755\n",
      "\tval loss: 0.01878\n",
      "epoch 520 / 20000\n",
      "gradient norm: 0.09323115833103657, minimum ratio: 2.5210526315789474\n",
      "\ttrain loss: 0.01752\n",
      "\tval loss: 0.01871\n",
      "epoch 521 / 20000\n",
      "gradient norm: 0.1891100958455354, minimum ratio: 2.518421052631579\n",
      "\ttrain loss: 0.01747\n",
      "\tval loss: 0.01865\n",
      "epoch 522 / 20000\n",
      "gradient norm: 0.11576280510053039, minimum ratio: 2.555263157894737\n",
      "\ttrain loss: 0.01738\n",
      "\tval loss: 0.01860\n",
      "epoch 523 / 20000\n",
      "gradient norm: 0.18498690822161734, minimum ratio: 2.557894736842105\n",
      "\ttrain loss: 0.01736\n",
      "\tval loss: 0.01855\n",
      "epoch 524 / 20000\n",
      "gradient norm: 0.10975717892870307, minimum ratio: 2.507894736842105\n",
      "\ttrain loss: 0.01732\n",
      "\tval loss: 0.01850\n",
      "epoch 525 / 20000\n",
      "gradient norm: 0.1828442143741995, minimum ratio: 2.5236842105263158\n",
      "\ttrain loss: 0.01728\n",
      "\tval loss: 0.01844\n",
      "epoch 526 / 20000\n",
      "gradient norm: 0.09969564061611891, minimum ratio: 2.539473684210526\n",
      "\ttrain loss: 0.01718\n",
      "\tval loss: 0.01839\n",
      "epoch 527 / 20000\n",
      "gradient norm: 0.16272824862971902, minimum ratio: 2.5315789473684207\n",
      "\ttrain loss: 0.01715\n",
      "\tval loss: 0.01832\n",
      "epoch 528 / 20000\n",
      "gradient norm: 0.09255323279649019, minimum ratio: 2.5184210526315787\n",
      "\ttrain loss: 0.01708\n",
      "\tval loss: 0.01827\n",
      "epoch 529 / 20000\n",
      "gradient norm: 0.11959178978577256, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.01706\n",
      "\tval loss: 0.01821\n",
      "epoch 530 / 20000\n",
      "gradient norm: 0.16248606238514185, minimum ratio: 2.5342105263157895\n",
      "\ttrain loss: 0.01699\n",
      "\tval loss: 0.01816\n",
      "epoch 531 / 20000\n",
      "gradient norm: 0.09659322677180171, minimum ratio: 2.5236842105263158\n",
      "\ttrain loss: 0.01695\n",
      "\tval loss: 0.01810\n",
      "epoch 532 / 20000\n",
      "gradient norm: 0.11483810190111399, minimum ratio: 2.5368421052631582\n",
      "\ttrain loss: 0.01692\n",
      "\tval loss: 0.01804\n",
      "epoch 533 / 20000\n",
      "gradient norm: 0.17271239031106234, minimum ratio: 2.5078947368421054\n",
      "\ttrain loss: 0.01686\n",
      "\tval loss: 0.01799\n",
      "epoch 534 / 20000\n",
      "gradient norm: 0.1104025652166456, minimum ratio: 2.5289473684210524\n",
      "\ttrain loss: 0.01678\n",
      "\tval loss: 0.01793\n",
      "epoch 535 / 20000\n",
      "gradient norm: 0.08653590059839189, minimum ratio: 2.5184210526315787\n",
      "\ttrain loss: 0.01672\n",
      "\tval loss: 0.01788\n",
      "epoch 536 / 20000\n",
      "gradient norm: 0.1468569110147655, minimum ratio: 2.5078947368421054\n",
      "\ttrain loss: 0.01668\n",
      "\tval loss: 0.01783\n",
      "epoch 537 / 20000\n",
      "gradient norm: 0.16199975600466132, minimum ratio: 2.518421052631579\n",
      "\ttrain loss: 0.01663\n",
      "\tval loss: 0.01778\n",
      "epoch 538 / 20000\n",
      "gradient norm: 0.10701381438411772, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.01661\n",
      "\tval loss: 0.01772\n",
      "epoch 539 / 20000\n",
      "gradient norm: 0.09030841919593513, minimum ratio: 2.5210526315789474\n",
      "\ttrain loss: 0.01649\n",
      "\tval loss: 0.01766\n",
      "epoch 540 / 20000\n",
      "gradient norm: 0.10153051442466676, minimum ratio: 2.5105263157894737\n",
      "\ttrain loss: 0.01650\n",
      "\tval loss: 0.01761\n",
      "epoch 541 / 20000\n",
      "gradient norm: 0.15910694608464837, minimum ratio: 2.505263157894737\n",
      "\ttrain loss: 0.01643\n",
      "\tval loss: 0.01756\n",
      "epoch 542 / 20000\n",
      "gradient norm: 0.14035755535587668, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.01637\n",
      "\tval loss: 0.01750\n",
      "epoch 543 / 20000\n",
      "gradient norm: 0.1293985852971673, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.01635\n",
      "\tval loss: 0.01746\n",
      "epoch 544 / 20000\n",
      "gradient norm: 0.08068838063627481, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.01627\n",
      "\tval loss: 0.01742\n",
      "epoch 545 / 20000\n",
      "gradient norm: 0.14901194837875664, minimum ratio: 2.5157894736842104\n",
      "\ttrain loss: 0.01623\n",
      "\tval loss: 0.01736\n",
      "epoch 546 / 20000\n",
      "gradient norm: 0.08987747458741069, minimum ratio: 2.4999999999999996\n",
      "\ttrain loss: 0.01622\n",
      "\tval loss: 0.01730\n",
      "epoch 547 / 20000\n",
      "gradient norm: 0.15559407067485154, minimum ratio: 2.5236842105263158\n",
      "\ttrain loss: 0.01617\n",
      "\tval loss: 0.01723\n",
      "epoch 548 / 20000\n",
      "gradient norm: 0.18290818692184985, minimum ratio: 2.5078947368421054\n",
      "\ttrain loss: 0.01612\n",
      "\tval loss: 0.01718\n",
      "epoch 549 / 20000\n",
      "gradient norm: 0.12042546574957669, minimum ratio: 2.492105263157895\n",
      "\ttrain loss: 0.01600\n",
      "\tval loss: 0.01715\n",
      "epoch 550 / 20000\n",
      "gradient norm: 0.14781162841245532, minimum ratio: 2.526315789473684\n",
      "\ttrain loss: 0.01601\n",
      "\tval loss: 0.01710\n",
      "epoch 551 / 20000\n",
      "gradient norm: 0.10366095067001879, minimum ratio: 2.526315789473684\n",
      "\ttrain loss: 0.01594\n",
      "\tval loss: 0.01705\n",
      "epoch 552 / 20000\n",
      "gradient norm: 0.11790546774864197, minimum ratio: 2.5210526315789474\n",
      "\ttrain loss: 0.01593\n",
      "\tval loss: 0.01700\n",
      "epoch 553 / 20000\n",
      "gradient norm: 0.15218179184012115, minimum ratio: 2.5\n",
      "\ttrain loss: 0.01583\n",
      "\tval loss: 0.01695\n",
      "epoch 554 / 20000\n",
      "gradient norm: 0.15009379899129272, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.01581\n",
      "\tval loss: 0.01688\n",
      "epoch 555 / 20000\n",
      "gradient norm: 0.11334727541543543, minimum ratio: 2.5105263157894737\n",
      "\ttrain loss: 0.01576\n",
      "\tval loss: 0.01683\n",
      "epoch 556 / 20000\n",
      "gradient norm: 0.10368810477666557, minimum ratio: 2.4868421052631575\n",
      "\ttrain loss: 0.01572\n",
      "\tval loss: 0.01678\n",
      "epoch 557 / 20000\n",
      "gradient norm: 0.102891308022663, minimum ratio: 2.5105263157894737\n",
      "\ttrain loss: 0.01564\n",
      "\tval loss: 0.01673\n",
      "epoch 558 / 20000\n",
      "gradient norm: 0.12326623196713626, minimum ratio: 2.526315789473684\n",
      "\ttrain loss: 0.01564\n",
      "\tval loss: 0.01670\n",
      "epoch 559 / 20000\n",
      "gradient norm: 0.10290052718482912, minimum ratio: 2.5236842105263158\n",
      "\ttrain loss: 0.01559\n",
      "\tval loss: 0.01663\n",
      "epoch 560 / 20000\n",
      "gradient norm: 0.11846657982096076, minimum ratio: 2.5473684210526315\n",
      "\ttrain loss: 0.01550\n",
      "\tval loss: 0.01659\n",
      "epoch 561 / 20000\n",
      "gradient norm: 0.10437664482742548, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.01549\n",
      "\tval loss: 0.01654\n",
      "epoch 562 / 20000\n",
      "gradient norm: 0.15886110113933682, minimum ratio: 2.492105263157895\n",
      "\ttrain loss: 0.01546\n",
      "\tval loss: 0.01648\n",
      "epoch 563 / 20000\n",
      "gradient norm: 0.16636348119936883, minimum ratio: 2.4973684210526312\n",
      "\ttrain loss: 0.01540\n",
      "\tval loss: 0.01643\n",
      "epoch 564 / 20000\n",
      "gradient norm: 0.10180447087623179, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.01536\n",
      "\tval loss: 0.01639\n",
      "epoch 565 / 20000\n",
      "gradient norm: 0.14960885723121464, minimum ratio: 2.5078947368421054\n",
      "\ttrain loss: 0.01530\n",
      "\tval loss: 0.01634\n",
      "epoch 566 / 20000\n",
      "gradient norm: 0.19547641137614846, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.01525\n",
      "\tval loss: 0.01631\n",
      "epoch 567 / 20000\n",
      "gradient norm: 0.09532073559239507, minimum ratio: 2.5131578947368425\n",
      "\ttrain loss: 0.01520\n",
      "\tval loss: 0.01625\n",
      "epoch 568 / 20000\n",
      "gradient norm: 0.1489357661921531, minimum ratio: 2.5236842105263158\n",
      "\ttrain loss: 0.01519\n",
      "\tval loss: 0.01619\n",
      "epoch 569 / 20000\n",
      "gradient norm: 0.12652665609493852, minimum ratio: 2.505263157894737\n",
      "\ttrain loss: 0.01512\n",
      "\tval loss: 0.01613\n",
      "epoch 570 / 20000\n",
      "gradient norm: 0.12835265649482608, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.01510\n",
      "\tval loss: 0.01609\n",
      "epoch 571 / 20000\n",
      "gradient norm: 0.09971462818793952, minimum ratio: 2.507894736842105\n",
      "\ttrain loss: 0.01505\n",
      "\tval loss: 0.01606\n",
      "epoch 572 / 20000\n",
      "gradient norm: 0.12486019171774387, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.01501\n",
      "\tval loss: 0.01602\n",
      "epoch 573 / 20000\n",
      "gradient norm: 0.13445467920973897, minimum ratio: 2.518421052631579\n",
      "\ttrain loss: 0.01495\n",
      "\tval loss: 0.01597\n",
      "epoch 574 / 20000\n",
      "gradient norm: 0.16970262047834694, minimum ratio: 2.5105263157894737\n",
      "\ttrain loss: 0.01491\n",
      "\tval loss: 0.01592\n",
      "epoch 575 / 20000\n",
      "gradient norm: 0.08199399570003152, minimum ratio: 2.5078947368421054\n",
      "\ttrain loss: 0.01488\n",
      "\tval loss: 0.01585\n",
      "epoch 576 / 20000\n",
      "gradient norm: 0.1480990678537637, minimum ratio: 2.5\n",
      "\ttrain loss: 0.01481\n",
      "\tval loss: 0.01580\n",
      "epoch 577 / 20000\n",
      "gradient norm: 0.09941228129900992, minimum ratio: 2.5105263157894737\n",
      "\ttrain loss: 0.01476\n",
      "\tval loss: 0.01576\n",
      "epoch 578 / 20000\n",
      "gradient norm: 0.13025296642445028, minimum ratio: 2.531578947368421\n",
      "\ttrain loss: 0.01471\n",
      "\tval loss: 0.01572\n",
      "epoch 579 / 20000\n",
      "gradient norm: 0.11457906244322658, minimum ratio: 2.492105263157895\n",
      "\ttrain loss: 0.01473\n",
      "\tval loss: 0.01569\n",
      "epoch 580 / 20000\n",
      "gradient norm: 0.10163389262743294, minimum ratio: 2.5342105263157895\n",
      "\ttrain loss: 0.01466\n",
      "\tval loss: 0.01563\n",
      "epoch 581 / 20000\n",
      "gradient norm: 0.09347769594751298, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.01462\n",
      "\tval loss: 0.01558\n",
      "epoch 582 / 20000\n",
      "gradient norm: 0.08999849506653845, minimum ratio: 2.5157894736842104\n",
      "\ttrain loss: 0.01457\n",
      "\tval loss: 0.01553\n",
      "epoch 583 / 20000\n",
      "gradient norm: 0.0822577994549647, minimum ratio: 2.513157894736842\n",
      "\ttrain loss: 0.01452\n",
      "\tval loss: 0.01548\n",
      "epoch 584 / 20000\n",
      "gradient norm: 0.1370312818326056, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.01447\n",
      "\tval loss: 0.01544\n",
      "epoch 585 / 20000\n",
      "gradient norm: 0.1335174961714074, minimum ratio: 2.5105263157894737\n",
      "\ttrain loss: 0.01443\n",
      "\tval loss: 0.01540\n",
      "epoch 586 / 20000\n",
      "gradient norm: 0.12743989331647754, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.01444\n",
      "\tval loss: 0.01537\n",
      "epoch 587 / 20000\n",
      "gradient norm: 0.16304507991299033, minimum ratio: 2.5157894736842104\n",
      "\ttrain loss: 0.01438\n",
      "\tval loss: 0.01533\n",
      "epoch 588 / 20000\n",
      "gradient norm: 0.08894302509725094, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.01429\n",
      "\tval loss: 0.01527\n",
      "epoch 589 / 20000\n",
      "gradient norm: 0.16339919972233474, minimum ratio: 2.507894736842105\n",
      "\ttrain loss: 0.01429\n",
      "\tval loss: 0.01520\n",
      "epoch 590 / 20000\n",
      "gradient norm: 0.09430135600268841, minimum ratio: 2.5\n",
      "\ttrain loss: 0.01425\n",
      "\tval loss: 0.01516\n",
      "epoch 591 / 20000\n",
      "gradient norm: 0.17198055679909885, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.01420\n",
      "\tval loss: 0.01512\n",
      "epoch 592 / 20000\n",
      "gradient norm: 0.17604738753288984, minimum ratio: 2.5210526315789474\n",
      "\ttrain loss: 0.01416\n",
      "\tval loss: 0.01511\n",
      "epoch 593 / 20000\n",
      "gradient norm: 0.12540314998477697, minimum ratio: 2.5236842105263158\n",
      "\ttrain loss: 0.01415\n",
      "\tval loss: 0.01506\n",
      "epoch 594 / 20000\n",
      "gradient norm: 0.1251367626246065, minimum ratio: 2.5342105263157895\n",
      "\ttrain loss: 0.01407\n",
      "\tval loss: 0.01500\n",
      "epoch 595 / 20000\n",
      "gradient norm: 0.1220260332338512, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.01403\n",
      "\tval loss: 0.01495\n",
      "epoch 596 / 20000\n",
      "gradient norm: 0.1197970702778548, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.01402\n",
      "\tval loss: 0.01491\n",
      "epoch 597 / 20000\n",
      "gradient norm: 0.1333745907759294, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.01398\n",
      "\tval loss: 0.01487\n",
      "epoch 598 / 20000\n",
      "gradient norm: 0.08093384513631463, minimum ratio: 2.5\n",
      "\ttrain loss: 0.01391\n",
      "\tval loss: 0.01482\n",
      "epoch 599 / 20000\n",
      "gradient norm: 0.1320856842212379, minimum ratio: 2.5236842105263158\n",
      "\ttrain loss: 0.01388\n",
      "\tval loss: 0.01478\n",
      "epoch 600 / 20000\n",
      "gradient norm: 0.09165407111868262, minimum ratio: 2.5105263157894733\n",
      "\ttrain loss: 0.01386\n",
      "\tval loss: 0.01474\n",
      "epoch 601 / 20000\n",
      "gradient norm: 0.10128035000525415, minimum ratio: 2.513157894736842\n",
      "\ttrain loss: 0.01381\n",
      "\tval loss: 0.01470\n",
      "epoch 602 / 20000\n",
      "gradient norm: 0.07030547223985195, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.01374\n",
      "\tval loss: 0.01466\n",
      "epoch 603 / 20000\n",
      "gradient norm: 0.08893610793165863, minimum ratio: 2.492105263157895\n",
      "\ttrain loss: 0.01374\n",
      "\tval loss: 0.01461\n",
      "epoch 604 / 20000\n",
      "gradient norm: 0.09375846991315484, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.01368\n",
      "\tval loss: 0.01457\n",
      "epoch 605 / 20000\n",
      "gradient norm: 0.13214263506233692, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.01363\n",
      "\tval loss: 0.01453\n",
      "epoch 606 / 20000\n",
      "gradient norm: 0.13955880794674158, minimum ratio: 2.507894736842105\n",
      "\ttrain loss: 0.01362\n",
      "\tval loss: 0.01448\n",
      "epoch 607 / 20000\n",
      "gradient norm: 0.08533745782915503, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.01356\n",
      "\tval loss: 0.01444\n",
      "epoch 608 / 20000\n",
      "gradient norm: 0.07627148181200027, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.01353\n",
      "\tval loss: 0.01440\n",
      "epoch 609 / 20000\n",
      "gradient norm: 0.10103318281471729, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.01353\n",
      "\tval loss: 0.01436\n",
      "epoch 610 / 20000\n",
      "gradient norm: 0.1505158527288586, minimum ratio: 2.5105263157894737\n",
      "\ttrain loss: 0.01348\n",
      "\tval loss: 0.01434\n",
      "epoch 611 / 20000\n",
      "gradient norm: 0.12110510538332164, minimum ratio: 2.513157894736842\n",
      "\ttrain loss: 0.01344\n",
      "\tval loss: 0.01428\n",
      "epoch 612 / 20000\n",
      "gradient norm: 0.07714763982221484, minimum ratio: 2.513157894736842\n",
      "\ttrain loss: 0.01339\n",
      "\tval loss: 0.01423\n",
      "epoch 613 / 20000\n",
      "gradient norm: 0.0832341241184622, minimum ratio: 2.5236842105263158\n",
      "\ttrain loss: 0.01338\n",
      "\tval loss: 0.01419\n",
      "epoch 614 / 20000\n",
      "gradient norm: 0.0819503590464592, minimum ratio: 2.5210526315789474\n",
      "\ttrain loss: 0.01331\n",
      "\tval loss: 0.01415\n",
      "epoch 615 / 20000\n",
      "gradient norm: 0.09993619681335986, minimum ratio: 2.5315789473684207\n",
      "\ttrain loss: 0.01329\n",
      "\tval loss: 0.01412\n",
      "epoch 616 / 20000\n",
      "gradient norm: 0.11015484482049942, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.01320\n",
      "\tval loss: 0.01408\n",
      "epoch 617 / 20000\n",
      "gradient norm: 0.09111797297373414, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.01320\n",
      "\tval loss: 0.01403\n",
      "epoch 618 / 20000\n",
      "gradient norm: 0.08582224720157683, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.01314\n",
      "\tval loss: 0.01399\n",
      "epoch 619 / 20000\n",
      "gradient norm: 0.0939785169903189, minimum ratio: 2.51578947368421\n",
      "\ttrain loss: 0.01312\n",
      "\tval loss: 0.01395\n",
      "epoch 620 / 20000\n",
      "gradient norm: 0.15481010102666914, minimum ratio: 2.526315789473684\n",
      "\ttrain loss: 0.01308\n",
      "\tval loss: 0.01391\n",
      "epoch 621 / 20000\n",
      "gradient norm: 0.07296829484403133, minimum ratio: 2.518421052631579\n",
      "\ttrain loss: 0.01304\n",
      "\tval loss: 0.01387\n",
      "epoch 622 / 20000\n",
      "gradient norm: 0.10800546011887491, minimum ratio: 2.5236842105263158\n",
      "\ttrain loss: 0.01302\n",
      "\tval loss: 0.01383\n",
      "epoch 623 / 20000\n",
      "gradient norm: 0.08465217822231352, minimum ratio: 2.5078947368421054\n",
      "\ttrain loss: 0.01296\n",
      "\tval loss: 0.01379\n",
      "epoch 624 / 20000\n",
      "gradient norm: 0.18202412594109774, minimum ratio: 2.5342105263157895\n",
      "\ttrain loss: 0.01296\n",
      "\tval loss: 0.01374\n",
      "epoch 625 / 20000\n",
      "gradient norm: 0.1351471438538283, minimum ratio: 2.5210526315789474\n",
      "\ttrain loss: 0.01292\n",
      "\tval loss: 0.01371\n",
      "epoch 626 / 20000\n",
      "gradient norm: 0.10818452504463494, minimum ratio: 2.5078947368421054\n",
      "\ttrain loss: 0.01291\n",
      "\tval loss: 0.01369\n",
      "epoch 627 / 20000\n",
      "gradient norm: 0.14832339773420244, minimum ratio: 2.5289473684210524\n",
      "\ttrain loss: 0.01285\n",
      "\tval loss: 0.01365\n",
      "epoch 628 / 20000\n",
      "gradient norm: 0.1549408850260079, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.01280\n",
      "\tval loss: 0.01359\n",
      "epoch 629 / 20000\n",
      "gradient norm: 0.07364024594426155, minimum ratio: 2.513157894736842\n",
      "\ttrain loss: 0.01275\n",
      "\tval loss: 0.01355\n",
      "epoch 630 / 20000\n",
      "gradient norm: 0.1687419645022601, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.01274\n",
      "\tval loss: 0.01352\n",
      "epoch 631 / 20000\n",
      "gradient norm: 0.09081432991661131, minimum ratio: 2.507894736842105\n",
      "\ttrain loss: 0.01269\n",
      "\tval loss: 0.01349\n",
      "epoch 632 / 20000\n",
      "gradient norm: 0.137982320622541, minimum ratio: 2.513157894736842\n",
      "\ttrain loss: 0.01265\n",
      "\tval loss: 0.01344\n",
      "epoch 633 / 20000\n",
      "gradient norm: 0.07865953189320862, minimum ratio: 2.5342105263157895\n",
      "\ttrain loss: 0.01262\n",
      "\tval loss: 0.01340\n",
      "epoch 634 / 20000\n",
      "gradient norm: 0.09761907649226487, minimum ratio: 2.505263157894737\n",
      "\ttrain loss: 0.01259\n",
      "\tval loss: 0.01337\n",
      "epoch 635 / 20000\n",
      "gradient norm: 0.13135272916406393, minimum ratio: 2.507894736842105\n",
      "\ttrain loss: 0.01257\n",
      "\tval loss: 0.01333\n",
      "epoch 636 / 20000\n",
      "gradient norm: 0.12402169243432581, minimum ratio: 2.5289473684210524\n",
      "\ttrain loss: 0.01254\n",
      "\tval loss: 0.01329\n",
      "epoch 637 / 20000\n",
      "gradient norm: 0.1435788869857788, minimum ratio: 2.5184210526315787\n",
      "\ttrain loss: 0.01250\n",
      "\tval loss: 0.01326\n",
      "epoch 638 / 20000\n",
      "gradient norm: 0.12114072730764747, minimum ratio: 2.526315789473684\n",
      "\ttrain loss: 0.01246\n",
      "\tval loss: 0.01321\n",
      "epoch 639 / 20000\n",
      "gradient norm: 0.10575543204322457, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.01241\n",
      "\tval loss: 0.01317\n",
      "epoch 640 / 20000\n",
      "gradient norm: 0.12129507446661592, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.01240\n",
      "\tval loss: 0.01314\n",
      "epoch 641 / 20000\n",
      "gradient norm: 0.10076526366174221, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.01236\n",
      "\tval loss: 0.01310\n",
      "epoch 642 / 20000\n",
      "gradient norm: 0.12151107762474567, minimum ratio: 2.515789473684211\n",
      "\ttrain loss: 0.01230\n",
      "\tval loss: 0.01306\n",
      "epoch 643 / 20000\n",
      "gradient norm: 0.0978082506917417, minimum ratio: 2.5\n",
      "\ttrain loss: 0.01229\n",
      "\tval loss: 0.01303\n",
      "epoch 644 / 20000\n",
      "gradient norm: 0.0720402398146689, minimum ratio: 2.5289473684210524\n",
      "\ttrain loss: 0.01225\n",
      "\tval loss: 0.01299\n",
      "epoch 645 / 20000\n",
      "gradient norm: 0.09743361175060272, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.01222\n",
      "\tval loss: 0.01295\n",
      "epoch 646 / 20000\n",
      "gradient norm: 0.1408816697075963, minimum ratio: 2.5105263157894737\n",
      "\ttrain loss: 0.01220\n",
      "\tval loss: 0.01291\n",
      "epoch 647 / 20000\n",
      "gradient norm: 0.09500123397447169, minimum ratio: 2.510526315789474\n",
      "\ttrain loss: 0.01215\n",
      "\tval loss: 0.01288\n",
      "epoch 648 / 20000\n",
      "gradient norm: 0.12414234410971403, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.01212\n",
      "\tval loss: 0.01285\n",
      "epoch 649 / 20000\n",
      "gradient norm: 0.09405987779609859, minimum ratio: 2.513157894736842\n",
      "\ttrain loss: 0.01209\n",
      "\tval loss: 0.01283\n",
      "epoch 650 / 20000\n",
      "gradient norm: 0.07336197863332927, minimum ratio: 2.5\n",
      "\ttrain loss: 0.01206\n",
      "\tval loss: 0.01278\n",
      "epoch 651 / 20000\n",
      "gradient norm: 0.10669835773296654, minimum ratio: 2.518421052631579\n",
      "\ttrain loss: 0.01201\n",
      "\tval loss: 0.01273\n",
      "epoch 652 / 20000\n",
      "gradient norm: 0.09133106435183436, minimum ratio: 2.515789473684211\n",
      "\ttrain loss: 0.01196\n",
      "\tval loss: 0.01270\n",
      "epoch 653 / 20000\n",
      "gradient norm: 0.07718329783529043, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.01196\n",
      "\tval loss: 0.01267\n",
      "epoch 654 / 20000\n",
      "gradient norm: 0.10378377349115908, minimum ratio: 2.5157894736842104\n",
      "\ttrain loss: 0.01193\n",
      "\tval loss: 0.01264\n",
      "epoch 655 / 20000\n",
      "gradient norm: 0.16829038492869586, minimum ratio: 2.526315789473684\n",
      "\ttrain loss: 0.01188\n",
      "\tval loss: 0.01260\n",
      "epoch 656 / 20000\n",
      "gradient norm: 0.08785633160732687, minimum ratio: 2.526315789473684\n",
      "\ttrain loss: 0.01187\n",
      "\tval loss: 0.01256\n",
      "epoch 657 / 20000\n",
      "gradient norm: 0.11484397947788239, minimum ratio: 2.518421052631579\n",
      "\ttrain loss: 0.01181\n",
      "\tval loss: 0.01252\n",
      "epoch 658 / 20000\n",
      "gradient norm: 0.11313264444470406, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.01180\n",
      "\tval loss: 0.01251\n",
      "epoch 659 / 20000\n",
      "gradient norm: 0.11685491516254842, minimum ratio: 2.526315789473684\n",
      "\ttrain loss: 0.01178\n",
      "\tval loss: 0.01248\n",
      "epoch 660 / 20000\n",
      "gradient norm: 0.15047747152857482, minimum ratio: 2.5236842105263158\n",
      "\ttrain loss: 0.01175\n",
      "\tval loss: 0.01242\n",
      "epoch 661 / 20000\n",
      "gradient norm: 0.13057093042880297, minimum ratio: 2.531578947368421\n",
      "\ttrain loss: 0.01172\n",
      "\tval loss: 0.01238\n",
      "epoch 662 / 20000\n",
      "gradient norm: 0.08960912702605128, minimum ratio: 2.526315789473684\n",
      "\ttrain loss: 0.01165\n",
      "\tval loss: 0.01235\n",
      "epoch 663 / 20000\n",
      "gradient norm: 0.057352237519808114, minimum ratio: 2.513157894736842\n",
      "\ttrain loss: 0.01167\n",
      "\tval loss: 0.01232\n",
      "epoch 664 / 20000\n",
      "gradient norm: 0.0961343094240874, minimum ratio: 2.513157894736842\n",
      "\ttrain loss: 0.01162\n",
      "\tval loss: 0.01230\n",
      "epoch 665 / 20000\n",
      "gradient norm: 0.1200196894351393, minimum ratio: 2.526315789473684\n",
      "\ttrain loss: 0.01160\n",
      "\tval loss: 0.01227\n",
      "epoch 666 / 20000\n",
      "gradient norm: 0.07258941419422626, minimum ratio: 2.518421052631579\n",
      "\ttrain loss: 0.01158\n",
      "\tval loss: 0.01222\n",
      "epoch 667 / 20000\n",
      "gradient norm: 0.10836694831959903, minimum ratio: 2.526315789473684\n",
      "\ttrain loss: 0.01154\n",
      "\tval loss: 0.01218\n",
      "epoch 668 / 20000\n",
      "gradient norm: 0.0750965760089457, minimum ratio: 2.526315789473684\n",
      "\ttrain loss: 0.01150\n",
      "\tval loss: 0.01214\n",
      "epoch 669 / 20000\n",
      "gradient norm: 0.08260941039770842, minimum ratio: 2.507894736842105\n",
      "\ttrain loss: 0.01147\n",
      "\tval loss: 0.01212\n",
      "epoch 670 / 20000\n",
      "gradient norm: 0.08434535062406212, minimum ratio: 2.5289473684210524\n",
      "\ttrain loss: 0.01142\n",
      "\tval loss: 0.01209\n",
      "epoch 671 / 20000\n",
      "gradient norm: 0.0914615320507437, minimum ratio: 2.5105263157894737\n",
      "\ttrain loss: 0.01141\n",
      "\tval loss: 0.01206\n",
      "epoch 672 / 20000\n",
      "gradient norm: 0.10513281903695315, minimum ratio: 2.518421052631579\n",
      "\ttrain loss: 0.01138\n",
      "\tval loss: 0.01202\n",
      "epoch 673 / 20000\n",
      "gradient norm: 0.07975918333977461, minimum ratio: 2.5263157894736845\n",
      "\ttrain loss: 0.01135\n",
      "\tval loss: 0.01199\n",
      "epoch 674 / 20000\n",
      "gradient norm: 0.10143314057495445, minimum ratio: 2.5\n",
      "\ttrain loss: 0.01132\n",
      "\tval loss: 0.01194\n",
      "epoch 675 / 20000\n",
      "gradient norm: 0.12161564768757671, minimum ratio: 2.5105263157894737\n",
      "\ttrain loss: 0.01130\n",
      "\tval loss: 0.01192\n",
      "epoch 676 / 20000\n",
      "gradient norm: 0.09827114478684962, minimum ratio: 2.518421052631579\n",
      "\ttrain loss: 0.01127\n",
      "\tval loss: 0.01190\n",
      "epoch 677 / 20000\n",
      "gradient norm: 0.1132822532672435, minimum ratio: 2.492105263157895\n",
      "\ttrain loss: 0.01123\n",
      "\tval loss: 0.01186\n",
      "epoch 678 / 20000\n",
      "gradient norm: 0.1354070238303393, minimum ratio: 2.5078947368421054\n",
      "\ttrain loss: 0.01119\n",
      "\tval loss: 0.01182\n",
      "epoch 679 / 20000\n",
      "gradient norm: 0.08161294320598245, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.01117\n",
      "\tval loss: 0.01179\n",
      "epoch 680 / 20000\n",
      "gradient norm: 0.06276572833303362, minimum ratio: 2.526315789473684\n",
      "\ttrain loss: 0.01115\n",
      "\tval loss: 0.01176\n",
      "epoch 681 / 20000\n",
      "gradient norm: 0.09606285998597741, minimum ratio: 2.507894736842106\n",
      "\ttrain loss: 0.01112\n",
      "\tval loss: 0.01173\n",
      "epoch 682 / 20000\n",
      "gradient norm: 0.08154604432638735, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.01108\n",
      "\tval loss: 0.01171\n",
      "epoch 683 / 20000\n",
      "gradient norm: 0.07148225582204759, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.01106\n",
      "\tval loss: 0.01167\n",
      "epoch 684 / 20000\n",
      "gradient norm: 0.05992433475330472, minimum ratio: 2.518421052631579\n",
      "\ttrain loss: 0.01102\n",
      "\tval loss: 0.01163\n",
      "epoch 685 / 20000\n",
      "gradient norm: 0.05408513022121042, minimum ratio: 2.492105263157895\n",
      "\ttrain loss: 0.01101\n",
      "\tval loss: 0.01160\n",
      "epoch 686 / 20000\n",
      "gradient norm: 0.08629539818502963, minimum ratio: 2.5368421052631582\n",
      "\ttrain loss: 0.01100\n",
      "\tval loss: 0.01157\n",
      "epoch 687 / 20000\n",
      "gradient norm: 0.05204841622617096, minimum ratio: 2.518421052631579\n",
      "\ttrain loss: 0.01093\n",
      "\tval loss: 0.01154\n",
      "epoch 688 / 20000\n",
      "gradient norm: 0.07050240761600435, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.01091\n",
      "\tval loss: 0.01151\n",
      "epoch 689 / 20000\n",
      "gradient norm: 0.059517156914807856, minimum ratio: 2.526315789473684\n",
      "\ttrain loss: 0.01087\n",
      "\tval loss: 0.01149\n",
      "epoch 690 / 20000\n",
      "gradient norm: 0.1498223035596311, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.01088\n",
      "\tval loss: 0.01146\n",
      "epoch 691 / 20000\n",
      "gradient norm: 0.09583550633396953, minimum ratio: 2.531578947368421\n",
      "\ttrain loss: 0.01084\n",
      "\tval loss: 0.01142\n",
      "epoch 692 / 20000\n",
      "gradient norm: 0.07072571432217956, minimum ratio: 2.544736842105263\n",
      "\ttrain loss: 0.01083\n",
      "\tval loss: 0.01138\n",
      "epoch 693 / 20000\n",
      "gradient norm: 0.11392963456455618, minimum ratio: 2.526315789473684\n",
      "\ttrain loss: 0.01079\n",
      "\tval loss: 0.01136\n",
      "epoch 694 / 20000\n",
      "gradient norm: 0.0820327929686755, minimum ratio: 2.5236842105263158\n",
      "\ttrain loss: 0.01075\n",
      "\tval loss: 0.01132\n",
      "epoch 695 / 20000\n",
      "gradient norm: 0.09429849125444889, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.01074\n",
      "\tval loss: 0.01129\n",
      "epoch 696 / 20000\n",
      "gradient norm: 0.06248587684240192, minimum ratio: 2.5210526315789474\n",
      "\ttrain loss: 0.01071\n",
      "\tval loss: 0.01127\n",
      "epoch 697 / 20000\n",
      "gradient norm: 0.10731664532795548, minimum ratio: 2.5105263157894737\n",
      "\ttrain loss: 0.01069\n",
      "\tval loss: 0.01125\n",
      "epoch 698 / 20000\n",
      "gradient norm: 0.08748366602230817, minimum ratio: 2.513157894736842\n",
      "\ttrain loss: 0.01065\n",
      "\tval loss: 0.01121\n",
      "epoch 699 / 20000\n",
      "gradient norm: 0.0808331014122814, minimum ratio: 2.536842105263158\n",
      "\ttrain loss: 0.01063\n",
      "\tval loss: 0.01117\n",
      "epoch 700 / 20000\n",
      "gradient norm: 0.05338350892998278, minimum ratio: 2.5236842105263158\n",
      "\ttrain loss: 0.01058\n",
      "\tval loss: 0.01114\n",
      "epoch 701 / 20000\n",
      "gradient norm: 0.054278901778161526, minimum ratio: 2.5157894736842104\n",
      "\ttrain loss: 0.01057\n",
      "\tval loss: 0.01112\n",
      "epoch 702 / 20000\n",
      "gradient norm: 0.05936564854346216, minimum ratio: 2.5342105263157895\n",
      "\ttrain loss: 0.01056\n",
      "\tval loss: 0.01109\n",
      "epoch 703 / 20000\n",
      "gradient norm: 0.13721371162682772, minimum ratio: 2.5078947368421054\n",
      "\ttrain loss: 0.01052\n",
      "\tval loss: 0.01106\n",
      "epoch 704 / 20000\n",
      "gradient norm: 0.10411822074092925, minimum ratio: 2.5236842105263158\n",
      "\ttrain loss: 0.01052\n",
      "\tval loss: 0.01103\n",
      "epoch 705 / 20000\n",
      "gradient norm: 0.05694633210077882, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.01047\n",
      "\tval loss: 0.01101\n",
      "epoch 706 / 20000\n",
      "gradient norm: 0.13318879576399922, minimum ratio: 2.531578947368421\n",
      "\ttrain loss: 0.01045\n",
      "\tval loss: 0.01097\n",
      "epoch 707 / 20000\n",
      "gradient norm: 0.11653985921293497, minimum ratio: 2.5105263157894733\n",
      "\ttrain loss: 0.01040\n",
      "\tval loss: 0.01094\n",
      "epoch 708 / 20000\n",
      "gradient norm: 0.08680553815793246, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.01039\n",
      "\tval loss: 0.01092\n",
      "epoch 709 / 20000\n",
      "gradient norm: 0.08661060873419046, minimum ratio: 2.513157894736842\n",
      "\ttrain loss: 0.01037\n",
      "\tval loss: 0.01090\n",
      "epoch 710 / 20000\n",
      "gradient norm: 0.10931205353699625, minimum ratio: 2.5105263157894737\n",
      "\ttrain loss: 0.01033\n",
      "\tval loss: 0.01087\n",
      "epoch 711 / 20000\n",
      "gradient norm: 0.12299536843784153, minimum ratio: 2.526315789473684\n",
      "\ttrain loss: 0.01034\n",
      "\tval loss: 0.01083\n",
      "epoch 712 / 20000\n",
      "gradient norm: 0.08401964814402163, minimum ratio: 2.5289473684210524\n",
      "\ttrain loss: 0.01030\n",
      "\tval loss: 0.01080\n",
      "epoch 713 / 20000\n",
      "gradient norm: 0.11414609372150153, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.01025\n",
      "\tval loss: 0.01077\n",
      "epoch 714 / 20000\n",
      "gradient norm: 0.11111164907924831, minimum ratio: 2.518421052631579\n",
      "\ttrain loss: 0.01024\n",
      "\tval loss: 0.01074\n",
      "epoch 715 / 20000\n",
      "gradient norm: 0.06898434017784894, minimum ratio: 2.531578947368421\n",
      "\ttrain loss: 0.01024\n",
      "\tval loss: 0.01073\n",
      "epoch 716 / 20000\n",
      "gradient norm: 0.1105389662552625, minimum ratio: 2.5289473684210524\n",
      "\ttrain loss: 0.01020\n",
      "\tval loss: 0.01070\n",
      "epoch 717 / 20000\n",
      "gradient norm: 0.08345177862793207, minimum ratio: 2.518421052631579\n",
      "\ttrain loss: 0.01018\n",
      "\tval loss: 0.01067\n",
      "epoch 718 / 20000\n",
      "gradient norm: 0.08586239535361528, minimum ratio: 2.5552631578947373\n",
      "\ttrain loss: 0.01015\n",
      "\tval loss: 0.01065\n",
      "epoch 719 / 20000\n",
      "gradient norm: 0.08502115833107382, minimum ratio: 2.5289473684210524\n",
      "\ttrain loss: 0.01013\n",
      "\tval loss: 0.01061\n",
      "epoch 720 / 20000\n",
      "gradient norm: 0.08349851320963353, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.01011\n",
      "\tval loss: 0.01058\n",
      "epoch 721 / 20000\n",
      "gradient norm: 0.14333025948144495, minimum ratio: 2.5210526315789474\n",
      "\ttrain loss: 0.01008\n",
      "\tval loss: 0.01057\n",
      "epoch 722 / 20000\n",
      "gradient norm: 0.07596992386970669, minimum ratio: 2.5078947368421054\n",
      "\ttrain loss: 0.01008\n",
      "\tval loss: 0.01054\n",
      "epoch 723 / 20000\n",
      "gradient norm: 0.089634049218148, minimum ratio: 2.5210526315789474\n",
      "\ttrain loss: 0.01004\n",
      "\tval loss: 0.01050\n",
      "epoch 724 / 20000\n",
      "gradient norm: 0.05891607329249382, minimum ratio: 2.5105263157894733\n",
      "\ttrain loss: 0.01000\n",
      "\tval loss: 0.01047\n",
      "epoch 725 / 20000\n",
      "gradient norm: 0.0834402609616518, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00997\n",
      "\tval loss: 0.01046\n",
      "epoch 726 / 20000\n",
      "gradient norm: 0.11258397926576436, minimum ratio: 2.5236842105263158\n",
      "\ttrain loss: 0.00995\n",
      "\tval loss: 0.01043\n",
      "epoch 727 / 20000\n",
      "gradient norm: 0.06957336387131363, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00996\n",
      "\tval loss: 0.01040\n",
      "epoch 728 / 20000\n",
      "gradient norm: 0.09948605147656053, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00990\n",
      "\tval loss: 0.01037\n",
      "epoch 729 / 20000\n",
      "gradient norm: 0.13129623921122402, minimum ratio: 2.507894736842105\n",
      "\ttrain loss: 0.00991\n",
      "\tval loss: 0.01034\n",
      "epoch 730 / 20000\n",
      "gradient norm: 0.06423418701160699, minimum ratio: 2.518421052631579\n",
      "\ttrain loss: 0.00987\n",
      "\tval loss: 0.01032\n",
      "epoch 731 / 20000\n",
      "gradient norm: 0.06457725202199072, minimum ratio: 2.526315789473684\n",
      "\ttrain loss: 0.00985\n",
      "\tval loss: 0.01031\n",
      "epoch 732 / 20000\n",
      "gradient norm: 0.057812231476418674, minimum ratio: 2.5315789473684207\n",
      "\ttrain loss: 0.00983\n",
      "\tval loss: 0.01028\n",
      "epoch 733 / 20000\n",
      "gradient norm: 0.06330236466601491, minimum ratio: 2.5078947368421054\n",
      "\ttrain loss: 0.00980\n",
      "\tval loss: 0.01024\n",
      "epoch 734 / 20000\n",
      "gradient norm: 0.11860814574174583, minimum ratio: 2.515789473684211\n",
      "\ttrain loss: 0.00977\n",
      "\tval loss: 0.01021\n",
      "epoch 735 / 20000\n",
      "gradient norm: 0.055527167627587914, minimum ratio: 2.526315789473684\n",
      "\ttrain loss: 0.00977\n",
      "\tval loss: 0.01020\n",
      "epoch 736 / 20000\n",
      "gradient norm: 0.11459124379325658, minimum ratio: 2.5342105263157895\n",
      "\ttrain loss: 0.00974\n",
      "\tval loss: 0.01017\n",
      "epoch 737 / 20000\n",
      "gradient norm: 0.07076710660476238, minimum ratio: 2.539473684210526\n",
      "\ttrain loss: 0.00970\n",
      "\tval loss: 0.01016\n",
      "epoch 738 / 20000\n",
      "gradient norm: 0.07697796786669642, minimum ratio: 2.5394736842105265\n",
      "\ttrain loss: 0.00971\n",
      "\tval loss: 0.01013\n",
      "epoch 739 / 20000\n",
      "gradient norm: 0.10401670332066715, minimum ratio: 2.5078947368421054\n",
      "\ttrain loss: 0.00966\n",
      "\tval loss: 0.01009\n",
      "epoch 740 / 20000\n",
      "gradient norm: 0.059677479322999716, minimum ratio: 2.534210526315789\n",
      "\ttrain loss: 0.00964\n",
      "\tval loss: 0.01007\n",
      "epoch 741 / 20000\n",
      "gradient norm: 0.08738601964432746, minimum ratio: 2.5210526315789474\n",
      "\ttrain loss: 0.00962\n",
      "\tval loss: 0.01005\n",
      "epoch 742 / 20000\n",
      "gradient norm: 0.0643528988584876, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00960\n",
      "\tval loss: 0.01003\n",
      "epoch 743 / 20000\n",
      "gradient norm: 0.13314886740408838, minimum ratio: 2.5421052631578944\n",
      "\ttrain loss: 0.00958\n",
      "\tval loss: 0.01000\n",
      "epoch 744 / 20000\n",
      "gradient norm: 0.07269882154650986, minimum ratio: 2.5342105263157895\n",
      "\ttrain loss: 0.00956\n",
      "\tval loss: 0.00998\n",
      "epoch 745 / 20000\n",
      "gradient norm: 0.0638684097211808, minimum ratio: 2.534210526315789\n",
      "\ttrain loss: 0.00954\n",
      "\tval loss: 0.00996\n",
      "epoch 746 / 20000\n",
      "gradient norm: 0.16129603330045938, minimum ratio: 2.5605263157894735\n",
      "\ttrain loss: 0.00951\n",
      "\tval loss: 0.00994\n",
      "epoch 747 / 20000\n",
      "gradient norm: 0.09663920395541936, minimum ratio: 2.518421052631579\n",
      "\ttrain loss: 0.00950\n",
      "\tval loss: 0.00989\n",
      "epoch 748 / 20000\n",
      "gradient norm: 0.0975523196393624, minimum ratio: 2.526315789473684\n",
      "\ttrain loss: 0.00947\n",
      "\tval loss: 0.00987\n",
      "epoch 749 / 20000\n",
      "gradient norm: 0.07792065595276654, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00945\n",
      "\tval loss: 0.00986\n",
      "epoch 750 / 20000\n",
      "gradient norm: 0.08045945013873279, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.00944\n",
      "\tval loss: 0.00984\n",
      "epoch 751 / 20000\n",
      "gradient norm: 0.07886116835288703, minimum ratio: 2.507894736842105\n",
      "\ttrain loss: 0.00939\n",
      "\tval loss: 0.00982\n",
      "epoch 752 / 20000\n",
      "gradient norm: 0.13147021480835974, minimum ratio: 2.5157894736842104\n",
      "\ttrain loss: 0.00939\n",
      "\tval loss: 0.00979\n",
      "epoch 753 / 20000\n",
      "gradient norm: 0.07359345245640725, minimum ratio: 2.518421052631579\n",
      "\ttrain loss: 0.00938\n",
      "\tval loss: 0.00976\n",
      "epoch 754 / 20000\n",
      "gradient norm: 0.107264255406335, minimum ratio: 2.5289473684210524\n",
      "\ttrain loss: 0.00933\n",
      "\tval loss: 0.00974\n",
      "epoch 755 / 20000\n",
      "gradient norm: 0.12914505111984909, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00932\n",
      "\tval loss: 0.00973\n",
      "epoch 756 / 20000\n",
      "gradient norm: 0.07830046699382365, minimum ratio: 2.526315789473684\n",
      "\ttrain loss: 0.00931\n",
      "\tval loss: 0.00969\n",
      "epoch 757 / 20000\n",
      "gradient norm: 0.07353448960930109, minimum ratio: 2.510526315789474\n",
      "\ttrain loss: 0.00929\n",
      "\tval loss: 0.00967\n",
      "epoch 758 / 20000\n",
      "gradient norm: 0.09229375084396452, minimum ratio: 2.5105263157894737\n",
      "\ttrain loss: 0.00926\n",
      "\tval loss: 0.00965\n",
      "epoch 759 / 20000\n",
      "gradient norm: 0.08819074556231499, minimum ratio: 2.5368421052631582\n",
      "\ttrain loss: 0.00925\n",
      "\tval loss: 0.00963\n",
      "epoch 760 / 20000\n",
      "gradient norm: 0.05471637786831707, minimum ratio: 2.515789473684211\n",
      "\ttrain loss: 0.00922\n",
      "\tval loss: 0.00961\n",
      "epoch 761 / 20000\n",
      "gradient norm: 0.08667018357664347, minimum ratio: 2.53421052631579\n",
      "\ttrain loss: 0.00921\n",
      "\tval loss: 0.00959\n",
      "epoch 762 / 20000\n",
      "gradient norm: 0.104165208642371, minimum ratio: 2.5105263157894737\n",
      "\ttrain loss: 0.00918\n",
      "\tval loss: 0.00957\n",
      "epoch 763 / 20000\n",
      "gradient norm: 0.13438695017248392, minimum ratio: 2.507894736842105\n",
      "\ttrain loss: 0.00918\n",
      "\tval loss: 0.00953\n",
      "epoch 764 / 20000\n",
      "gradient norm: 0.09778003476094455, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00914\n",
      "\tval loss: 0.00951\n",
      "epoch 765 / 20000\n",
      "gradient norm: 0.1285304413177073, minimum ratio: 2.5236842105263158\n",
      "\ttrain loss: 0.00913\n",
      "\tval loss: 0.00950\n",
      "epoch 766 / 20000\n",
      "gradient norm: 0.14098319865297526, minimum ratio: 2.5078947368421054\n",
      "\ttrain loss: 0.00914\n",
      "\tval loss: 0.00948\n",
      "epoch 767 / 20000\n",
      "gradient norm: 0.07292123488150537, minimum ratio: 2.5236842105263158\n",
      "\ttrain loss: 0.00910\n",
      "\tval loss: 0.00947\n",
      "epoch 768 / 20000\n",
      "gradient norm: 0.10604825569316745, minimum ratio: 2.5078947368421054\n",
      "\ttrain loss: 0.00907\n",
      "\tval loss: 0.00945\n",
      "epoch 769 / 20000\n",
      "gradient norm: 0.06501835293602198, minimum ratio: 2.505263157894737\n",
      "\ttrain loss: 0.00905\n",
      "\tval loss: 0.00942\n",
      "epoch 770 / 20000\n",
      "gradient norm: 0.11865645146463066, minimum ratio: 2.518421052631579\n",
      "\ttrain loss: 0.00903\n",
      "\tval loss: 0.00938\n",
      "epoch 771 / 20000\n",
      "gradient norm: 0.12542707426473498, minimum ratio: 2.505263157894737\n",
      "\ttrain loss: 0.00904\n",
      "\tval loss: 0.00936\n",
      "epoch 772 / 20000\n",
      "gradient norm: 0.08608604117762297, minimum ratio: 2.526315789473684\n",
      "\ttrain loss: 0.00901\n",
      "\tval loss: 0.00936\n",
      "epoch 773 / 20000\n",
      "gradient norm: 0.1055684630991891, minimum ratio: 2.5236842105263158\n",
      "\ttrain loss: 0.00899\n",
      "\tval loss: 0.00933\n",
      "epoch 774 / 20000\n",
      "gradient norm: 0.11366015090607107, minimum ratio: 2.526315789473684\n",
      "\ttrain loss: 0.00896\n",
      "\tval loss: 0.00931\n",
      "epoch 775 / 20000\n",
      "gradient norm: 0.14354410185478628, minimum ratio: 2.5210526315789474\n",
      "\ttrain loss: 0.00897\n",
      "\tval loss: 0.00928\n",
      "epoch 776 / 20000\n",
      "gradient norm: 0.12604611029382795, minimum ratio: 2.5131578947368425\n",
      "\ttrain loss: 0.00893\n",
      "\tval loss: 0.00927\n",
      "epoch 777 / 20000\n",
      "gradient norm: 0.093030990450643, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00892\n",
      "\tval loss: 0.00925\n",
      "epoch 778 / 20000\n",
      "gradient norm: 0.11815130349714309, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00889\n",
      "\tval loss: 0.00924\n",
      "epoch 779 / 20000\n",
      "gradient norm: 0.11271558492444456, minimum ratio: 2.5236842105263158\n",
      "\ttrain loss: 0.00888\n",
      "\tval loss: 0.00921\n",
      "epoch 780 / 20000\n",
      "gradient norm: 0.07821339217480272, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00885\n",
      "\tval loss: 0.00918\n",
      "epoch 781 / 20000\n",
      "gradient norm: 0.05387056968174875, minimum ratio: 2.526315789473684\n",
      "\ttrain loss: 0.00884\n",
      "\tval loss: 0.00916\n",
      "epoch 782 / 20000\n",
      "gradient norm: 0.06984484323766083, minimum ratio: 2.515789473684211\n",
      "\ttrain loss: 0.00882\n",
      "\tval loss: 0.00915\n",
      "epoch 783 / 20000\n",
      "gradient norm: 0.046702268766239285, minimum ratio: 2.5210526315789474\n",
      "\ttrain loss: 0.00880\n",
      "\tval loss: 0.00913\n",
      "epoch 784 / 20000\n",
      "gradient norm: 0.0989991124952212, minimum ratio: 2.5315789473684207\n",
      "\ttrain loss: 0.00877\n",
      "\tval loss: 0.00911\n",
      "epoch 785 / 20000\n",
      "gradient norm: 0.050242460682056844, minimum ratio: 2.5210526315789474\n",
      "\ttrain loss: 0.00876\n",
      "\tval loss: 0.00909\n",
      "epoch 786 / 20000\n",
      "gradient norm: 0.16318303951993585, minimum ratio: 2.534210526315789\n",
      "\ttrain loss: 0.00876\n",
      "\tval loss: 0.00905\n",
      "epoch 787 / 20000\n",
      "gradient norm: 0.052493830560706556, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00874\n",
      "\tval loss: 0.00905\n",
      "epoch 788 / 20000\n",
      "gradient norm: 0.08667857991531491, minimum ratio: 2.536842105263158\n",
      "\ttrain loss: 0.00872\n",
      "\tval loss: 0.00903\n",
      "epoch 789 / 20000\n",
      "gradient norm: 0.06651890289504081, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00869\n",
      "\tval loss: 0.00901\n",
      "epoch 790 / 20000\n",
      "gradient norm: 0.09898646036162972, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.00868\n",
      "\tval loss: 0.00900\n",
      "epoch 791 / 20000\n",
      "gradient norm: 0.14587086357641965, minimum ratio: 2.513157894736842\n",
      "\ttrain loss: 0.00870\n",
      "\tval loss: 0.00896\n",
      "epoch 792 / 20000\n",
      "gradient norm: 0.06025892775505781, minimum ratio: 2.5342105263157895\n",
      "\ttrain loss: 0.00864\n",
      "\tval loss: 0.00895\n",
      "epoch 793 / 20000\n",
      "gradient norm: 0.08624057366978377, minimum ratio: 2.526315789473684\n",
      "\ttrain loss: 0.00865\n",
      "\tval loss: 0.00893\n",
      "epoch 794 / 20000\n",
      "gradient norm: 0.1068531007040292, minimum ratio: 2.5078947368421054\n",
      "\ttrain loss: 0.00860\n",
      "\tval loss: 0.00893\n",
      "epoch 795 / 20000\n",
      "gradient norm: 0.09008940891362727, minimum ratio: 2.5315789473684207\n",
      "\ttrain loss: 0.00860\n",
      "\tval loss: 0.00889\n",
      "epoch 796 / 20000\n",
      "gradient norm: 0.0867331379558891, minimum ratio: 2.5394736842105265\n",
      "\ttrain loss: 0.00860\n",
      "\tval loss: 0.00887\n",
      "epoch 797 / 20000\n",
      "gradient norm: 0.08269321790430695, minimum ratio: 2.5210526315789474\n",
      "\ttrain loss: 0.00859\n",
      "\tval loss: 0.00886\n",
      "epoch 798 / 20000\n",
      "gradient norm: 0.12721280532423407, minimum ratio: 2.515789473684211\n",
      "\ttrain loss: 0.00856\n",
      "\tval loss: 0.00886\n",
      "epoch 799 / 20000\n",
      "gradient norm: 0.07901885570026934, minimum ratio: 2.534210526315789\n",
      "\ttrain loss: 0.00854\n",
      "\tval loss: 0.00883\n",
      "epoch 800 / 20000\n",
      "gradient norm: 0.05515934934373945, minimum ratio: 2.5289473684210524\n",
      "\ttrain loss: 0.00853\n",
      "\tval loss: 0.00880\n",
      "epoch 801 / 20000\n",
      "gradient norm: 0.05361902015283704, minimum ratio: 2.515789473684211\n",
      "\ttrain loss: 0.00851\n",
      "\tval loss: 0.00877\n",
      "epoch 802 / 20000\n",
      "gradient norm: 0.1080790488049388, minimum ratio: 2.515789473684211\n",
      "\ttrain loss: 0.00850\n",
      "\tval loss: 0.00877\n",
      "epoch 803 / 20000\n",
      "gradient norm: 0.07327485724817961, minimum ratio: 2.5236842105263158\n",
      "\ttrain loss: 0.00847\n",
      "\tval loss: 0.00875\n",
      "epoch 804 / 20000\n",
      "gradient norm: 0.08019667491316795, minimum ratio: 2.5473684210526315\n",
      "\ttrain loss: 0.00846\n",
      "\tval loss: 0.00874\n",
      "epoch 805 / 20000\n",
      "gradient norm: 0.07012184534687549, minimum ratio: 2.5078947368421054\n",
      "\ttrain loss: 0.00842\n",
      "\tval loss: 0.00871\n",
      "epoch 806 / 20000\n",
      "gradient norm: 0.09199699608143419, minimum ratio: 2.513157894736842\n",
      "\ttrain loss: 0.00844\n",
      "\tval loss: 0.00869\n",
      "epoch 807 / 20000\n",
      "gradient norm: 0.06023020145948976, minimum ratio: 2.5157894736842104\n",
      "\ttrain loss: 0.00841\n",
      "\tval loss: 0.00868\n",
      "epoch 808 / 20000\n",
      "gradient norm: 0.06224235822446644, minimum ratio: 2.518421052631579\n",
      "\ttrain loss: 0.00839\n",
      "\tval loss: 0.00866\n",
      "epoch 809 / 20000\n",
      "gradient norm: 0.05630517454119399, minimum ratio: 2.526315789473684\n",
      "\ttrain loss: 0.00839\n",
      "\tval loss: 0.00865\n",
      "epoch 810 / 20000\n",
      "gradient norm: 0.0667623316985555, minimum ratio: 2.5342105263157895\n",
      "\ttrain loss: 0.00837\n",
      "\tval loss: 0.00863\n",
      "epoch 811 / 20000\n",
      "gradient norm: 0.16273391840513796, minimum ratio: 2.518421052631579\n",
      "\ttrain loss: 0.00836\n",
      "\tval loss: 0.00862\n",
      "epoch 812 / 20000\n",
      "gradient norm: 0.10552175750490278, minimum ratio: 2.5289473684210524\n",
      "\ttrain loss: 0.00835\n",
      "\tval loss: 0.00858\n",
      "epoch 813 / 20000\n",
      "gradient norm: 0.10641236579976976, minimum ratio: 2.4894736842105267\n",
      "\ttrain loss: 0.00833\n",
      "\tval loss: 0.00856\n",
      "epoch 814 / 20000\n",
      "gradient norm: 0.08260265114950016, minimum ratio: 2.507894736842105\n",
      "\ttrain loss: 0.00831\n",
      "\tval loss: 0.00856\n",
      "epoch 815 / 20000\n",
      "gradient norm: 0.06969763722736388, minimum ratio: 2.5105263157894737\n",
      "\ttrain loss: 0.00830\n",
      "\tval loss: 0.00855\n",
      "epoch 816 / 20000\n",
      "gradient norm: 0.10036135045811534, minimum ratio: 2.513157894736842\n",
      "\ttrain loss: 0.00828\n",
      "\tval loss: 0.00853\n",
      "epoch 817 / 20000\n",
      "gradient norm: 0.06141434400342405, minimum ratio: 2.534210526315789\n",
      "\ttrain loss: 0.00826\n",
      "\tval loss: 0.00850\n",
      "epoch 818 / 20000\n",
      "gradient norm: 0.05474993196548894, minimum ratio: 2.5315789473684207\n",
      "\ttrain loss: 0.00825\n",
      "\tval loss: 0.00848\n",
      "epoch 819 / 20000\n",
      "gradient norm: 0.08158565533813089, minimum ratio: 2.5105263157894737\n",
      "\ttrain loss: 0.00824\n",
      "\tval loss: 0.00846\n",
      "epoch 820 / 20000\n",
      "gradient norm: 0.10667935071978718, minimum ratio: 2.5210526315789474\n",
      "\ttrain loss: 0.00822\n",
      "\tval loss: 0.00846\n",
      "epoch 821 / 20000\n",
      "gradient norm: 0.04123761900700629, minimum ratio: 2.5236842105263158\n",
      "\ttrain loss: 0.00820\n",
      "\tval loss: 0.00844\n",
      "epoch 822 / 20000\n",
      "gradient norm: 0.0918830104637891, minimum ratio: 2.5184210526315787\n",
      "\ttrain loss: 0.00819\n",
      "\tval loss: 0.00842\n",
      "epoch 823 / 20000\n",
      "gradient norm: 0.06240349332801998, minimum ratio: 2.526315789473684\n",
      "\ttrain loss: 0.00819\n",
      "\tval loss: 0.00840\n",
      "epoch 824 / 20000\n",
      "gradient norm: 0.11085951363202184, minimum ratio: 2.526315789473684\n",
      "\ttrain loss: 0.00817\n",
      "\tval loss: 0.00838\n",
      "epoch 825 / 20000\n",
      "gradient norm: 0.04030177625827491, minimum ratio: 2.5210526315789474\n",
      "\ttrain loss: 0.00815\n",
      "\tval loss: 0.00837\n",
      "epoch 826 / 20000\n",
      "gradient norm: 0.07218511262908578, minimum ratio: 2.528947368421053\n",
      "\ttrain loss: 0.00814\n",
      "\tval loss: 0.00836\n",
      "epoch 827 / 20000\n",
      "gradient norm: 0.07358135492540896, minimum ratio: 2.5236842105263158\n",
      "\ttrain loss: 0.00811\n",
      "\tval loss: 0.00835\n",
      "epoch 828 / 20000\n",
      "gradient norm: 0.040501443087123334, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00811\n",
      "\tval loss: 0.00832\n",
      "epoch 829 / 20000\n",
      "gradient norm: 0.07854233833495528, minimum ratio: 2.5236842105263158\n",
      "\ttrain loss: 0.00809\n",
      "\tval loss: 0.00830\n",
      "epoch 830 / 20000\n",
      "gradient norm: 0.08379269321449101, minimum ratio: 2.526315789473684\n",
      "\ttrain loss: 0.00810\n",
      "\tval loss: 0.00828\n",
      "epoch 831 / 20000\n",
      "gradient norm: 0.07680910755880177, minimum ratio: 2.5315789473684207\n",
      "\ttrain loss: 0.00808\n",
      "\tval loss: 0.00828\n",
      "epoch 832 / 20000\n",
      "gradient norm: 0.06272020551841706, minimum ratio: 2.542105263157895\n",
      "\ttrain loss: 0.00806\n",
      "\tval loss: 0.00827\n",
      "epoch 833 / 20000\n",
      "gradient norm: 0.1006509989965707, minimum ratio: 2.515789473684211\n",
      "\ttrain loss: 0.00804\n",
      "\tval loss: 0.00824\n",
      "epoch 834 / 20000\n",
      "gradient norm: 0.05740735586732626, minimum ratio: 2.531578947368421\n",
      "\ttrain loss: 0.00803\n",
      "\tval loss: 0.00822\n",
      "epoch 835 / 20000\n",
      "gradient norm: 0.04856179642956704, minimum ratio: 2.536842105263158\n",
      "\ttrain loss: 0.00800\n",
      "\tval loss: 0.00822\n",
      "epoch 836 / 20000\n",
      "gradient norm: 0.11482948996126652, minimum ratio: 2.5184210526315787\n",
      "\ttrain loss: 0.00800\n",
      "\tval loss: 0.00820\n",
      "epoch 837 / 20000\n",
      "gradient norm: 0.03965545538812876, minimum ratio: 2.5131578947368425\n",
      "\ttrain loss: 0.00799\n",
      "\tval loss: 0.00818\n",
      "epoch 838 / 20000\n",
      "gradient norm: 0.08716917084529996, minimum ratio: 2.5289473684210524\n",
      "\ttrain loss: 0.00797\n",
      "\tval loss: 0.00816\n",
      "epoch 839 / 20000\n",
      "gradient norm: 0.08522282668855041, minimum ratio: 2.5342105263157895\n",
      "\ttrain loss: 0.00796\n",
      "\tval loss: 0.00816\n",
      "epoch 840 / 20000\n",
      "gradient norm: 0.1695337921846658, minimum ratio: 2.518421052631579\n",
      "\ttrain loss: 0.00794\n",
      "\tval loss: 0.00814\n",
      "epoch 841 / 20000\n",
      "gradient norm: 0.08679342566756532, minimum ratio: 2.5473684210526315\n",
      "\ttrain loss: 0.00795\n",
      "\tval loss: 0.00813\n",
      "epoch 842 / 20000\n",
      "gradient norm: 0.10506449965760112, minimum ratio: 2.5157894736842104\n",
      "\ttrain loss: 0.00791\n",
      "\tval loss: 0.00810\n",
      "epoch 843 / 20000\n",
      "gradient norm: 0.066819166415371, minimum ratio: 2.5210526315789474\n",
      "\ttrain loss: 0.00790\n",
      "\tval loss: 0.00808\n",
      "epoch 844 / 20000\n",
      "gradient norm: 0.04365430842153728, minimum ratio: 2.5105263157894733\n",
      "\ttrain loss: 0.00790\n",
      "\tval loss: 0.00808\n",
      "epoch 845 / 20000\n",
      "gradient norm: 0.06245427438989282, minimum ratio: 2.5289473684210524\n",
      "\ttrain loss: 0.00789\n",
      "\tval loss: 0.00807\n",
      "epoch 846 / 20000\n",
      "gradient norm: 0.10802265605889261, minimum ratio: 2.5157894736842104\n",
      "\ttrain loss: 0.00786\n",
      "\tval loss: 0.00806\n",
      "epoch 847 / 20000\n",
      "gradient norm: 0.10165448137558997, minimum ratio: 2.5157894736842104\n",
      "\ttrain loss: 0.00786\n",
      "\tval loss: 0.00803\n",
      "epoch 848 / 20000\n",
      "gradient norm: 0.08014030347112566, minimum ratio: 2.5078947368421054\n",
      "\ttrain loss: 0.00784\n",
      "\tval loss: 0.00801\n",
      "epoch 849 / 20000\n",
      "gradient norm: 0.07827858440577984, minimum ratio: 2.515789473684211\n",
      "\ttrain loss: 0.00783\n",
      "\tval loss: 0.00799\n",
      "epoch 850 / 20000\n",
      "gradient norm: 0.06361728289630264, minimum ratio: 2.5105263157894737\n",
      "\ttrain loss: 0.00782\n",
      "\tval loss: 0.00799\n",
      "epoch 851 / 20000\n",
      "gradient norm: 0.10115460731321946, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00780\n",
      "\tval loss: 0.00798\n",
      "epoch 852 / 20000\n",
      "gradient norm: 0.054805454914458096, minimum ratio: 2.5078947368421054\n",
      "\ttrain loss: 0.00779\n",
      "\tval loss: 0.00796\n",
      "epoch 853 / 20000\n",
      "gradient norm: 0.09298662550281733, minimum ratio: 2.5210526315789474\n",
      "\ttrain loss: 0.00779\n",
      "\tval loss: 0.00794\n",
      "epoch 854 / 20000\n",
      "gradient norm: 0.09875267487950623, minimum ratio: 2.528947368421053\n",
      "\ttrain loss: 0.00777\n",
      "\tval loss: 0.00792\n",
      "epoch 855 / 20000\n",
      "gradient norm: 0.10006948537193239, minimum ratio: 2.5210526315789474\n",
      "\ttrain loss: 0.00776\n",
      "\tval loss: 0.00792\n",
      "epoch 856 / 20000\n",
      "gradient norm: 0.08118887495948002, minimum ratio: 2.5210526315789474\n",
      "\ttrain loss: 0.00774\n",
      "\tval loss: 0.00790\n",
      "epoch 857 / 20000\n",
      "gradient norm: 0.07814450818113983, minimum ratio: 2.5157894736842104\n",
      "\ttrain loss: 0.00774\n",
      "\tval loss: 0.00789\n",
      "epoch 858 / 20000\n",
      "gradient norm: 0.04880514496471733, minimum ratio: 2.5131578947368425\n",
      "\ttrain loss: 0.00771\n",
      "\tval loss: 0.00787\n",
      "epoch 859 / 20000\n",
      "gradient norm: 0.04054687259485945, minimum ratio: 2.5342105263157895\n",
      "\ttrain loss: 0.00769\n",
      "\tval loss: 0.00786\n",
      "epoch 860 / 20000\n",
      "gradient norm: 0.07136685377918184, minimum ratio: 2.5210526315789474\n",
      "\ttrain loss: 0.00770\n",
      "\tval loss: 0.00785\n",
      "epoch 861 / 20000\n",
      "gradient norm: 0.044168840744532645, minimum ratio: 2.5105263157894737\n",
      "\ttrain loss: 0.00768\n",
      "\tval loss: 0.00783\n",
      "epoch 862 / 20000\n",
      "gradient norm: 0.05412836401956156, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.00766\n",
      "\tval loss: 0.00782\n",
      "epoch 863 / 20000\n",
      "gradient norm: 0.054369324119761586, minimum ratio: 2.5184210526315787\n",
      "\ttrain loss: 0.00766\n",
      "\tval loss: 0.00780\n",
      "epoch 864 / 20000\n",
      "gradient norm: 0.0873661080840975, minimum ratio: 2.5157894736842104\n",
      "\ttrain loss: 0.00764\n",
      "\tval loss: 0.00780\n",
      "epoch 865 / 20000\n",
      "gradient norm: 0.09429170447401702, minimum ratio: 2.5131578947368425\n",
      "\ttrain loss: 0.00763\n",
      "\tval loss: 0.00778\n",
      "epoch 866 / 20000\n",
      "gradient norm: 0.12514732812996954, minimum ratio: 2.507894736842105\n",
      "\ttrain loss: 0.00761\n",
      "\tval loss: 0.00777\n",
      "epoch 867 / 20000\n",
      "gradient norm: 0.0971330733736977, minimum ratio: 2.531578947368421\n",
      "\ttrain loss: 0.00761\n",
      "\tval loss: 0.00774\n",
      "epoch 868 / 20000\n",
      "gradient norm: 0.061297419713810086, minimum ratio: 2.513157894736842\n",
      "\ttrain loss: 0.00759\n",
      "\tval loss: 0.00774\n",
      "epoch 869 / 20000\n",
      "gradient norm: 0.08837838540785015, minimum ratio: 2.526315789473684\n",
      "\ttrain loss: 0.00759\n",
      "\tval loss: 0.00772\n",
      "epoch 870 / 20000\n",
      "gradient norm: 0.06729580974206328, minimum ratio: 2.5315789473684207\n",
      "\ttrain loss: 0.00757\n",
      "\tval loss: 0.00772\n",
      "epoch 871 / 20000\n",
      "gradient norm: 0.09675995900761336, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00756\n",
      "\tval loss: 0.00770\n",
      "epoch 872 / 20000\n",
      "gradient norm: 0.042438965290784836, minimum ratio: 2.526315789473684\n",
      "\ttrain loss: 0.00756\n",
      "\tval loss: 0.00768\n",
      "epoch 873 / 20000\n",
      "gradient norm: 0.06083519506501034, minimum ratio: 2.528947368421053\n",
      "\ttrain loss: 0.00754\n",
      "\tval loss: 0.00766\n",
      "epoch 874 / 20000\n",
      "gradient norm: 0.07625512953381985, minimum ratio: 2.5236842105263158\n",
      "\ttrain loss: 0.00753\n",
      "\tval loss: 0.00766\n",
      "epoch 875 / 20000\n",
      "gradient norm: 0.0802355099003762, minimum ratio: 2.518421052631579\n",
      "\ttrain loss: 0.00752\n",
      "\tval loss: 0.00765\n",
      "epoch 876 / 20000\n",
      "gradient norm: 0.0442573179025203, minimum ratio: 2.557894736842105\n",
      "\ttrain loss: 0.00750\n",
      "\tval loss: 0.00763\n",
      "epoch 877 / 20000\n",
      "gradient norm: 0.10186979721765965, minimum ratio: 2.526315789473684\n",
      "\ttrain loss: 0.00751\n",
      "\tval loss: 0.00761\n",
      "epoch 878 / 20000\n",
      "gradient norm: 0.053456756577361375, minimum ratio: 2.518421052631579\n",
      "\ttrain loss: 0.00750\n",
      "\tval loss: 0.00760\n",
      "epoch 879 / 20000\n",
      "gradient norm: 0.05139179760590196, minimum ratio: 2.5342105263157895\n",
      "\ttrain loss: 0.00749\n",
      "\tval loss: 0.00760\n",
      "epoch 880 / 20000\n",
      "gradient norm: 0.0581028419546783, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00746\n",
      "\tval loss: 0.00758\n",
      "epoch 881 / 20000\n",
      "gradient norm: 0.09274355776142329, minimum ratio: 2.5210526315789474\n",
      "\ttrain loss: 0.00745\n",
      "\tval loss: 0.00756\n",
      "epoch 882 / 20000\n",
      "gradient norm: 0.06775953446049243, minimum ratio: 2.515789473684211\n",
      "\ttrain loss: 0.00743\n",
      "\tval loss: 0.00755\n",
      "epoch 883 / 20000\n",
      "gradient norm: 0.08713780948892236, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00742\n",
      "\tval loss: 0.00754\n",
      "epoch 884 / 20000\n",
      "gradient norm: 0.07262007845565677, minimum ratio: 2.55\n",
      "\ttrain loss: 0.00742\n",
      "\tval loss: 0.00753\n",
      "epoch 885 / 20000\n",
      "gradient norm: 0.08822480821982026, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00741\n",
      "\tval loss: 0.00752\n",
      "epoch 886 / 20000\n",
      "gradient norm: 0.03979714529123157, minimum ratio: 2.5315789473684207\n",
      "\ttrain loss: 0.00739\n",
      "\tval loss: 0.00750\n",
      "epoch 887 / 20000\n",
      "gradient norm: 0.05452395346947014, minimum ratio: 2.526315789473684\n",
      "\ttrain loss: 0.00738\n",
      "\tval loss: 0.00749\n",
      "epoch 888 / 20000\n",
      "gradient norm: 0.07790241745533422, minimum ratio: 2.5078947368421054\n",
      "\ttrain loss: 0.00737\n",
      "\tval loss: 0.00748\n",
      "epoch 889 / 20000\n",
      "gradient norm: 0.04538433987181634, minimum ratio: 2.5236842105263158\n",
      "\ttrain loss: 0.00737\n",
      "\tval loss: 0.00746\n",
      "epoch 890 / 20000\n",
      "gradient norm: 0.08239477779716253, minimum ratio: 2.542105263157895\n",
      "\ttrain loss: 0.00737\n",
      "\tval loss: 0.00745\n",
      "epoch 891 / 20000\n",
      "gradient norm: 0.067729800241068, minimum ratio: 2.528947368421053\n",
      "\ttrain loss: 0.00734\n",
      "\tval loss: 0.00744\n",
      "epoch 892 / 20000\n",
      "gradient norm: 0.057266143208835274, minimum ratio: 2.507894736842105\n",
      "\ttrain loss: 0.00733\n",
      "\tval loss: 0.00744\n",
      "epoch 893 / 20000\n",
      "gradient norm: 0.055718144576530904, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00733\n",
      "\tval loss: 0.00742\n",
      "epoch 894 / 20000\n",
      "gradient norm: 0.10296891117468476, minimum ratio: 2.536842105263158\n",
      "\ttrain loss: 0.00732\n",
      "\tval loss: 0.00740\n",
      "epoch 895 / 20000\n",
      "gradient norm: 0.07155806350056082, minimum ratio: 2.536842105263158\n",
      "\ttrain loss: 0.00731\n",
      "\tval loss: 0.00739\n",
      "epoch 896 / 20000\n",
      "gradient norm: 0.100253103999421, minimum ratio: 2.5342105263157895\n",
      "\ttrain loss: 0.00729\n",
      "\tval loss: 0.00739\n",
      "epoch 897 / 20000\n",
      "gradient norm: 0.0711926082149148, minimum ratio: 2.5105263157894733\n",
      "\ttrain loss: 0.00728\n",
      "\tval loss: 0.00738\n",
      "epoch 898 / 20000\n",
      "gradient norm: 0.06790830113459378, minimum ratio: 2.531578947368421\n",
      "\ttrain loss: 0.00728\n",
      "\tval loss: 0.00736\n",
      "epoch 899 / 20000\n",
      "gradient norm: 0.0957772737601772, minimum ratio: 2.526315789473684\n",
      "\ttrain loss: 0.00727\n",
      "\tval loss: 0.00735\n",
      "epoch 900 / 20000\n",
      "gradient norm: 0.05546396202407777, minimum ratio: 2.5157894736842104\n",
      "\ttrain loss: 0.00725\n",
      "\tval loss: 0.00733\n",
      "epoch 901 / 20000\n",
      "gradient norm: 0.05338472675066441, minimum ratio: 2.544736842105263\n",
      "\ttrain loss: 0.00724\n",
      "\tval loss: 0.00732\n",
      "epoch 902 / 20000\n",
      "gradient norm: 0.11795946140773594, minimum ratio: 2.5289473684210524\n",
      "\ttrain loss: 0.00724\n",
      "\tval loss: 0.00732\n",
      "epoch 903 / 20000\n",
      "gradient norm: 0.09013889607740566, minimum ratio: 2.5210526315789474\n",
      "\ttrain loss: 0.00724\n",
      "\tval loss: 0.00729\n",
      "epoch 904 / 20000\n",
      "gradient norm: 0.11510254058521241, minimum ratio: 2.5473684210526315\n",
      "\ttrain loss: 0.00722\n",
      "\tval loss: 0.00728\n",
      "epoch 905 / 20000\n",
      "gradient norm: 0.0926816399442032, minimum ratio: 2.5157894736842104\n",
      "\ttrain loss: 0.00720\n",
      "\tval loss: 0.00728\n",
      "epoch 906 / 20000\n",
      "gradient norm: 0.11600818927399814, minimum ratio: 2.542105263157895\n",
      "\ttrain loss: 0.00718\n",
      "\tval loss: 0.00728\n",
      "epoch 907 / 20000\n",
      "gradient norm: 0.0569346621632576, minimum ratio: 2.5184210526315787\n",
      "\ttrain loss: 0.00718\n",
      "\tval loss: 0.00725\n",
      "epoch 908 / 20000\n",
      "gradient norm: 0.07498792558908463, minimum ratio: 2.507894736842105\n",
      "\ttrain loss: 0.00717\n",
      "\tval loss: 0.00724\n",
      "epoch 909 / 20000\n",
      "gradient norm: 0.11641893826890737, minimum ratio: 2.505263157894737\n",
      "\ttrain loss: 0.00717\n",
      "\tval loss: 0.00723\n",
      "epoch 910 / 20000\n",
      "gradient norm: 0.08564639347605407, minimum ratio: 2.528947368421053\n",
      "\ttrain loss: 0.00716\n",
      "\tval loss: 0.00722\n",
      "epoch 911 / 20000\n",
      "gradient norm: 0.08791734953410923, minimum ratio: 2.5236842105263158\n",
      "\ttrain loss: 0.00715\n",
      "\tval loss: 0.00721\n",
      "epoch 912 / 20000\n",
      "gradient norm: 0.08993444149382412, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00714\n",
      "\tval loss: 0.00720\n",
      "epoch 913 / 20000\n",
      "gradient norm: 0.06532083614729345, minimum ratio: 2.5315789473684207\n",
      "\ttrain loss: 0.00712\n",
      "\tval loss: 0.00720\n",
      "epoch 914 / 20000\n",
      "gradient norm: 0.11000660655554384, minimum ratio: 2.5157894736842104\n",
      "\ttrain loss: 0.00713\n",
      "\tval loss: 0.00718\n",
      "epoch 915 / 20000\n",
      "gradient norm: 0.11730090342462063, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00710\n",
      "\tval loss: 0.00717\n",
      "epoch 916 / 20000\n",
      "gradient norm: 0.058490260038524866, minimum ratio: 2.5473684210526315\n",
      "\ttrain loss: 0.00710\n",
      "\tval loss: 0.00715\n",
      "epoch 917 / 20000\n",
      "gradient norm: 0.13506413460709155, minimum ratio: 2.518421052631579\n",
      "\ttrain loss: 0.00710\n",
      "\tval loss: 0.00714\n",
      "epoch 918 / 20000\n",
      "gradient norm: 0.05582408339250833, minimum ratio: 2.5184210526315787\n",
      "\ttrain loss: 0.00709\n",
      "\tval loss: 0.00715\n",
      "epoch 919 / 20000\n",
      "gradient norm: 0.07440454897005111, minimum ratio: 2.5289473684210524\n",
      "\ttrain loss: 0.00706\n",
      "\tval loss: 0.00714\n",
      "epoch 920 / 20000\n",
      "gradient norm: 0.04333186079747975, minimum ratio: 2.5289473684210524\n",
      "\ttrain loss: 0.00705\n",
      "\tval loss: 0.00712\n",
      "epoch 921 / 20000\n",
      "gradient norm: 0.07571743981679901, minimum ratio: 2.5157894736842104\n",
      "\ttrain loss: 0.00707\n",
      "\tval loss: 0.00711\n",
      "epoch 922 / 20000\n",
      "gradient norm: 0.06267575069796294, minimum ratio: 2.557894736842105\n",
      "\ttrain loss: 0.00706\n",
      "\tval loss: 0.00710\n",
      "epoch 923 / 20000\n",
      "gradient norm: 0.058617281378246844, minimum ratio: 2.505263157894737\n",
      "\ttrain loss: 0.00704\n",
      "\tval loss: 0.00709\n",
      "epoch 924 / 20000\n",
      "gradient norm: 0.06343630503397435, minimum ratio: 2.515789473684211\n",
      "\ttrain loss: 0.00705\n",
      "\tval loss: 0.00708\n",
      "epoch 925 / 20000\n",
      "gradient norm: 0.05096925562247634, minimum ratio: 2.5131578947368425\n",
      "\ttrain loss: 0.00701\n",
      "\tval loss: 0.00707\n",
      "epoch 926 / 20000\n",
      "gradient norm: 0.06199424632359296, minimum ratio: 2.5131578947368425\n",
      "\ttrain loss: 0.00701\n",
      "\tval loss: 0.00706\n",
      "epoch 927 / 20000\n",
      "gradient norm: 0.06796130409929901, minimum ratio: 2.531578947368421\n",
      "\ttrain loss: 0.00702\n",
      "\tval loss: 0.00705\n",
      "epoch 928 / 20000\n",
      "gradient norm: 0.06119850615505129, minimum ratio: 2.521052631578947\n",
      "\ttrain loss: 0.00699\n",
      "\tval loss: 0.00704\n",
      "epoch 929 / 20000\n",
      "gradient norm: 0.08188814466120675, minimum ratio: 2.513157894736842\n",
      "\ttrain loss: 0.00700\n",
      "\tval loss: 0.00703\n",
      "epoch 930 / 20000\n",
      "gradient norm: 0.09069189365254715, minimum ratio: 2.531578947368421\n",
      "\ttrain loss: 0.00698\n",
      "\tval loss: 0.00702\n",
      "epoch 931 / 20000\n",
      "gradient norm: 0.06168872586567886, minimum ratio: 2.5236842105263158\n",
      "\ttrain loss: 0.00697\n",
      "\tval loss: 0.00702\n",
      "epoch 932 / 20000\n",
      "gradient norm: 0.11598917772062123, minimum ratio: 2.5289473684210524\n",
      "\ttrain loss: 0.00696\n",
      "\tval loss: 0.00701\n",
      "epoch 933 / 20000\n",
      "gradient norm: 0.08834435930475593, minimum ratio: 2.5473684210526315\n",
      "\ttrain loss: 0.00697\n",
      "\tval loss: 0.00700\n",
      "epoch 934 / 20000\n",
      "gradient norm: 0.058915721194352955, minimum ratio: 2.526315789473684\n",
      "\ttrain loss: 0.00695\n",
      "\tval loss: 0.00698\n",
      "epoch 935 / 20000\n",
      "gradient norm: 0.07583260739920661, minimum ratio: 2.526315789473684\n",
      "\ttrain loss: 0.00694\n",
      "\tval loss: 0.00698\n",
      "epoch 936 / 20000\n",
      "gradient norm: 0.05379345110850409, minimum ratio: 2.5157894736842104\n",
      "\ttrain loss: 0.00693\n",
      "\tval loss: 0.00697\n",
      "epoch 937 / 20000\n",
      "gradient norm: 0.08746127982158214, minimum ratio: 2.5315789473684207\n",
      "\ttrain loss: 0.00693\n",
      "\tval loss: 0.00696\n",
      "epoch 938 / 20000\n",
      "gradient norm: 0.08818217949010432, minimum ratio: 2.5078947368421054\n",
      "\ttrain loss: 0.00692\n",
      "\tval loss: 0.00696\n",
      "epoch 939 / 20000\n",
      "gradient norm: 0.06307508057216182, minimum ratio: 2.515789473684211\n",
      "\ttrain loss: 0.00691\n",
      "\tval loss: 0.00695\n",
      "epoch 940 / 20000\n",
      "gradient norm: 0.05621187941869721, minimum ratio: 2.513157894736842\n",
      "\ttrain loss: 0.00691\n",
      "\tval loss: 0.00693\n",
      "epoch 941 / 20000\n",
      "gradient norm: 0.07989630301017314, minimum ratio: 2.5105263157894737\n",
      "\ttrain loss: 0.00690\n",
      "\tval loss: 0.00693\n",
      "epoch 942 / 20000\n",
      "gradient norm: 0.05544427770655602, minimum ratio: 2.513157894736842\n",
      "\ttrain loss: 0.00689\n",
      "\tval loss: 0.00691\n",
      "epoch 943 / 20000\n",
      "gradient norm: 0.05261895357398316, minimum ratio: 2.5210526315789474\n",
      "\ttrain loss: 0.00688\n",
      "\tval loss: 0.00691\n",
      "epoch 944 / 20000\n",
      "gradient norm: 0.08433471084572375, minimum ratio: 2.5210526315789474\n",
      "\ttrain loss: 0.00688\n",
      "\tval loss: 0.00692\n",
      "epoch 945 / 20000\n",
      "gradient norm: 0.059501293988432735, minimum ratio: 2.539473684210526\n",
      "\ttrain loss: 0.00688\n",
      "\tval loss: 0.00689\n",
      "epoch 946 / 20000\n",
      "gradient norm: 0.055992797832004726, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00686\n",
      "\tval loss: 0.00688\n",
      "epoch 947 / 20000\n",
      "gradient norm: 0.08034416061127558, minimum ratio: 2.5157894736842104\n",
      "\ttrain loss: 0.00685\n",
      "\tval loss: 0.00687\n",
      "epoch 948 / 20000\n",
      "gradient norm: 0.08006593305617571, minimum ratio: 2.5131578947368425\n",
      "\ttrain loss: 0.00684\n",
      "\tval loss: 0.00687\n",
      "epoch 949 / 20000\n",
      "gradient norm: 0.05630297935567796, minimum ratio: 2.513157894736842\n",
      "\ttrain loss: 0.00685\n",
      "\tval loss: 0.00686\n",
      "epoch 950 / 20000\n",
      "gradient norm: 0.08073416270781308, minimum ratio: 2.5210526315789474\n",
      "\ttrain loss: 0.00683\n",
      "\tval loss: 0.00686\n",
      "epoch 951 / 20000\n",
      "gradient norm: 0.06097888050135225, minimum ratio: 2.5210526315789474\n",
      "\ttrain loss: 0.00683\n",
      "\tval loss: 0.00684\n",
      "epoch 952 / 20000\n",
      "gradient norm: 0.08667416521348059, minimum ratio: 2.5289473684210524\n",
      "\ttrain loss: 0.00684\n",
      "\tval loss: 0.00684\n",
      "epoch 953 / 20000\n",
      "gradient norm: 0.0685294111026451, minimum ratio: 2.518421052631579\n",
      "\ttrain loss: 0.00682\n",
      "\tval loss: 0.00684\n",
      "epoch 954 / 20000\n",
      "gradient norm: 0.13498092052759603, minimum ratio: 2.5210526315789474\n",
      "\ttrain loss: 0.00682\n",
      "\tval loss: 0.00683\n",
      "epoch 955 / 20000\n",
      "gradient norm: 0.09495763730956241, minimum ratio: 2.5236842105263158\n",
      "\ttrain loss: 0.00681\n",
      "\tval loss: 0.00683\n",
      "epoch 956 / 20000\n",
      "gradient norm: 0.04137803753837943, minimum ratio: 2.5368421052631573\n",
      "\ttrain loss: 0.00680\n",
      "\tval loss: 0.00681\n",
      "epoch 957 / 20000\n",
      "gradient norm: 0.0702093516010791, minimum ratio: 2.515789473684211\n",
      "\ttrain loss: 0.00679\n",
      "\tval loss: 0.00680\n",
      "epoch 958 / 20000\n",
      "gradient norm: 0.13900609500706196, minimum ratio: 2.544736842105263\n",
      "\ttrain loss: 0.00680\n",
      "\tval loss: 0.00679\n",
      "epoch 959 / 20000\n",
      "gradient norm: 0.08958626189269125, minimum ratio: 2.5236842105263158\n",
      "\ttrain loss: 0.00679\n",
      "\tval loss: 0.00679\n",
      "epoch 960 / 20000\n",
      "gradient norm: 0.10427480802172795, minimum ratio: 2.5184210526315787\n",
      "\ttrain loss: 0.00678\n",
      "\tval loss: 0.00679\n",
      "epoch 961 / 20000\n",
      "gradient norm: 0.030710526392795146, minimum ratio: 2.518421052631579\n",
      "\ttrain loss: 0.00677\n",
      "\tval loss: 0.00677\n",
      "epoch 962 / 20000\n",
      "gradient norm: 0.07340951153310016, minimum ratio: 2.5500000000000003\n",
      "\ttrain loss: 0.00677\n",
      "\tval loss: 0.00676\n",
      "epoch 963 / 20000\n",
      "gradient norm: 0.09920168714597821, minimum ratio: 2.528947368421053\n",
      "\ttrain loss: 0.00675\n",
      "\tval loss: 0.00676\n",
      "epoch 964 / 20000\n",
      "gradient norm: 0.0879668333218433, minimum ratio: 2.5210526315789474\n",
      "\ttrain loss: 0.00675\n",
      "\tval loss: 0.00676\n",
      "epoch 965 / 20000\n",
      "gradient norm: 0.09040048834867775, minimum ratio: 2.5157894736842104\n",
      "\ttrain loss: 0.00675\n",
      "\tval loss: 0.00674\n",
      "epoch 966 / 20000\n",
      "gradient norm: 0.08057816285872832, minimum ratio: 2.515789473684211\n",
      "\ttrain loss: 0.00675\n",
      "\tval loss: 0.00674\n",
      "epoch 967 / 20000\n",
      "gradient norm: 0.07876316865440458, minimum ratio: 2.518421052631579\n",
      "\ttrain loss: 0.00673\n",
      "\tval loss: 0.00674\n",
      "epoch 968 / 20000\n",
      "gradient norm: 0.06259059277363122, minimum ratio: 2.5105263157894733\n",
      "\ttrain loss: 0.00671\n",
      "\tval loss: 0.00673\n",
      "epoch 969 / 20000\n",
      "gradient norm: 0.08552783686900511, minimum ratio: 2.5078947368421054\n",
      "\ttrain loss: 0.00673\n",
      "\tval loss: 0.00671\n",
      "epoch 970 / 20000\n",
      "gradient norm: 0.06495852337684482, minimum ratio: 2.5210526315789474\n",
      "\ttrain loss: 0.00672\n",
      "\tval loss: 0.00671\n",
      "epoch 971 / 20000\n",
      "gradient norm: 0.09333138924557716, minimum ratio: 2.536842105263158\n",
      "\ttrain loss: 0.00672\n",
      "\tval loss: 0.00672\n",
      "epoch 972 / 20000\n",
      "gradient norm: 0.05340630083810538, minimum ratio: 2.5105263157894733\n",
      "\ttrain loss: 0.00670\n",
      "\tval loss: 0.00670\n",
      "epoch 973 / 20000\n",
      "gradient norm: 0.0481164469383657, minimum ratio: 2.507894736842105\n",
      "\ttrain loss: 0.00669\n",
      "\tval loss: 0.00669\n",
      "epoch 974 / 20000\n",
      "gradient norm: 0.06737719714874402, minimum ratio: 2.542105263157895\n",
      "\ttrain loss: 0.00670\n",
      "\tval loss: 0.00669\n",
      "epoch 975 / 20000\n",
      "gradient norm: 0.08871491515310481, minimum ratio: 2.5105263157894737\n",
      "\ttrain loss: 0.00668\n",
      "\tval loss: 0.00670\n",
      "epoch 976 / 20000\n",
      "gradient norm: 0.0723301013931632, minimum ratio: 2.507894736842105\n",
      "\ttrain loss: 0.00669\n",
      "\tval loss: 0.00669\n",
      "epoch 977 / 20000\n",
      "gradient norm: 0.07513770973309875, minimum ratio: 2.528947368421053\n",
      "\ttrain loss: 0.00667\n",
      "\tval loss: 0.00667\n",
      "epoch 978 / 20000\n",
      "gradient norm: 0.12495520350057632, minimum ratio: 2.5078947368421054\n",
      "\ttrain loss: 0.00668\n",
      "\tval loss: 0.00666\n",
      "epoch 979 / 20000\n",
      "gradient norm: 0.09241693740477785, minimum ratio: 2.5236842105263158\n",
      "\ttrain loss: 0.00667\n",
      "\tval loss: 0.00668\n",
      "epoch 980 / 20000\n",
      "gradient norm: 0.0780074613285251, minimum ratio: 2.5289473684210524\n",
      "\ttrain loss: 0.00667\n",
      "\tval loss: 0.00667\n",
      "epoch 981 / 20000\n",
      "gradient norm: 0.09526732802623883, minimum ratio: 2.5236842105263158\n",
      "\ttrain loss: 0.00667\n",
      "\tval loss: 0.00664\n",
      "epoch 982 / 20000\n",
      "gradient norm: 0.04615293664392084, minimum ratio: 2.55\n",
      "\ttrain loss: 0.00666\n",
      "\tval loss: 0.00664\n",
      "epoch 983 / 20000\n",
      "gradient norm: 0.05123333079973236, minimum ratio: 2.542105263157895\n",
      "\ttrain loss: 0.00665\n",
      "\tval loss: 0.00665\n",
      "epoch 984 / 20000\n",
      "gradient norm: 0.03955443319864571, minimum ratio: 2.5236842105263158\n",
      "\ttrain loss: 0.00665\n",
      "\tval loss: 0.00664\n",
      "epoch 985 / 20000\n",
      "gradient norm: 0.05986332206521183, minimum ratio: 2.5315789473684207\n",
      "\ttrain loss: 0.00663\n",
      "\tval loss: 0.00663\n",
      "epoch 986 / 20000\n",
      "gradient norm: 0.05989522737218067, minimum ratio: 2.513157894736842\n",
      "\ttrain loss: 0.00664\n",
      "\tval loss: 0.00662\n",
      "epoch 987 / 20000\n",
      "gradient norm: 0.08427413762547076, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00661\n",
      "\tval loss: 0.00661\n",
      "epoch 988 / 20000\n",
      "gradient norm: 0.049671480868710205, minimum ratio: 2.5473684210526315\n",
      "\ttrain loss: 0.00663\n",
      "\tval loss: 0.00662\n",
      "epoch 989 / 20000\n",
      "gradient norm: 0.030535037978552282, minimum ratio: 2.5394736842105265\n",
      "\ttrain loss: 0.00661\n",
      "\tval loss: 0.00661\n",
      "epoch 990 / 20000\n",
      "gradient norm: 0.07354786113137379, minimum ratio: 2.526315789473684\n",
      "\ttrain loss: 0.00662\n",
      "\tval loss: 0.00660\n",
      "epoch 991 / 20000\n",
      "gradient norm: 0.06207693397300318, minimum ratio: 2.526315789473684\n",
      "\ttrain loss: 0.00660\n",
      "\tval loss: 0.00659\n",
      "epoch 992 / 20000\n",
      "gradient norm: 0.056828055530786514, minimum ratio: 2.526315789473684\n",
      "\ttrain loss: 0.00661\n",
      "\tval loss: 0.00658\n",
      "epoch 993 / 20000\n",
      "gradient norm: 0.0965439222054556, minimum ratio: 2.544736842105263\n",
      "\ttrain loss: 0.00659\n",
      "\tval loss: 0.00659\n",
      "epoch 994 / 20000\n",
      "gradient norm: 0.06647888792213053, minimum ratio: 2.526315789473684\n",
      "\ttrain loss: 0.00659\n",
      "\tval loss: 0.00658\n",
      "epoch 995 / 20000\n",
      "gradient norm: 0.10573282139375806, minimum ratio: 2.5210526315789474\n",
      "\ttrain loss: 0.00658\n",
      "\tval loss: 0.00657\n",
      "epoch 996 / 20000\n",
      "gradient norm: 0.07207874493906274, minimum ratio: 2.5315789473684207\n",
      "\ttrain loss: 0.00658\n",
      "\tval loss: 0.00658\n",
      "epoch 997 / 20000\n",
      "gradient norm: 0.06830042309593409, minimum ratio: 2.544736842105263\n",
      "\ttrain loss: 0.00658\n",
      "\tval loss: 0.00657\n",
      "epoch 998 / 20000\n",
      "gradient norm: 0.04920285224216059, minimum ratio: 2.515789473684211\n",
      "\ttrain loss: 0.00657\n",
      "\tval loss: 0.00656\n",
      "epoch 999 / 20000\n",
      "gradient norm: 0.06818799825850874, minimum ratio: 2.5157894736842104\n",
      "\ttrain loss: 0.00658\n",
      "\tval loss: 0.00655\n",
      "epoch 1000 / 20000\n",
      "gradient norm: 0.037327579222619534, minimum ratio: 2.5421052631578944\n",
      "\ttrain loss: 0.00657\n",
      "\tval loss: 0.00656\n",
      "epoch 1001 / 20000\n",
      "gradient norm: 0.07721365900943056, minimum ratio: 2.531578947368421\n",
      "\ttrain loss: 0.00656\n",
      "\tval loss: 0.00655\n",
      "epoch 1002 / 20000\n",
      "gradient norm: 0.051567610702477396, minimum ratio: 2.5236842105263158\n",
      "\ttrain loss: 0.00656\n",
      "\tval loss: 0.00654\n",
      "epoch 1003 / 20000\n",
      "gradient norm: 0.07358673680573702, minimum ratio: 2.5315789473684207\n",
      "\ttrain loss: 0.00656\n",
      "\tval loss: 0.00653\n",
      "epoch 1004 / 20000\n",
      "gradient norm: 0.02258835732936859, minimum ratio: 2.507894736842105\n",
      "\ttrain loss: 0.00654\n",
      "\tval loss: 0.00654\n",
      "epoch 1005 / 20000\n",
      "gradient norm: 0.05919697316130623, minimum ratio: 2.5289473684210524\n",
      "\ttrain loss: 0.00656\n",
      "\tval loss: 0.00653\n",
      "epoch 1006 / 20000\n",
      "gradient norm: 0.03418631825479679, minimum ratio: 2.5289473684210524\n",
      "\ttrain loss: 0.00655\n",
      "\tval loss: 0.00653\n",
      "epoch 1007 / 20000\n",
      "gradient norm: 0.07398540910799056, minimum ratio: 2.536842105263158\n",
      "\ttrain loss: 0.00656\n",
      "\tval loss: 0.00652\n",
      "epoch 1008 / 20000\n",
      "gradient norm: 0.027409465634264052, minimum ratio: 2.518421052631579\n",
      "\ttrain loss: 0.00652\n",
      "\tval loss: 0.00652\n",
      "epoch 1009 / 20000\n",
      "gradient norm: 0.06384756474290043, minimum ratio: 2.518421052631579\n",
      "\ttrain loss: 0.00653\n",
      "\tval loss: 0.00652\n",
      "epoch 1010 / 20000\n",
      "gradient norm: 0.10571704455651343, minimum ratio: 2.5289473684210524\n",
      "\ttrain loss: 0.00653\n",
      "\tval loss: 0.00650\n",
      "epoch 1011 / 20000\n",
      "gradient norm: 0.054878054943401366, minimum ratio: 2.5105263157894737\n",
      "\ttrain loss: 0.00651\n",
      "\tval loss: 0.00651\n",
      "epoch 1012 / 20000\n",
      "gradient norm: 0.05951743706827983, minimum ratio: 2.528947368421053\n",
      "\ttrain loss: 0.00653\n",
      "\tval loss: 0.00650\n",
      "epoch 1013 / 20000\n",
      "gradient norm: 0.06243100541178137, minimum ratio: 2.531578947368421\n",
      "\ttrain loss: 0.00651\n",
      "\tval loss: 0.00650\n",
      "epoch 1014 / 20000\n",
      "gradient norm: 0.06192981742788106, minimum ratio: 2.5236842105263158\n",
      "\ttrain loss: 0.00651\n",
      "\tval loss: 0.00649\n",
      "epoch 1015 / 20000\n",
      "gradient norm: 0.035074419691227376, minimum ratio: 2.5315789473684207\n",
      "\ttrain loss: 0.00651\n",
      "\tval loss: 0.00649\n",
      "epoch 1016 / 20000\n",
      "gradient norm: 0.07813718164106831, minimum ratio: 2.5342105263157895\n",
      "\ttrain loss: 0.00651\n",
      "\tval loss: 0.00649\n",
      "epoch 1017 / 20000\n",
      "gradient norm: 0.1360240806825459, minimum ratio: 2.5157894736842104\n",
      "\ttrain loss: 0.00651\n",
      "\tval loss: 0.00648\n",
      "epoch 1018 / 20000\n",
      "gradient norm: 0.10078486922429875, minimum ratio: 2.513157894736842\n",
      "\ttrain loss: 0.00650\n",
      "\tval loss: 0.00646\n",
      "epoch 1019 / 20000\n",
      "gradient norm: 0.08242573542520404, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00652\n",
      "\tval loss: 0.00646\n",
      "epoch 1020 / 20000\n",
      "gradient norm: 0.10893215774558485, minimum ratio: 2.492105263157895\n",
      "\ttrain loss: 0.00649\n",
      "\tval loss: 0.00647\n",
      "epoch 1021 / 20000\n",
      "gradient norm: 0.06419885525247082, minimum ratio: 2.5315789473684207\n",
      "\ttrain loss: 0.00649\n",
      "\tval loss: 0.00647\n",
      "epoch 1022 / 20000\n",
      "gradient norm: 0.044121600803919137, minimum ratio: 2.536842105263158\n",
      "\ttrain loss: 0.00647\n",
      "\tval loss: 0.00646\n",
      "epoch 1023 / 20000\n",
      "gradient norm: 0.0525308899814263, minimum ratio: 2.518421052631579\n",
      "\ttrain loss: 0.00648\n",
      "\tval loss: 0.00645\n",
      "epoch 1024 / 20000\n",
      "gradient norm: 0.0598133354797028, minimum ratio: 2.5078947368421054\n",
      "\ttrain loss: 0.00648\n",
      "\tval loss: 0.00645\n",
      "epoch 1025 / 20000\n",
      "gradient norm: 0.028976292174775153, minimum ratio: 2.5289473684210524\n",
      "\ttrain loss: 0.00647\n",
      "\tval loss: 0.00645\n",
      "epoch 1026 / 20000\n",
      "gradient norm: 0.09121405042242259, minimum ratio: 2.536842105263158\n",
      "\ttrain loss: 0.00647\n",
      "\tval loss: 0.00645\n",
      "epoch 1027 / 20000\n",
      "gradient norm: 0.05251262319507077, minimum ratio: 2.5315789473684207\n",
      "\ttrain loss: 0.00646\n",
      "\tval loss: 0.00644\n",
      "epoch 1028 / 20000\n",
      "gradient norm: 0.04124207090353593, minimum ratio: 2.536842105263158\n",
      "\ttrain loss: 0.00646\n",
      "\tval loss: 0.00643\n",
      "epoch 1029 / 20000\n",
      "gradient norm: 0.05716073972871527, minimum ratio: 2.542105263157895\n",
      "\ttrain loss: 0.00646\n",
      "\tval loss: 0.00643\n",
      "epoch 1030 / 20000\n",
      "gradient norm: 0.07799879723461345, minimum ratio: 2.5289473684210524\n",
      "\ttrain loss: 0.00645\n",
      "\tval loss: 0.00643\n",
      "epoch 1031 / 20000\n",
      "gradient norm: 0.06401383271440864, minimum ratio: 2.5236842105263158\n",
      "\ttrain loss: 0.00645\n",
      "\tval loss: 0.00643\n",
      "epoch 1032 / 20000\n",
      "gradient norm: 0.0592217956436798, minimum ratio: 2.526315789473684\n",
      "\ttrain loss: 0.00645\n",
      "\tval loss: 0.00642\n",
      "epoch 1033 / 20000\n",
      "gradient norm: 0.038434167101513594, minimum ratio: 2.5210526315789474\n",
      "\ttrain loss: 0.00645\n",
      "\tval loss: 0.00641\n",
      "epoch 1034 / 20000\n",
      "gradient norm: 0.09445773146580905, minimum ratio: 2.5157894736842104\n",
      "\ttrain loss: 0.00645\n",
      "\tval loss: 0.00642\n",
      "epoch 1035 / 20000\n",
      "gradient norm: 0.07414806913584471, minimum ratio: 2.518421052631579\n",
      "\ttrain loss: 0.00643\n",
      "\tval loss: 0.00641\n",
      "epoch 1036 / 20000\n",
      "gradient norm: 0.038400876335799694, minimum ratio: 2.5342105263157895\n",
      "\ttrain loss: 0.00644\n",
      "\tval loss: 0.00640\n",
      "epoch 1037 / 20000\n",
      "gradient norm: 0.06739444652339444, minimum ratio: 2.5342105263157895\n",
      "\ttrain loss: 0.00644\n",
      "\tval loss: 0.00640\n",
      "epoch 1038 / 20000\n",
      "gradient norm: 0.04844958474859595, minimum ratio: 2.518421052631579\n",
      "\ttrain loss: 0.00643\n",
      "\tval loss: 0.00640\n",
      "epoch 1039 / 20000\n",
      "gradient norm: 0.07756805809913203, minimum ratio: 2.5421052631578944\n",
      "\ttrain loss: 0.00642\n",
      "\tval loss: 0.00641\n",
      "epoch 1040 / 20000\n",
      "gradient norm: 0.06174886616645381, minimum ratio: 2.5236842105263158\n",
      "\ttrain loss: 0.00642\n",
      "\tval loss: 0.00639\n",
      "epoch 1041 / 20000\n",
      "gradient norm: 0.05716818873770535, minimum ratio: 2.526315789473684\n",
      "\ttrain loss: 0.00641\n",
      "\tval loss: 0.00638\n",
      "epoch 1042 / 20000\n",
      "gradient norm: 0.05783276940928772, minimum ratio: 2.526315789473684\n",
      "\ttrain loss: 0.00643\n",
      "\tval loss: 0.00638\n",
      "epoch 1043 / 20000\n",
      "gradient norm: 0.06205247907200828, minimum ratio: 2.5342105263157895\n",
      "\ttrain loss: 0.00642\n",
      "\tval loss: 0.00639\n",
      "epoch 1044 / 20000\n",
      "gradient norm: 0.04487064672866836, minimum ratio: 2.531578947368421\n",
      "\ttrain loss: 0.00642\n",
      "\tval loss: 0.00638\n",
      "epoch 1045 / 20000\n",
      "gradient norm: 0.027393750671762973, minimum ratio: 2.5342105263157895\n",
      "\ttrain loss: 0.00640\n",
      "\tval loss: 0.00637\n",
      "epoch 1046 / 20000\n",
      "gradient norm: 0.04404877405613661, minimum ratio: 2.5236842105263158\n",
      "\ttrain loss: 0.00641\n",
      "\tval loss: 0.00638\n",
      "epoch 1047 / 20000\n",
      "gradient norm: 0.05519207028555684, minimum ratio: 2.5394736842105265\n",
      "\ttrain loss: 0.00640\n",
      "\tval loss: 0.00637\n",
      "epoch 1048 / 20000\n",
      "gradient norm: 0.10373827640432864, minimum ratio: 2.557894736842105\n",
      "\ttrain loss: 0.00639\n",
      "\tval loss: 0.00638\n",
      "epoch 1049 / 20000\n",
      "gradient norm: 0.04837122646858916, minimum ratio: 2.5289473684210524\n",
      "\ttrain loss: 0.00640\n",
      "\tval loss: 0.00636\n",
      "epoch 1050 / 20000\n",
      "gradient norm: 0.06162256607785821, minimum ratio: 2.518421052631579\n",
      "\ttrain loss: 0.00639\n",
      "\tval loss: 0.00635\n",
      "epoch 1051 / 20000\n",
      "gradient norm: 0.07823250914225355, minimum ratio: 2.5289473684210524\n",
      "\ttrain loss: 0.00640\n",
      "\tval loss: 0.00635\n",
      "epoch 1052 / 20000\n",
      "gradient norm: 0.09347034437814727, minimum ratio: 2.5078947368421054\n",
      "\ttrain loss: 0.00639\n",
      "\tval loss: 0.00637\n",
      "epoch 1053 / 20000\n",
      "gradient norm: 0.06872968695824966, minimum ratio: 2.55\n",
      "\ttrain loss: 0.00639\n",
      "\tval loss: 0.00637\n",
      "epoch 1054 / 20000\n",
      "gradient norm: 0.04936806199839339, minimum ratio: 2.507894736842105\n",
      "\ttrain loss: 0.00639\n",
      "\tval loss: 0.00634\n",
      "epoch 1055 / 20000\n",
      "gradient norm: 0.03988986724289134, minimum ratio: 2.518421052631579\n",
      "\ttrain loss: 0.00638\n",
      "\tval loss: 0.00634\n",
      "epoch 1056 / 20000\n",
      "gradient norm: 0.0484328810707666, minimum ratio: 2.5289473684210524\n",
      "\ttrain loss: 0.00637\n",
      "\tval loss: 0.00634\n",
      "epoch 1057 / 20000\n",
      "gradient norm: 0.06270948267774656, minimum ratio: 2.526315789473684\n",
      "\ttrain loss: 0.00638\n",
      "\tval loss: 0.00635\n",
      "epoch 1058 / 20000\n",
      "gradient norm: 0.07263500074623153, minimum ratio: 2.5210526315789474\n",
      "\ttrain loss: 0.00639\n",
      "\tval loss: 0.00634\n",
      "epoch 1059 / 20000\n",
      "gradient norm: 0.05366890091681853, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00636\n",
      "\tval loss: 0.00633\n",
      "epoch 1060 / 20000\n",
      "gradient norm: 0.08468067579087801, minimum ratio: 2.55\n",
      "\ttrain loss: 0.00637\n",
      "\tval loss: 0.00633\n",
      "epoch 1061 / 20000\n",
      "gradient norm: 0.07983600010629743, minimum ratio: 2.539473684210526\n",
      "\ttrain loss: 0.00638\n",
      "\tval loss: 0.00632\n",
      "epoch 1062 / 20000\n",
      "gradient norm: 0.020518055360298604, minimum ratio: 2.5421052631578944\n",
      "\ttrain loss: 0.00637\n",
      "\tval loss: 0.00633\n",
      "epoch 1063 / 20000\n",
      "gradient norm: 0.07039872813038528, minimum ratio: 2.526315789473684\n",
      "\ttrain loss: 0.00636\n",
      "\tval loss: 0.00633\n",
      "epoch 1064 / 20000\n",
      "gradient norm: 0.07707061874680221, minimum ratio: 2.5236842105263158\n",
      "\ttrain loss: 0.00636\n",
      "\tval loss: 0.00633\n",
      "epoch 1065 / 20000\n",
      "gradient norm: 0.11935572617221624, minimum ratio: 2.513157894736842\n",
      "\ttrain loss: 0.00638\n",
      "\tval loss: 0.00630\n",
      "epoch 1066 / 20000\n",
      "gradient norm: 0.08704908983781934, minimum ratio: 2.5315789473684207\n",
      "\ttrain loss: 0.00636\n",
      "\tval loss: 0.00631\n",
      "epoch 1067 / 20000\n",
      "gradient norm: 0.0519286299822852, minimum ratio: 2.534210526315789\n",
      "\ttrain loss: 0.00635\n",
      "\tval loss: 0.00633\n",
      "epoch 1068 / 20000\n",
      "gradient norm: 0.051301786210387945, minimum ratio: 2.526315789473684\n",
      "\ttrain loss: 0.00634\n",
      "\tval loss: 0.00631\n",
      "epoch 1069 / 20000\n",
      "gradient norm: 0.0875233393162489, minimum ratio: 2.5157894736842104\n",
      "\ttrain loss: 0.00633\n",
      "\tval loss: 0.00631\n",
      "epoch 1070 / 20000\n",
      "gradient norm: 0.045897119474830106, minimum ratio: 2.526315789473684\n",
      "\ttrain loss: 0.00635\n",
      "\tval loss: 0.00629\n",
      "epoch 1071 / 20000\n",
      "gradient norm: 0.02502944049774669, minimum ratio: 2.544736842105263\n",
      "\ttrain loss: 0.00633\n",
      "\tval loss: 0.00630\n",
      "epoch 1072 / 20000\n",
      "gradient norm: 0.03623347444226965, minimum ratio: 2.5236842105263158\n",
      "\ttrain loss: 0.00634\n",
      "\tval loss: 0.00631\n",
      "epoch 1073 / 20000\n",
      "gradient norm: 0.09087329468457028, minimum ratio: 2.5184210526315787\n",
      "\ttrain loss: 0.00633\n",
      "\tval loss: 0.00629\n",
      "epoch 1074 / 20000\n",
      "gradient norm: 0.0509272058843635, minimum ratio: 2.5394736842105265\n",
      "\ttrain loss: 0.00633\n",
      "\tval loss: 0.00629\n",
      "epoch 1075 / 20000\n",
      "gradient norm: 0.062074794550426304, minimum ratio: 2.5289473684210524\n",
      "\ttrain loss: 0.00633\n",
      "\tval loss: 0.00630\n",
      "epoch 1076 / 20000\n",
      "gradient norm: 0.0636219183797948, minimum ratio: 2.5236842105263158\n",
      "\ttrain loss: 0.00634\n",
      "\tval loss: 0.00629\n",
      "epoch 1077 / 20000\n",
      "gradient norm: 0.10021793658961542, minimum ratio: 2.5315789473684207\n",
      "\ttrain loss: 0.00634\n",
      "\tval loss: 0.00628\n",
      "epoch 1078 / 20000\n",
      "gradient norm: 0.07051251045777462, minimum ratio: 2.513157894736842\n",
      "\ttrain loss: 0.00634\n",
      "\tval loss: 0.00629\n",
      "epoch 1079 / 20000\n",
      "gradient norm: 0.09407146635930985, minimum ratio: 2.5236842105263158\n",
      "\ttrain loss: 0.00632\n",
      "\tval loss: 0.00628\n",
      "epoch 1080 / 20000\n",
      "gradient norm: 0.06062162626767531, minimum ratio: 2.568421052631579\n",
      "\ttrain loss: 0.00632\n",
      "\tval loss: 0.00628\n",
      "epoch 1081 / 20000\n",
      "gradient norm: 0.030988081532996148, minimum ratio: 2.557894736842105\n",
      "\ttrain loss: 0.00631\n",
      "\tval loss: 0.00628\n",
      "epoch 1082 / 20000\n",
      "gradient norm: 0.0489134494564496, minimum ratio: 2.507894736842105\n",
      "\ttrain loss: 0.00632\n",
      "\tval loss: 0.00627\n",
      "epoch 1083 / 20000\n",
      "gradient norm: 0.08018125063972548, minimum ratio: 2.531578947368421\n",
      "\ttrain loss: 0.00631\n",
      "\tval loss: 0.00628\n",
      "epoch 1084 / 20000\n",
      "gradient norm: 0.06522483431035653, minimum ratio: 2.542105263157895\n",
      "\ttrain loss: 0.00631\n",
      "\tval loss: 0.00627\n",
      "epoch 1085 / 20000\n",
      "gradient norm: 0.08860526175703853, minimum ratio: 2.513157894736842\n",
      "\ttrain loss: 0.00631\n",
      "\tval loss: 0.00627\n",
      "epoch 1086 / 20000\n",
      "gradient norm: 0.05170366045786068, minimum ratio: 2.5105263157894737\n",
      "\ttrain loss: 0.00630\n",
      "\tval loss: 0.00627\n",
      "epoch 1087 / 20000\n",
      "gradient norm: 0.059056206489913166, minimum ratio: 2.5236842105263158\n",
      "\ttrain loss: 0.00631\n",
      "\tval loss: 0.00626\n",
      "epoch 1088 / 20000\n",
      "gradient norm: 0.040756872593192384, minimum ratio: 2.5289473684210524\n",
      "\ttrain loss: 0.00630\n",
      "\tval loss: 0.00626\n",
      "epoch 1089 / 20000\n",
      "gradient norm: 0.048987421789206564, minimum ratio: 2.526315789473684\n",
      "\ttrain loss: 0.00630\n",
      "\tval loss: 0.00626\n",
      "epoch 1090 / 20000\n",
      "gradient norm: 0.024886112310923636, minimum ratio: 2.5157894736842104\n",
      "\ttrain loss: 0.00629\n",
      "\tval loss: 0.00626\n",
      "epoch 1091 / 20000\n",
      "gradient norm: 0.04967988998396322, minimum ratio: 2.5210526315789474\n",
      "\ttrain loss: 0.00630\n",
      "\tval loss: 0.00625\n",
      "epoch 1092 / 20000\n",
      "gradient norm: 0.08049312781076878, minimum ratio: 2.526315789473684\n",
      "\ttrain loss: 0.00630\n",
      "\tval loss: 0.00625\n",
      "epoch 1093 / 20000\n",
      "gradient norm: 0.0591800736146979, minimum ratio: 2.513157894736842\n",
      "\ttrain loss: 0.00629\n",
      "\tval loss: 0.00626\n",
      "epoch 1094 / 20000\n",
      "gradient norm: 0.058502316183876246, minimum ratio: 2.5131578947368425\n",
      "\ttrain loss: 0.00629\n",
      "\tval loss: 0.00625\n",
      "epoch 1095 / 20000\n",
      "gradient norm: 0.03280360027565621, minimum ratio: 2.528947368421053\n",
      "\ttrain loss: 0.00629\n",
      "\tval loss: 0.00624\n",
      "epoch 1096 / 20000\n",
      "gradient norm: 0.08416442369343713, minimum ratio: 2.5210526315789474\n",
      "\ttrain loss: 0.00629\n",
      "\tval loss: 0.00624\n",
      "epoch 1097 / 20000\n",
      "gradient norm: 0.05934004648588598, minimum ratio: 2.5078947368421054\n",
      "\ttrain loss: 0.00629\n",
      "\tval loss: 0.00624\n",
      "epoch 1098 / 20000\n",
      "gradient norm: 0.06247056048596278, minimum ratio: 2.5368421052631582\n",
      "\ttrain loss: 0.00629\n",
      "\tval loss: 0.00624\n",
      "epoch 1099 / 20000\n",
      "gradient norm: 0.05030124995391816, minimum ratio: 2.55\n",
      "\ttrain loss: 0.00628\n",
      "\tval loss: 0.00624\n",
      "epoch 1100 / 20000\n",
      "gradient norm: 0.07690097944578156, minimum ratio: 2.5078947368421054\n",
      "\ttrain loss: 0.00629\n",
      "\tval loss: 0.00624\n",
      "epoch 1101 / 20000\n",
      "gradient norm: 0.04288950370391831, minimum ratio: 2.555263157894737\n",
      "\ttrain loss: 0.00628\n",
      "\tval loss: 0.00624\n",
      "epoch 1102 / 20000\n",
      "gradient norm: 0.09199513201019727, minimum ratio: 2.518421052631579\n",
      "\ttrain loss: 0.00628\n",
      "\tval loss: 0.00624\n",
      "epoch 1103 / 20000\n",
      "gradient norm: 0.05149869492743164, minimum ratio: 2.507894736842105\n",
      "\ttrain loss: 0.00628\n",
      "\tval loss: 0.00622\n",
      "epoch 1104 / 20000\n",
      "gradient norm: 0.1027768305502832, minimum ratio: 2.513157894736842\n",
      "\ttrain loss: 0.00627\n",
      "\tval loss: 0.00623\n",
      "epoch 1105 / 20000\n",
      "gradient norm: 0.06013230845564976, minimum ratio: 2.5342105263157895\n",
      "\ttrain loss: 0.00628\n",
      "\tval loss: 0.00623\n",
      "epoch 1106 / 20000\n",
      "gradient norm: 0.13105329149402678, minimum ratio: 2.521052631578947\n",
      "\ttrain loss: 0.00627\n",
      "\tval loss: 0.00622\n",
      "epoch 1107 / 20000\n",
      "gradient norm: 0.09062281472142786, minimum ratio: 2.5236842105263158\n",
      "\ttrain loss: 0.00626\n",
      "\tval loss: 0.00623\n",
      "epoch 1108 / 20000\n",
      "gradient norm: 0.04861470253672451, minimum ratio: 2.542105263157895\n",
      "\ttrain loss: 0.00626\n",
      "\tval loss: 0.00622\n",
      "epoch 1109 / 20000\n",
      "gradient norm: 0.05372344667557627, minimum ratio: 2.5342105263157895\n",
      "\ttrain loss: 0.00627\n",
      "\tval loss: 0.00621\n",
      "epoch 1110 / 20000\n",
      "gradient norm: 0.07310549722751603, minimum ratio: 2.526315789473684\n",
      "\ttrain loss: 0.00627\n",
      "\tval loss: 0.00622\n",
      "epoch 1111 / 20000\n",
      "gradient norm: 0.10650990391150117, minimum ratio: 2.544736842105263\n",
      "\ttrain loss: 0.00626\n",
      "\tval loss: 0.00623\n",
      "epoch 1112 / 20000\n",
      "gradient norm: 0.06846414331812412, minimum ratio: 2.542105263157895\n",
      "\ttrain loss: 0.00626\n",
      "\tval loss: 0.00621\n",
      "epoch 1113 / 20000\n",
      "gradient norm: 0.0935375441040378, minimum ratio: 2.5289473684210524\n",
      "\ttrain loss: 0.00626\n",
      "\tval loss: 0.00620\n",
      "epoch 1114 / 20000\n",
      "gradient norm: 0.03902375270263292, minimum ratio: 2.5236842105263158\n",
      "\ttrain loss: 0.00627\n",
      "\tval loss: 0.00621\n",
      "epoch 1115 / 20000\n",
      "gradient norm: 0.035162024723831564, minimum ratio: 2.5210526315789474\n",
      "\ttrain loss: 0.00625\n",
      "\tval loss: 0.00622\n",
      "epoch 1116 / 20000\n",
      "gradient norm: 0.028322243015281856, minimum ratio: 2.536842105263158\n",
      "\ttrain loss: 0.00626\n",
      "\tval loss: 0.00621\n",
      "epoch 1117 / 20000\n",
      "gradient norm: 0.06440830390783958, minimum ratio: 2.5394736842105265\n",
      "\ttrain loss: 0.00625\n",
      "\tval loss: 0.00619\n",
      "epoch 1118 / 20000\n",
      "gradient norm: 0.05734460602980107, minimum ratio: 2.5157894736842104\n",
      "\ttrain loss: 0.00626\n",
      "\tval loss: 0.00620\n",
      "epoch 1119 / 20000\n",
      "gradient norm: 0.1672612481052056, minimum ratio: 2.526315789473684\n",
      "\ttrain loss: 0.00626\n",
      "\tval loss: 0.00622\n",
      "epoch 1120 / 20000\n",
      "gradient norm: 0.07115480853826739, minimum ratio: 2.5236842105263158\n",
      "\ttrain loss: 0.00625\n",
      "\tval loss: 0.00619\n",
      "epoch 1121 / 20000\n",
      "gradient norm: 0.07485705486033112, minimum ratio: 2.507894736842105\n",
      "\ttrain loss: 0.00624\n",
      "\tval loss: 0.00619\n",
      "epoch 1122 / 20000\n",
      "gradient norm: 0.07665947999339551, minimum ratio: 2.5289473684210524\n",
      "\ttrain loss: 0.00625\n",
      "\tval loss: 0.00619\n",
      "epoch 1123 / 20000\n",
      "gradient norm: 0.08412158628925681, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00625\n",
      "\tval loss: 0.00621\n",
      "epoch 1124 / 20000\n",
      "gradient norm: 0.0720111464324873, minimum ratio: 2.5315789473684207\n",
      "\ttrain loss: 0.00625\n",
      "\tval loss: 0.00619\n",
      "epoch 1125 / 20000\n",
      "gradient norm: 0.056191904412116855, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00624\n",
      "\tval loss: 0.00619\n",
      "epoch 1126 / 20000\n",
      "gradient norm: 0.06625392736168578, minimum ratio: 2.5473684210526315\n",
      "\ttrain loss: 0.00623\n",
      "\tval loss: 0.00619\n",
      "epoch 1127 / 20000\n",
      "gradient norm: 0.047167422861093655, minimum ratio: 2.5236842105263158\n",
      "\ttrain loss: 0.00626\n",
      "\tval loss: 0.00618\n",
      "epoch 1128 / 20000\n",
      "gradient norm: 0.07377559714950621, minimum ratio: 2.518421052631579\n",
      "\ttrain loss: 0.00624\n",
      "\tval loss: 0.00619\n",
      "epoch 1129 / 20000\n",
      "gradient norm: 0.06689791614189744, minimum ratio: 2.536842105263158\n",
      "\ttrain loss: 0.00624\n",
      "\tval loss: 0.00620\n",
      "epoch 1130 / 20000\n",
      "gradient norm: 0.038348725240211934, minimum ratio: 2.518421052631579\n",
      "\ttrain loss: 0.00624\n",
      "\tval loss: 0.00618\n",
      "epoch 1131 / 20000\n",
      "gradient norm: 0.06016137094411533, minimum ratio: 2.5473684210526315\n",
      "\ttrain loss: 0.00624\n",
      "\tval loss: 0.00617\n",
      "epoch 1132 / 20000\n",
      "gradient norm: 0.09205469442531466, minimum ratio: 2.5289473684210524\n",
      "\ttrain loss: 0.00623\n",
      "\tval loss: 0.00619\n",
      "epoch 1133 / 20000\n",
      "gradient norm: 0.040336808597203344, minimum ratio: 2.534210526315789\n",
      "\ttrain loss: 0.00622\n",
      "\tval loss: 0.00618\n",
      "epoch 1134 / 20000\n",
      "gradient norm: 0.02304892902611755, minimum ratio: 2.5210526315789474\n",
      "\ttrain loss: 0.00623\n",
      "\tval loss: 0.00617\n",
      "epoch 1135 / 20000\n",
      "gradient norm: 0.06777815514942631, minimum ratio: 2.518421052631579\n",
      "\ttrain loss: 0.00624\n",
      "\tval loss: 0.00617\n",
      "epoch 1136 / 20000\n",
      "gradient norm: 0.10915262083290145, minimum ratio: 2.526315789473684\n",
      "\ttrain loss: 0.00622\n",
      "\tval loss: 0.00618\n",
      "epoch 1137 / 20000\n",
      "gradient norm: 0.06015526529517956, minimum ratio: 2.5131578947368425\n",
      "\ttrain loss: 0.00622\n",
      "\tval loss: 0.00617\n",
      "epoch 1138 / 20000\n",
      "gradient norm: 0.06719159166095778, minimum ratio: 2.5368421052631582\n",
      "\ttrain loss: 0.00622\n",
      "\tval loss: 0.00617\n",
      "epoch 1139 / 20000\n",
      "gradient norm: 0.08969563146820292, minimum ratio: 2.539473684210526\n",
      "\ttrain loss: 0.00622\n",
      "\tval loss: 0.00617\n",
      "epoch 1140 / 20000\n",
      "gradient norm: 0.0776521020452492, minimum ratio: 2.5342105263157895\n",
      "\ttrain loss: 0.00623\n",
      "\tval loss: 0.00616\n",
      "epoch 1141 / 20000\n",
      "gradient norm: 0.062454024446196854, minimum ratio: 2.5210526315789474\n",
      "\ttrain loss: 0.00623\n",
      "\tval loss: 0.00617\n",
      "epoch 1142 / 20000\n",
      "gradient norm: 0.04283863084856421, minimum ratio: 2.5473684210526315\n",
      "\ttrain loss: 0.00623\n",
      "\tval loss: 0.00617\n",
      "epoch 1143 / 20000\n",
      "gradient norm: 0.041109394922386855, minimum ratio: 2.536842105263158\n",
      "\ttrain loss: 0.00622\n",
      "\tval loss: 0.00617\n",
      "epoch 1144 / 20000\n",
      "gradient norm: 0.07890428582322784, minimum ratio: 2.531578947368421\n",
      "\ttrain loss: 0.00621\n",
      "\tval loss: 0.00615\n",
      "epoch 1145 / 20000\n",
      "gradient norm: 0.10311306145740673, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00621\n",
      "\tval loss: 0.00616\n",
      "epoch 1146 / 20000\n",
      "gradient norm: 0.1453451367560774, minimum ratio: 2.518421052631579\n",
      "\ttrain loss: 0.00621\n",
      "\tval loss: 0.00618\n",
      "epoch 1147 / 20000\n",
      "gradient norm: 0.08166546851862222, minimum ratio: 2.5131578947368425\n",
      "\ttrain loss: 0.00622\n",
      "\tval loss: 0.00615\n",
      "epoch 1148 / 20000\n",
      "gradient norm: 0.055441146600060165, minimum ratio: 2.5289473684210524\n",
      "\ttrain loss: 0.00621\n",
      "\tval loss: 0.00615\n",
      "epoch 1149 / 20000\n",
      "gradient norm: 0.08568221746827476, minimum ratio: 2.5289473684210524\n",
      "\ttrain loss: 0.00622\n",
      "\tval loss: 0.00615\n",
      "epoch 1150 / 20000\n",
      "gradient norm: 0.08268971971119754, minimum ratio: 2.5105263157894733\n",
      "\ttrain loss: 0.00621\n",
      "\tval loss: 0.00618\n",
      "epoch 1151 / 20000\n",
      "gradient norm: 0.05356973496964201, minimum ratio: 2.5210526315789474\n",
      "\ttrain loss: 0.00622\n",
      "\tval loss: 0.00615\n",
      "epoch 1152 / 20000\n",
      "gradient norm: 0.05640183261130005, minimum ratio: 2.518421052631579\n",
      "\ttrain loss: 0.00622\n",
      "\tval loss: 0.00614\n",
      "epoch 1153 / 20000\n",
      "gradient norm: 0.04541295062517747, minimum ratio: 2.5236842105263158\n",
      "\ttrain loss: 0.00619\n",
      "\tval loss: 0.00614\n",
      "epoch 1154 / 20000\n",
      "gradient norm: 0.047434572712518275, minimum ratio: 2.531578947368421\n",
      "\ttrain loss: 0.00619\n",
      "\tval loss: 0.00616\n",
      "epoch 1155 / 20000\n",
      "gradient norm: 0.056765925779473037, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00621\n",
      "\tval loss: 0.00616\n",
      "epoch 1156 / 20000\n",
      "gradient norm: 0.0556080192909576, minimum ratio: 2.518421052631579\n",
      "\ttrain loss: 0.00618\n",
      "\tval loss: 0.00614\n",
      "epoch 1157 / 20000\n",
      "gradient norm: 0.08788462751545012, minimum ratio: 2.5289473684210524\n",
      "\ttrain loss: 0.00618\n",
      "\tval loss: 0.00614\n",
      "epoch 1158 / 20000\n",
      "gradient norm: 0.04079718398861587, minimum ratio: 2.526315789473684\n",
      "\ttrain loss: 0.00620\n",
      "\tval loss: 0.00614\n",
      "epoch 1159 / 20000\n",
      "gradient norm: 0.09538771340157837, minimum ratio: 2.528947368421053\n",
      "\ttrain loss: 0.00620\n",
      "\tval loss: 0.00615\n",
      "epoch 1160 / 20000\n",
      "gradient norm: 0.09196427560527809, minimum ratio: 2.5157894736842104\n",
      "\ttrain loss: 0.00621\n",
      "\tval loss: 0.00613\n",
      "epoch 1161 / 20000\n",
      "gradient norm: 0.051880461687687784, minimum ratio: 2.552631578947368\n",
      "\ttrain loss: 0.00619\n",
      "\tval loss: 0.00614\n",
      "epoch 1162 / 20000\n",
      "gradient norm: 0.03005943653988652, minimum ratio: 2.5394736842105265\n",
      "\ttrain loss: 0.00620\n",
      "\tval loss: 0.00614\n",
      "epoch 1163 / 20000\n",
      "gradient norm: 0.04148059868020937, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00618\n",
      "\tval loss: 0.00614\n",
      "epoch 1164 / 20000\n",
      "gradient norm: 0.08517275017220527, minimum ratio: 2.518421052631579\n",
      "\ttrain loss: 0.00619\n",
      "\tval loss: 0.00614\n",
      "epoch 1165 / 20000\n",
      "gradient norm: 0.04961755927070044, minimum ratio: 2.534210526315789\n",
      "\ttrain loss: 0.00619\n",
      "\tval loss: 0.00612\n",
      "epoch 1166 / 20000\n",
      "gradient norm: 0.051419875846477225, minimum ratio: 2.5210526315789474\n",
      "\ttrain loss: 0.00619\n",
      "\tval loss: 0.00613\n",
      "epoch 1167 / 20000\n",
      "gradient norm: 0.07426669157575816, minimum ratio: 2.5315789473684207\n",
      "\ttrain loss: 0.00618\n",
      "\tval loss: 0.00614\n",
      "epoch 1168 / 20000\n",
      "gradient norm: 0.053140576608711854, minimum ratio: 2.518421052631579\n",
      "\ttrain loss: 0.00619\n",
      "\tval loss: 0.00614\n",
      "epoch 1169 / 20000\n",
      "gradient norm: 0.039725638504023664, minimum ratio: 2.5289473684210524\n",
      "\ttrain loss: 0.00619\n",
      "\tval loss: 0.00612\n",
      "epoch 1170 / 20000\n",
      "gradient norm: 0.07594384276308119, minimum ratio: 2.5210526315789474\n",
      "\ttrain loss: 0.00618\n",
      "\tval loss: 0.00612\n",
      "epoch 1171 / 20000\n",
      "gradient norm: 0.043679137917933986, minimum ratio: 2.536842105263158\n",
      "\ttrain loss: 0.00619\n",
      "\tval loss: 0.00613\n",
      "epoch 1172 / 20000\n",
      "gradient norm: 0.058961897710105404, minimum ratio: 2.536842105263158\n",
      "\ttrain loss: 0.00619\n",
      "\tval loss: 0.00614\n",
      "epoch 1173 / 20000\n",
      "gradient norm: 0.05389722326071933, minimum ratio: 2.5157894736842104\n",
      "\ttrain loss: 0.00619\n",
      "\tval loss: 0.00612\n",
      "epoch 1174 / 20000\n",
      "gradient norm: 0.036374887684360147, minimum ratio: 2.547368421052632\n",
      "\ttrain loss: 0.00618\n",
      "\tval loss: 0.00611\n",
      "epoch 1175 / 20000\n",
      "gradient norm: 0.08378496422665194, minimum ratio: 2.5289473684210524\n",
      "\ttrain loss: 0.00619\n",
      "\tval loss: 0.00612\n",
      "epoch 1176 / 20000\n",
      "gradient norm: 0.05212826433125883, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00618\n",
      "\tval loss: 0.00612\n",
      "epoch 1177 / 20000\n",
      "gradient norm: 0.06693046324653551, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00617\n",
      "\tval loss: 0.00612\n",
      "epoch 1178 / 20000\n",
      "gradient norm: 0.07046536909183487, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00618\n",
      "\tval loss: 0.00612\n",
      "epoch 1179 / 20000\n",
      "gradient norm: 0.06911799966474064, minimum ratio: 2.5236842105263158\n",
      "\ttrain loss: 0.00618\n",
      "\tval loss: 0.00612\n",
      "epoch 1180 / 20000\n",
      "gradient norm: 0.06641561578726396, minimum ratio: 2.5157894736842104\n",
      "\ttrain loss: 0.00619\n",
      "\tval loss: 0.00611\n",
      "epoch 1181 / 20000\n",
      "gradient norm: 0.06281636247877032, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00616\n",
      "\tval loss: 0.00612\n",
      "epoch 1182 / 20000\n",
      "gradient norm: 0.05633803832461126, minimum ratio: 2.544736842105263\n",
      "\ttrain loss: 0.00616\n",
      "\tval loss: 0.00612\n",
      "epoch 1183 / 20000\n",
      "gradient norm: 0.07029728652560152, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00619\n",
      "\tval loss: 0.00611\n",
      "epoch 1184 / 20000\n",
      "gradient norm: 0.03802890668157488, minimum ratio: 2.515789473684211\n",
      "\ttrain loss: 0.00618\n",
      "\tval loss: 0.00611\n",
      "epoch 1185 / 20000\n",
      "gradient norm: 0.0782548023853451, minimum ratio: 2.5210526315789474\n",
      "\ttrain loss: 0.00616\n",
      "\tval loss: 0.00612\n",
      "epoch 1186 / 20000\n",
      "gradient norm: 0.03296308359131217, minimum ratio: 2.5236842105263158\n",
      "\ttrain loss: 0.00617\n",
      "\tval loss: 0.00611\n",
      "epoch 1187 / 20000\n",
      "gradient norm: 0.062354510417208076, minimum ratio: 2.5210526315789474\n",
      "\ttrain loss: 0.00617\n",
      "\tval loss: 0.00610\n",
      "epoch 1188 / 20000\n",
      "gradient norm: 0.060514959710417315, minimum ratio: 2.5236842105263158\n",
      "\ttrain loss: 0.00617\n",
      "\tval loss: 0.00611\n",
      "epoch 1189 / 20000\n",
      "gradient norm: 0.09757270896807313, minimum ratio: 2.5184210526315787\n",
      "\ttrain loss: 0.00617\n",
      "\tval loss: 0.00612\n",
      "epoch 1190 / 20000\n",
      "gradient norm: 0.05250960338162258, minimum ratio: 2.539473684210526\n",
      "\ttrain loss: 0.00615\n",
      "\tval loss: 0.00610\n",
      "epoch 1191 / 20000\n",
      "gradient norm: 0.07423061691224575, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00617\n",
      "\tval loss: 0.00609\n",
      "epoch 1192 / 20000\n",
      "gradient norm: 0.05073421433917247, minimum ratio: 2.5210526315789474\n",
      "\ttrain loss: 0.00617\n",
      "\tval loss: 0.00611\n",
      "epoch 1193 / 20000\n",
      "gradient norm: 0.062045407205005176, minimum ratio: 2.5078947368421054\n",
      "\ttrain loss: 0.00616\n",
      "\tval loss: 0.00612\n",
      "epoch 1194 / 20000\n",
      "gradient norm: 0.06361425836803392, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00618\n",
      "\tval loss: 0.00609\n",
      "epoch 1195 / 20000\n",
      "gradient norm: 0.09815424348926172, minimum ratio: 2.5105263157894737\n",
      "\ttrain loss: 0.00618\n",
      "\tval loss: 0.00609\n",
      "epoch 1196 / 20000\n",
      "gradient norm: 0.040958814963232726, minimum ratio: 2.5315789473684207\n",
      "\ttrain loss: 0.00615\n",
      "\tval loss: 0.00611\n",
      "epoch 1197 / 20000\n",
      "gradient norm: 0.11822153977118433, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00615\n",
      "\tval loss: 0.00611\n",
      "epoch 1198 / 20000\n",
      "gradient norm: 0.1128552207374014, minimum ratio: 2.515789473684211\n",
      "\ttrain loss: 0.00615\n",
      "\tval loss: 0.00608\n",
      "epoch 1199 / 20000\n",
      "gradient norm: 0.07775075489189476, minimum ratio: 2.544736842105263\n",
      "\ttrain loss: 0.00616\n",
      "\tval loss: 0.00610\n",
      "epoch 1200 / 20000\n",
      "gradient norm: 0.07231775292893872, minimum ratio: 2.5105263157894733\n",
      "\ttrain loss: 0.00615\n",
      "\tval loss: 0.00610\n",
      "epoch 1201 / 20000\n",
      "gradient norm: 0.02410919772228226, minimum ratio: 2.5236842105263158\n",
      "\ttrain loss: 0.00615\n",
      "\tval loss: 0.00609\n",
      "epoch 1202 / 20000\n",
      "gradient norm: 0.033821521676145494, minimum ratio: 2.5236842105263158\n",
      "\ttrain loss: 0.00616\n",
      "\tval loss: 0.00609\n",
      "epoch 1203 / 20000\n",
      "gradient norm: 0.03817762131802738, minimum ratio: 2.5105263157894733\n",
      "\ttrain loss: 0.00614\n",
      "\tval loss: 0.00609\n",
      "epoch 1204 / 20000\n",
      "gradient norm: 0.0477943768928526, minimum ratio: 2.526315789473684\n",
      "\ttrain loss: 0.00615\n",
      "\tval loss: 0.00610\n",
      "epoch 1205 / 20000\n",
      "gradient norm: 0.0970021296525374, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00616\n",
      "\tval loss: 0.00609\n",
      "epoch 1206 / 20000\n",
      "gradient norm: 0.05032559362007305, minimum ratio: 2.5157894736842104\n",
      "\ttrain loss: 0.00615\n",
      "\tval loss: 0.00609\n",
      "epoch 1207 / 20000\n",
      "gradient norm: 0.06263140117516741, minimum ratio: 2.5184210526315787\n",
      "\ttrain loss: 0.00615\n",
      "\tval loss: 0.00609\n",
      "epoch 1208 / 20000\n",
      "gradient norm: 0.030795107770245522, minimum ratio: 2.539473684210526\n",
      "\ttrain loss: 0.00614\n",
      "\tval loss: 0.00608\n",
      "epoch 1209 / 20000\n",
      "gradient norm: 0.06224037580250297, minimum ratio: 2.518421052631579\n",
      "\ttrain loss: 0.00615\n",
      "\tval loss: 0.00608\n",
      "epoch 1210 / 20000\n",
      "gradient norm: 0.07670714892446995, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00614\n",
      "\tval loss: 0.00609\n",
      "epoch 1211 / 20000\n",
      "gradient norm: 0.09748796472558752, minimum ratio: 2.513157894736842\n",
      "\ttrain loss: 0.00615\n",
      "\tval loss: 0.00609\n",
      "epoch 1212 / 20000\n",
      "gradient norm: 0.06627740192925557, minimum ratio: 2.515789473684211\n",
      "\ttrain loss: 0.00614\n",
      "\tval loss: 0.00608\n",
      "epoch 1213 / 20000\n",
      "gradient norm: 0.06988593548885547, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00613\n",
      "\tval loss: 0.00608\n",
      "epoch 1214 / 20000\n",
      "gradient norm: 0.09394446306396276, minimum ratio: 2.5078947368421054\n",
      "\ttrain loss: 0.00615\n",
      "\tval loss: 0.00608\n",
      "epoch 1215 / 20000\n",
      "gradient norm: 0.03928778803674504, minimum ratio: 2.5157894736842104\n",
      "\ttrain loss: 0.00613\n",
      "\tval loss: 0.00608\n",
      "epoch 1216 / 20000\n",
      "gradient norm: 0.08694997319253162, minimum ratio: 2.5105263157894737\n",
      "\ttrain loss: 0.00616\n",
      "\tval loss: 0.00607\n",
      "epoch 1217 / 20000\n",
      "gradient norm: 0.05359543234226294, minimum ratio: 2.526315789473684\n",
      "\ttrain loss: 0.00614\n",
      "\tval loss: 0.00608\n",
      "epoch 1218 / 20000\n",
      "gradient norm: 0.0375934952753596, minimum ratio: 2.5131578947368425\n",
      "\ttrain loss: 0.00613\n",
      "\tval loss: 0.00608\n",
      "epoch 1219 / 20000\n",
      "gradient norm: 0.0446658217406366, minimum ratio: 2.5315789473684207\n",
      "\ttrain loss: 0.00615\n",
      "\tval loss: 0.00607\n",
      "epoch 1220 / 20000\n",
      "gradient norm: 0.04901081070420332, minimum ratio: 2.513157894736842\n",
      "\ttrain loss: 0.00613\n",
      "\tval loss: 0.00608\n",
      "epoch 1221 / 20000\n",
      "gradient norm: 0.0897233662835788, minimum ratio: 2.5236842105263158\n",
      "\ttrain loss: 0.00614\n",
      "\tval loss: 0.00607\n",
      "epoch 1222 / 20000\n",
      "gradient norm: 0.05705518164904788, minimum ratio: 2.5289473684210524\n",
      "\ttrain loss: 0.00615\n",
      "\tval loss: 0.00607\n",
      "epoch 1223 / 20000\n",
      "gradient norm: 0.07768895814660937, minimum ratio: 2.5236842105263158\n",
      "\ttrain loss: 0.00613\n",
      "\tval loss: 0.00607\n",
      "epoch 1224 / 20000\n",
      "gradient norm: 0.07958792964927852, minimum ratio: 2.513157894736842\n",
      "\ttrain loss: 0.00613\n",
      "\tval loss: 0.00608\n",
      "epoch 1225 / 20000\n",
      "gradient norm: 0.08441850283998065, minimum ratio: 2.5105263157894737\n",
      "\ttrain loss: 0.00613\n",
      "\tval loss: 0.00607\n",
      "epoch 1226 / 20000\n",
      "gradient norm: 0.06809975067153573, minimum ratio: 2.5105263157894733\n",
      "\ttrain loss: 0.00613\n",
      "\tval loss: 0.00606\n",
      "epoch 1227 / 20000\n",
      "gradient norm: 0.06466237385757267, minimum ratio: 2.5157894736842104\n",
      "\ttrain loss: 0.00613\n",
      "\tval loss: 0.00607\n",
      "epoch 1228 / 20000\n",
      "gradient norm: 0.0639988383918535, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00613\n",
      "\tval loss: 0.00607\n",
      "epoch 1229 / 20000\n",
      "gradient norm: 0.09739338516374119, minimum ratio: 2.518421052631579\n",
      "\ttrain loss: 0.00613\n",
      "\tval loss: 0.00608\n",
      "epoch 1230 / 20000\n",
      "gradient norm: 0.09816530300304294, minimum ratio: 2.5210526315789474\n",
      "\ttrain loss: 0.00613\n",
      "\tval loss: 0.00606\n",
      "epoch 1231 / 20000\n",
      "gradient norm: 0.034868401009589434, minimum ratio: 2.507894736842105\n",
      "\ttrain loss: 0.00613\n",
      "\tval loss: 0.00606\n",
      "epoch 1232 / 20000\n",
      "gradient norm: 0.07725131828919984, minimum ratio: 2.5342105263157895\n",
      "\ttrain loss: 0.00612\n",
      "\tval loss: 0.00607\n",
      "epoch 1233 / 20000\n",
      "gradient norm: 0.06983588612638414, minimum ratio: 2.5105263157894733\n",
      "\ttrain loss: 0.00612\n",
      "\tval loss: 0.00606\n",
      "epoch 1234 / 20000\n",
      "gradient norm: 0.09073907346464694, minimum ratio: 2.5131578947368416\n",
      "\ttrain loss: 0.00613\n",
      "\tval loss: 0.00605\n",
      "epoch 1235 / 20000\n",
      "gradient norm: 0.04307856102241203, minimum ratio: 2.5210526315789474\n",
      "\ttrain loss: 0.00613\n",
      "\tval loss: 0.00606\n",
      "epoch 1236 / 20000\n",
      "gradient norm: 0.06798639264889061, minimum ratio: 2.5131578947368425\n",
      "\ttrain loss: 0.00612\n",
      "\tval loss: 0.00607\n",
      "epoch 1237 / 20000\n",
      "gradient norm: 0.05340160889318213, minimum ratio: 2.528947368421053\n",
      "\ttrain loss: 0.00611\n",
      "\tval loss: 0.00606\n",
      "epoch 1238 / 20000\n",
      "gradient norm: 0.07632710412144661, minimum ratio: 2.5315789473684207\n",
      "\ttrain loss: 0.00612\n",
      "\tval loss: 0.00606\n",
      "epoch 1239 / 20000\n",
      "gradient norm: 0.05632395124848699, minimum ratio: 2.5236842105263158\n",
      "\ttrain loss: 0.00611\n",
      "\tval loss: 0.00605\n",
      "epoch 1240 / 20000\n",
      "gradient norm: 0.05960559664526954, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00612\n",
      "\tval loss: 0.00605\n",
      "epoch 1241 / 20000\n",
      "gradient norm: 0.08257035337737761, minimum ratio: 2.513157894736842\n",
      "\ttrain loss: 0.00613\n",
      "\tval loss: 0.00606\n",
      "epoch 1242 / 20000\n",
      "gradient norm: 0.09675771780894138, minimum ratio: 2.515789473684211\n",
      "\ttrain loss: 0.00614\n",
      "\tval loss: 0.00605\n",
      "epoch 1243 / 20000\n",
      "gradient norm: 0.025597131534595974, minimum ratio: 2.5368421052631582\n",
      "\ttrain loss: 0.00612\n",
      "\tval loss: 0.00605\n",
      "epoch 1244 / 20000\n",
      "gradient norm: 0.08842907194048166, minimum ratio: 2.542105263157895\n",
      "\ttrain loss: 0.00613\n",
      "\tval loss: 0.00605\n",
      "epoch 1245 / 20000\n",
      "gradient norm: 0.07702452092780732, minimum ratio: 2.5473684210526315\n",
      "\ttrain loss: 0.00610\n",
      "\tval loss: 0.00605\n",
      "epoch 1246 / 20000\n",
      "gradient norm: 0.0903723346273182, minimum ratio: 2.526315789473684\n",
      "\ttrain loss: 0.00612\n",
      "\tval loss: 0.00606\n",
      "epoch 1247 / 20000\n",
      "gradient norm: 0.04730959582957439, minimum ratio: 2.531578947368421\n",
      "\ttrain loss: 0.00612\n",
      "\tval loss: 0.00604\n",
      "epoch 1248 / 20000\n",
      "gradient norm: 0.0399236314551672, minimum ratio: 2.5421052631578944\n",
      "\ttrain loss: 0.00611\n",
      "\tval loss: 0.00604\n",
      "epoch 1249 / 20000\n",
      "gradient norm: 0.07691359159070998, minimum ratio: 2.544736842105263\n",
      "\ttrain loss: 0.00612\n",
      "\tval loss: 0.00605\n",
      "epoch 1250 / 20000\n",
      "gradient norm: 0.09036856138845906, minimum ratio: 2.5394736842105265\n",
      "\ttrain loss: 0.00612\n",
      "\tval loss: 0.00607\n",
      "epoch 1251 / 20000\n",
      "gradient norm: 0.07028355212241877, minimum ratio: 2.5289473684210524\n",
      "\ttrain loss: 0.00610\n",
      "\tval loss: 0.00604\n",
      "epoch 1252 / 20000\n",
      "gradient norm: 0.0936020981753245, minimum ratio: 2.526315789473684\n",
      "\ttrain loss: 0.00613\n",
      "\tval loss: 0.00603\n",
      "epoch 1253 / 20000\n",
      "gradient norm: 0.07080510424566455, minimum ratio: 2.542105263157895\n",
      "\ttrain loss: 0.00611\n",
      "\tval loss: 0.00605\n",
      "epoch 1254 / 20000\n",
      "gradient norm: 0.05653505073860288, minimum ratio: 2.518421052631579\n",
      "\ttrain loss: 0.00613\n",
      "\tval loss: 0.00606\n",
      "epoch 1255 / 20000\n",
      "gradient norm: 0.06233519551460631, minimum ratio: 2.5315789473684216\n",
      "\ttrain loss: 0.00611\n",
      "\tval loss: 0.00604\n",
      "epoch 1256 / 20000\n",
      "gradient norm: 0.043108186102472246, minimum ratio: 2.5210526315789474\n",
      "\ttrain loss: 0.00611\n",
      "\tval loss: 0.00604\n",
      "epoch 1257 / 20000\n",
      "gradient norm: 0.06844482297310606, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00611\n",
      "\tval loss: 0.00604\n",
      "epoch 1258 / 20000\n",
      "gradient norm: 0.04577172637800686, minimum ratio: 2.5315789473684207\n",
      "\ttrain loss: 0.00611\n",
      "\tval loss: 0.00604\n",
      "epoch 1259 / 20000\n",
      "gradient norm: 0.13002584833884612, minimum ratio: 2.5368421052631582\n",
      "\ttrain loss: 0.00611\n",
      "\tval loss: 0.00604\n",
      "epoch 1260 / 20000\n",
      "gradient norm: 0.07632872724207118, minimum ratio: 2.536842105263158\n",
      "\ttrain loss: 0.00610\n",
      "\tval loss: 0.00604\n",
      "epoch 1261 / 20000\n",
      "gradient norm: 0.07295919257740024, minimum ratio: 2.5473684210526315\n",
      "\ttrain loss: 0.00610\n",
      "\tval loss: 0.00603\n",
      "epoch 1262 / 20000\n",
      "gradient norm: 0.12913284031674266, minimum ratio: 2.5315789473684207\n",
      "\ttrain loss: 0.00612\n",
      "\tval loss: 0.00603\n",
      "epoch 1263 / 20000\n",
      "gradient norm: 0.08078376075718552, minimum ratio: 2.5342105263157895\n",
      "\ttrain loss: 0.00611\n",
      "\tval loss: 0.00606\n",
      "epoch 1264 / 20000\n",
      "gradient norm: 0.05931022952427156, minimum ratio: 2.518421052631579\n",
      "\ttrain loss: 0.00611\n",
      "\tval loss: 0.00604\n",
      "epoch 1265 / 20000\n",
      "gradient norm: 0.11938511760672554, minimum ratio: 2.5210526315789474\n",
      "\ttrain loss: 0.00611\n",
      "\tval loss: 0.00602\n",
      "epoch 1266 / 20000\n",
      "gradient norm: 0.10872764134546742, minimum ratio: 2.5289473684210524\n",
      "\ttrain loss: 0.00610\n",
      "\tval loss: 0.00604\n",
      "epoch 1267 / 20000\n",
      "gradient norm: 0.076990865112748, minimum ratio: 2.531578947368421\n",
      "\ttrain loss: 0.00610\n",
      "\tval loss: 0.00604\n",
      "epoch 1268 / 20000\n",
      "gradient norm: 0.04686359077459201, minimum ratio: 2.5368421052631582\n",
      "\ttrain loss: 0.00610\n",
      "\tval loss: 0.00603\n",
      "epoch 1269 / 20000\n",
      "gradient norm: 0.028468482414609753, minimum ratio: 2.5473684210526315\n",
      "\ttrain loss: 0.00610\n",
      "\tval loss: 0.00603\n",
      "epoch 1270 / 20000\n",
      "gradient norm: 0.08592875555041246, minimum ratio: 2.5210526315789474\n",
      "\ttrain loss: 0.00609\n",
      "\tval loss: 0.00603\n",
      "epoch 1271 / 20000\n",
      "gradient norm: 0.05455492282635532, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00609\n",
      "\tval loss: 0.00603\n",
      "epoch 1272 / 20000\n",
      "gradient norm: 0.0267077989410609, minimum ratio: 2.5473684210526315\n",
      "\ttrain loss: 0.00610\n",
      "\tval loss: 0.00603\n",
      "epoch 1273 / 20000\n",
      "gradient norm: 0.07022367970785126, minimum ratio: 2.5210526315789474\n",
      "\ttrain loss: 0.00609\n",
      "\tval loss: 0.00603\n",
      "epoch 1274 / 20000\n",
      "gradient norm: 0.12000110483495519, minimum ratio: 2.526315789473684\n",
      "\ttrain loss: 0.00610\n",
      "\tval loss: 0.00604\n",
      "epoch 1275 / 20000\n",
      "gradient norm: 0.11215019063092768, minimum ratio: 2.5289473684210524\n",
      "\ttrain loss: 0.00611\n",
      "\tval loss: 0.00602\n",
      "epoch 1276 / 20000\n",
      "gradient norm: 0.040812287537846714, minimum ratio: 2.5157894736842104\n",
      "\ttrain loss: 0.00610\n",
      "\tval loss: 0.00603\n",
      "epoch 1277 / 20000\n",
      "gradient norm: 0.08866225948440842, minimum ratio: 2.5236842105263158\n",
      "\ttrain loss: 0.00609\n",
      "\tval loss: 0.00603\n",
      "epoch 1278 / 20000\n",
      "gradient norm: 0.039352911757305264, minimum ratio: 2.5315789473684207\n",
      "\ttrain loss: 0.00610\n",
      "\tval loss: 0.00604\n",
      "epoch 1279 / 20000\n",
      "gradient norm: 0.02324469038285315, minimum ratio: 2.507894736842105\n",
      "\ttrain loss: 0.00609\n",
      "\tval loss: 0.00603\n",
      "epoch 1280 / 20000\n",
      "gradient norm: 0.07707973814103752, minimum ratio: 2.5236842105263158\n",
      "\ttrain loss: 0.00609\n",
      "\tval loss: 0.00602\n",
      "epoch 1281 / 20000\n",
      "gradient norm: 0.04339409258682281, minimum ratio: 2.5210526315789474\n",
      "\ttrain loss: 0.00609\n",
      "\tval loss: 0.00602\n",
      "epoch 1282 / 20000\n",
      "gradient norm: 0.07565321197034791, minimum ratio: 2.5289473684210524\n",
      "\ttrain loss: 0.00609\n",
      "\tval loss: 0.00603\n",
      "epoch 1283 / 20000\n",
      "gradient norm: 0.09579725156072527, minimum ratio: 2.494736842105263\n",
      "\ttrain loss: 0.00609\n",
      "\tval loss: 0.00602\n",
      "epoch 1284 / 20000\n",
      "gradient norm: 0.1225881430436857, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.00610\n",
      "\tval loss: 0.00601\n",
      "epoch 1285 / 20000\n",
      "gradient norm: 0.05550183990271762, minimum ratio: 2.5210526315789474\n",
      "\ttrain loss: 0.00609\n",
      "\tval loss: 0.00602\n",
      "epoch 1286 / 20000\n",
      "gradient norm: 0.06173249596031383, minimum ratio: 2.5394736842105265\n",
      "\ttrain loss: 0.00607\n",
      "\tval loss: 0.00603\n",
      "epoch 1287 / 20000\n",
      "gradient norm: 0.10827212856383994, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00610\n",
      "\tval loss: 0.00603\n",
      "epoch 1288 / 20000\n",
      "gradient norm: 0.09140983805991709, minimum ratio: 2.5289473684210524\n",
      "\ttrain loss: 0.00610\n",
      "\tval loss: 0.00601\n",
      "epoch 1289 / 20000\n",
      "gradient norm: 0.05091976255062036, minimum ratio: 2.536842105263158\n",
      "\ttrain loss: 0.00609\n",
      "\tval loss: 0.00601\n",
      "epoch 1290 / 20000\n",
      "gradient norm: 0.05512667589937337, minimum ratio: 2.518421052631579\n",
      "\ttrain loss: 0.00608\n",
      "\tval loss: 0.00603\n",
      "epoch 1291 / 20000\n",
      "gradient norm: 0.05333144904579967, minimum ratio: 2.542105263157895\n",
      "\ttrain loss: 0.00609\n",
      "\tval loss: 0.00602\n",
      "epoch 1292 / 20000\n",
      "gradient norm: 0.10434506458113901, minimum ratio: 2.536842105263158\n",
      "\ttrain loss: 0.00610\n",
      "\tval loss: 0.00600\n",
      "epoch 1293 / 20000\n",
      "gradient norm: 0.0708149217243772, minimum ratio: 2.536842105263158\n",
      "\ttrain loss: 0.00608\n",
      "\tval loss: 0.00602\n",
      "epoch 1294 / 20000\n",
      "gradient norm: 0.039687623881036416, minimum ratio: 2.5315789473684207\n",
      "\ttrain loss: 0.00609\n",
      "\tval loss: 0.00602\n",
      "epoch 1295 / 20000\n",
      "gradient norm: 0.07326780282892287, minimum ratio: 2.5236842105263158\n",
      "\ttrain loss: 0.00608\n",
      "\tval loss: 0.00602\n",
      "epoch 1296 / 20000\n",
      "gradient norm: 0.09144327789545059, minimum ratio: 2.526315789473684\n",
      "\ttrain loss: 0.00609\n",
      "\tval loss: 0.00600\n",
      "epoch 1297 / 20000\n",
      "gradient norm: 0.07752978691132739, minimum ratio: 2.536842105263158\n",
      "\ttrain loss: 0.00608\n",
      "\tval loss: 0.00602\n",
      "epoch 1298 / 20000\n",
      "gradient norm: 0.07602557176142, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00608\n",
      "\tval loss: 0.00601\n",
      "epoch 1299 / 20000\n",
      "gradient norm: 0.07067429053131491, minimum ratio: 2.5184210526315787\n",
      "\ttrain loss: 0.00607\n",
      "\tval loss: 0.00601\n",
      "epoch 1300 / 20000\n",
      "gradient norm: 0.046419435093412176, minimum ratio: 2.526315789473684\n",
      "\ttrain loss: 0.00608\n",
      "\tval loss: 0.00600\n",
      "epoch 1301 / 20000\n",
      "gradient norm: 0.07332827124628238, minimum ratio: 2.531578947368421\n",
      "\ttrain loss: 0.00608\n",
      "\tval loss: 0.00600\n",
      "epoch 1302 / 20000\n",
      "gradient norm: 0.0449585187016055, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00608\n",
      "\tval loss: 0.00601\n",
      "epoch 1303 / 20000\n",
      "gradient norm: 0.032118917995831, minimum ratio: 2.5236842105263158\n",
      "\ttrain loss: 0.00608\n",
      "\tval loss: 0.00601\n",
      "epoch 1304 / 20000\n",
      "gradient norm: 0.05849619893706404, minimum ratio: 2.5105263157894737\n",
      "\ttrain loss: 0.00608\n",
      "\tval loss: 0.00600\n",
      "epoch 1305 / 20000\n",
      "gradient norm: 0.053328759808209725, minimum ratio: 2.5315789473684207\n",
      "\ttrain loss: 0.00608\n",
      "\tval loss: 0.00600\n",
      "epoch 1306 / 20000\n",
      "gradient norm: 0.04545782212517224, minimum ratio: 2.5342105263157895\n",
      "\ttrain loss: 0.00608\n",
      "\tval loss: 0.00601\n",
      "epoch 1307 / 20000\n",
      "gradient norm: 0.050885009666671976, minimum ratio: 2.518421052631579\n",
      "\ttrain loss: 0.00607\n",
      "\tval loss: 0.00601\n",
      "epoch 1308 / 20000\n",
      "gradient norm: 0.054328569924109615, minimum ratio: 2.513157894736842\n",
      "\ttrain loss: 0.00608\n",
      "\tval loss: 0.00600\n",
      "epoch 1309 / 20000\n",
      "gradient norm: 0.06581878862925805, minimum ratio: 2.5315789473684207\n",
      "\ttrain loss: 0.00608\n",
      "\tval loss: 0.00600\n",
      "epoch 1310 / 20000\n",
      "gradient norm: 0.07055014511570334, minimum ratio: 2.5368421052631582\n",
      "\ttrain loss: 0.00609\n",
      "\tval loss: 0.00600\n",
      "epoch 1311 / 20000\n",
      "gradient norm: 0.07851495026261546, minimum ratio: 2.5131578947368416\n",
      "\ttrain loss: 0.00607\n",
      "\tval loss: 0.00600\n",
      "epoch 1312 / 20000\n",
      "gradient norm: 0.043622210854664445, minimum ratio: 2.5289473684210524\n",
      "\ttrain loss: 0.00608\n",
      "\tval loss: 0.00600\n",
      "epoch 1313 / 20000\n",
      "gradient norm: 0.05241461319383234, minimum ratio: 2.534210526315789\n",
      "\ttrain loss: 0.00607\n",
      "\tval loss: 0.00601\n",
      "epoch 1314 / 20000\n",
      "gradient norm: 0.03762649683631025, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00607\n",
      "\tval loss: 0.00599\n",
      "epoch 1315 / 20000\n",
      "gradient norm: 0.06794794311281294, minimum ratio: 2.5289473684210524\n",
      "\ttrain loss: 0.00606\n",
      "\tval loss: 0.00600\n",
      "epoch 1316 / 20000\n",
      "gradient norm: 0.10482874588342384, minimum ratio: 2.5473684210526315\n",
      "\ttrain loss: 0.00607\n",
      "\tval loss: 0.00600\n",
      "epoch 1317 / 20000\n",
      "gradient norm: 0.11093716393224895, minimum ratio: 2.513157894736842\n",
      "\ttrain loss: 0.00607\n",
      "\tval loss: 0.00599\n",
      "epoch 1318 / 20000\n",
      "gradient norm: 0.05835073531488888, minimum ratio: 2.518421052631579\n",
      "\ttrain loss: 0.00607\n",
      "\tval loss: 0.00599\n",
      "epoch 1319 / 20000\n",
      "gradient norm: 0.07527276780456305, minimum ratio: 2.518421052631579\n",
      "\ttrain loss: 0.00607\n",
      "\tval loss: 0.00600\n",
      "epoch 1320 / 20000\n",
      "gradient norm: 0.09391648485325277, minimum ratio: 2.5289473684210524\n",
      "\ttrain loss: 0.00608\n",
      "\tval loss: 0.00599\n",
      "epoch 1321 / 20000\n",
      "gradient norm: 0.08033723599510267, minimum ratio: 2.5105263157894737\n",
      "\ttrain loss: 0.00607\n",
      "\tval loss: 0.00599\n",
      "epoch 1322 / 20000\n",
      "gradient norm: 0.07670270069502294, minimum ratio: 2.552631578947368\n",
      "\ttrain loss: 0.00608\n",
      "\tval loss: 0.00601\n",
      "epoch 1323 / 20000\n",
      "gradient norm: 0.08167405717540532, minimum ratio: 2.542105263157895\n",
      "\ttrain loss: 0.00608\n",
      "\tval loss: 0.00599\n",
      "epoch 1324 / 20000\n",
      "gradient norm: 0.05356201037648134, minimum ratio: 2.5157894736842104\n",
      "\ttrain loss: 0.00607\n",
      "\tval loss: 0.00598\n",
      "epoch 1325 / 20000\n",
      "gradient norm: 0.04657762675196864, minimum ratio: 2.5473684210526315\n",
      "\ttrain loss: 0.00606\n",
      "\tval loss: 0.00600\n",
      "epoch 1326 / 20000\n",
      "gradient norm: 0.05835652383393608, minimum ratio: 2.536842105263158\n",
      "\ttrain loss: 0.00607\n",
      "\tval loss: 0.00600\n",
      "epoch 1327 / 20000\n",
      "gradient norm: 0.04639786033658311, minimum ratio: 2.534210526315789\n",
      "\ttrain loss: 0.00607\n",
      "\tval loss: 0.00599\n",
      "epoch 1328 / 20000\n",
      "gradient norm: 0.0743643948371755, minimum ratio: 2.536842105263158\n",
      "\ttrain loss: 0.00605\n",
      "\tval loss: 0.00598\n",
      "epoch 1329 / 20000\n",
      "gradient norm: 0.06974121002713218, minimum ratio: 2.534210526315789\n",
      "\ttrain loss: 0.00608\n",
      "\tval loss: 0.00598\n",
      "epoch 1330 / 20000\n",
      "gradient norm: 0.03898679278790951, minimum ratio: 2.5236842105263158\n",
      "\ttrain loss: 0.00605\n",
      "\tval loss: 0.00598\n",
      "epoch 1331 / 20000\n",
      "gradient norm: 0.05052776384400204, minimum ratio: 2.5421052631578944\n",
      "\ttrain loss: 0.00606\n",
      "\tval loss: 0.00599\n",
      "epoch 1332 / 20000\n",
      "gradient norm: 0.03908068053715397, minimum ratio: 2.5342105263157895\n",
      "\ttrain loss: 0.00605\n",
      "\tval loss: 0.00598\n",
      "epoch 1333 / 20000\n",
      "gradient norm: 0.06558525329455733, minimum ratio: 2.515789473684211\n",
      "\ttrain loss: 0.00606\n",
      "\tval loss: 0.00598\n",
      "epoch 1334 / 20000\n",
      "gradient norm: 0.0445550789590925, minimum ratio: 2.56578947368421\n",
      "\ttrain loss: 0.00606\n",
      "\tval loss: 0.00599\n",
      "epoch 1335 / 20000\n",
      "gradient norm: 0.09680870368902106, minimum ratio: 2.5263157894736845\n",
      "\ttrain loss: 0.00607\n",
      "\tval loss: 0.00598\n",
      "epoch 1336 / 20000\n",
      "gradient norm: 0.05777866195421666, minimum ratio: 2.5394736842105265\n",
      "\ttrain loss: 0.00606\n",
      "\tval loss: 0.00600\n",
      "epoch 1337 / 20000\n",
      "gradient norm: 0.06709753705217736, minimum ratio: 2.528947368421053\n",
      "\ttrain loss: 0.00607\n",
      "\tval loss: 0.00598\n",
      "epoch 1338 / 20000\n",
      "gradient norm: 0.04917620393098332, minimum ratio: 2.542105263157895\n",
      "\ttrain loss: 0.00606\n",
      "\tval loss: 0.00598\n",
      "epoch 1339 / 20000\n",
      "gradient norm: 0.053370048524811864, minimum ratio: 2.526315789473684\n",
      "\ttrain loss: 0.00606\n",
      "\tval loss: 0.00598\n",
      "epoch 1340 / 20000\n",
      "gradient norm: 0.0980463694431819, minimum ratio: 2.55\n",
      "\ttrain loss: 0.00606\n",
      "\tval loss: 0.00599\n",
      "epoch 1341 / 20000\n",
      "gradient norm: 0.045563019055407494, minimum ratio: 2.542105263157895\n",
      "\ttrain loss: 0.00605\n",
      "\tval loss: 0.00598\n",
      "epoch 1342 / 20000\n",
      "gradient norm: 0.11526561353821307, minimum ratio: 2.5657894736842106\n",
      "\ttrain loss: 0.00605\n",
      "\tval loss: 0.00597\n",
      "epoch 1343 / 20000\n",
      "gradient norm: 0.03106404616846703, minimum ratio: 2.5315789473684207\n",
      "\ttrain loss: 0.00605\n",
      "\tval loss: 0.00598\n",
      "epoch 1344 / 20000\n",
      "gradient norm: 0.034521672190749086, minimum ratio: 2.5236842105263158\n",
      "\ttrain loss: 0.00606\n",
      "\tval loss: 0.00598\n",
      "epoch 1345 / 20000\n",
      "gradient norm: 0.08018113486468792, minimum ratio: 2.55\n",
      "\ttrain loss: 0.00605\n",
      "\tval loss: 0.00598\n",
      "epoch 1346 / 20000\n",
      "gradient norm: 0.08358198942732997, minimum ratio: 2.544736842105263\n",
      "\ttrain loss: 0.00606\n",
      "\tval loss: 0.00597\n",
      "epoch 1347 / 20000\n",
      "gradient norm: 0.03379943667096086, minimum ratio: 2.521052631578947\n",
      "\ttrain loss: 0.00604\n",
      "\tval loss: 0.00598\n",
      "epoch 1348 / 20000\n",
      "gradient norm: 0.11809103994164616, minimum ratio: 2.526315789473684\n",
      "\ttrain loss: 0.00605\n",
      "\tval loss: 0.00597\n",
      "epoch 1349 / 20000\n",
      "gradient norm: 0.03198753626202233, minimum ratio: 2.55\n",
      "\ttrain loss: 0.00606\n",
      "\tval loss: 0.00598\n",
      "epoch 1350 / 20000\n",
      "gradient norm: 0.06758055812679231, minimum ratio: 2.518421052631579\n",
      "\ttrain loss: 0.00604\n",
      "\tval loss: 0.00598\n",
      "epoch 1351 / 20000\n",
      "gradient norm: 0.0505381617549574, minimum ratio: 2.521052631578947\n",
      "\ttrain loss: 0.00605\n",
      "\tval loss: 0.00597\n",
      "epoch 1352 / 20000\n",
      "gradient norm: 0.04364007612457499, minimum ratio: 2.5236842105263158\n",
      "\ttrain loss: 0.00605\n",
      "\tval loss: 0.00597\n",
      "epoch 1353 / 20000\n",
      "gradient norm: 0.08113913316628896, minimum ratio: 2.526315789473684\n",
      "\ttrain loss: 0.00606\n",
      "\tval loss: 0.00598\n",
      "epoch 1354 / 20000\n",
      "gradient norm: 0.0686309028242249, minimum ratio: 2.531578947368421\n",
      "\ttrain loss: 0.00603\n",
      "\tval loss: 0.00597\n",
      "epoch 1355 / 20000\n",
      "gradient norm: 0.04662330780411139, minimum ratio: 2.513157894736842\n",
      "\ttrain loss: 0.00605\n",
      "\tval loss: 0.00597\n",
      "epoch 1356 / 20000\n",
      "gradient norm: 0.04434016940649599, minimum ratio: 2.5105263157894737\n",
      "\ttrain loss: 0.00604\n",
      "\tval loss: 0.00597\n",
      "epoch 1357 / 20000\n",
      "gradient norm: 0.101656799641205, minimum ratio: 2.531578947368421\n",
      "\ttrain loss: 0.00604\n",
      "\tval loss: 0.00598\n",
      "epoch 1358 / 20000\n",
      "gradient norm: 0.07170018419856206, minimum ratio: 2.5236842105263158\n",
      "\ttrain loss: 0.00605\n",
      "\tval loss: 0.00597\n",
      "epoch 1359 / 20000\n",
      "gradient norm: 0.07499594218097627, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00605\n",
      "\tval loss: 0.00596\n",
      "epoch 1360 / 20000\n",
      "gradient norm: 0.08452565610059537, minimum ratio: 2.526315789473684\n",
      "\ttrain loss: 0.00605\n",
      "\tval loss: 0.00597\n",
      "epoch 1361 / 20000\n",
      "gradient norm: 0.08594802138395607, minimum ratio: 2.5184210526315787\n",
      "\ttrain loss: 0.00606\n",
      "\tval loss: 0.00598\n",
      "epoch 1362 / 20000\n",
      "gradient norm: 0.03775428736116737, minimum ratio: 2.5236842105263158\n",
      "\ttrain loss: 0.00605\n",
      "\tval loss: 0.00596\n",
      "epoch 1363 / 20000\n",
      "gradient norm: 0.045124190364731476, minimum ratio: 2.542105263157895\n",
      "\ttrain loss: 0.00604\n",
      "\tval loss: 0.00596\n",
      "epoch 1364 / 20000\n",
      "gradient norm: 0.09970801681629382, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00605\n",
      "\tval loss: 0.00596\n",
      "epoch 1365 / 20000\n",
      "gradient norm: 0.053331376548158005, minimum ratio: 2.5315789473684207\n",
      "\ttrain loss: 0.00604\n",
      "\tval loss: 0.00598\n",
      "epoch 1366 / 20000\n",
      "gradient norm: 0.08920634631067514, minimum ratio: 2.542105263157895\n",
      "\ttrain loss: 0.00604\n",
      "\tval loss: 0.00596\n",
      "epoch 1367 / 20000\n",
      "gradient norm: 0.07054312294349074, minimum ratio: 2.539473684210526\n",
      "\ttrain loss: 0.00605\n",
      "\tval loss: 0.00595\n",
      "epoch 1368 / 20000\n",
      "gradient norm: 0.03605262836208567, minimum ratio: 2.5105263157894737\n",
      "\ttrain loss: 0.00605\n",
      "\tval loss: 0.00597\n",
      "epoch 1369 / 20000\n",
      "gradient norm: 0.05510629931814037, minimum ratio: 2.515789473684211\n",
      "\ttrain loss: 0.00604\n",
      "\tval loss: 0.00598\n",
      "epoch 1370 / 20000\n",
      "gradient norm: 0.048477200587512925, minimum ratio: 2.544736842105263\n",
      "\ttrain loss: 0.00605\n",
      "\tval loss: 0.00596\n",
      "epoch 1371 / 20000\n",
      "gradient norm: 0.10174932520021684, minimum ratio: 2.5157894736842104\n",
      "\ttrain loss: 0.00604\n",
      "\tval loss: 0.00596\n",
      "epoch 1372 / 20000\n",
      "gradient norm: 0.03274136422260199, minimum ratio: 2.5210526315789474\n",
      "\ttrain loss: 0.00603\n",
      "\tval loss: 0.00596\n",
      "epoch 1373 / 20000\n",
      "gradient norm: 0.03891114033467602, minimum ratio: 2.5289473684210524\n",
      "\ttrain loss: 0.00604\n",
      "\tval loss: 0.00596\n",
      "epoch 1374 / 20000\n",
      "gradient norm: 0.07772154308622703, minimum ratio: 2.544736842105263\n",
      "\ttrain loss: 0.00603\n",
      "\tval loss: 0.00596\n",
      "epoch 1375 / 20000\n",
      "gradient norm: 0.038004950707545504, minimum ratio: 2.507894736842105\n",
      "\ttrain loss: 0.00603\n",
      "\tval loss: 0.00595\n",
      "epoch 1376 / 20000\n",
      "gradient norm: 0.06822282797656953, minimum ratio: 2.5157894736842104\n",
      "\ttrain loss: 0.00604\n",
      "\tval loss: 0.00595\n",
      "epoch 1377 / 20000\n",
      "gradient norm: 0.07564657993498258, minimum ratio: 2.507894736842105\n",
      "\ttrain loss: 0.00604\n",
      "\tval loss: 0.00596\n",
      "epoch 1378 / 20000\n",
      "gradient norm: 0.057489662256557494, minimum ratio: 2.5289473684210524\n",
      "\ttrain loss: 0.00604\n",
      "\tval loss: 0.00596\n",
      "epoch 1379 / 20000\n",
      "gradient norm: 0.05522553724586032, minimum ratio: 2.542105263157895\n",
      "\ttrain loss: 0.00603\n",
      "\tval loss: 0.00596\n",
      "epoch 1380 / 20000\n",
      "gradient norm: 0.07158103055553511, minimum ratio: 2.5105263157894733\n",
      "\ttrain loss: 0.00603\n",
      "\tval loss: 0.00595\n",
      "epoch 1381 / 20000\n",
      "gradient norm: 0.04266444515087642, minimum ratio: 2.513157894736842\n",
      "\ttrain loss: 0.00603\n",
      "\tval loss: 0.00595\n",
      "epoch 1382 / 20000\n",
      "gradient norm: 0.08404876690474339, minimum ratio: 2.526315789473684\n",
      "\ttrain loss: 0.00603\n",
      "\tval loss: 0.00597\n",
      "epoch 1383 / 20000\n",
      "gradient norm: 0.04824951331829652, minimum ratio: 2.523684210526316\n",
      "\ttrain loss: 0.00603\n",
      "\tval loss: 0.00595\n",
      "epoch 1384 / 20000\n",
      "gradient norm: 0.06846841878723353, minimum ratio: 2.55\n",
      "\ttrain loss: 0.00605\n",
      "\tval loss: 0.00595\n",
      "epoch 1385 / 20000\n",
      "gradient norm: 0.12256928690476343, minimum ratio: 2.526315789473684\n",
      "\ttrain loss: 0.00602\n",
      "\tval loss: 0.00596\n",
      "epoch 1386 / 20000\n",
      "gradient norm: 0.056201874191174284, minimum ratio: 2.494736842105263\n",
      "\ttrain loss: 0.00604\n",
      "\tval loss: 0.00596\n",
      "epoch 1387 / 20000\n",
      "gradient norm: 0.04001059627626091, minimum ratio: 2.5184210526315787\n",
      "\ttrain loss: 0.00604\n",
      "\tval loss: 0.00595\n",
      "epoch 1388 / 20000\n",
      "gradient norm: 0.03917281195754185, minimum ratio: 2.5421052631578944\n",
      "\ttrain loss: 0.00601\n",
      "\tval loss: 0.00595\n",
      "epoch 1389 / 20000\n",
      "gradient norm: 0.04314315167721361, minimum ratio: 2.526315789473684\n",
      "\ttrain loss: 0.00603\n",
      "\tval loss: 0.00594\n",
      "epoch 1390 / 20000\n",
      "gradient norm: 0.05448808197979815, minimum ratio: 2.544736842105263\n",
      "\ttrain loss: 0.00602\n",
      "\tval loss: 0.00595\n",
      "epoch 1391 / 20000\n",
      "gradient norm: 0.03501004583085887, minimum ratio: 2.5105263157894737\n",
      "\ttrain loss: 0.00603\n",
      "\tval loss: 0.00595\n",
      "epoch 1392 / 20000\n",
      "gradient norm: 0.06673638540087268, minimum ratio: 2.5315789473684207\n",
      "\ttrain loss: 0.00601\n",
      "\tval loss: 0.00595\n",
      "epoch 1393 / 20000\n",
      "gradient norm: 0.08593002991983667, minimum ratio: 2.526315789473684\n",
      "\ttrain loss: 0.00602\n",
      "\tval loss: 0.00594\n",
      "epoch 1394 / 20000\n",
      "gradient norm: 0.08016968113952316, minimum ratio: 2.5184210526315787\n",
      "\ttrain loss: 0.00603\n",
      "\tval loss: 0.00594\n",
      "epoch 1395 / 20000\n",
      "gradient norm: 0.0884218830615282, minimum ratio: 2.5210526315789474\n",
      "\ttrain loss: 0.00602\n",
      "\tval loss: 0.00595\n",
      "epoch 1396 / 20000\n",
      "gradient norm: 0.1078131134272553, minimum ratio: 2.531578947368421\n",
      "\ttrain loss: 0.00604\n",
      "\tval loss: 0.00594\n",
      "epoch 1397 / 20000\n",
      "gradient norm: 0.04896321568230633, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00603\n",
      "\tval loss: 0.00596\n",
      "epoch 1398 / 20000\n",
      "gradient norm: 0.03371837513986975, minimum ratio: 2.513157894736842\n",
      "\ttrain loss: 0.00602\n",
      "\tval loss: 0.00595\n",
      "epoch 1399 / 20000\n",
      "gradient norm: 0.05828790640225634, minimum ratio: 2.5131578947368425\n",
      "\ttrain loss: 0.00603\n",
      "\tval loss: 0.00594\n",
      "epoch 1400 / 20000\n",
      "gradient norm: 0.05381753187975846, minimum ratio: 2.5342105263157895\n",
      "\ttrain loss: 0.00604\n",
      "\tval loss: 0.00594\n",
      "epoch 1401 / 20000\n",
      "gradient norm: 0.03850879148012609, minimum ratio: 2.5342105263157895\n",
      "\ttrain loss: 0.00603\n",
      "\tval loss: 0.00595\n",
      "epoch 1402 / 20000\n",
      "gradient norm: 0.04286984875216149, minimum ratio: 2.5368421052631582\n",
      "\ttrain loss: 0.00603\n",
      "\tval loss: 0.00595\n",
      "epoch 1403 / 20000\n",
      "gradient norm: 0.0929043412907049, minimum ratio: 2.5315789473684207\n",
      "\ttrain loss: 0.00602\n",
      "\tval loss: 0.00593\n",
      "epoch 1404 / 20000\n",
      "gradient norm: 0.09449183638207614, minimum ratio: 2.5078947368421054\n",
      "\ttrain loss: 0.00602\n",
      "\tval loss: 0.00594\n",
      "epoch 1405 / 20000\n",
      "gradient norm: 0.09125901636434719, minimum ratio: 2.542105263157895\n",
      "\ttrain loss: 0.00604\n",
      "\tval loss: 0.00594\n",
      "epoch 1406 / 20000\n",
      "gradient norm: 0.05486842434038408, minimum ratio: 2.5210526315789474\n",
      "\ttrain loss: 0.00603\n",
      "\tval loss: 0.00595\n",
      "epoch 1407 / 20000\n",
      "gradient norm: 0.06220079131890088, minimum ratio: 2.518421052631579\n",
      "\ttrain loss: 0.00602\n",
      "\tval loss: 0.00594\n",
      "epoch 1408 / 20000\n",
      "gradient norm: 0.12677940315916203, minimum ratio: 2.531578947368421\n",
      "\ttrain loss: 0.00602\n",
      "\tval loss: 0.00593\n",
      "epoch 1409 / 20000\n",
      "gradient norm: 0.06461909780045971, minimum ratio: 2.528947368421053\n",
      "\ttrain loss: 0.00601\n",
      "\tval loss: 0.00593\n",
      "epoch 1410 / 20000\n",
      "gradient norm: 0.026318111820728518, minimum ratio: 2.5210526315789474\n",
      "\ttrain loss: 0.00603\n",
      "\tval loss: 0.00594\n",
      "epoch 1411 / 20000\n",
      "gradient norm: 0.10856388963293284, minimum ratio: 2.5394736842105265\n",
      "\ttrain loss: 0.00602\n",
      "\tval loss: 0.00595\n",
      "epoch 1412 / 20000\n",
      "gradient norm: 0.060855985357193276, minimum ratio: 2.5236842105263158\n",
      "\ttrain loss: 0.00602\n",
      "\tval loss: 0.00593\n",
      "epoch 1413 / 20000\n",
      "gradient norm: 0.10118587920442224, minimum ratio: 2.526315789473684\n",
      "\ttrain loss: 0.00602\n",
      "\tval loss: 0.00593\n",
      "epoch 1414 / 20000\n",
      "gradient norm: 0.05173394922167063, minimum ratio: 2.536842105263158\n",
      "\ttrain loss: 0.00602\n",
      "\tval loss: 0.00593\n",
      "epoch 1415 / 20000\n",
      "gradient norm: 0.03330698862555437, minimum ratio: 2.536842105263158\n",
      "\ttrain loss: 0.00602\n",
      "\tval loss: 0.00594\n",
      "epoch 1416 / 20000\n",
      "gradient norm: 0.061950934294145554, minimum ratio: 2.5105263157894737\n",
      "\ttrain loss: 0.00602\n",
      "\tval loss: 0.00594\n",
      "epoch 1417 / 20000\n",
      "gradient norm: 0.0899656408582814, minimum ratio: 2.5210526315789474\n",
      "\ttrain loss: 0.00602\n",
      "\tval loss: 0.00594\n",
      "epoch 1418 / 20000\n",
      "gradient norm: 0.09276409237645566, minimum ratio: 2.536842105263158\n",
      "\ttrain loss: 0.00603\n",
      "\tval loss: 0.00592\n",
      "epoch 1419 / 20000\n",
      "gradient norm: 0.03496562590589747, minimum ratio: 2.5394736842105265\n",
      "\ttrain loss: 0.00601\n",
      "\tval loss: 0.00594\n",
      "epoch 1420 / 20000\n",
      "gradient norm: 0.07475162105401978, minimum ratio: 2.539473684210526\n",
      "\ttrain loss: 0.00603\n",
      "\tval loss: 0.00594\n",
      "epoch 1421 / 20000\n",
      "gradient norm: 0.08978459239006042, minimum ratio: 2.536842105263158\n",
      "\ttrain loss: 0.00602\n",
      "\tval loss: 0.00593\n",
      "epoch 1422 / 20000\n",
      "gradient norm: 0.08389600637019612, minimum ratio: 2.5342105263157895\n",
      "\ttrain loss: 0.00602\n",
      "\tval loss: 0.00592\n",
      "epoch 1423 / 20000\n",
      "gradient norm: 0.06831374281318858, minimum ratio: 2.555263157894737\n",
      "\ttrain loss: 0.00603\n",
      "\tval loss: 0.00592\n",
      "epoch 1424 / 20000\n",
      "gradient norm: 0.05908674049715046, minimum ratio: 2.5394736842105265\n",
      "\ttrain loss: 0.00601\n",
      "\tval loss: 0.00594\n",
      "epoch 1425 / 20000\n",
      "gradient norm: 0.0579918694566004, minimum ratio: 2.5473684210526315\n",
      "\ttrain loss: 0.00603\n",
      "\tval loss: 0.00593\n",
      "epoch 1426 / 20000\n",
      "gradient norm: 0.04245351237477735, minimum ratio: 2.5368421052631573\n",
      "\ttrain loss: 0.00600\n",
      "\tval loss: 0.00593\n",
      "epoch 1427 / 20000\n",
      "gradient norm: 0.0644080525089521, minimum ratio: 2.536842105263158\n",
      "\ttrain loss: 0.00601\n",
      "\tval loss: 0.00593\n",
      "epoch 1428 / 20000\n",
      "gradient norm: 0.055126912833657116, minimum ratio: 2.5473684210526315\n",
      "\ttrain loss: 0.00601\n",
      "\tval loss: 0.00593\n",
      "epoch 1429 / 20000\n",
      "gradient norm: 0.0470947363646701, minimum ratio: 2.5473684210526315\n",
      "\ttrain loss: 0.00601\n",
      "\tval loss: 0.00592\n",
      "epoch 1430 / 20000\n",
      "gradient norm: 0.08288974256720394, minimum ratio: 2.531578947368421\n",
      "\ttrain loss: 0.00601\n",
      "\tval loss: 0.00592\n",
      "epoch 1431 / 20000\n",
      "gradient norm: 0.04246027173940092, minimum ratio: 2.5236842105263158\n",
      "\ttrain loss: 0.00601\n",
      "\tval loss: 0.00592\n",
      "epoch 1432 / 20000\n",
      "gradient norm: 0.07795608101878315, minimum ratio: 2.5473684210526315\n",
      "\ttrain loss: 0.00601\n",
      "\tval loss: 0.00593\n",
      "epoch 1433 / 20000\n",
      "gradient norm: 0.05318381200777367, minimum ratio: 2.5368421052631582\n",
      "\ttrain loss: 0.00600\n",
      "\tval loss: 0.00592\n",
      "epoch 1434 / 20000\n",
      "gradient norm: 0.027636565995635465, minimum ratio: 2.5368421052631573\n",
      "\ttrain loss: 0.00600\n",
      "\tval loss: 0.00592\n",
      "epoch 1435 / 20000\n",
      "gradient norm: 0.11453002548660152, minimum ratio: 2.5289473684210524\n",
      "\ttrain loss: 0.00601\n",
      "\tval loss: 0.00593\n",
      "epoch 1436 / 20000\n",
      "gradient norm: 0.04301787435542792, minimum ratio: 2.5578947368421057\n",
      "\ttrain loss: 0.00601\n",
      "\tval loss: 0.00592\n",
      "epoch 1437 / 20000\n",
      "gradient norm: 0.07057317480212077, minimum ratio: 2.5315789473684207\n",
      "\ttrain loss: 0.00602\n",
      "\tval loss: 0.00591\n",
      "epoch 1438 / 20000\n",
      "gradient norm: 0.07293482357636094, minimum ratio: 2.5131578947368416\n",
      "\ttrain loss: 0.00601\n",
      "\tval loss: 0.00592\n",
      "epoch 1439 / 20000\n",
      "gradient norm: 0.06884002222795971, minimum ratio: 2.5289473684210524\n",
      "\ttrain loss: 0.00600\n",
      "\tval loss: 0.00594\n",
      "epoch 1440 / 20000\n",
      "gradient norm: 0.10182639851700515, minimum ratio: 2.513157894736842\n",
      "\ttrain loss: 0.00600\n",
      "\tval loss: 0.00592\n",
      "epoch 1441 / 20000\n",
      "gradient norm: 0.10649770993040875, minimum ratio: 2.5105263157894737\n",
      "\ttrain loss: 0.00602\n",
      "\tval loss: 0.00591\n",
      "epoch 1442 / 20000\n",
      "gradient norm: 0.06083488534204662, minimum ratio: 2.5394736842105265\n",
      "\ttrain loss: 0.00602\n",
      "\tval loss: 0.00593\n",
      "epoch 1443 / 20000\n",
      "gradient norm: 0.053941403777571395, minimum ratio: 2.5105263157894737\n",
      "\ttrain loss: 0.00600\n",
      "\tval loss: 0.00593\n",
      "epoch 1444 / 20000\n",
      "gradient norm: 0.09628787406836636, minimum ratio: 2.5210526315789474\n",
      "\ttrain loss: 0.00599\n",
      "\tval loss: 0.00592\n",
      "epoch 1445 / 20000\n",
      "gradient norm: 0.07747483905404806, minimum ratio: 2.544736842105263\n",
      "\ttrain loss: 0.00600\n",
      "\tval loss: 0.00591\n",
      "epoch 1446 / 20000\n",
      "gradient norm: 0.09001550040557049, minimum ratio: 2.5078947368421054\n",
      "\ttrain loss: 0.00601\n",
      "\tval loss: 0.00591\n",
      "epoch 1447 / 20000\n",
      "gradient norm: 0.02549885679036379, minimum ratio: 2.5342105263157895\n",
      "\ttrain loss: 0.00601\n",
      "\tval loss: 0.00592\n",
      "epoch 1448 / 20000\n",
      "gradient norm: 0.09543244776432402, minimum ratio: 2.5263157894736845\n",
      "\ttrain loss: 0.00600\n",
      "\tval loss: 0.00593\n",
      "epoch 1449 / 20000\n",
      "gradient norm: 0.10027537436690181, minimum ratio: 2.5289473684210524\n",
      "\ttrain loss: 0.00601\n",
      "\tval loss: 0.00591\n",
      "epoch 1450 / 20000\n",
      "gradient norm: 0.05356623548868811, minimum ratio: 2.557894736842105\n",
      "\ttrain loss: 0.00600\n",
      "\tval loss: 0.00591\n",
      "epoch 1451 / 20000\n",
      "gradient norm: 0.07664132694480941, minimum ratio: 2.5342105263157895\n",
      "\ttrain loss: 0.00598\n",
      "\tval loss: 0.00592\n",
      "epoch 1452 / 20000\n",
      "gradient norm: 0.07689234765712172, minimum ratio: 2.536842105263158\n",
      "\ttrain loss: 0.00599\n",
      "\tval loss: 0.00591\n",
      "epoch 1453 / 20000\n",
      "gradient norm: 0.06608468721969984, minimum ratio: 2.518421052631579\n",
      "\ttrain loss: 0.00600\n",
      "\tval loss: 0.00591\n",
      "epoch 1454 / 20000\n",
      "gradient norm: 0.0435650036088191, minimum ratio: 2.513157894736842\n",
      "\ttrain loss: 0.00600\n",
      "\tval loss: 0.00592\n",
      "epoch 1455 / 20000\n",
      "gradient norm: 0.03566149569815025, minimum ratio: 2.5210526315789474\n",
      "\ttrain loss: 0.00601\n",
      "\tval loss: 0.00591\n",
      "epoch 1456 / 20000\n",
      "gradient norm: 0.02887554295011796, minimum ratio: 2.5105263157894733\n",
      "\ttrain loss: 0.00600\n",
      "\tval loss: 0.00591\n",
      "epoch 1457 / 20000\n",
      "gradient norm: 0.04627937643090263, minimum ratio: 2.5289473684210524\n",
      "\ttrain loss: 0.00599\n",
      "\tval loss: 0.00591\n",
      "epoch 1458 / 20000\n",
      "gradient norm: 0.030329289060318843, minimum ratio: 2.526315789473684\n",
      "\ttrain loss: 0.00600\n",
      "\tval loss: 0.00591\n",
      "epoch 1459 / 20000\n",
      "gradient norm: 0.055582787812454626, minimum ratio: 2.513157894736842\n",
      "\ttrain loss: 0.00599\n",
      "\tval loss: 0.00591\n",
      "epoch 1460 / 20000\n",
      "gradient norm: 0.04658201278652996, minimum ratio: 2.510526315789474\n",
      "\ttrain loss: 0.00601\n",
      "\tval loss: 0.00591\n",
      "epoch 1461 / 20000\n",
      "gradient norm: 0.12267230090219527, minimum ratio: 2.526315789473684\n",
      "\ttrain loss: 0.00599\n",
      "\tval loss: 0.00592\n",
      "epoch 1462 / 20000\n",
      "gradient norm: 0.06575872086978052, minimum ratio: 2.5157894736842104\n",
      "\ttrain loss: 0.00600\n",
      "\tval loss: 0.00590\n",
      "epoch 1463 / 20000\n",
      "gradient norm: 0.04356640855257865, minimum ratio: 2.544736842105263\n",
      "\ttrain loss: 0.00600\n",
      "\tval loss: 0.00591\n",
      "epoch 1464 / 20000\n",
      "gradient norm: 0.12881312728859484, minimum ratio: 2.513157894736842\n",
      "\ttrain loss: 0.00600\n",
      "\tval loss: 0.00593\n",
      "epoch 1465 / 20000\n",
      "gradient norm: 0.09274590713903308, minimum ratio: 2.526315789473684\n",
      "\ttrain loss: 0.00599\n",
      "\tval loss: 0.00590\n",
      "epoch 1466 / 20000\n",
      "gradient norm: 0.06518582307035103, minimum ratio: 2.5342105263157895\n",
      "\ttrain loss: 0.00600\n",
      "\tval loss: 0.00590\n",
      "epoch 1467 / 20000\n",
      "gradient norm: 0.019816738116787747, minimum ratio: 2.5210526315789474\n",
      "\ttrain loss: 0.00600\n",
      "\tval loss: 0.00591\n",
      "epoch 1468 / 20000\n",
      "gradient norm: 0.09928720979951322, minimum ratio: 2.515789473684211\n",
      "\ttrain loss: 0.00600\n",
      "\tval loss: 0.00591\n",
      "epoch 1469 / 20000\n",
      "gradient norm: 0.02879331099393312, minimum ratio: 2.544736842105263\n",
      "\ttrain loss: 0.00599\n",
      "\tval loss: 0.00591\n",
      "epoch 1470 / 20000\n",
      "gradient norm: 0.09075742197455838, minimum ratio: 2.542105263157895\n",
      "\ttrain loss: 0.00601\n",
      "\tval loss: 0.00590\n",
      "epoch 1471 / 20000\n",
      "gradient norm: 0.04404561466071755, minimum ratio: 2.534210526315789\n",
      "\ttrain loss: 0.00599\n",
      "\tval loss: 0.00590\n",
      "epoch 1472 / 20000\n",
      "gradient norm: 0.04866957984631881, minimum ratio: 2.510526315789474\n",
      "\ttrain loss: 0.00599\n",
      "\tval loss: 0.00591\n",
      "epoch 1473 / 20000\n",
      "gradient norm: 0.09165681430022232, minimum ratio: 2.5368421052631582\n",
      "\ttrain loss: 0.00599\n",
      "\tval loss: 0.00591\n",
      "epoch 1474 / 20000\n",
      "gradient norm: 0.05230316164670512, minimum ratio: 2.5473684210526315\n",
      "\ttrain loss: 0.00599\n",
      "\tval loss: 0.00591\n",
      "epoch 1475 / 20000\n",
      "gradient norm: 0.0960144231794402, minimum ratio: 2.5105263157894733\n",
      "\ttrain loss: 0.00600\n",
      "\tval loss: 0.00589\n",
      "epoch 1476 / 20000\n",
      "gradient norm: 0.06323762948159128, minimum ratio: 2.513157894736842\n",
      "\ttrain loss: 0.00599\n",
      "\tval loss: 0.00590\n",
      "epoch 1477 / 20000\n",
      "gradient norm: 0.06830271513899788, minimum ratio: 2.542105263157895\n",
      "\ttrain loss: 0.00597\n",
      "\tval loss: 0.00590\n",
      "epoch 1478 / 20000\n",
      "gradient norm: 0.019847472751280293, minimum ratio: 2.5473684210526315\n",
      "\ttrain loss: 0.00599\n",
      "\tval loss: 0.00590\n",
      "epoch 1479 / 20000\n",
      "gradient norm: 0.062386819132370874, minimum ratio: 2.5157894736842104\n",
      "\ttrain loss: 0.00599\n",
      "\tval loss: 0.00590\n",
      "epoch 1480 / 20000\n",
      "gradient norm: 0.053123201068956405, minimum ratio: 2.526315789473684\n",
      "\ttrain loss: 0.00599\n",
      "\tval loss: 0.00590\n",
      "epoch 1481 / 20000\n",
      "gradient norm: 0.0838985089212656, minimum ratio: 2.531578947368421\n",
      "\ttrain loss: 0.00599\n",
      "\tval loss: 0.00589\n",
      "epoch 1482 / 20000\n",
      "gradient norm: 0.042723141581518576, minimum ratio: 2.5394736842105265\n",
      "\ttrain loss: 0.00599\n",
      "\tval loss: 0.00590\n",
      "epoch 1483 / 20000\n",
      "gradient norm: 0.09277127022505738, minimum ratio: 2.5210526315789474\n",
      "\ttrain loss: 0.00600\n",
      "\tval loss: 0.00591\n",
      "epoch 1484 / 20000\n",
      "gradient norm: 0.04208697113790549, minimum ratio: 2.5342105263157895\n",
      "\ttrain loss: 0.00599\n",
      "\tval loss: 0.00589\n",
      "epoch 1485 / 20000\n",
      "gradient norm: 0.05177319189533591, minimum ratio: 2.5157894736842104\n",
      "\ttrain loss: 0.00599\n",
      "\tval loss: 0.00589\n",
      "epoch 1486 / 20000\n",
      "gradient norm: 0.06665589002659544, minimum ratio: 2.5342105263157895\n",
      "\ttrain loss: 0.00597\n",
      "\tval loss: 0.00590\n",
      "epoch 1487 / 20000\n",
      "gradient norm: 0.037481462088180706, minimum ratio: 2.5236842105263158\n",
      "\ttrain loss: 0.00598\n",
      "\tval loss: 0.00590\n",
      "epoch 1488 / 20000\n",
      "gradient norm: 0.07562899278855184, minimum ratio: 2.526315789473684\n",
      "\ttrain loss: 0.00600\n",
      "\tval loss: 0.00589\n",
      "epoch 1489 / 20000\n",
      "gradient norm: 0.09761691244784743, minimum ratio: 2.526315789473684\n",
      "\ttrain loss: 0.00600\n",
      "\tval loss: 0.00591\n",
      "epoch 1490 / 20000\n",
      "gradient norm: 0.06206312606809661, minimum ratio: 2.5184210526315787\n",
      "\ttrain loss: 0.00597\n",
      "\tval loss: 0.00589\n",
      "epoch 1491 / 20000\n",
      "gradient norm: 0.07837931459653191, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00600\n",
      "\tval loss: 0.00588\n",
      "epoch 1492 / 20000\n",
      "gradient norm: 0.08888304413994774, minimum ratio: 2.536842105263158\n",
      "\ttrain loss: 0.00599\n",
      "\tval loss: 0.00590\n",
      "epoch 1493 / 20000\n",
      "gradient norm: 0.09514799027238041, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00599\n",
      "\tval loss: 0.00593\n",
      "epoch 1494 / 20000\n",
      "gradient norm: 0.09009404596872628, minimum ratio: 2.5394736842105265\n",
      "\ttrain loss: 0.00598\n",
      "\tval loss: 0.00588\n",
      "epoch 1495 / 20000\n",
      "gradient norm: 0.0736827728105709, minimum ratio: 2.5368421052631582\n",
      "\ttrain loss: 0.00598\n",
      "\tval loss: 0.00589\n",
      "epoch 1496 / 20000\n",
      "gradient norm: 0.059845353302080184, minimum ratio: 2.513157894736842\n",
      "\ttrain loss: 0.00599\n",
      "\tval loss: 0.00591\n",
      "epoch 1497 / 20000\n",
      "gradient norm: 0.06654705962864682, minimum ratio: 2.542105263157895\n",
      "\ttrain loss: 0.00598\n",
      "\tval loss: 0.00590\n",
      "epoch 1498 / 20000\n",
      "gradient norm: 0.0496486428019125, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00598\n",
      "\tval loss: 0.00588\n",
      "epoch 1499 / 20000\n",
      "gradient norm: 0.05232194231939502, minimum ratio: 2.526315789473684\n",
      "\ttrain loss: 0.00599\n",
      "\tval loss: 0.00589\n",
      "epoch 1500 / 20000\n",
      "gradient norm: 0.04550516947347205, minimum ratio: 2.536842105263158\n",
      "\ttrain loss: 0.00597\n",
      "\tval loss: 0.00591\n",
      "epoch 1501 / 20000\n",
      "gradient norm: 0.06931974564213306, minimum ratio: 2.526315789473684\n",
      "\ttrain loss: 0.00598\n",
      "\tval loss: 0.00589\n",
      "epoch 1502 / 20000\n",
      "gradient norm: 0.04654989068512805, minimum ratio: 2.5342105263157895\n",
      "\ttrain loss: 0.00598\n",
      "\tval loss: 0.00588\n",
      "epoch 1503 / 20000\n",
      "gradient norm: 0.03991049126489088, minimum ratio: 2.5184210526315787\n",
      "\ttrain loss: 0.00600\n",
      "\tval loss: 0.00588\n",
      "epoch 1504 / 20000\n",
      "gradient norm: 0.0799098092247732, minimum ratio: 2.526315789473684\n",
      "\ttrain loss: 0.00599\n",
      "\tval loss: 0.00589\n",
      "epoch 1505 / 20000\n",
      "gradient norm: 0.03877880748768803, minimum ratio: 2.5157894736842104\n",
      "\ttrain loss: 0.00599\n",
      "\tval loss: 0.00590\n",
      "epoch 1506 / 20000\n",
      "gradient norm: 0.0386848732814542, minimum ratio: 2.526315789473684\n",
      "\ttrain loss: 0.00599\n",
      "\tval loss: 0.00589\n",
      "epoch 1507 / 20000\n",
      "gradient norm: 0.02979491528822109, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00597\n",
      "\tval loss: 0.00588\n",
      "epoch 1508 / 20000\n",
      "gradient norm: 0.07322330254828557, minimum ratio: 2.505263157894737\n",
      "\ttrain loss: 0.00596\n",
      "\tval loss: 0.00589\n",
      "epoch 1509 / 20000\n",
      "gradient norm: 0.03538828530872706, minimum ratio: 2.5394736842105265\n",
      "\ttrain loss: 0.00598\n",
      "\tval loss: 0.00589\n",
      "epoch 1510 / 20000\n",
      "gradient norm: 0.12503444170579314, minimum ratio: 2.5105263157894733\n",
      "\ttrain loss: 0.00598\n",
      "\tval loss: 0.00588\n",
      "epoch 1511 / 20000\n",
      "gradient norm: 0.08573446144873742, minimum ratio: 2.518421052631579\n",
      "\ttrain loss: 0.00598\n",
      "\tval loss: 0.00589\n",
      "epoch 1512 / 20000\n",
      "gradient norm: 0.048732635827036574, minimum ratio: 2.531578947368421\n",
      "\ttrain loss: 0.00597\n",
      "\tval loss: 0.00589\n",
      "epoch 1513 / 20000\n",
      "gradient norm: 0.07863825812819414, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00598\n",
      "\tval loss: 0.00588\n",
      "epoch 1514 / 20000\n",
      "gradient norm: 0.06656017730711028, minimum ratio: 2.555263157894737\n",
      "\ttrain loss: 0.00597\n",
      "\tval loss: 0.00590\n",
      "epoch 1515 / 20000\n",
      "gradient norm: 0.08921028336044401, minimum ratio: 2.542105263157895\n",
      "\ttrain loss: 0.00597\n",
      "\tval loss: 0.00588\n",
      "epoch 1516 / 20000\n",
      "gradient norm: 0.02766629689722322, minimum ratio: 2.5342105263157895\n",
      "\ttrain loss: 0.00598\n",
      "\tval loss: 0.00588\n",
      "epoch 1517 / 20000\n",
      "gradient norm: 0.04504125483799726, minimum ratio: 2.5289473684210524\n",
      "\ttrain loss: 0.00598\n",
      "\tval loss: 0.00588\n",
      "epoch 1518 / 20000\n",
      "gradient norm: 0.053142721502808854, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00597\n",
      "\tval loss: 0.00588\n",
      "epoch 1519 / 20000\n",
      "gradient norm: 0.05217656848253682, minimum ratio: 2.515789473684211\n",
      "\ttrain loss: 0.00597\n",
      "\tval loss: 0.00588\n",
      "epoch 1520 / 20000\n",
      "gradient norm: 0.035968888842035085, minimum ratio: 2.5210526315789474\n",
      "\ttrain loss: 0.00598\n",
      "\tval loss: 0.00588\n",
      "epoch 1521 / 20000\n",
      "gradient norm: 0.057579942542361096, minimum ratio: 2.544736842105263\n",
      "\ttrain loss: 0.00599\n",
      "\tval loss: 0.00588\n",
      "epoch 1522 / 20000\n",
      "gradient norm: 0.0648289499222301, minimum ratio: 2.5157894736842104\n",
      "\ttrain loss: 0.00597\n",
      "\tval loss: 0.00589\n",
      "epoch 1523 / 20000\n",
      "gradient norm: 0.02863065607380122, minimum ratio: 2.5210526315789474\n",
      "\ttrain loss: 0.00598\n",
      "\tval loss: 0.00588\n",
      "epoch 1524 / 20000\n",
      "gradient norm: 0.051629244757350534, minimum ratio: 2.5473684210526315\n",
      "\ttrain loss: 0.00597\n",
      "\tval loss: 0.00588\n",
      "epoch 1525 / 20000\n",
      "gradient norm: 0.035327957855770364, minimum ratio: 2.5473684210526315\n",
      "\ttrain loss: 0.00597\n",
      "\tval loss: 0.00588\n",
      "epoch 1526 / 20000\n",
      "gradient norm: 0.08846738404827192, minimum ratio: 2.5210526315789474\n",
      "\ttrain loss: 0.00598\n",
      "\tval loss: 0.00588\n",
      "epoch 1527 / 20000\n",
      "gradient norm: 0.1402245870558545, minimum ratio: 2.5289473684210524\n",
      "\ttrain loss: 0.00600\n",
      "\tval loss: 0.00587\n",
      "epoch 1528 / 20000\n",
      "gradient norm: 0.0786262896435801, minimum ratio: 2.5289473684210524\n",
      "\ttrain loss: 0.00596\n",
      "\tval loss: 0.00589\n",
      "epoch 1529 / 20000\n",
      "gradient norm: 0.08816769029363059, minimum ratio: 2.539473684210526\n",
      "\ttrain loss: 0.00597\n",
      "\tval loss: 0.00590\n",
      "epoch 1530 / 20000\n",
      "gradient norm: 0.07965284230886027, minimum ratio: 2.5078947368421054\n",
      "\ttrain loss: 0.00598\n",
      "\tval loss: 0.00587\n",
      "epoch 1531 / 20000\n",
      "gradient norm: 0.060071611471357755, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00597\n",
      "\tval loss: 0.00587\n",
      "epoch 1532 / 20000\n",
      "gradient norm: 0.034639552410226315, minimum ratio: 2.513157894736842\n",
      "\ttrain loss: 0.00598\n",
      "\tval loss: 0.00588\n",
      "epoch 1533 / 20000\n",
      "gradient norm: 0.11964035805431195, minimum ratio: 2.5342105263157895\n",
      "\ttrain loss: 0.00599\n",
      "\tval loss: 0.00588\n",
      "epoch 1534 / 20000\n",
      "gradient norm: 0.06713853008113801, minimum ratio: 2.544736842105263\n",
      "\ttrain loss: 0.00597\n",
      "\tval loss: 0.00589\n",
      "epoch 1535 / 20000\n",
      "gradient norm: 0.04483532808080781, minimum ratio: 2.531578947368421\n",
      "\ttrain loss: 0.00597\n",
      "\tval loss: 0.00587\n",
      "epoch 1536 / 20000\n",
      "gradient norm: 0.07754544971976429, minimum ratio: 2.518421052631579\n",
      "\ttrain loss: 0.00598\n",
      "\tval loss: 0.00587\n",
      "epoch 1537 / 20000\n",
      "gradient norm: 0.036300961597589776, minimum ratio: 2.536842105263158\n",
      "\ttrain loss: 0.00596\n",
      "\tval loss: 0.00588\n",
      "epoch 1538 / 20000\n",
      "gradient norm: 0.1366682859370485, minimum ratio: 2.528947368421053\n",
      "\ttrain loss: 0.00597\n",
      "\tval loss: 0.00590\n",
      "epoch 1539 / 20000\n",
      "gradient norm: 0.05728748248657212, minimum ratio: 2.5289473684210524\n",
      "\ttrain loss: 0.00597\n",
      "\tval loss: 0.00587\n",
      "epoch 1540 / 20000\n",
      "gradient norm: 0.14255471515934914, minimum ratio: 2.5342105263157895\n",
      "\ttrain loss: 0.00598\n",
      "\tval loss: 0.00587\n",
      "epoch 1541 / 20000\n",
      "gradient norm: 0.050778379663825035, minimum ratio: 2.531578947368421\n",
      "\ttrain loss: 0.00596\n",
      "\tval loss: 0.00589\n",
      "epoch 1542 / 20000\n",
      "gradient norm: 0.08999276120448485, minimum ratio: 2.5236842105263158\n",
      "\ttrain loss: 0.00597\n",
      "\tval loss: 0.00589\n",
      "epoch 1543 / 20000\n",
      "gradient norm: 0.07613692371523939, minimum ratio: 2.5394736842105265\n",
      "\ttrain loss: 0.00596\n",
      "\tval loss: 0.00586\n",
      "epoch 1544 / 20000\n",
      "gradient norm: 0.07723372883629054, minimum ratio: 2.53421052631579\n",
      "\ttrain loss: 0.00598\n",
      "\tval loss: 0.00586\n",
      "epoch 1545 / 20000\n",
      "gradient norm: 0.03842362426803447, minimum ratio: 2.526315789473684\n",
      "\ttrain loss: 0.00596\n",
      "\tval loss: 0.00589\n",
      "epoch 1546 / 20000\n",
      "gradient norm: 0.08083302355953492, minimum ratio: 2.55\n",
      "\ttrain loss: 0.00596\n",
      "\tval loss: 0.00588\n",
      "epoch 1547 / 20000\n",
      "gradient norm: 0.040161485609132797, minimum ratio: 2.5157894736842104\n",
      "\ttrain loss: 0.00596\n",
      "\tval loss: 0.00587\n",
      "epoch 1548 / 20000\n",
      "gradient norm: 0.04790676048287423, minimum ratio: 2.526315789473684\n",
      "\ttrain loss: 0.00596\n",
      "\tval loss: 0.00586\n",
      "epoch 1549 / 20000\n",
      "gradient norm: 0.027448768552858382, minimum ratio: 2.5315789473684207\n",
      "\ttrain loss: 0.00596\n",
      "\tval loss: 0.00587\n",
      "epoch 1550 / 20000\n",
      "gradient norm: 0.06856952923408244, minimum ratio: 2.5289473684210524\n",
      "\ttrain loss: 0.00596\n",
      "\tval loss: 0.00589\n",
      "epoch 1551 / 20000\n",
      "gradient norm: 0.1626441873377189, minimum ratio: 2.5315789473684207\n",
      "\ttrain loss: 0.00601\n",
      "\tval loss: 0.00586\n",
      "epoch 1552 / 20000\n",
      "gradient norm: 0.10151127248536795, minimum ratio: 2.5289473684210524\n",
      "\ttrain loss: 0.00596\n",
      "\tval loss: 0.00588\n",
      "epoch 1553 / 20000\n",
      "gradient norm: 0.07464233640348539, minimum ratio: 2.526315789473684\n",
      "\ttrain loss: 0.00595\n",
      "\tval loss: 0.00589\n",
      "epoch 1554 / 20000\n",
      "gradient norm: 0.0817176976124756, minimum ratio: 2.513157894736842\n",
      "\ttrain loss: 0.00596\n",
      "\tval loss: 0.00586\n",
      "epoch 1555 / 20000\n",
      "gradient norm: 0.057817837805487216, minimum ratio: 2.5263157894736845\n",
      "\ttrain loss: 0.00596\n",
      "\tval loss: 0.00586\n",
      "epoch 1556 / 20000\n",
      "gradient norm: 0.042297078674891964, minimum ratio: 2.5552631578947365\n",
      "\ttrain loss: 0.00595\n",
      "\tval loss: 0.00588\n",
      "epoch 1557 / 20000\n",
      "gradient norm: 0.09123803302645683, minimum ratio: 2.5394736842105265\n",
      "\ttrain loss: 0.00597\n",
      "\tval loss: 0.00588\n",
      "epoch 1558 / 20000\n",
      "gradient norm: 0.07678628456051229, minimum ratio: 2.507894736842105\n",
      "\ttrain loss: 0.00597\n",
      "\tval loss: 0.00586\n",
      "epoch 1559 / 20000\n",
      "gradient norm: 0.06878425017930567, minimum ratio: 2.539473684210526\n",
      "\ttrain loss: 0.00598\n",
      "\tval loss: 0.00586\n",
      "epoch 1560 / 20000\n",
      "gradient norm: 0.11232062749331817, minimum ratio: 2.539473684210526\n",
      "\ttrain loss: 0.00597\n",
      "\tval loss: 0.00589\n",
      "epoch 1561 / 20000\n",
      "gradient norm: 0.07028873939998448, minimum ratio: 2.515789473684211\n",
      "\ttrain loss: 0.00595\n",
      "\tval loss: 0.00586\n",
      "epoch 1562 / 20000\n",
      "gradient norm: 0.034553465971839614, minimum ratio: 2.5315789473684207\n",
      "\ttrain loss: 0.00595\n",
      "\tval loss: 0.00586\n",
      "epoch 1563 / 20000\n",
      "gradient norm: 0.0737209624494426, minimum ratio: 2.5131578947368416\n",
      "\ttrain loss: 0.00596\n",
      "\tval loss: 0.00587\n",
      "epoch 1564 / 20000\n",
      "gradient norm: 0.05463737336685881, minimum ratio: 2.526315789473684\n",
      "\ttrain loss: 0.00595\n",
      "\tval loss: 0.00587\n",
      "epoch 1565 / 20000\n",
      "gradient norm: 0.06704681237170007, minimum ratio: 2.526315789473684\n",
      "\ttrain loss: 0.00597\n",
      "\tval loss: 0.00587\n",
      "epoch 1566 / 20000\n",
      "gradient norm: 0.07835523676476441, minimum ratio: 2.5157894736842104\n",
      "\ttrain loss: 0.00595\n",
      "\tval loss: 0.00585\n",
      "epoch 1567 / 20000\n",
      "gradient norm: 0.08630734936741646, minimum ratio: 2.531578947368421\n",
      "\ttrain loss: 0.00597\n",
      "\tval loss: 0.00586\n",
      "epoch 1568 / 20000\n",
      "gradient norm: 0.0725083205034025, minimum ratio: 2.515789473684211\n",
      "\ttrain loss: 0.00595\n",
      "\tval loss: 0.00588\n",
      "epoch 1569 / 20000\n",
      "gradient norm: 0.05726379342377186, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00596\n",
      "\tval loss: 0.00587\n",
      "epoch 1570 / 20000\n",
      "gradient norm: 0.10301191205508076, minimum ratio: 2.513157894736842\n",
      "\ttrain loss: 0.00596\n",
      "\tval loss: 0.00585\n",
      "epoch 1571 / 20000\n",
      "gradient norm: 0.06384646182414144, minimum ratio: 2.55\n",
      "\ttrain loss: 0.00597\n",
      "\tval loss: 0.00586\n",
      "epoch 1572 / 20000\n",
      "gradient norm: 0.0553710576496087, minimum ratio: 2.5315789473684207\n",
      "\ttrain loss: 0.00596\n",
      "\tval loss: 0.00588\n",
      "epoch 1573 / 20000\n",
      "gradient norm: 0.09173728013411164, minimum ratio: 2.5236842105263158\n",
      "\ttrain loss: 0.00595\n",
      "\tval loss: 0.00587\n",
      "epoch 1574 / 20000\n",
      "gradient norm: 0.03692130549461581, minimum ratio: 2.5342105263157895\n",
      "\ttrain loss: 0.00595\n",
      "\tval loss: 0.00585\n",
      "epoch 1575 / 20000\n",
      "gradient norm: 0.0849556864995975, minimum ratio: 2.507894736842105\n",
      "\ttrain loss: 0.00598\n",
      "\tval loss: 0.00585\n",
      "epoch 1576 / 20000\n",
      "gradient norm: 0.1087693574372679, minimum ratio: 2.5526315789473686\n",
      "\ttrain loss: 0.00596\n",
      "\tval loss: 0.00589\n",
      "epoch 1577 / 20000\n",
      "gradient norm: 0.07599452440626919, minimum ratio: 2.5078947368421054\n",
      "\ttrain loss: 0.00595\n",
      "\tval loss: 0.00587\n",
      "epoch 1578 / 20000\n",
      "gradient norm: 0.05377869922085665, minimum ratio: 2.544736842105263\n",
      "\ttrain loss: 0.00595\n",
      "\tval loss: 0.00585\n",
      "epoch 1579 / 20000\n",
      "gradient norm: 0.06333536647434812, minimum ratio: 2.518421052631579\n",
      "\ttrain loss: 0.00596\n",
      "\tval loss: 0.00585\n",
      "epoch 1580 / 20000\n",
      "gradient norm: 0.09126388537697494, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00597\n",
      "\tval loss: 0.00588\n",
      "epoch 1581 / 20000\n",
      "gradient norm: 0.05028012780530844, minimum ratio: 2.5315789473684207\n",
      "\ttrain loss: 0.00597\n",
      "\tval loss: 0.00586\n",
      "epoch 1582 / 20000\n",
      "gradient norm: 0.044474913069279864, minimum ratio: 2.528947368421053\n",
      "\ttrain loss: 0.00595\n",
      "\tval loss: 0.00585\n",
      "epoch 1583 / 20000\n",
      "gradient norm: 0.05350361128512304, minimum ratio: 2.5184210526315787\n",
      "\ttrain loss: 0.00595\n",
      "\tval loss: 0.00586\n",
      "epoch 1584 / 20000\n",
      "gradient norm: 0.103024797514081, minimum ratio: 2.5078947368421054\n",
      "\ttrain loss: 0.00595\n",
      "\tval loss: 0.00587\n",
      "epoch 1585 / 20000\n",
      "gradient norm: 0.048073321871925145, minimum ratio: 2.5078947368421054\n",
      "\ttrain loss: 0.00594\n",
      "\tval loss: 0.00585\n",
      "epoch 1586 / 20000\n",
      "gradient norm: 0.041388425044715405, minimum ratio: 2.528947368421053\n",
      "\ttrain loss: 0.00596\n",
      "\tval loss: 0.00585\n",
      "epoch 1587 / 20000\n",
      "gradient norm: 0.06673525011865422, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00595\n",
      "\tval loss: 0.00586\n",
      "epoch 1588 / 20000\n",
      "gradient norm: 0.053838527703192085, minimum ratio: 2.5289473684210524\n",
      "\ttrain loss: 0.00594\n",
      "\tval loss: 0.00586\n",
      "epoch 1589 / 20000\n",
      "gradient norm: 0.11405783402733505, minimum ratio: 2.5236842105263158\n",
      "\ttrain loss: 0.00595\n",
      "\tval loss: 0.00586\n",
      "epoch 1590 / 20000\n",
      "gradient norm: 0.05206263836589642, minimum ratio: 2.536842105263158\n",
      "\ttrain loss: 0.00595\n",
      "\tval loss: 0.00585\n",
      "epoch 1591 / 20000\n",
      "gradient norm: 0.07557372745941393, minimum ratio: 2.544736842105263\n",
      "\ttrain loss: 0.00596\n",
      "\tval loss: 0.00585\n",
      "epoch 1592 / 20000\n",
      "gradient norm: 0.07820454693865031, minimum ratio: 2.5210526315789474\n",
      "\ttrain loss: 0.00596\n",
      "\tval loss: 0.00589\n",
      "epoch 1593 / 20000\n",
      "gradient norm: 0.05395965534262359, minimum ratio: 2.5526315789473686\n",
      "\ttrain loss: 0.00596\n",
      "\tval loss: 0.00585\n",
      "epoch 1594 / 20000\n",
      "gradient norm: 0.07250852306606248, minimum ratio: 2.528947368421053\n",
      "\ttrain loss: 0.00595\n",
      "\tval loss: 0.00584\n",
      "epoch 1595 / 20000\n",
      "gradient norm: 0.046774666116107255, minimum ratio: 2.5394736842105265\n",
      "\ttrain loss: 0.00595\n",
      "\tval loss: 0.00586\n",
      "epoch 1596 / 20000\n",
      "gradient norm: 0.06460998521652073, minimum ratio: 2.5236842105263158\n",
      "\ttrain loss: 0.00595\n",
      "\tval loss: 0.00587\n",
      "epoch 1597 / 20000\n",
      "gradient norm: 0.07454103277996182, minimum ratio: 2.5210526315789474\n",
      "\ttrain loss: 0.00595\n",
      "\tval loss: 0.00585\n",
      "epoch 1598 / 20000\n",
      "gradient norm: 0.06951590935932472, minimum ratio: 2.5078947368421054\n",
      "\ttrain loss: 0.00596\n",
      "\tval loss: 0.00585\n",
      "epoch 1599 / 20000\n",
      "gradient norm: 0.08462686085840687, minimum ratio: 2.526315789473684\n",
      "\ttrain loss: 0.00594\n",
      "\tval loss: 0.00585\n",
      "epoch 1600 / 20000\n",
      "gradient norm: 0.06988107785582542, minimum ratio: 2.55\n",
      "\ttrain loss: 0.00595\n",
      "\tval loss: 0.00585\n",
      "epoch 1601 / 20000\n",
      "gradient norm: 0.08295134990476072, minimum ratio: 2.5210526315789474\n",
      "\ttrain loss: 0.00594\n",
      "\tval loss: 0.00586\n",
      "epoch 1602 / 20000\n",
      "gradient norm: 0.03842253639595583, minimum ratio: 2.5105263157894737\n",
      "\ttrain loss: 0.00595\n",
      "\tval loss: 0.00585\n",
      "epoch 1603 / 20000\n",
      "gradient norm: 0.07222048845142126, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00595\n",
      "\tval loss: 0.00584\n",
      "epoch 1604 / 20000\n",
      "gradient norm: 0.032112248707562685, minimum ratio: 2.542105263157895\n",
      "\ttrain loss: 0.00595\n",
      "\tval loss: 0.00586\n",
      "epoch 1605 / 20000\n",
      "gradient norm: 0.09404363622888923, minimum ratio: 2.518421052631579\n",
      "\ttrain loss: 0.00595\n",
      "\tval loss: 0.00586\n",
      "epoch 1606 / 20000\n",
      "gradient norm: 0.04648397563141771, minimum ratio: 2.5236842105263158\n",
      "\ttrain loss: 0.00594\n",
      "\tval loss: 0.00585\n",
      "epoch 1607 / 20000\n",
      "gradient norm: 0.0629680722777266, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00595\n",
      "\tval loss: 0.00584\n",
      "epoch 1608 / 20000\n",
      "gradient norm: 0.034704600082477555, minimum ratio: 2.5157894736842104\n",
      "\ttrain loss: 0.00595\n",
      "\tval loss: 0.00585\n",
      "epoch 1609 / 20000\n",
      "gradient norm: 0.0805085696047172, minimum ratio: 2.544736842105263\n",
      "\ttrain loss: 0.00596\n",
      "\tval loss: 0.00585\n",
      "epoch 1610 / 20000\n",
      "gradient norm: 0.05263252486474812, minimum ratio: 2.5236842105263158\n",
      "\ttrain loss: 0.00594\n",
      "\tval loss: 0.00585\n",
      "epoch 1611 / 20000\n",
      "gradient norm: 0.06972097785910591, minimum ratio: 2.544736842105263\n",
      "\ttrain loss: 0.00595\n",
      "\tval loss: 0.00586\n",
      "epoch 1612 / 20000\n",
      "gradient norm: 0.0286327033827547, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00593\n",
      "\tval loss: 0.00584\n",
      "epoch 1613 / 20000\n",
      "gradient norm: 0.08476609637727961, minimum ratio: 2.505263157894737\n",
      "\ttrain loss: 0.00597\n",
      "\tval loss: 0.00584\n",
      "epoch 1614 / 20000\n",
      "gradient norm: 0.09178652940317988, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.00596\n",
      "\tval loss: 0.00588\n",
      "epoch 1615 / 20000\n",
      "gradient norm: 0.09171692933887243, minimum ratio: 2.5210526315789474\n",
      "\ttrain loss: 0.00597\n",
      "\tval loss: 0.00585\n",
      "epoch 1616 / 20000\n",
      "gradient norm: 0.10089089721441269, minimum ratio: 2.518421052631579\n",
      "\ttrain loss: 0.00597\n",
      "\tval loss: 0.00584\n",
      "epoch 1617 / 20000\n",
      "gradient norm: 0.11511373205576092, minimum ratio: 2.539473684210526\n",
      "\ttrain loss: 0.00594\n",
      "\tval loss: 0.00587\n",
      "epoch 1618 / 20000\n",
      "gradient norm: 0.06426268548239022, minimum ratio: 2.5315789473684207\n",
      "\ttrain loss: 0.00594\n",
      "\tval loss: 0.00586\n",
      "epoch 1619 / 20000\n",
      "gradient norm: 0.07570820196997374, minimum ratio: 2.5131578947368416\n",
      "\ttrain loss: 0.00594\n",
      "\tval loss: 0.00584\n",
      "epoch 1620 / 20000\n",
      "gradient norm: 0.06665671001246665, minimum ratio: 2.5263157894736845\n",
      "\ttrain loss: 0.00595\n",
      "\tval loss: 0.00584\n",
      "epoch 1621 / 20000\n",
      "gradient norm: 0.050698375853244215, minimum ratio: 2.5210526315789474\n",
      "\ttrain loss: 0.00595\n",
      "\tval loss: 0.00586\n",
      "epoch 1622 / 20000\n",
      "gradient norm: 0.05110544903436676, minimum ratio: 2.513157894736842\n",
      "\ttrain loss: 0.00594\n",
      "\tval loss: 0.00586\n",
      "epoch 1623 / 20000\n",
      "gradient norm: 0.10700277370051481, minimum ratio: 2.526315789473684\n",
      "\ttrain loss: 0.00595\n",
      "\tval loss: 0.00584\n",
      "epoch 1624 / 20000\n",
      "gradient norm: 0.07035942871880252, minimum ratio: 2.507894736842105\n",
      "\ttrain loss: 0.00595\n",
      "\tval loss: 0.00586\n",
      "epoch 1625 / 20000\n",
      "gradient norm: 0.052137535909423605, minimum ratio: 2.5236842105263158\n",
      "\ttrain loss: 0.00596\n",
      "\tval loss: 0.00585\n",
      "epoch 1626 / 20000\n",
      "gradient norm: 0.10973401130468119, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00594\n",
      "\tval loss: 0.00584\n",
      "epoch 1627 / 20000\n",
      "gradient norm: 0.03950307978084311, minimum ratio: 2.5210526315789474\n",
      "\ttrain loss: 0.00594\n",
      "\tval loss: 0.00586\n",
      "epoch 1628 / 20000\n",
      "gradient norm: 0.10496779189270455, minimum ratio: 2.539473684210526\n",
      "\ttrain loss: 0.00596\n",
      "\tval loss: 0.00585\n",
      "epoch 1629 / 20000\n",
      "gradient norm: 0.0654085619316902, minimum ratio: 2.5105263157894737\n",
      "\ttrain loss: 0.00595\n",
      "\tval loss: 0.00585\n",
      "epoch 1630 / 20000\n",
      "gradient norm: 0.044378674996551126, minimum ratio: 2.515789473684211\n",
      "\ttrain loss: 0.00593\n",
      "\tval loss: 0.00584\n",
      "epoch 1631 / 20000\n",
      "gradient norm: 0.06353830714942887, minimum ratio: 2.5236842105263158\n",
      "\ttrain loss: 0.00595\n",
      "\tval loss: 0.00584\n",
      "epoch 1632 / 20000\n",
      "gradient norm: 0.03753006848273799, minimum ratio: 2.5131578947368416\n",
      "\ttrain loss: 0.00593\n",
      "\tval loss: 0.00586\n",
      "epoch 1633 / 20000\n",
      "gradient norm: 0.05250763153890148, minimum ratio: 2.5236842105263158\n",
      "\ttrain loss: 0.00594\n",
      "\tval loss: 0.00585\n",
      "epoch 1634 / 20000\n",
      "gradient norm: 0.07270322121621575, minimum ratio: 2.5315789473684207\n",
      "\ttrain loss: 0.00594\n",
      "\tval loss: 0.00585\n",
      "epoch 1635 / 20000\n",
      "gradient norm: 0.04322287655668333, minimum ratio: 2.5394736842105265\n",
      "\ttrain loss: 0.00594\n",
      "\tval loss: 0.00584\n",
      "epoch 1636 / 20000\n",
      "gradient norm: 0.05606868246104568, minimum ratio: 2.5210526315789474\n",
      "\ttrain loss: 0.00594\n",
      "\tval loss: 0.00584\n",
      "epoch 1637 / 20000\n",
      "gradient norm: 0.07303408917505294, minimum ratio: 2.518421052631579\n",
      "\ttrain loss: 0.00592\n",
      "\tval loss: 0.00585\n",
      "epoch 1638 / 20000\n",
      "gradient norm: 0.063941091299057, minimum ratio: 2.5289473684210524\n",
      "\ttrain loss: 0.00595\n",
      "\tval loss: 0.00585\n",
      "epoch 1639 / 20000\n",
      "gradient norm: 0.059110381320351735, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00595\n",
      "\tval loss: 0.00584\n",
      "epoch 1640 / 20000\n",
      "gradient norm: 0.056525960768340155, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00595\n",
      "\tval loss: 0.00584\n",
      "epoch 1641 / 20000\n",
      "gradient norm: 0.06319229572545737, minimum ratio: 2.492105263157895\n",
      "\ttrain loss: 0.00594\n",
      "\tval loss: 0.00585\n",
      "epoch 1642 / 20000\n",
      "gradient norm: 0.04819151433184743, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00595\n",
      "\tval loss: 0.00585\n",
      "epoch 1643 / 20000\n",
      "gradient norm: 0.0949727533152327, minimum ratio: 2.5289473684210524\n",
      "\ttrain loss: 0.00594\n",
      "\tval loss: 0.00584\n",
      "epoch 1644 / 20000\n",
      "gradient norm: 0.021429585394798778, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00594\n",
      "\tval loss: 0.00584\n",
      "epoch 1645 / 20000\n",
      "gradient norm: 0.03524424488568911, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00593\n",
      "\tval loss: 0.00584\n",
      "epoch 1646 / 20000\n",
      "gradient norm: 0.10055936616845429, minimum ratio: 2.5473684210526315\n",
      "\ttrain loss: 0.00593\n",
      "\tval loss: 0.00584\n",
      "epoch 1647 / 20000\n",
      "gradient norm: 0.07499173161340877, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00593\n",
      "\tval loss: 0.00583\n",
      "epoch 1648 / 20000\n",
      "gradient norm: 0.09334430817398243, minimum ratio: 2.5105263157894733\n",
      "\ttrain loss: 0.00595\n",
      "\tval loss: 0.00584\n",
      "epoch 1649 / 20000\n",
      "gradient norm: 0.0556013987516053, minimum ratio: 2.5078947368421054\n",
      "\ttrain loss: 0.00594\n",
      "\tval loss: 0.00585\n",
      "epoch 1650 / 20000\n",
      "gradient norm: 0.07890233813668601, minimum ratio: 2.518421052631579\n",
      "\ttrain loss: 0.00593\n",
      "\tval loss: 0.00585\n",
      "epoch 1651 / 20000\n",
      "gradient norm: 0.03596062786527909, minimum ratio: 2.5078947368421054\n",
      "\ttrain loss: 0.00593\n",
      "\tval loss: 0.00583\n",
      "epoch 1652 / 20000\n",
      "gradient norm: 0.07248090585926548, minimum ratio: 2.5315789473684207\n",
      "\ttrain loss: 0.00595\n",
      "\tval loss: 0.00583\n",
      "epoch 1653 / 20000\n",
      "gradient norm: 0.08764048555167392, minimum ratio: 2.5210526315789474\n",
      "\ttrain loss: 0.00595\n",
      "\tval loss: 0.00586\n",
      "epoch 1654 / 20000\n",
      "gradient norm: 0.038573370286030695, minimum ratio: 2.505263157894737\n",
      "\ttrain loss: 0.00593\n",
      "\tval loss: 0.00584\n",
      "epoch 1655 / 20000\n",
      "gradient norm: 0.07700917235342786, minimum ratio: 2.526315789473684\n",
      "\ttrain loss: 0.00594\n",
      "\tval loss: 0.00583\n",
      "epoch 1656 / 20000\n",
      "gradient norm: 0.07422540156403556, minimum ratio: 2.5368421052631582\n",
      "\ttrain loss: 0.00593\n",
      "\tval loss: 0.00584\n",
      "epoch 1657 / 20000\n",
      "gradient norm: 0.062207918032072484, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00595\n",
      "\tval loss: 0.00584\n",
      "epoch 1658 / 20000\n",
      "gradient norm: 0.052819778269622475, minimum ratio: 2.5105263157894737\n",
      "\ttrain loss: 0.00593\n",
      "\tval loss: 0.00583\n",
      "epoch 1659 / 20000\n",
      "gradient norm: 0.05188142854603939, minimum ratio: 2.513157894736842\n",
      "\ttrain loss: 0.00592\n",
      "\tval loss: 0.00584\n",
      "epoch 1660 / 20000\n",
      "gradient norm: 0.05535880180832464, minimum ratio: 2.5315789473684207\n",
      "\ttrain loss: 0.00593\n",
      "\tval loss: 0.00584\n",
      "epoch 1661 / 20000\n",
      "gradient norm: 0.05077994934981689, minimum ratio: 2.5184210526315787\n",
      "\ttrain loss: 0.00594\n",
      "\tval loss: 0.00583\n",
      "epoch 1662 / 20000\n",
      "gradient norm: 0.06179199053440243, minimum ratio: 2.5105263157894737\n",
      "\ttrain loss: 0.00594\n",
      "\tval loss: 0.00584\n",
      "epoch 1663 / 20000\n",
      "gradient norm: 0.07311245275195688, minimum ratio: 2.5210526315789474\n",
      "\ttrain loss: 0.00594\n",
      "\tval loss: 0.00584\n",
      "epoch 1664 / 20000\n",
      "gradient norm: 0.07013135781744495, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00595\n",
      "\tval loss: 0.00583\n",
      "epoch 1665 / 20000\n",
      "gradient norm: 0.042886712471954525, minimum ratio: 2.5078947368421054\n",
      "\ttrain loss: 0.00593\n",
      "\tval loss: 0.00583\n",
      "epoch 1666 / 20000\n",
      "gradient norm: 0.04975154050043784, minimum ratio: 2.5184210526315787\n",
      "\ttrain loss: 0.00593\n",
      "\tval loss: 0.00584\n",
      "epoch 1667 / 20000\n",
      "gradient norm: 0.023003545902611222, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00592\n",
      "\tval loss: 0.00584\n",
      "epoch 1668 / 20000\n",
      "gradient norm: 0.1424225604860112, minimum ratio: 2.526315789473684\n",
      "\ttrain loss: 0.00596\n",
      "\tval loss: 0.00583\n",
      "epoch 1669 / 20000\n",
      "gradient norm: 0.09214822622016072, minimum ratio: 2.5236842105263158\n",
      "\ttrain loss: 0.00594\n",
      "\tval loss: 0.00585\n",
      "epoch 1670 / 20000\n",
      "gradient norm: 0.06812211111537181, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00593\n",
      "\tval loss: 0.00585\n",
      "epoch 1671 / 20000\n",
      "gradient norm: 0.048895139509113505, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00593\n",
      "\tval loss: 0.00583\n",
      "epoch 1672 / 20000\n",
      "gradient norm: 0.032127666563610546, minimum ratio: 2.5315789473684207\n",
      "\ttrain loss: 0.00594\n",
      "\tval loss: 0.00583\n",
      "epoch 1673 / 20000\n",
      "gradient norm: 0.07429554790724069, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00592\n",
      "\tval loss: 0.00584\n",
      "epoch 1674 / 20000\n",
      "gradient norm: 0.1099638293380849, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00595\n",
      "\tval loss: 0.00585\n",
      "epoch 1675 / 20000\n",
      "gradient norm: 0.030561772495275363, minimum ratio: 2.492105263157895\n",
      "\ttrain loss: 0.00593\n",
      "\tval loss: 0.00583\n",
      "epoch 1676 / 20000\n",
      "gradient norm: 0.05209728196496144, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00594\n",
      "\tval loss: 0.00583\n",
      "epoch 1677 / 20000\n",
      "gradient norm: 0.01764437820384046, minimum ratio: 2.5105263157894733\n",
      "\ttrain loss: 0.00593\n",
      "\tval loss: 0.00584\n",
      "epoch 1678 / 20000\n",
      "gradient norm: 0.08003887091763318, minimum ratio: 2.526315789473684\n",
      "\ttrain loss: 0.00593\n",
      "\tval loss: 0.00584\n",
      "epoch 1679 / 20000\n",
      "gradient norm: 0.05826009172596969, minimum ratio: 2.507894736842105\n",
      "\ttrain loss: 0.00593\n",
      "\tval loss: 0.00583\n",
      "epoch 1680 / 20000\n",
      "gradient norm: 0.07598413969390094, minimum ratio: 2.507894736842105\n",
      "\ttrain loss: 0.00592\n",
      "\tval loss: 0.00582\n",
      "epoch 1681 / 20000\n",
      "gradient norm: 0.04733375881914981, minimum ratio: 2.507894736842105\n",
      "\ttrain loss: 0.00593\n",
      "\tval loss: 0.00583\n",
      "epoch 1682 / 20000\n",
      "gradient norm: 0.05531440637423657, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00594\n",
      "\tval loss: 0.00585\n",
      "epoch 1683 / 20000\n",
      "gradient norm: 0.07821524480823427, minimum ratio: 2.505263157894737\n",
      "\ttrain loss: 0.00594\n",
      "\tval loss: 0.00582\n",
      "epoch 1684 / 20000\n",
      "gradient norm: 0.06984982592985034, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00592\n",
      "\tval loss: 0.00583\n",
      "epoch 1685 / 20000\n",
      "gradient norm: 0.03702739351138007, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00593\n",
      "\tval loss: 0.00583\n",
      "epoch 1686 / 20000\n",
      "gradient norm: 0.07239287334959954, minimum ratio: 2.5157894736842104\n",
      "\ttrain loss: 0.00593\n",
      "\tval loss: 0.00583\n",
      "epoch 1687 / 20000\n",
      "gradient norm: 0.08995019490248524, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00594\n",
      "\tval loss: 0.00582\n",
      "epoch 1688 / 20000\n",
      "gradient norm: 0.08042261616355972, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00593\n",
      "\tval loss: 0.00584\n",
      "epoch 1689 / 20000\n",
      "gradient norm: 0.05005667236400768, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00593\n",
      "\tval loss: 0.00584\n",
      "epoch 1690 / 20000\n",
      "gradient norm: 0.06437376276880968, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00593\n",
      "\tval loss: 0.00582\n",
      "epoch 1691 / 20000\n",
      "gradient norm: 0.10317001596558839, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00593\n",
      "\tval loss: 0.00582\n",
      "epoch 1692 / 20000\n",
      "gradient norm: 0.05974665196845308, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00593\n",
      "\tval loss: 0.00583\n",
      "epoch 1693 / 20000\n",
      "gradient norm: 0.06301094096852466, minimum ratio: 2.5131578947368425\n",
      "\ttrain loss: 0.00593\n",
      "\tval loss: 0.00584\n",
      "epoch 1694 / 20000\n",
      "gradient norm: 0.08286355048767291, minimum ratio: 2.5105263157894737\n",
      "\ttrain loss: 0.00593\n",
      "\tval loss: 0.00582\n",
      "epoch 1695 / 20000\n",
      "gradient norm: 0.057727031817194074, minimum ratio: 2.492105263157895\n",
      "\ttrain loss: 0.00593\n",
      "\tval loss: 0.00582\n",
      "epoch 1696 / 20000\n",
      "gradient norm: 0.08083827124210075, minimum ratio: 2.518421052631579\n",
      "\ttrain loss: 0.00593\n",
      "\tval loss: 0.00584\n",
      "epoch 1697 / 20000\n",
      "gradient norm: 0.05940677400212735, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00593\n",
      "\tval loss: 0.00584\n",
      "epoch 1698 / 20000\n",
      "gradient norm: 0.03954357485054061, minimum ratio: 2.5210526315789474\n",
      "\ttrain loss: 0.00592\n",
      "\tval loss: 0.00582\n",
      "epoch 1699 / 20000\n",
      "gradient norm: 0.06808559107594192, minimum ratio: 2.5210526315789474\n",
      "\ttrain loss: 0.00593\n",
      "\tval loss: 0.00582\n",
      "epoch 1700 / 20000\n",
      "gradient norm: 0.04700373290688731, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00593\n",
      "\tval loss: 0.00583\n",
      "epoch 1701 / 20000\n",
      "gradient norm: 0.06104887701803818, minimum ratio: 2.518421052631579\n",
      "\ttrain loss: 0.00595\n",
      "\tval loss: 0.00583\n",
      "epoch 1702 / 20000\n",
      "gradient norm: 0.061668026726692915, minimum ratio: 2.5105263157894737\n",
      "\ttrain loss: 0.00593\n",
      "\tval loss: 0.00583\n",
      "epoch 1703 / 20000\n",
      "gradient norm: 0.06500237190630287, minimum ratio: 2.518421052631579\n",
      "\ttrain loss: 0.00592\n",
      "\tval loss: 0.00582\n",
      "epoch 1704 / 20000\n",
      "gradient norm: 0.10293423238908872, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00593\n",
      "\tval loss: 0.00582\n",
      "epoch 1705 / 20000\n",
      "gradient norm: 0.04171074341866188, minimum ratio: 2.518421052631579\n",
      "\ttrain loss: 0.00594\n",
      "\tval loss: 0.00585\n",
      "epoch 1706 / 20000\n",
      "gradient norm: 0.07317781372694299, minimum ratio: 2.539473684210526\n",
      "\ttrain loss: 0.00593\n",
      "\tval loss: 0.00582\n",
      "epoch 1707 / 20000\n",
      "gradient norm: 0.045203063811641186, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00591\n",
      "\tval loss: 0.00582\n",
      "epoch 1708 / 20000\n",
      "gradient norm: 0.059029392956290394, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.00591\n",
      "\tval loss: 0.00583\n",
      "epoch 1709 / 20000\n",
      "gradient norm: 0.09499830566346645, minimum ratio: 2.542105263157895\n",
      "\ttrain loss: 0.00592\n",
      "\tval loss: 0.00582\n",
      "epoch 1710 / 20000\n",
      "gradient norm: 0.02851088454190176, minimum ratio: 2.5105263157894737\n",
      "\ttrain loss: 0.00592\n",
      "\tval loss: 0.00582\n",
      "epoch 1711 / 20000\n",
      "gradient norm: 0.05476034397725016, minimum ratio: 2.5184210526315787\n",
      "\ttrain loss: 0.00593\n",
      "\tval loss: 0.00583\n",
      "epoch 1712 / 20000\n",
      "gradient norm: 0.07357254360977095, minimum ratio: 2.536842105263158\n",
      "\ttrain loss: 0.00593\n",
      "\tval loss: 0.00583\n",
      "epoch 1713 / 20000\n",
      "gradient norm: 0.0552412436081795, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00593\n",
      "\tval loss: 0.00582\n",
      "epoch 1714 / 20000\n",
      "gradient norm: 0.07052426447626203, minimum ratio: 2.5210526315789474\n",
      "\ttrain loss: 0.00591\n",
      "\tval loss: 0.00583\n",
      "epoch 1715 / 20000\n",
      "gradient norm: 0.061742698948364705, minimum ratio: 2.5131578947368416\n",
      "\ttrain loss: 0.00591\n",
      "\tval loss: 0.00583\n",
      "epoch 1716 / 20000\n",
      "gradient norm: 0.0221936589514371, minimum ratio: 2.5131578947368425\n",
      "\ttrain loss: 0.00592\n",
      "\tval loss: 0.00582\n",
      "epoch 1717 / 20000\n",
      "gradient norm: 0.108802957329317, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00593\n",
      "\tval loss: 0.00582\n",
      "epoch 1718 / 20000\n",
      "gradient norm: 0.01885209567262791, minimum ratio: 2.5105263157894737\n",
      "\ttrain loss: 0.00592\n",
      "\tval loss: 0.00582\n",
      "epoch 1719 / 20000\n",
      "gradient norm: 0.048572177678579465, minimum ratio: 2.528947368421053\n",
      "\ttrain loss: 0.00591\n",
      "\tval loss: 0.00582\n",
      "epoch 1720 / 20000\n",
      "gradient norm: 0.05955896803061478, minimum ratio: 2.5105263157894737\n",
      "\ttrain loss: 0.00593\n",
      "\tval loss: 0.00583\n",
      "epoch 1721 / 20000\n",
      "gradient norm: 0.04674189951037988, minimum ratio: 2.515789473684211\n",
      "\ttrain loss: 0.00593\n",
      "\tval loss: 0.00582\n",
      "epoch 1722 / 20000\n",
      "gradient norm: 0.041687764576636255, minimum ratio: 2.531578947368421\n",
      "\ttrain loss: 0.00592\n",
      "\tval loss: 0.00581\n",
      "epoch 1723 / 20000\n",
      "gradient norm: 0.07280164101393893, minimum ratio: 2.5342105263157895\n",
      "\ttrain loss: 0.00591\n",
      "\tval loss: 0.00582\n",
      "epoch 1724 / 20000\n",
      "gradient norm: 0.0984976107138209, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00593\n",
      "\tval loss: 0.00582\n",
      "epoch 1725 / 20000\n",
      "gradient norm: 0.0670130648650229, minimum ratio: 2.5210526315789474\n",
      "\ttrain loss: 0.00591\n",
      "\tval loss: 0.00584\n",
      "epoch 1726 / 20000\n",
      "gradient norm: 0.05890153662767261, minimum ratio: 2.5105263157894737\n",
      "\ttrain loss: 0.00593\n",
      "\tval loss: 0.00582\n",
      "epoch 1727 / 20000\n",
      "gradient norm: 0.06198315275833011, minimum ratio: 2.5105263157894737\n",
      "\ttrain loss: 0.00592\n",
      "\tval loss: 0.00582\n",
      "epoch 1728 / 20000\n",
      "gradient norm: 0.0423923542839475, minimum ratio: 2.536842105263158\n",
      "\ttrain loss: 0.00592\n",
      "\tval loss: 0.00582\n",
      "epoch 1729 / 20000\n",
      "gradient norm: 0.031392615055665374, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.00594\n",
      "\tval loss: 0.00583\n",
      "epoch 1730 / 20000\n",
      "gradient norm: 0.12355898058740422, minimum ratio: 2.518421052631579\n",
      "\ttrain loss: 0.00591\n",
      "\tval loss: 0.00583\n",
      "epoch 1731 / 20000\n",
      "gradient norm: 0.11767773469910026, minimum ratio: 2.5157894736842104\n",
      "\ttrain loss: 0.00594\n",
      "\tval loss: 0.00581\n",
      "epoch 1732 / 20000\n",
      "gradient norm: 0.11160869838204235, minimum ratio: 2.5289473684210524\n",
      "\ttrain loss: 0.00593\n",
      "\tval loss: 0.00584\n",
      "epoch 1733 / 20000\n",
      "gradient norm: 0.05516666534822434, minimum ratio: 2.5315789473684207\n",
      "\ttrain loss: 0.00592\n",
      "\tval loss: 0.00583\n",
      "epoch 1734 / 20000\n",
      "gradient norm: 0.031895398402411956, minimum ratio: 2.5394736842105265\n",
      "\ttrain loss: 0.00591\n",
      "\tval loss: 0.00581\n",
      "epoch 1735 / 20000\n",
      "gradient norm: 0.043034512986196205, minimum ratio: 2.5236842105263158\n",
      "\ttrain loss: 0.00593\n",
      "\tval loss: 0.00582\n",
      "epoch 1736 / 20000\n",
      "gradient norm: 0.06881701879319735, minimum ratio: 2.507894736842105\n",
      "\ttrain loss: 0.00592\n",
      "\tval loss: 0.00582\n",
      "epoch 1737 / 20000\n",
      "gradient norm: 0.08092576047056355, minimum ratio: 2.55\n",
      "\ttrain loss: 0.00593\n",
      "\tval loss: 0.00583\n",
      "epoch 1738 / 20000\n",
      "gradient norm: 0.024452536046737805, minimum ratio: 2.526315789473684\n",
      "\ttrain loss: 0.00592\n",
      "\tval loss: 0.00581\n",
      "epoch 1739 / 20000\n",
      "gradient norm: 0.036477752422797494, minimum ratio: 2.5210526315789474\n",
      "\ttrain loss: 0.00594\n",
      "\tval loss: 0.00581\n",
      "epoch 1740 / 20000\n",
      "gradient norm: 0.027593723905738443, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00590\n",
      "\tval loss: 0.00582\n",
      "epoch 1741 / 20000\n",
      "gradient norm: 0.04597992909839377, minimum ratio: 2.513157894736842\n",
      "\ttrain loss: 0.00593\n",
      "\tval loss: 0.00582\n",
      "epoch 1742 / 20000\n",
      "gradient norm: 0.06970697222277522, minimum ratio: 2.507894736842105\n",
      "\ttrain loss: 0.00591\n",
      "\tval loss: 0.00582\n",
      "epoch 1743 / 20000\n",
      "gradient norm: 0.06357585664954968, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00593\n",
      "\tval loss: 0.00581\n",
      "epoch 1744 / 20000\n",
      "gradient norm: 0.0864489400119055, minimum ratio: 2.5342105263157895\n",
      "\ttrain loss: 0.00592\n",
      "\tval loss: 0.00583\n",
      "epoch 1745 / 20000\n",
      "gradient norm: 0.07852565399662126, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00593\n",
      "\tval loss: 0.00581\n",
      "epoch 1746 / 20000\n",
      "gradient norm: 0.10626710602082312, minimum ratio: 2.518421052631579\n",
      "\ttrain loss: 0.00593\n",
      "\tval loss: 0.00581\n",
      "epoch 1747 / 20000\n",
      "gradient norm: 0.0657066258136183, minimum ratio: 2.5342105263157895\n",
      "\ttrain loss: 0.00592\n",
      "\tval loss: 0.00584\n",
      "epoch 1748 / 20000\n",
      "gradient norm: 0.0738218702172162, minimum ratio: 2.507894736842105\n",
      "\ttrain loss: 0.00594\n",
      "\tval loss: 0.00581\n",
      "epoch 1749 / 20000\n",
      "gradient norm: 0.041988030228822026, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00592\n",
      "\tval loss: 0.00581\n",
      "epoch 1750 / 20000\n",
      "gradient norm: 0.07814944518031552, minimum ratio: 2.5078947368421054\n",
      "\ttrain loss: 0.00592\n",
      "\tval loss: 0.00582\n",
      "epoch 1751 / 20000\n",
      "gradient norm: 0.0549677394083119, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.00591\n",
      "\tval loss: 0.00581\n",
      "epoch 1752 / 20000\n",
      "gradient norm: 0.06627802047296427, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00592\n",
      "\tval loss: 0.00581\n",
      "epoch 1753 / 20000\n",
      "gradient norm: 0.1079644958517747, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00592\n",
      "\tval loss: 0.00582\n",
      "epoch 1754 / 20000\n",
      "gradient norm: 0.08184251433704048, minimum ratio: 2.542105263157895\n",
      "\ttrain loss: 0.00593\n",
      "\tval loss: 0.00582\n",
      "epoch 1755 / 20000\n",
      "gradient norm: 0.019603053922764957, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00592\n",
      "\tval loss: 0.00581\n",
      "epoch 1756 / 20000\n",
      "gradient norm: 0.06700945826014504, minimum ratio: 2.5131578947368425\n",
      "\ttrain loss: 0.00593\n",
      "\tval loss: 0.00581\n",
      "epoch 1757 / 20000\n",
      "gradient norm: 0.06298109411727637, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00591\n",
      "\tval loss: 0.00583\n",
      "epoch 1758 / 20000\n",
      "gradient norm: 0.049951038614381105, minimum ratio: 2.513157894736842\n",
      "\ttrain loss: 0.00592\n",
      "\tval loss: 0.00582\n",
      "epoch 1759 / 20000\n",
      "gradient norm: 0.03241857884131605, minimum ratio: 2.492105263157895\n",
      "\ttrain loss: 0.00590\n",
      "\tval loss: 0.00581\n",
      "epoch 1760 / 20000\n",
      "gradient norm: 0.04125409200787544, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.00591\n",
      "\tval loss: 0.00581\n",
      "epoch 1761 / 20000\n",
      "gradient norm: 0.04207066817616578, minimum ratio: 2.5078947368421054\n",
      "\ttrain loss: 0.00591\n",
      "\tval loss: 0.00582\n",
      "epoch 1762 / 20000\n",
      "gradient norm: 0.13789781788364053, minimum ratio: 2.5210526315789474\n",
      "\ttrain loss: 0.00592\n",
      "\tval loss: 0.00583\n",
      "epoch 1763 / 20000\n",
      "gradient norm: 0.05177090139477514, minimum ratio: 2.507894736842105\n",
      "\ttrain loss: 0.00592\n",
      "\tval loss: 0.00580\n",
      "epoch 1764 / 20000\n",
      "gradient norm: 0.06711277311842423, minimum ratio: 2.5157894736842104\n",
      "\ttrain loss: 0.00592\n",
      "\tval loss: 0.00581\n",
      "epoch 1765 / 20000\n",
      "gradient norm: 0.04042659737751819, minimum ratio: 2.518421052631579\n",
      "\ttrain loss: 0.00592\n",
      "\tval loss: 0.00582\n",
      "epoch 1766 / 20000\n",
      "gradient norm: 0.03629072118201293, minimum ratio: 2.507894736842105\n",
      "\ttrain loss: 0.00591\n",
      "\tval loss: 0.00581\n",
      "epoch 1767 / 20000\n",
      "gradient norm: 0.07232548901811242, minimum ratio: 2.518421052631579\n",
      "\ttrain loss: 0.00592\n",
      "\tval loss: 0.00580\n",
      "epoch 1768 / 20000\n",
      "gradient norm: 0.03637540360796265, minimum ratio: 2.515789473684211\n",
      "\ttrain loss: 0.00592\n",
      "\tval loss: 0.00582\n",
      "epoch 1769 / 20000\n",
      "gradient norm: 0.05298322736052796, minimum ratio: 2.5105263157894737\n",
      "\ttrain loss: 0.00592\n",
      "\tval loss: 0.00582\n",
      "epoch 1770 / 20000\n",
      "gradient norm: 0.08260453643742949, minimum ratio: 2.515789473684211\n",
      "\ttrain loss: 0.00592\n",
      "\tval loss: 0.00581\n",
      "epoch 1771 / 20000\n",
      "gradient norm: 0.1416164884576574, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00591\n",
      "\tval loss: 0.00581\n",
      "epoch 1772 / 20000\n",
      "gradient norm: 0.07201755873393267, minimum ratio: 2.5210526315789474\n",
      "\ttrain loss: 0.00591\n",
      "\tval loss: 0.00581\n",
      "epoch 1773 / 20000\n",
      "gradient norm: 0.07494245714042336, minimum ratio: 2.5236842105263158\n",
      "\ttrain loss: 0.00590\n",
      "\tval loss: 0.00581\n",
      "epoch 1774 / 20000\n",
      "gradient norm: 0.0779394811252132, minimum ratio: 2.513157894736842\n",
      "\ttrain loss: 0.00592\n",
      "\tval loss: 0.00581\n",
      "epoch 1775 / 20000\n",
      "gradient norm: 0.08947883822838776, minimum ratio: 2.5105263157894733\n",
      "\ttrain loss: 0.00592\n",
      "\tval loss: 0.00580\n",
      "epoch 1776 / 20000\n",
      "gradient norm: 0.055293203477049246, minimum ratio: 2.507894736842105\n",
      "\ttrain loss: 0.00592\n",
      "\tval loss: 0.00582\n",
      "epoch 1777 / 20000\n",
      "gradient norm: 0.07218993033166043, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00593\n",
      "\tval loss: 0.00582\n",
      "epoch 1778 / 20000\n",
      "gradient norm: 0.03197139209078159, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00591\n",
      "\tval loss: 0.00580\n",
      "epoch 1779 / 20000\n",
      "gradient norm: 0.04788437986280769, minimum ratio: 2.515789473684211\n",
      "\ttrain loss: 0.00591\n",
      "\tval loss: 0.00581\n",
      "epoch 1780 / 20000\n",
      "gradient norm: 0.03051378665259108, minimum ratio: 2.521052631578947\n",
      "\ttrain loss: 0.00592\n",
      "\tval loss: 0.00582\n",
      "epoch 1781 / 20000\n",
      "gradient norm: 0.0499866151221795, minimum ratio: 2.513157894736842\n",
      "\ttrain loss: 0.00590\n",
      "\tval loss: 0.00581\n",
      "epoch 1782 / 20000\n",
      "gradient norm: 0.03553421000833623, minimum ratio: 2.515789473684211\n",
      "\ttrain loss: 0.00590\n",
      "\tval loss: 0.00581\n",
      "epoch 1783 / 20000\n",
      "gradient norm: 0.06770962773589417, minimum ratio: 2.518421052631579\n",
      "\ttrain loss: 0.00591\n",
      "\tval loss: 0.00580\n",
      "epoch 1784 / 20000\n",
      "gradient norm: 0.06396980711724609, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00592\n",
      "\tval loss: 0.00582\n",
      "epoch 1785 / 20000\n",
      "gradient norm: 0.06092925276607275, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00590\n",
      "\tval loss: 0.00581\n",
      "epoch 1786 / 20000\n",
      "gradient norm: 0.03456046467181295, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00590\n",
      "\tval loss: 0.00580\n",
      "epoch 1787 / 20000\n",
      "gradient norm: 0.14083419571397826, minimum ratio: 2.518421052631579\n",
      "\ttrain loss: 0.00592\n",
      "\tval loss: 0.00582\n",
      "epoch 1788 / 20000\n",
      "gradient norm: 0.077226540830452, minimum ratio: 2.5289473684210524\n",
      "\ttrain loss: 0.00589\n",
      "\tval loss: 0.00581\n",
      "epoch 1789 / 20000\n",
      "gradient norm: 0.08815321209840477, minimum ratio: 2.5236842105263158\n",
      "\ttrain loss: 0.00591\n",
      "\tval loss: 0.00580\n",
      "epoch 1790 / 20000\n",
      "gradient norm: 0.03650506831763778, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00591\n",
      "\tval loss: 0.00580\n",
      "epoch 1791 / 20000\n",
      "gradient norm: 0.05275563441682607, minimum ratio: 2.528947368421053\n",
      "\ttrain loss: 0.00590\n",
      "\tval loss: 0.00581\n",
      "epoch 1792 / 20000\n",
      "gradient norm: 0.10289031965658069, minimum ratio: 2.5342105263157895\n",
      "\ttrain loss: 0.00592\n",
      "\tval loss: 0.00581\n",
      "epoch 1793 / 20000\n",
      "gradient norm: 0.11582957895006984, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00594\n",
      "\tval loss: 0.00580\n",
      "epoch 1794 / 20000\n",
      "gradient norm: 0.0822910628921818, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00592\n",
      "\tval loss: 0.00583\n",
      "epoch 1795 / 20000\n",
      "gradient norm: 0.06953328696545213, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00592\n",
      "\tval loss: 0.00580\n",
      "epoch 1796 / 20000\n",
      "gradient norm: 0.08725849341135472, minimum ratio: 2.515789473684211\n",
      "\ttrain loss: 0.00593\n",
      "\tval loss: 0.00581\n",
      "epoch 1797 / 20000\n",
      "gradient norm: 0.0739451399713289, minimum ratio: 2.513157894736842\n",
      "\ttrain loss: 0.00592\n",
      "\tval loss: 0.00580\n",
      "epoch 1798 / 20000\n",
      "gradient norm: 0.10184503614436835, minimum ratio: 2.5342105263157895\n",
      "\ttrain loss: 0.00591\n",
      "\tval loss: 0.00582\n",
      "epoch 1799 / 20000\n",
      "gradient norm: 0.04702993429964408, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00591\n",
      "\tval loss: 0.00580\n",
      "epoch 1800 / 20000\n",
      "gradient norm: 0.04110966586449649, minimum ratio: 2.5236842105263158\n",
      "\ttrain loss: 0.00591\n",
      "\tval loss: 0.00580\n",
      "epoch 1801 / 20000\n",
      "gradient norm: 0.05890834364981856, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00592\n",
      "\tval loss: 0.00581\n",
      "epoch 1802 / 20000\n",
      "gradient norm: 0.04810863852617331, minimum ratio: 2.5236842105263158\n",
      "\ttrain loss: 0.00590\n",
      "\tval loss: 0.00580\n",
      "epoch 1803 / 20000\n",
      "gradient norm: 0.040220749215222895, minimum ratio: 2.5105263157894733\n",
      "\ttrain loss: 0.00591\n",
      "\tval loss: 0.00580\n",
      "epoch 1804 / 20000\n",
      "gradient norm: 0.07531244741403498, minimum ratio: 2.5236842105263158\n",
      "\ttrain loss: 0.00590\n",
      "\tval loss: 0.00580\n",
      "epoch 1805 / 20000\n",
      "gradient norm: 0.041132465266855434, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00592\n",
      "\tval loss: 0.00581\n",
      "epoch 1806 / 20000\n",
      "gradient norm: 0.04206232061551418, minimum ratio: 2.5184210526315787\n",
      "\ttrain loss: 0.00591\n",
      "\tval loss: 0.00581\n",
      "epoch 1807 / 20000\n",
      "gradient norm: 0.02773505332879722, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00589\n",
      "\tval loss: 0.00580\n",
      "epoch 1808 / 20000\n",
      "gradient norm: 0.06961715611396357, minimum ratio: 2.507894736842105\n",
      "\ttrain loss: 0.00592\n",
      "\tval loss: 0.00581\n",
      "epoch 1809 / 20000\n",
      "gradient norm: 0.08384087902959436, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00591\n",
      "\tval loss: 0.00581\n",
      "epoch 1810 / 20000\n",
      "gradient norm: 0.07897850454901345, minimum ratio: 2.515789473684211\n",
      "\ttrain loss: 0.00591\n",
      "\tval loss: 0.00579\n",
      "epoch 1811 / 20000\n",
      "gradient norm: 0.045656642236281186, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00590\n",
      "\tval loss: 0.00580\n",
      "epoch 1812 / 20000\n",
      "gradient norm: 0.11882966119446792, minimum ratio: 2.5210526315789474\n",
      "\ttrain loss: 0.00592\n",
      "\tval loss: 0.00581\n",
      "epoch 1813 / 20000\n",
      "gradient norm: 0.037503784435102716, minimum ratio: 2.507894736842105\n",
      "\ttrain loss: 0.00591\n",
      "\tval loss: 0.00581\n",
      "epoch 1814 / 20000\n",
      "gradient norm: 0.049881162121891975, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00591\n",
      "\tval loss: 0.00580\n",
      "epoch 1815 / 20000\n",
      "gradient norm: 0.09150285116629675, minimum ratio: 2.5236842105263158\n",
      "\ttrain loss: 0.00590\n",
      "\tval loss: 0.00580\n",
      "epoch 1816 / 20000\n",
      "gradient norm: 0.07098535982368048, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00591\n",
      "\tval loss: 0.00580\n",
      "epoch 1817 / 20000\n",
      "gradient norm: 0.042680970815126784, minimum ratio: 2.505263157894737\n",
      "\ttrain loss: 0.00590\n",
      "\tval loss: 0.00581\n",
      "epoch 1818 / 20000\n",
      "gradient norm: 0.08547049475600943, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00591\n",
      "\tval loss: 0.00580\n",
      "epoch 1819 / 20000\n",
      "gradient norm: 0.04873490997124463, minimum ratio: 2.513157894736842\n",
      "\ttrain loss: 0.00592\n",
      "\tval loss: 0.00580\n",
      "epoch 1820 / 20000\n",
      "gradient norm: 0.07524915289832279, minimum ratio: 2.5131578947368416\n",
      "\ttrain loss: 0.00591\n",
      "\tval loss: 0.00581\n",
      "epoch 1821 / 20000\n",
      "gradient norm: 0.04117964245961048, minimum ratio: 2.507894736842105\n",
      "\ttrain loss: 0.00590\n",
      "\tval loss: 0.00580\n",
      "epoch 1822 / 20000\n",
      "gradient norm: 0.09455746656749398, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00591\n",
      "\tval loss: 0.00580\n",
      "epoch 1823 / 20000\n",
      "gradient norm: 0.02793458363157697, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00590\n",
      "\tval loss: 0.00581\n",
      "epoch 1824 / 20000\n",
      "gradient norm: 0.06825235765427351, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00589\n",
      "\tval loss: 0.00581\n",
      "epoch 1825 / 20000\n",
      "gradient norm: 0.05505133522092365, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00590\n",
      "\tval loss: 0.00579\n",
      "epoch 1826 / 20000\n",
      "gradient norm: 0.04739838087698445, minimum ratio: 2.507894736842105\n",
      "\ttrain loss: 0.00591\n",
      "\tval loss: 0.00580\n",
      "epoch 1827 / 20000\n",
      "gradient norm: 0.13232458080165088, minimum ratio: 2.5131578947368425\n",
      "\ttrain loss: 0.00590\n",
      "\tval loss: 0.00581\n",
      "epoch 1828 / 20000\n",
      "gradient norm: 0.037339767412049696, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00590\n",
      "\tval loss: 0.00579\n",
      "epoch 1829 / 20000\n",
      "gradient norm: 0.06341910862829536, minimum ratio: 2.5105263157894737\n",
      "\ttrain loss: 0.00590\n",
      "\tval loss: 0.00580\n",
      "epoch 1830 / 20000\n",
      "gradient norm: 0.10161332623101771, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00589\n",
      "\tval loss: 0.00582\n",
      "epoch 1831 / 20000\n",
      "gradient norm: 0.06356889801099896, minimum ratio: 2.513157894736842\n",
      "\ttrain loss: 0.00590\n",
      "\tval loss: 0.00580\n",
      "epoch 1832 / 20000\n",
      "gradient norm: 0.14273574808612466, minimum ratio: 2.5289473684210524\n",
      "\ttrain loss: 0.00591\n",
      "\tval loss: 0.00579\n",
      "epoch 1833 / 20000\n",
      "gradient norm: 0.08298079716041684, minimum ratio: 2.507894736842105\n",
      "\ttrain loss: 0.00591\n",
      "\tval loss: 0.00582\n",
      "epoch 1834 / 20000\n",
      "gradient norm: 0.06741059216437861, minimum ratio: 2.507894736842105\n",
      "\ttrain loss: 0.00592\n",
      "\tval loss: 0.00580\n",
      "epoch 1835 / 20000\n",
      "gradient norm: 0.0701132939720992, minimum ratio: 2.5289473684210524\n",
      "\ttrain loss: 0.00591\n",
      "\tval loss: 0.00579\n",
      "epoch 1836 / 20000\n",
      "gradient norm: 0.06485401763347909, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00591\n",
      "\tval loss: 0.00580\n",
      "epoch 1837 / 20000\n",
      "gradient norm: 0.0602556568919681, minimum ratio: 2.4868421052631575\n",
      "\ttrain loss: 0.00592\n",
      "\tval loss: 0.00583\n",
      "epoch 1838 / 20000\n",
      "gradient norm: 0.10192099632695317, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00591\n",
      "\tval loss: 0.00580\n",
      "epoch 1839 / 20000\n",
      "gradient norm: 0.07499584462493658, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00589\n",
      "\tval loss: 0.00579\n",
      "epoch 1840 / 20000\n",
      "gradient norm: 0.1072163819335401, minimum ratio: 2.518421052631579\n",
      "\ttrain loss: 0.00592\n",
      "\tval loss: 0.00579\n",
      "epoch 1841 / 20000\n",
      "gradient norm: 0.0443646741041448, minimum ratio: 2.505263157894737\n",
      "\ttrain loss: 0.00591\n",
      "\tval loss: 0.00582\n",
      "epoch 1842 / 20000\n",
      "gradient norm: 0.06434363119478803, minimum ratio: 2.5105263157894737\n",
      "\ttrain loss: 0.00588\n",
      "\tval loss: 0.00580\n",
      "epoch 1843 / 20000\n",
      "gradient norm: 0.07283242349512875, minimum ratio: 2.518421052631579\n",
      "\ttrain loss: 0.00590\n",
      "\tval loss: 0.00579\n",
      "epoch 1844 / 20000\n",
      "gradient norm: 0.058210785064147785, minimum ratio: 2.515789473684211\n",
      "\ttrain loss: 0.00590\n",
      "\tval loss: 0.00579\n",
      "epoch 1845 / 20000\n",
      "gradient norm: 0.05991420819191262, minimum ratio: 2.515789473684211\n",
      "\ttrain loss: 0.00591\n",
      "\tval loss: 0.00580\n",
      "epoch 1846 / 20000\n",
      "gradient norm: 0.08531139977276325, minimum ratio: 2.5157894736842104\n",
      "\ttrain loss: 0.00590\n",
      "\tval loss: 0.00580\n",
      "epoch 1847 / 20000\n",
      "gradient norm: 0.05401211690332275, minimum ratio: 2.5131578947368425\n",
      "\ttrain loss: 0.00590\n",
      "\tval loss: 0.00579\n",
      "epoch 1848 / 20000\n",
      "gradient norm: 0.06998223536356818, minimum ratio: 2.5105263157894733\n",
      "\ttrain loss: 0.00591\n",
      "\tval loss: 0.00579\n",
      "epoch 1849 / 20000\n",
      "gradient norm: 0.124931211466901, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00591\n",
      "\tval loss: 0.00583\n",
      "epoch 1850 / 20000\n",
      "gradient norm: 0.10671038937289268, minimum ratio: 2.5236842105263158\n",
      "\ttrain loss: 0.00590\n",
      "\tval loss: 0.00579\n",
      "epoch 1851 / 20000\n",
      "gradient norm: 0.06019779233611189, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00590\n",
      "\tval loss: 0.00579\n",
      "epoch 1852 / 20000\n",
      "gradient norm: 0.03679809044115245, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00590\n",
      "\tval loss: 0.00580\n",
      "epoch 1853 / 20000\n",
      "gradient norm: 0.0753272772708442, minimum ratio: 2.5105263157894733\n",
      "\ttrain loss: 0.00591\n",
      "\tval loss: 0.00581\n",
      "epoch 1854 / 20000\n",
      "gradient norm: 0.04860043484950438, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00590\n",
      "\tval loss: 0.00578\n",
      "epoch 1855 / 20000\n",
      "gradient norm: 0.06984477222431451, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00591\n",
      "\tval loss: 0.00579\n",
      "epoch 1856 / 20000\n",
      "gradient norm: 0.06702307228988502, minimum ratio: 2.5289473684210524\n",
      "\ttrain loss: 0.00591\n",
      "\tval loss: 0.00582\n",
      "epoch 1857 / 20000\n",
      "gradient norm: 0.10603996482677758, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00590\n",
      "\tval loss: 0.00579\n",
      "epoch 1858 / 20000\n",
      "gradient norm: 0.07795815757708624, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00591\n",
      "\tval loss: 0.00579\n",
      "epoch 1859 / 20000\n",
      "gradient norm: 0.06448027188889682, minimum ratio: 2.507894736842105\n",
      "\ttrain loss: 0.00589\n",
      "\tval loss: 0.00581\n",
      "epoch 1860 / 20000\n",
      "gradient norm: 0.04922092526976485, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00590\n",
      "\tval loss: 0.00579\n",
      "epoch 1861 / 20000\n",
      "gradient norm: 0.03489404762513004, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00589\n",
      "\tval loss: 0.00580\n",
      "epoch 1862 / 20000\n",
      "gradient norm: 0.10376930236816406, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.00590\n",
      "\tval loss: 0.00579\n",
      "epoch 1863 / 20000\n",
      "gradient norm: 0.021699702483601868, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00590\n",
      "\tval loss: 0.00580\n",
      "epoch 1864 / 20000\n",
      "gradient norm: 0.05683480464358581, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00588\n",
      "\tval loss: 0.00579\n",
      "epoch 1865 / 20000\n",
      "gradient norm: 0.08132804109482095, minimum ratio: 2.518421052631579\n",
      "\ttrain loss: 0.00590\n",
      "\tval loss: 0.00579\n",
      "epoch 1866 / 20000\n",
      "gradient norm: 0.08993964991532266, minimum ratio: 2.494736842105263\n",
      "\ttrain loss: 0.00591\n",
      "\tval loss: 0.00579\n",
      "epoch 1867 / 20000\n",
      "gradient norm: 0.048687840200727805, minimum ratio: 2.5105263157894737\n",
      "\ttrain loss: 0.00591\n",
      "\tval loss: 0.00579\n",
      "epoch 1868 / 20000\n",
      "gradient norm: 0.058379467052873224, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00590\n",
      "\tval loss: 0.00580\n",
      "epoch 1869 / 20000\n",
      "gradient norm: 0.07019685755949467, minimum ratio: 2.5105263157894733\n",
      "\ttrain loss: 0.00589\n",
      "\tval loss: 0.00580\n",
      "epoch 1870 / 20000\n",
      "gradient norm: 0.06747507792897522, minimum ratio: 2.5394736842105265\n",
      "\ttrain loss: 0.00589\n",
      "\tval loss: 0.00579\n",
      "epoch 1871 / 20000\n",
      "gradient norm: 0.06587913824478164, minimum ratio: 2.5210526315789474\n",
      "\ttrain loss: 0.00590\n",
      "\tval loss: 0.00578\n",
      "epoch 1872 / 20000\n",
      "gradient norm: 0.05257632507709786, minimum ratio: 2.5131578947368425\n",
      "\ttrain loss: 0.00590\n",
      "\tval loss: 0.00580\n",
      "epoch 1873 / 20000\n",
      "gradient norm: 0.10545765678398311, minimum ratio: 2.5105263157894733\n",
      "\ttrain loss: 0.00589\n",
      "\tval loss: 0.00581\n",
      "epoch 1874 / 20000\n",
      "gradient norm: 0.04124680475797504, minimum ratio: 2.518421052631579\n",
      "\ttrain loss: 0.00589\n",
      "\tval loss: 0.00578\n",
      "epoch 1875 / 20000\n",
      "gradient norm: 0.07141632528509945, minimum ratio: 2.5078947368421054\n",
      "\ttrain loss: 0.00591\n",
      "\tval loss: 0.00578\n",
      "epoch 1876 / 20000\n",
      "gradient norm: 0.05734483152627945, minimum ratio: 2.5157894736842104\n",
      "\ttrain loss: 0.00590\n",
      "\tval loss: 0.00581\n",
      "epoch 1877 / 20000\n",
      "gradient norm: 0.05220076223486103, minimum ratio: 2.492105263157895\n",
      "\ttrain loss: 0.00590\n",
      "\tval loss: 0.00579\n",
      "epoch 1878 / 20000\n",
      "gradient norm: 0.06945980346063152, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00590\n",
      "\tval loss: 0.00579\n",
      "epoch 1879 / 20000\n",
      "gradient norm: 0.06353681042673998, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00588\n",
      "\tval loss: 0.00578\n",
      "epoch 1880 / 20000\n",
      "gradient norm: 0.06642328745510895, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00590\n",
      "\tval loss: 0.00580\n",
      "epoch 1881 / 20000\n",
      "gradient norm: 0.039575773756951094, minimum ratio: 2.518421052631579\n",
      "\ttrain loss: 0.00589\n",
      "\tval loss: 0.00579\n",
      "epoch 1882 / 20000\n",
      "gradient norm: 0.06313411274459213, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00591\n",
      "\tval loss: 0.00579\n",
      "epoch 1883 / 20000\n",
      "gradient norm: 0.08468057040590793, minimum ratio: 2.518421052631579\n",
      "\ttrain loss: 0.00590\n",
      "\tval loss: 0.00578\n",
      "epoch 1884 / 20000\n",
      "gradient norm: 0.0691635250186664, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.00591\n",
      "\tval loss: 0.00580\n",
      "epoch 1885 / 20000\n",
      "gradient norm: 0.034971041983226314, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00589\n",
      "\tval loss: 0.00579\n",
      "epoch 1886 / 20000\n",
      "gradient norm: 0.06876949471188709, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00590\n",
      "\tval loss: 0.00578\n",
      "epoch 1887 / 20000\n",
      "gradient norm: 0.10573717096121982, minimum ratio: 2.5078947368421054\n",
      "\ttrain loss: 0.00590\n",
      "\tval loss: 0.00580\n",
      "epoch 1888 / 20000\n",
      "gradient norm: 0.03946010013896739, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00590\n",
      "\tval loss: 0.00578\n",
      "epoch 1889 / 20000\n",
      "gradient norm: 0.08309417881537229, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00590\n",
      "\tval loss: 0.00578\n",
      "epoch 1890 / 20000\n",
      "gradient norm: 0.1004128799540922, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00591\n",
      "\tval loss: 0.00581\n",
      "epoch 1891 / 20000\n",
      "gradient norm: 0.06055550105520524, minimum ratio: 2.513157894736842\n",
      "\ttrain loss: 0.00589\n",
      "\tval loss: 0.00579\n",
      "epoch 1892 / 20000\n",
      "gradient norm: 0.07300954809761606, minimum ratio: 2.513157894736842\n",
      "\ttrain loss: 0.00589\n",
      "\tval loss: 0.00579\n",
      "epoch 1893 / 20000\n",
      "gradient norm: 0.03814601356862113, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00589\n",
      "\tval loss: 0.00579\n",
      "epoch 1894 / 20000\n",
      "gradient norm: 0.035737999685807154, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00590\n",
      "\tval loss: 0.00579\n",
      "epoch 1895 / 20000\n",
      "gradient norm: 0.07982373508275487, minimum ratio: 2.513157894736842\n",
      "\ttrain loss: 0.00590\n",
      "\tval loss: 0.00579\n",
      "epoch 1896 / 20000\n",
      "gradient norm: 0.06914735457394272, minimum ratio: 2.5078947368421054\n",
      "\ttrain loss: 0.00590\n",
      "\tval loss: 0.00579\n",
      "epoch 1897 / 20000\n",
      "gradient norm: 0.05176050978479907, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00589\n",
      "\tval loss: 0.00579\n",
      "epoch 1898 / 20000\n",
      "gradient norm: 0.05726239731302485, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00589\n",
      "\tval loss: 0.00579\n",
      "epoch 1899 / 20000\n",
      "gradient norm: 0.06514485995285213, minimum ratio: 2.5105263157894737\n",
      "\ttrain loss: 0.00589\n",
      "\tval loss: 0.00579\n",
      "epoch 1900 / 20000\n",
      "gradient norm: 0.01523880437889602, minimum ratio: 2.4868421052631575\n",
      "\ttrain loss: 0.00590\n",
      "\tval loss: 0.00578\n",
      "epoch 1901 / 20000\n",
      "gradient norm: 0.040957694116514176, minimum ratio: 2.518421052631579\n",
      "\ttrain loss: 0.00589\n",
      "\tval loss: 0.00579\n",
      "epoch 1902 / 20000\n",
      "gradient norm: 0.09204965288517997, minimum ratio: 2.528947368421053\n",
      "\ttrain loss: 0.00589\n",
      "\tval loss: 0.00579\n",
      "epoch 1903 / 20000\n",
      "gradient norm: 0.03522697159496602, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00591\n",
      "\tval loss: 0.00578\n",
      "epoch 1904 / 20000\n",
      "gradient norm: 0.04947418186930008, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00588\n",
      "\tval loss: 0.00578\n",
      "epoch 1905 / 20000\n",
      "gradient norm: 0.02753831635345705, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00590\n",
      "\tval loss: 0.00579\n",
      "epoch 1906 / 20000\n",
      "gradient norm: 0.042119268560782075, minimum ratio: 2.5078947368421054\n",
      "\ttrain loss: 0.00591\n",
      "\tval loss: 0.00580\n",
      "epoch 1907 / 20000\n",
      "gradient norm: 0.07757440919522196, minimum ratio: 2.5210526315789474\n",
      "\ttrain loss: 0.00589\n",
      "\tval loss: 0.00579\n",
      "epoch 1908 / 20000\n",
      "gradient norm: 0.07122012079344131, minimum ratio: 2.5078947368421054\n",
      "\ttrain loss: 0.00590\n",
      "\tval loss: 0.00578\n",
      "epoch 1909 / 20000\n",
      "gradient norm: 0.08159298961982131, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00590\n",
      "\tval loss: 0.00580\n",
      "epoch 1910 / 20000\n",
      "gradient norm: 0.03524752479279414, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00589\n",
      "\tval loss: 0.00579\n",
      "epoch 1911 / 20000\n",
      "gradient norm: 0.03740325404214673, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00590\n",
      "\tval loss: 0.00578\n",
      "epoch 1912 / 20000\n",
      "gradient norm: 0.09454485966125503, minimum ratio: 2.5210526315789474\n",
      "\ttrain loss: 0.00590\n",
      "\tval loss: 0.00579\n",
      "epoch 1913 / 20000\n",
      "gradient norm: 0.0626005282101687, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00589\n",
      "\tval loss: 0.00579\n",
      "epoch 1914 / 20000\n",
      "gradient norm: 0.035249659878900275, minimum ratio: 2.526315789473684\n",
      "\ttrain loss: 0.00589\n",
      "\tval loss: 0.00578\n",
      "epoch 1915 / 20000\n",
      "gradient norm: 0.11347837570065167, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00589\n",
      "\tval loss: 0.00578\n",
      "epoch 1916 / 20000\n",
      "gradient norm: 0.08900563907809556, minimum ratio: 2.513157894736842\n",
      "\ttrain loss: 0.00590\n",
      "\tval loss: 0.00578\n",
      "epoch 1917 / 20000\n",
      "gradient norm: 0.05811466195154935, minimum ratio: 2.489473684210526\n",
      "\ttrain loss: 0.00588\n",
      "\tval loss: 0.00578\n",
      "epoch 1918 / 20000\n",
      "gradient norm: 0.06091808986093383, minimum ratio: 2.526315789473684\n",
      "\ttrain loss: 0.00589\n",
      "\tval loss: 0.00578\n",
      "epoch 1919 / 20000\n",
      "gradient norm: 0.11216028220951557, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00589\n",
      "\tval loss: 0.00579\n",
      "epoch 1920 / 20000\n",
      "gradient norm: 0.05882957132416777, minimum ratio: 2.518421052631579\n",
      "\ttrain loss: 0.00589\n",
      "\tval loss: 0.00579\n",
      "epoch 1921 / 20000\n",
      "gradient norm: 0.06000203936127946, minimum ratio: 2.531578947368421\n",
      "\ttrain loss: 0.00588\n",
      "\tval loss: 0.00578\n",
      "epoch 1922 / 20000\n",
      "gradient norm: 0.07472133036935702, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00588\n",
      "\tval loss: 0.00578\n",
      "epoch 1923 / 20000\n",
      "gradient norm: 0.05864154055598192, minimum ratio: 2.5210526315789474\n",
      "\ttrain loss: 0.00588\n",
      "\tval loss: 0.00578\n",
      "epoch 1924 / 20000\n",
      "gradient norm: 0.07976025139214471, minimum ratio: 2.5157894736842104\n",
      "\ttrain loss: 0.00590\n",
      "\tval loss: 0.00580\n",
      "epoch 1925 / 20000\n",
      "gradient norm: 0.13247588515514508, minimum ratio: 2.515789473684211\n",
      "\ttrain loss: 0.00591\n",
      "\tval loss: 0.00577\n",
      "epoch 1926 / 20000\n",
      "gradient norm: 0.0627610762603581, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00589\n",
      "\tval loss: 0.00579\n",
      "epoch 1927 / 20000\n",
      "gradient norm: 0.05617729632649571, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00589\n",
      "\tval loss: 0.00579\n",
      "epoch 1928 / 20000\n",
      "gradient norm: 0.07750375161413103, minimum ratio: 2.507894736842105\n",
      "\ttrain loss: 0.00589\n",
      "\tval loss: 0.00578\n",
      "epoch 1929 / 20000\n",
      "gradient norm: 0.059960573562420905, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00589\n",
      "\tval loss: 0.00578\n",
      "epoch 1930 / 20000\n",
      "gradient norm: 0.06979178747860715, minimum ratio: 2.5105263157894733\n",
      "\ttrain loss: 0.00589\n",
      "\tval loss: 0.00579\n",
      "epoch 1931 / 20000\n",
      "gradient norm: 0.04708559179562144, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00589\n",
      "\tval loss: 0.00578\n",
      "epoch 1932 / 20000\n",
      "gradient norm: 0.02888717909809202, minimum ratio: 2.507894736842105\n",
      "\ttrain loss: 0.00589\n",
      "\tval loss: 0.00578\n",
      "epoch 1933 / 20000\n",
      "gradient norm: 0.06039019237505272, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00589\n",
      "\tval loss: 0.00579\n",
      "epoch 1934 / 20000\n",
      "gradient norm: 0.029989256407134235, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00589\n",
      "\tval loss: 0.00578\n",
      "epoch 1935 / 20000\n",
      "gradient norm: 0.05039166533970274, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00589\n",
      "\tval loss: 0.00577\n",
      "epoch 1936 / 20000\n",
      "gradient norm: 0.09390281292144209, minimum ratio: 2.494736842105263\n",
      "\ttrain loss: 0.00589\n",
      "\tval loss: 0.00578\n",
      "epoch 1937 / 20000\n",
      "gradient norm: 0.054781512648332864, minimum ratio: 2.507894736842105\n",
      "\ttrain loss: 0.00589\n",
      "\tval loss: 0.00580\n",
      "epoch 1938 / 20000\n",
      "gradient norm: 0.056460698833689094, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00590\n",
      "\tval loss: 0.00578\n",
      "epoch 1939 / 20000\n",
      "gradient norm: 0.05592316479305737, minimum ratio: 2.5105263157894737\n",
      "\ttrain loss: 0.00588\n",
      "\tval loss: 0.00578\n",
      "epoch 1940 / 20000\n",
      "gradient norm: 0.04017354025563691, minimum ratio: 2.5236842105263158\n",
      "\ttrain loss: 0.00589\n",
      "\tval loss: 0.00578\n",
      "epoch 1941 / 20000\n",
      "gradient norm: 0.09575581643730402, minimum ratio: 2.5157894736842104\n",
      "\ttrain loss: 0.00590\n",
      "\tval loss: 0.00578\n",
      "epoch 1942 / 20000\n",
      "gradient norm: 0.07662952406099066, minimum ratio: 2.5210526315789474\n",
      "\ttrain loss: 0.00588\n",
      "\tval loss: 0.00578\n",
      "epoch 1943 / 20000\n",
      "gradient norm: 0.07898005002789432, minimum ratio: 2.5105263157894737\n",
      "\ttrain loss: 0.00590\n",
      "\tval loss: 0.00578\n",
      "epoch 1944 / 20000\n",
      "gradient norm: 0.042171353510639165, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00589\n",
      "\tval loss: 0.00578\n",
      "epoch 1945 / 20000\n",
      "gradient norm: 0.04840968974167481, minimum ratio: 2.5184210526315787\n",
      "\ttrain loss: 0.00588\n",
      "\tval loss: 0.00578\n",
      "epoch 1946 / 20000\n",
      "gradient norm: 0.032307338042301126, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00589\n",
      "\tval loss: 0.00578\n",
      "epoch 1947 / 20000\n",
      "gradient norm: 0.04868310361780459, minimum ratio: 2.492105263157895\n",
      "\ttrain loss: 0.00589\n",
      "\tval loss: 0.00577\n",
      "epoch 1948 / 20000\n",
      "gradient norm: 0.09065194788854569, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00589\n",
      "\tval loss: 0.00579\n",
      "epoch 1949 / 20000\n",
      "gradient norm: 0.02960787678603083, minimum ratio: 2.5210526315789474\n",
      "\ttrain loss: 0.00588\n",
      "\tval loss: 0.00577\n",
      "epoch 1950 / 20000\n",
      "gradient norm: 0.05824620136991143, minimum ratio: 2.5131578947368425\n",
      "\ttrain loss: 0.00589\n",
      "\tval loss: 0.00578\n",
      "epoch 1951 / 20000\n",
      "gradient norm: 0.03345118329161778, minimum ratio: 2.5078947368421054\n",
      "\ttrain loss: 0.00589\n",
      "\tval loss: 0.00577\n",
      "epoch 1952 / 20000\n",
      "gradient norm: 0.05845566760399379, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00588\n",
      "\tval loss: 0.00579\n",
      "epoch 1953 / 20000\n",
      "gradient norm: 0.0716203525516903, minimum ratio: 2.5131578947368425\n",
      "\ttrain loss: 0.00589\n",
      "\tval loss: 0.00577\n",
      "epoch 1954 / 20000\n",
      "gradient norm: 0.09207581740338355, minimum ratio: 2.5236842105263158\n",
      "\ttrain loss: 0.00589\n",
      "\tval loss: 0.00578\n",
      "epoch 1955 / 20000\n",
      "gradient norm: 0.09230379777727649, minimum ratio: 2.5157894736842104\n",
      "\ttrain loss: 0.00589\n",
      "\tval loss: 0.00579\n",
      "epoch 1956 / 20000\n",
      "gradient norm: 0.04740121299983002, minimum ratio: 2.5157894736842104\n",
      "\ttrain loss: 0.00588\n",
      "\tval loss: 0.00577\n",
      "epoch 1957 / 20000\n",
      "gradient norm: 0.06907738659356255, minimum ratio: 2.507894736842105\n",
      "\ttrain loss: 0.00587\n",
      "\tval loss: 0.00577\n",
      "epoch 1958 / 20000\n",
      "gradient norm: 0.022808264766354114, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00589\n",
      "\tval loss: 0.00578\n",
      "epoch 1959 / 20000\n",
      "gradient norm: 0.03406193287810311, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.00590\n",
      "\tval loss: 0.00578\n",
      "epoch 1960 / 20000\n",
      "gradient norm: 0.05627657915465534, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00589\n",
      "\tval loss: 0.00578\n",
      "epoch 1961 / 20000\n",
      "gradient norm: 0.04704893968300894, minimum ratio: 2.507894736842105\n",
      "\ttrain loss: 0.00588\n",
      "\tval loss: 0.00577\n",
      "epoch 1962 / 20000\n",
      "gradient norm: 0.04125307110371068, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00589\n",
      "\tval loss: 0.00578\n",
      "epoch 1963 / 20000\n",
      "gradient norm: 0.06471501107444055, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00589\n",
      "\tval loss: 0.00578\n",
      "epoch 1964 / 20000\n",
      "gradient norm: 0.058111526843276806, minimum ratio: 2.5289473684210524\n",
      "\ttrain loss: 0.00589\n",
      "\tval loss: 0.00577\n",
      "epoch 1965 / 20000\n",
      "gradient norm: 0.06043192438664846, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00589\n",
      "\tval loss: 0.00577\n",
      "epoch 1966 / 20000\n",
      "gradient norm: 0.059643277258146554, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.00588\n",
      "\tval loss: 0.00579\n",
      "epoch 1967 / 20000\n",
      "gradient norm: 0.09302087221294641, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00591\n",
      "\tval loss: 0.00579\n",
      "epoch 1968 / 20000\n",
      "gradient norm: 0.07736261916579679, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00588\n",
      "\tval loss: 0.00577\n",
      "epoch 1969 / 20000\n",
      "gradient norm: 0.08622415957506746, minimum ratio: 2.5078947368421054\n",
      "\ttrain loss: 0.00590\n",
      "\tval loss: 0.00578\n",
      "epoch 1970 / 20000\n",
      "gradient norm: 0.04863397142617032, minimum ratio: 2.5105263157894733\n",
      "\ttrain loss: 0.00589\n",
      "\tval loss: 0.00578\n",
      "epoch 1971 / 20000\n",
      "gradient norm: 0.04492282521096058, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00589\n",
      "\tval loss: 0.00577\n",
      "epoch 1972 / 20000\n",
      "gradient norm: 0.11532795231323689, minimum ratio: 2.5157894736842104\n",
      "\ttrain loss: 0.00589\n",
      "\tval loss: 0.00578\n",
      "epoch 1973 / 20000\n",
      "gradient norm: 0.07264780066907406, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00588\n",
      "\tval loss: 0.00577\n",
      "epoch 1974 / 20000\n",
      "gradient norm: 0.0675502392987255, minimum ratio: 2.518421052631579\n",
      "\ttrain loss: 0.00589\n",
      "\tval loss: 0.00577\n",
      "epoch 1975 / 20000\n",
      "gradient norm: 0.08586953941266984, minimum ratio: 2.513157894736842\n",
      "\ttrain loss: 0.00589\n",
      "\tval loss: 0.00578\n",
      "epoch 1976 / 20000\n",
      "gradient norm: 0.0607391960802488, minimum ratio: 2.5210526315789474\n",
      "\ttrain loss: 0.00588\n",
      "\tval loss: 0.00577\n",
      "epoch 1977 / 20000\n",
      "gradient norm: 0.018757842990453355, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00588\n",
      "\tval loss: 0.00578\n",
      "epoch 1978 / 20000\n",
      "gradient norm: 0.044752818008419126, minimum ratio: 2.5157894736842104\n",
      "\ttrain loss: 0.00588\n",
      "\tval loss: 0.00579\n",
      "epoch 1979 / 20000\n",
      "gradient norm: 0.058922333031659946, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00588\n",
      "\tval loss: 0.00577\n",
      "epoch 1980 / 20000\n",
      "gradient norm: 0.08270305395126343, minimum ratio: 2.507894736842105\n",
      "\ttrain loss: 0.00589\n",
      "\tval loss: 0.00577\n",
      "epoch 1981 / 20000\n",
      "gradient norm: 0.05300385755253956, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00587\n",
      "\tval loss: 0.00580\n",
      "epoch 1982 / 20000\n",
      "gradient norm: 0.047168495919322595, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00588\n",
      "\tval loss: 0.00577\n",
      "epoch 1983 / 20000\n",
      "gradient norm: 0.06415773218031973, minimum ratio: 2.4973684210526312\n",
      "\ttrain loss: 0.00588\n",
      "\tval loss: 0.00577\n",
      "epoch 1984 / 20000\n",
      "gradient norm: 0.05887302628252655, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00590\n",
      "\tval loss: 0.00577\n",
      "epoch 1985 / 20000\n",
      "gradient norm: 0.06912985671078786, minimum ratio: 2.5236842105263158\n",
      "\ttrain loss: 0.00587\n",
      "\tval loss: 0.00579\n",
      "epoch 1986 / 20000\n",
      "gradient norm: 0.06321472665877081, minimum ratio: 2.4868421052631584\n",
      "\ttrain loss: 0.00589\n",
      "\tval loss: 0.00578\n",
      "epoch 1987 / 20000\n",
      "gradient norm: 0.042758785595651716, minimum ratio: 2.515789473684211\n",
      "\ttrain loss: 0.00588\n",
      "\tval loss: 0.00577\n",
      "epoch 1988 / 20000\n",
      "gradient norm: 0.08500703511526808, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00590\n",
      "\tval loss: 0.00576\n",
      "epoch 1989 / 20000\n",
      "gradient norm: 0.057044415560085326, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00588\n",
      "\tval loss: 0.00580\n",
      "epoch 1990 / 20000\n",
      "gradient norm: 0.06853832457272802, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00590\n",
      "\tval loss: 0.00578\n",
      "epoch 1991 / 20000\n",
      "gradient norm: 0.0711013256222941, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00587\n",
      "\tval loss: 0.00577\n",
      "epoch 1992 / 20000\n",
      "gradient norm: 0.08535843738354743, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00590\n",
      "\tval loss: 0.00576\n",
      "epoch 1993 / 20000\n",
      "gradient norm: 0.08014238870237023, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00589\n",
      "\tval loss: 0.00578\n",
      "epoch 1994 / 20000\n",
      "gradient norm: 0.10627957200631499, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.00587\n",
      "\tval loss: 0.00578\n",
      "epoch 1995 / 20000\n",
      "gradient norm: 0.07318966806633398, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00590\n",
      "\tval loss: 0.00577\n",
      "epoch 1996 / 20000\n",
      "gradient norm: 0.06152216752525419, minimum ratio: 2.5105263157894737\n",
      "\ttrain loss: 0.00587\n",
      "\tval loss: 0.00577\n",
      "epoch 1997 / 20000\n",
      "gradient norm: 0.08380287562613375, minimum ratio: 2.4973684210526312\n",
      "\ttrain loss: 0.00588\n",
      "\tval loss: 0.00578\n",
      "epoch 1998 / 20000\n",
      "gradient norm: 0.027154995979799423, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00589\n",
      "\tval loss: 0.00577\n",
      "epoch 1999 / 20000\n",
      "gradient norm: 0.07568401345633902, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00587\n",
      "\tval loss: 0.00577\n",
      "epoch 2000 / 20000\n",
      "gradient norm: 0.03931163226661738, minimum ratio: 2.515789473684211\n",
      "\ttrain loss: 0.00588\n",
      "\tval loss: 0.00576\n",
      "epoch 2001 / 20000\n",
      "gradient norm: 0.06709394318750128, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00590\n",
      "\tval loss: 0.00576\n",
      "epoch 2002 / 20000\n",
      "gradient norm: 0.044214954104973, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00588\n",
      "\tval loss: 0.00579\n",
      "epoch 2003 / 20000\n",
      "gradient norm: 0.07412168942391872, minimum ratio: 2.489473684210526\n",
      "\ttrain loss: 0.00587\n",
      "\tval loss: 0.00577\n",
      "epoch 2004 / 20000\n",
      "gradient norm: 0.04931375599699095, minimum ratio: 2.4868421052631584\n",
      "\ttrain loss: 0.00588\n",
      "\tval loss: 0.00576\n",
      "epoch 2005 / 20000\n",
      "gradient norm: 0.036967812418879475, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00588\n",
      "\tval loss: 0.00577\n",
      "epoch 2006 / 20000\n",
      "gradient norm: 0.08875424216967076, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00588\n",
      "\tval loss: 0.00578\n",
      "epoch 2007 / 20000\n",
      "gradient norm: 0.11890818167012185, minimum ratio: 2.5131578947368425\n",
      "\ttrain loss: 0.00589\n",
      "\tval loss: 0.00576\n",
      "epoch 2008 / 20000\n",
      "gradient norm: 0.04379905620589852, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00588\n",
      "\tval loss: 0.00577\n",
      "epoch 2009 / 20000\n",
      "gradient norm: 0.06306753773242235, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.00587\n",
      "\tval loss: 0.00578\n",
      "epoch 2010 / 20000\n",
      "gradient norm: 0.03921767658175668, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00590\n",
      "\tval loss: 0.00577\n",
      "epoch 2011 / 20000\n",
      "gradient norm: 0.07853844040073454, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00589\n",
      "\tval loss: 0.00576\n",
      "epoch 2012 / 20000\n",
      "gradient norm: 0.0783588491322007, minimum ratio: 2.5210526315789474\n",
      "\ttrain loss: 0.00589\n",
      "\tval loss: 0.00576\n",
      "epoch 2013 / 20000\n",
      "gradient norm: 0.08111060276860371, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00587\n",
      "\tval loss: 0.00579\n",
      "epoch 2014 / 20000\n",
      "gradient norm: 0.11019646230852231, minimum ratio: 2.515789473684211\n",
      "\ttrain loss: 0.00589\n",
      "\tval loss: 0.00576\n",
      "epoch 2015 / 20000\n",
      "gradient norm: 0.06663834722712636, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.00588\n",
      "\tval loss: 0.00576\n",
      "epoch 2016 / 20000\n",
      "gradient norm: 0.046101680083666, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00588\n",
      "\tval loss: 0.00578\n",
      "epoch 2017 / 20000\n",
      "gradient norm: 0.10039040705305524, minimum ratio: 2.518421052631579\n",
      "\ttrain loss: 0.00589\n",
      "\tval loss: 0.00580\n",
      "epoch 2018 / 20000\n",
      "gradient norm: 0.048529926512856036, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00588\n",
      "\tval loss: 0.00576\n",
      "epoch 2019 / 20000\n",
      "gradient norm: 0.07042600854765624, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00588\n",
      "\tval loss: 0.00576\n",
      "epoch 2020 / 20000\n",
      "gradient norm: 0.08549141747062095, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00587\n",
      "\tval loss: 0.00578\n",
      "epoch 2021 / 20000\n",
      "gradient norm: 0.05873601482016966, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00588\n",
      "\tval loss: 0.00577\n",
      "epoch 2022 / 20000\n",
      "gradient norm: 0.0351532798667904, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00587\n",
      "\tval loss: 0.00576\n",
      "epoch 2023 / 20000\n",
      "gradient norm: 0.04011688721948303, minimum ratio: 2.5210526315789474\n",
      "\ttrain loss: 0.00588\n",
      "\tval loss: 0.00576\n",
      "epoch 2024 / 20000\n",
      "gradient norm: 0.060973687504883856, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00588\n",
      "\tval loss: 0.00578\n",
      "epoch 2025 / 20000\n",
      "gradient norm: 0.11100742904818617, minimum ratio: 2.513157894736842\n",
      "\ttrain loss: 0.00587\n",
      "\tval loss: 0.00577\n",
      "epoch 2026 / 20000\n",
      "gradient norm: 0.054827905289130285, minimum ratio: 2.5210526315789474\n",
      "\ttrain loss: 0.00588\n",
      "\tval loss: 0.00576\n",
      "epoch 2027 / 20000\n",
      "gradient norm: 0.04338576295413077, minimum ratio: 2.513157894736842\n",
      "\ttrain loss: 0.00588\n",
      "\tval loss: 0.00577\n",
      "epoch 2028 / 20000\n",
      "gradient norm: 0.03257247134752106, minimum ratio: 2.5315789473684207\n",
      "\ttrain loss: 0.00588\n",
      "\tval loss: 0.00577\n",
      "epoch 2029 / 20000\n",
      "gradient norm: 0.07422004823456518, minimum ratio: 2.5078947368421054\n",
      "\ttrain loss: 0.00588\n",
      "\tval loss: 0.00576\n",
      "epoch 2030 / 20000\n",
      "gradient norm: 0.047575946897268295, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00587\n",
      "\tval loss: 0.00576\n",
      "epoch 2031 / 20000\n",
      "gradient norm: 0.02293859372730367, minimum ratio: 2.494736842105263\n",
      "\ttrain loss: 0.00588\n",
      "\tval loss: 0.00577\n",
      "epoch 2032 / 20000\n",
      "gradient norm: 0.05653869682282675, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00587\n",
      "\tval loss: 0.00577\n",
      "epoch 2033 / 20000\n",
      "gradient norm: 0.113477528328076, minimum ratio: 2.5289473684210524\n",
      "\ttrain loss: 0.00587\n",
      "\tval loss: 0.00577\n",
      "epoch 2034 / 20000\n",
      "gradient norm: 0.07940546338795684, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00588\n",
      "\tval loss: 0.00576\n",
      "epoch 2035 / 20000\n",
      "gradient norm: 0.03894136828603223, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00588\n",
      "\tval loss: 0.00577\n",
      "epoch 2036 / 20000\n",
      "gradient norm: 0.08383983047679067, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00588\n",
      "\tval loss: 0.00577\n",
      "epoch 2037 / 20000\n",
      "gradient norm: 0.13844497478567064, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00589\n",
      "\tval loss: 0.00576\n",
      "epoch 2038 / 20000\n",
      "gradient norm: 0.029943836212623864, minimum ratio: 2.513157894736842\n",
      "\ttrain loss: 0.00588\n",
      "\tval loss: 0.00578\n",
      "epoch 2039 / 20000\n",
      "gradient norm: 0.0918076882371679, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00589\n",
      "\tval loss: 0.00578\n",
      "epoch 2040 / 20000\n",
      "gradient norm: 0.05485176645743195, minimum ratio: 2.5236842105263158\n",
      "\ttrain loss: 0.00589\n",
      "\tval loss: 0.00576\n",
      "epoch 2041 / 20000\n",
      "gradient norm: 0.1021948631387204, minimum ratio: 2.513157894736842\n",
      "\ttrain loss: 0.00588\n",
      "\tval loss: 0.00576\n",
      "epoch 2042 / 20000\n",
      "gradient norm: 0.03295645090111066, minimum ratio: 2.5105263157894737\n",
      "\ttrain loss: 0.00588\n",
      "\tval loss: 0.00577\n",
      "epoch 2043 / 20000\n",
      "gradient norm: 0.1084516579285264, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00588\n",
      "\tval loss: 0.00576\n",
      "epoch 2044 / 20000\n",
      "gradient norm: 0.05924826324917376, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00588\n",
      "\tval loss: 0.00576\n",
      "epoch 2045 / 20000\n",
      "gradient norm: 0.12857776903547347, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00587\n",
      "\tval loss: 0.00578\n",
      "epoch 2046 / 20000\n",
      "gradient norm: 0.06220055840094574, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00588\n",
      "\tval loss: 0.00576\n",
      "epoch 2047 / 20000\n",
      "gradient norm: 0.11515682778554037, minimum ratio: 2.5157894736842104\n",
      "\ttrain loss: 0.00588\n",
      "\tval loss: 0.00576\n",
      "epoch 2048 / 20000\n",
      "gradient norm: 0.05040793531225063, minimum ratio: 2.5105263157894737\n",
      "\ttrain loss: 0.00588\n",
      "\tval loss: 0.00578\n",
      "epoch 2049 / 20000\n",
      "gradient norm: 0.08383913789293729, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00587\n",
      "\tval loss: 0.00577\n",
      "epoch 2050 / 20000\n",
      "gradient norm: 0.04812711867270991, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00587\n",
      "\tval loss: 0.00576\n",
      "epoch 2051 / 20000\n",
      "gradient norm: 0.06864045810652897, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00587\n",
      "\tval loss: 0.00576\n",
      "epoch 2052 / 20000\n",
      "gradient norm: 0.08246207679621875, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00588\n",
      "\tval loss: 0.00576\n",
      "epoch 2053 / 20000\n",
      "gradient norm: 0.06776160403387621, minimum ratio: 2.507894736842105\n",
      "\ttrain loss: 0.00587\n",
      "\tval loss: 0.00577\n",
      "epoch 2054 / 20000\n",
      "gradient norm: 0.05446637778368313, minimum ratio: 2.5236842105263158\n",
      "\ttrain loss: 0.00588\n",
      "\tval loss: 0.00576\n",
      "epoch 2055 / 20000\n",
      "gradient norm: 0.04564985280740075, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00588\n",
      "\tval loss: 0.00575\n",
      "epoch 2056 / 20000\n",
      "gradient norm: 0.08857881964650005, minimum ratio: 2.518421052631579\n",
      "\ttrain loss: 0.00587\n",
      "\tval loss: 0.00576\n",
      "epoch 2057 / 20000\n",
      "gradient norm: 0.04781583044677973, minimum ratio: 2.494736842105263\n",
      "\ttrain loss: 0.00587\n",
      "\tval loss: 0.00577\n",
      "epoch 2058 / 20000\n",
      "gradient norm: 0.04127685402636416, minimum ratio: 2.4842105263157896\n",
      "\ttrain loss: 0.00588\n",
      "\tval loss: 0.00576\n",
      "epoch 2059 / 20000\n",
      "gradient norm: 0.09608854941325262, minimum ratio: 2.507894736842105\n",
      "\ttrain loss: 0.00587\n",
      "\tval loss: 0.00576\n",
      "epoch 2060 / 20000\n",
      "gradient norm: 0.05592592846369371, minimum ratio: 2.5210526315789474\n",
      "\ttrain loss: 0.00588\n",
      "\tval loss: 0.00577\n",
      "epoch 2061 / 20000\n",
      "gradient norm: 0.04740459116874263, minimum ratio: 2.5131578947368425\n",
      "\ttrain loss: 0.00587\n",
      "\tval loss: 0.00576\n",
      "epoch 2062 / 20000\n",
      "gradient norm: 0.07260162977036089, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00587\n",
      "\tval loss: 0.00576\n",
      "epoch 2063 / 20000\n",
      "gradient norm: 0.04810797452228144, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00588\n",
      "\tval loss: 0.00577\n",
      "epoch 2064 / 20000\n",
      "gradient norm: 0.0517236645828234, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00587\n",
      "\tval loss: 0.00577\n",
      "epoch 2065 / 20000\n",
      "gradient norm: 0.07262229126354214, minimum ratio: 2.5236842105263158\n",
      "\ttrain loss: 0.00588\n",
      "\tval loss: 0.00576\n",
      "epoch 2066 / 20000\n",
      "gradient norm: 0.06838967295334442, minimum ratio: 2.494736842105263\n",
      "\ttrain loss: 0.00588\n",
      "\tval loss: 0.00576\n",
      "epoch 2067 / 20000\n",
      "gradient norm: 0.05094491588533856, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00586\n",
      "\tval loss: 0.00576\n",
      "epoch 2068 / 20000\n",
      "gradient norm: 0.04510569659760222, minimum ratio: 2.5105263157894733\n",
      "\ttrain loss: 0.00588\n",
      "\tval loss: 0.00575\n",
      "epoch 2069 / 20000\n",
      "gradient norm: 0.10407754508196376, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00587\n",
      "\tval loss: 0.00576\n",
      "epoch 2070 / 20000\n",
      "gradient norm: 0.04892164681223221, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00586\n",
      "\tval loss: 0.00577\n",
      "epoch 2071 / 20000\n",
      "gradient norm: 0.1685488431248814, minimum ratio: 2.4894736842105267\n",
      "\ttrain loss: 0.00590\n",
      "\tval loss: 0.00575\n",
      "epoch 2072 / 20000\n",
      "gradient norm: 0.029078143823426217, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00587\n",
      "\tval loss: 0.00577\n",
      "epoch 2073 / 20000\n",
      "gradient norm: 0.05393384690978564, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.00588\n",
      "\tval loss: 0.00577\n",
      "epoch 2074 / 20000\n",
      "gradient norm: 0.059104809537529945, minimum ratio: 2.5131578947368425\n",
      "\ttrain loss: 0.00588\n",
      "\tval loss: 0.00575\n",
      "epoch 2075 / 20000\n",
      "gradient norm: 0.07072837930900278, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00588\n",
      "\tval loss: 0.00576\n",
      "epoch 2076 / 20000\n",
      "gradient norm: 0.03722374560311437, minimum ratio: 2.5131578947368425\n",
      "\ttrain loss: 0.00588\n",
      "\tval loss: 0.00576\n",
      "epoch 2077 / 20000\n",
      "gradient norm: 0.09422655453090556, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00587\n",
      "\tval loss: 0.00575\n",
      "epoch 2078 / 20000\n",
      "gradient norm: 0.11504403210710734, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00588\n",
      "\tval loss: 0.00576\n",
      "epoch 2079 / 20000\n",
      "gradient norm: 0.046939491701778024, minimum ratio: 2.5105263157894737\n",
      "\ttrain loss: 0.00585\n",
      "\tval loss: 0.00575\n",
      "epoch 2080 / 20000\n",
      "gradient norm: 0.10809578181942925, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00588\n",
      "\tval loss: 0.00575\n",
      "epoch 2081 / 20000\n",
      "gradient norm: 0.05224963692307938, minimum ratio: 2.4842105263157896\n",
      "\ttrain loss: 0.00586\n",
      "\tval loss: 0.00578\n",
      "epoch 2082 / 20000\n",
      "gradient norm: 0.09727285074768588, minimum ratio: 2.518421052631579\n",
      "\ttrain loss: 0.00590\n",
      "\tval loss: 0.00577\n",
      "epoch 2083 / 20000\n",
      "gradient norm: 0.07945174118503928, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00588\n",
      "\tval loss: 0.00575\n",
      "epoch 2084 / 20000\n",
      "gradient norm: 0.04745981976157054, minimum ratio: 2.492105263157895\n",
      "\ttrain loss: 0.00586\n",
      "\tval loss: 0.00576\n",
      "epoch 2085 / 20000\n",
      "gradient norm: 0.07228511216817424, minimum ratio: 2.5157894736842104\n",
      "\ttrain loss: 0.00588\n",
      "\tval loss: 0.00577\n",
      "epoch 2086 / 20000\n",
      "gradient norm: 0.07313356688246131, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00588\n",
      "\tval loss: 0.00576\n",
      "epoch 2087 / 20000\n",
      "gradient norm: 0.11079223064007238, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00590\n",
      "\tval loss: 0.00575\n",
      "epoch 2088 / 20000\n",
      "gradient norm: 0.0475869384536054, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00587\n",
      "\tval loss: 0.00577\n",
      "epoch 2089 / 20000\n",
      "gradient norm: 0.08777817667578347, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.00589\n",
      "\tval loss: 0.00578\n",
      "epoch 2090 / 20000\n",
      "gradient norm: 0.06380468256247696, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00588\n",
      "\tval loss: 0.00575\n",
      "epoch 2091 / 20000\n",
      "gradient norm: 0.0586446023080498, minimum ratio: 2.515789473684211\n",
      "\ttrain loss: 0.00588\n",
      "\tval loss: 0.00575\n",
      "epoch 2092 / 20000\n",
      "gradient norm: 0.055343679850921035, minimum ratio: 2.526315789473684\n",
      "\ttrain loss: 0.00587\n",
      "\tval loss: 0.00576\n",
      "epoch 2093 / 20000\n",
      "gradient norm: 0.05635163391707465, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00586\n",
      "\tval loss: 0.00578\n",
      "epoch 2094 / 20000\n",
      "gradient norm: 0.06358305760659277, minimum ratio: 2.513157894736842\n",
      "\ttrain loss: 0.00587\n",
      "\tval loss: 0.00575\n",
      "epoch 2095 / 20000\n",
      "gradient norm: 0.08787523384671658, minimum ratio: 2.5210526315789474\n",
      "\ttrain loss: 0.00587\n",
      "\tval loss: 0.00576\n",
      "epoch 2096 / 20000\n",
      "gradient norm: 0.04643464964465238, minimum ratio: 2.5210526315789474\n",
      "\ttrain loss: 0.00588\n",
      "\tval loss: 0.00575\n",
      "epoch 2097 / 20000\n",
      "gradient norm: 0.07991221628617495, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00589\n",
      "\tval loss: 0.00575\n",
      "epoch 2098 / 20000\n",
      "gradient norm: 0.020944511765264906, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00587\n",
      "\tval loss: 0.00576\n",
      "epoch 2099 / 20000\n",
      "gradient norm: 0.07971322939556558, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.00590\n",
      "\tval loss: 0.00575\n",
      "epoch 2100 / 20000\n",
      "gradient norm: 0.10211390662880149, minimum ratio: 2.518421052631579\n",
      "\ttrain loss: 0.00587\n",
      "\tval loss: 0.00576\n",
      "epoch 2101 / 20000\n",
      "gradient norm: 0.06405309354886413, minimum ratio: 2.518421052631579\n",
      "\ttrain loss: 0.00587\n",
      "\tval loss: 0.00576\n",
      "epoch 2102 / 20000\n",
      "gradient norm: 0.047461379697779194, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00586\n",
      "\tval loss: 0.00576\n",
      "epoch 2103 / 20000\n",
      "gradient norm: 0.10562144633149728, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00587\n",
      "\tval loss: 0.00575\n",
      "epoch 2104 / 20000\n",
      "gradient norm: 0.14425723266322166, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00588\n",
      "\tval loss: 0.00578\n",
      "epoch 2105 / 20000\n",
      "gradient norm: 0.05023376666213153, minimum ratio: 2.507894736842105\n",
      "\ttrain loss: 0.00587\n",
      "\tval loss: 0.00575\n",
      "epoch 2106 / 20000\n",
      "gradient norm: 0.09844679123489186, minimum ratio: 2.513157894736842\n",
      "\ttrain loss: 0.00587\n",
      "\tval loss: 0.00575\n",
      "epoch 2107 / 20000\n",
      "gradient norm: 0.04380564086022787, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00586\n",
      "\tval loss: 0.00577\n",
      "epoch 2108 / 20000\n",
      "gradient norm: 0.05660468083806336, minimum ratio: 2.513157894736842\n",
      "\ttrain loss: 0.00587\n",
      "\tval loss: 0.00576\n",
      "epoch 2109 / 20000\n",
      "gradient norm: 0.03534431947628036, minimum ratio: 2.5236842105263158\n",
      "\ttrain loss: 0.00587\n",
      "\tval loss: 0.00575\n",
      "epoch 2110 / 20000\n",
      "gradient norm: 0.06344172940589488, minimum ratio: 2.507894736842105\n",
      "\ttrain loss: 0.00586\n",
      "\tval loss: 0.00576\n",
      "epoch 2111 / 20000\n",
      "gradient norm: 0.07394584314897656, minimum ratio: 2.5078947368421054\n",
      "\ttrain loss: 0.00586\n",
      "\tval loss: 0.00576\n",
      "epoch 2112 / 20000\n",
      "gradient norm: 0.10354982429998927, minimum ratio: 2.518421052631579\n",
      "\ttrain loss: 0.00588\n",
      "\tval loss: 0.00575\n",
      "epoch 2113 / 20000\n",
      "gradient norm: 0.09215069038327783, minimum ratio: 2.5210526315789474\n",
      "\ttrain loss: 0.00589\n",
      "\tval loss: 0.00576\n",
      "epoch 2114 / 20000\n",
      "gradient norm: 0.06394225377880502, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00587\n",
      "\tval loss: 0.00576\n",
      "epoch 2115 / 20000\n",
      "gradient norm: 0.049421313538914546, minimum ratio: 2.4894736842105267\n",
      "\ttrain loss: 0.00587\n",
      "\tval loss: 0.00576\n",
      "epoch 2116 / 20000\n",
      "gradient norm: 0.04782253556186333, minimum ratio: 2.526315789473684\n",
      "\ttrain loss: 0.00587\n",
      "\tval loss: 0.00575\n",
      "epoch 2117 / 20000\n",
      "gradient norm: 0.056353298539761454, minimum ratio: 2.4894736842105267\n",
      "\ttrain loss: 0.00588\n",
      "\tval loss: 0.00575\n",
      "epoch 2118 / 20000\n",
      "gradient norm: 0.1186278443201445, minimum ratio: 2.5210526315789474\n",
      "\ttrain loss: 0.00587\n",
      "\tval loss: 0.00577\n",
      "epoch 2119 / 20000\n",
      "gradient norm: 0.042027962423162535, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00587\n",
      "\tval loss: 0.00575\n",
      "epoch 2120 / 20000\n",
      "gradient norm: 0.056263309641508386, minimum ratio: 2.513157894736842\n",
      "\ttrain loss: 0.00587\n",
      "\tval loss: 0.00575\n",
      "epoch 2121 / 20000\n",
      "gradient norm: 0.060868870496051386, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00587\n",
      "\tval loss: 0.00576\n",
      "epoch 2122 / 20000\n",
      "gradient norm: 0.05415653417003341, minimum ratio: 2.5394736842105265\n",
      "\ttrain loss: 0.00585\n",
      "\tval loss: 0.00577\n",
      "epoch 2123 / 20000\n",
      "gradient norm: 0.048108809016412124, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00586\n",
      "\tval loss: 0.00575\n",
      "epoch 2124 / 20000\n",
      "gradient norm: 0.08125512636615895, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00588\n",
      "\tval loss: 0.00575\n",
      "epoch 2125 / 20000\n",
      "gradient norm: 0.11234720586799085, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00586\n",
      "\tval loss: 0.00578\n",
      "epoch 2126 / 20000\n",
      "gradient norm: 0.05657957118819468, minimum ratio: 2.5078947368421054\n",
      "\ttrain loss: 0.00586\n",
      "\tval loss: 0.00575\n",
      "epoch 2127 / 20000\n",
      "gradient norm: 0.0748127878177911, minimum ratio: 2.505263157894737\n",
      "\ttrain loss: 0.00587\n",
      "\tval loss: 0.00575\n",
      "epoch 2128 / 20000\n",
      "gradient norm: 0.06970081976032816, minimum ratio: 2.513157894736842\n",
      "\ttrain loss: 0.00586\n",
      "\tval loss: 0.00577\n",
      "epoch 2129 / 20000\n",
      "gradient norm: 0.05261947767576203, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00587\n",
      "\tval loss: 0.00575\n",
      "epoch 2130 / 20000\n",
      "gradient norm: 0.08544829965103418, minimum ratio: 2.5342105263157895\n",
      "\ttrain loss: 0.00586\n",
      "\tval loss: 0.00575\n",
      "epoch 2131 / 20000\n",
      "gradient norm: 0.030216712249966804, minimum ratio: 2.507894736842105\n",
      "\ttrain loss: 0.00586\n",
      "\tval loss: 0.00575\n",
      "epoch 2132 / 20000\n",
      "gradient norm: 0.06593549269018695, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00587\n",
      "\tval loss: 0.00575\n",
      "epoch 2133 / 20000\n",
      "gradient norm: 0.125679477234371, minimum ratio: 2.505263157894737\n",
      "\ttrain loss: 0.00587\n",
      "\tval loss: 0.00576\n",
      "epoch 2134 / 20000\n",
      "gradient norm: 0.08222263010975439, minimum ratio: 2.518421052631579\n",
      "\ttrain loss: 0.00588\n",
      "\tval loss: 0.00574\n",
      "epoch 2135 / 20000\n",
      "gradient norm: 0.0704757408821024, minimum ratio: 2.5157894736842104\n",
      "\ttrain loss: 0.00586\n",
      "\tval loss: 0.00576\n",
      "epoch 2136 / 20000\n",
      "gradient norm: 0.07193765867850743, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00586\n",
      "\tval loss: 0.00576\n",
      "epoch 2137 / 20000\n",
      "gradient norm: 0.10999401955632493, minimum ratio: 2.528947368421053\n",
      "\ttrain loss: 0.00587\n",
      "\tval loss: 0.00574\n",
      "epoch 2138 / 20000\n",
      "gradient norm: 0.07368807937018573, minimum ratio: 2.5210526315789474\n",
      "\ttrain loss: 0.00586\n",
      "\tval loss: 0.00576\n",
      "epoch 2139 / 20000\n",
      "gradient norm: 0.03069275563757401, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00586\n",
      "\tval loss: 0.00575\n",
      "epoch 2140 / 20000\n",
      "gradient norm: 0.0853665873000864, minimum ratio: 2.5342105263157895\n",
      "\ttrain loss: 0.00586\n",
      "\tval loss: 0.00575\n",
      "epoch 2141 / 20000\n",
      "gradient norm: 0.07681755139492452, minimum ratio: 2.526315789473684\n",
      "\ttrain loss: 0.00587\n",
      "\tval loss: 0.00574\n",
      "epoch 2142 / 20000\n",
      "gradient norm: 0.06354563146305736, minimum ratio: 2.4842105263157896\n",
      "\ttrain loss: 0.00586\n",
      "\tval loss: 0.00576\n",
      "epoch 2143 / 20000\n",
      "gradient norm: 0.04121476567524951, minimum ratio: 2.518421052631579\n",
      "\ttrain loss: 0.00586\n",
      "\tval loss: 0.00576\n",
      "epoch 2144 / 20000\n",
      "gradient norm: 0.08467818447388709, minimum ratio: 2.521052631578947\n",
      "\ttrain loss: 0.00588\n",
      "\tval loss: 0.00574\n",
      "epoch 2145 / 20000\n",
      "gradient norm: 0.03647801715123933, minimum ratio: 2.521052631578947\n",
      "\ttrain loss: 0.00586\n",
      "\tval loss: 0.00575\n",
      "epoch 2146 / 20000\n",
      "gradient norm: 0.07100818240724038, minimum ratio: 2.5131578947368416\n",
      "\ttrain loss: 0.00587\n",
      "\tval loss: 0.00576\n",
      "epoch 2147 / 20000\n",
      "gradient norm: 0.07878475797770079, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00587\n",
      "\tval loss: 0.00574\n",
      "epoch 2148 / 20000\n",
      "gradient norm: 0.09081209800206125, minimum ratio: 2.5289473684210524\n",
      "\ttrain loss: 0.00587\n",
      "\tval loss: 0.00575\n",
      "epoch 2149 / 20000\n",
      "gradient norm: 0.06939353002235293, minimum ratio: 2.492105263157895\n",
      "\ttrain loss: 0.00586\n",
      "\tval loss: 0.00577\n",
      "epoch 2150 / 20000\n",
      "gradient norm: 0.04724602593341842, minimum ratio: 2.5184210526315787\n",
      "\ttrain loss: 0.00587\n",
      "\tval loss: 0.00574\n",
      "epoch 2151 / 20000\n",
      "gradient norm: 0.05652810103492811, minimum ratio: 2.515789473684211\n",
      "\ttrain loss: 0.00588\n",
      "\tval loss: 0.00574\n",
      "epoch 2152 / 20000\n",
      "gradient norm: 0.10022549342829734, minimum ratio: 2.507894736842105\n",
      "\ttrain loss: 0.00587\n",
      "\tval loss: 0.00577\n",
      "epoch 2153 / 20000\n",
      "gradient norm: 0.08787648507859558, minimum ratio: 2.5105263157894733\n",
      "\ttrain loss: 0.00586\n",
      "\tval loss: 0.00574\n",
      "epoch 2154 / 20000\n",
      "gradient norm: 0.11752853443613276, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00586\n",
      "\tval loss: 0.00574\n",
      "epoch 2155 / 20000\n",
      "gradient norm: 0.11764382873661816, minimum ratio: 2.526315789473684\n",
      "\ttrain loss: 0.00586\n",
      "\tval loss: 0.00577\n",
      "epoch 2156 / 20000\n",
      "gradient norm: 0.07767609728034586, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00587\n",
      "\tval loss: 0.00574\n",
      "epoch 2157 / 20000\n",
      "gradient norm: 0.06251151743344963, minimum ratio: 2.5289473684210524\n",
      "\ttrain loss: 0.00587\n",
      "\tval loss: 0.00574\n",
      "epoch 2158 / 20000\n",
      "gradient norm: 0.04066666084690951, minimum ratio: 2.5105263157894737\n",
      "\ttrain loss: 0.00586\n",
      "\tval loss: 0.00576\n",
      "epoch 2159 / 20000\n",
      "gradient norm: 0.07649496156955138, minimum ratio: 2.510526315789474\n",
      "\ttrain loss: 0.00587\n",
      "\tval loss: 0.00576\n",
      "epoch 2160 / 20000\n",
      "gradient norm: 0.03005228642723523, minimum ratio: 2.5236842105263158\n",
      "\ttrain loss: 0.00586\n",
      "\tval loss: 0.00574\n",
      "epoch 2161 / 20000\n",
      "gradient norm: 0.09778450231533498, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00587\n",
      "\tval loss: 0.00574\n",
      "epoch 2162 / 20000\n",
      "gradient norm: 0.04074741911608726, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00585\n",
      "\tval loss: 0.00576\n",
      "epoch 2163 / 20000\n",
      "gradient norm: 0.04363128438126296, minimum ratio: 2.5289473684210524\n",
      "\ttrain loss: 0.00586\n",
      "\tval loss: 0.00576\n",
      "epoch 2164 / 20000\n",
      "gradient norm: 0.06308951930259354, minimum ratio: 2.5236842105263158\n",
      "\ttrain loss: 0.00585\n",
      "\tval loss: 0.00574\n",
      "epoch 2165 / 20000\n",
      "gradient norm: 0.1211482531944057, minimum ratio: 2.5157894736842104\n",
      "\ttrain loss: 0.00586\n",
      "\tval loss: 0.00574\n",
      "epoch 2166 / 20000\n",
      "gradient norm: 0.08738514801370911, minimum ratio: 2.5131578947368425\n",
      "\ttrain loss: 0.00587\n",
      "\tval loss: 0.00574\n",
      "epoch 2167 / 20000\n",
      "gradient norm: 0.04162305174395442, minimum ratio: 2.513157894736842\n",
      "\ttrain loss: 0.00585\n",
      "\tval loss: 0.00576\n",
      "epoch 2168 / 20000\n",
      "gradient norm: 0.09336974762845784, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00588\n",
      "\tval loss: 0.00575\n",
      "epoch 2169 / 20000\n",
      "gradient norm: 0.11016037169611081, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00588\n",
      "\tval loss: 0.00574\n",
      "epoch 2170 / 20000\n",
      "gradient norm: 0.057114783296128735, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00586\n",
      "\tval loss: 0.00576\n",
      "epoch 2171 / 20000\n",
      "gradient norm: 0.141880449722521, minimum ratio: 2.5210526315789474\n",
      "\ttrain loss: 0.00585\n",
      "\tval loss: 0.00577\n",
      "epoch 2172 / 20000\n",
      "gradient norm: 0.09730643953662366, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00586\n",
      "\tval loss: 0.00574\n",
      "epoch 2173 / 20000\n",
      "gradient norm: 0.11740433843806386, minimum ratio: 2.5210526315789474\n",
      "\ttrain loss: 0.00587\n",
      "\tval loss: 0.00573\n",
      "epoch 2174 / 20000\n",
      "gradient norm: 0.056674005347304046, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00585\n",
      "\tval loss: 0.00575\n",
      "epoch 2175 / 20000\n",
      "gradient norm: 0.09637428080895916, minimum ratio: 2.4894736842105267\n",
      "\ttrain loss: 0.00587\n",
      "\tval loss: 0.00579\n",
      "epoch 2176 / 20000\n",
      "gradient norm: 0.06889706116635352, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00587\n",
      "\tval loss: 0.00574\n",
      "epoch 2177 / 20000\n",
      "gradient norm: 0.09815212452667765, minimum ratio: 2.513157894736842\n",
      "\ttrain loss: 0.00588\n",
      "\tval loss: 0.00573\n",
      "epoch 2178 / 20000\n",
      "gradient norm: 0.1158336898079142, minimum ratio: 2.507894736842105\n",
      "\ttrain loss: 0.00587\n",
      "\tval loss: 0.00578\n",
      "epoch 2179 / 20000\n",
      "gradient norm: 0.0790987130603753, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00587\n",
      "\tval loss: 0.00575\n",
      "epoch 2180 / 20000\n",
      "gradient norm: 0.08577243910985999, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00586\n",
      "\tval loss: 0.00573\n",
      "epoch 2181 / 20000\n",
      "gradient norm: 0.11060626432299614, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00588\n",
      "\tval loss: 0.00574\n",
      "epoch 2182 / 20000\n",
      "gradient norm: 0.08640099968761206, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.00585\n",
      "\tval loss: 0.00579\n",
      "epoch 2183 / 20000\n",
      "gradient norm: 0.13217710555181839, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00588\n",
      "\tval loss: 0.00573\n",
      "epoch 2184 / 20000\n",
      "gradient norm: 0.0495370902644936, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00586\n",
      "\tval loss: 0.00574\n",
      "epoch 2185 / 20000\n",
      "gradient norm: 0.046907000927603804, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00585\n",
      "\tval loss: 0.00575\n",
      "epoch 2186 / 20000\n",
      "gradient norm: 0.07034375099465251, minimum ratio: 2.4868421052631575\n",
      "\ttrain loss: 0.00586\n",
      "\tval loss: 0.00575\n",
      "epoch 2187 / 20000\n",
      "gradient norm: 0.11208629666361958, minimum ratio: 2.492105263157895\n",
      "\ttrain loss: 0.00586\n",
      "\tval loss: 0.00575\n",
      "epoch 2188 / 20000\n",
      "gradient norm: 0.09333610493922606, minimum ratio: 2.492105263157895\n",
      "\ttrain loss: 0.00588\n",
      "\tval loss: 0.00573\n",
      "epoch 2189 / 20000\n",
      "gradient norm: 0.05452851712470874, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00586\n",
      "\tval loss: 0.00576\n",
      "epoch 2190 / 20000\n",
      "gradient norm: 0.1044167426880449, minimum ratio: 2.513157894736842\n",
      "\ttrain loss: 0.00588\n",
      "\tval loss: 0.00575\n",
      "epoch 2191 / 20000\n",
      "gradient norm: 0.025182888231938705, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00587\n",
      "\tval loss: 0.00574\n",
      "epoch 2192 / 20000\n",
      "gradient norm: 0.0317634193925187, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00587\n",
      "\tval loss: 0.00574\n",
      "epoch 2193 / 20000\n",
      "gradient norm: 0.04948553076246753, minimum ratio: 2.513157894736842\n",
      "\ttrain loss: 0.00586\n",
      "\tval loss: 0.00575\n",
      "epoch 2194 / 20000\n",
      "gradient norm: 0.05245856166584417, minimum ratio: 2.5078947368421054\n",
      "\ttrain loss: 0.00586\n",
      "\tval loss: 0.00574\n",
      "epoch 2195 / 20000\n",
      "gradient norm: 0.05942574632354081, minimum ratio: 2.5105263157894737\n",
      "\ttrain loss: 0.00585\n",
      "\tval loss: 0.00574\n",
      "epoch 2196 / 20000\n",
      "gradient norm: 0.05665123004291672, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00586\n",
      "\tval loss: 0.00574\n",
      "epoch 2197 / 20000\n",
      "gradient norm: 0.05634276784257963, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00584\n",
      "\tval loss: 0.00574\n",
      "epoch 2198 / 20000\n",
      "gradient norm: 0.0669117634097347, minimum ratio: 2.5105263157894737\n",
      "\ttrain loss: 0.00586\n",
      "\tval loss: 0.00574\n",
      "epoch 2199 / 20000\n",
      "gradient norm: 0.06808671225735452, minimum ratio: 2.5184210526315787\n",
      "\ttrain loss: 0.00586\n",
      "\tval loss: 0.00575\n",
      "epoch 2200 / 20000\n",
      "gradient norm: 0.07201234604144702, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00588\n",
      "\tval loss: 0.00574\n",
      "epoch 2201 / 20000\n",
      "gradient norm: 0.0741447209729813, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00586\n",
      "\tval loss: 0.00575\n",
      "epoch 2202 / 20000\n",
      "gradient norm: 0.1298171507078223, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00587\n",
      "\tval loss: 0.00573\n",
      "epoch 2203 / 20000\n",
      "gradient norm: 0.0666115073254332, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00586\n",
      "\tval loss: 0.00575\n",
      "epoch 2204 / 20000\n",
      "gradient norm: 0.04010163591010496, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00586\n",
      "\tval loss: 0.00575\n",
      "epoch 2205 / 20000\n",
      "gradient norm: 0.06697640644415515, minimum ratio: 2.536842105263158\n",
      "\ttrain loss: 0.00585\n",
      "\tval loss: 0.00574\n",
      "epoch 2206 / 20000\n",
      "gradient norm: 0.06554736642283387, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00585\n",
      "\tval loss: 0.00574\n",
      "epoch 2207 / 20000\n",
      "gradient norm: 0.05805306660477072, minimum ratio: 2.5105263157894737\n",
      "\ttrain loss: 0.00585\n",
      "\tval loss: 0.00574\n",
      "epoch 2208 / 20000\n",
      "gradient norm: 0.0365267392116948, minimum ratio: 2.513157894736842\n",
      "\ttrain loss: 0.00586\n",
      "\tval loss: 0.00575\n",
      "epoch 2209 / 20000\n",
      "gradient norm: 0.05944535092567094, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00586\n",
      "\tval loss: 0.00574\n",
      "epoch 2210 / 20000\n",
      "gradient norm: 0.10025296348612756, minimum ratio: 2.492105263157895\n",
      "\ttrain loss: 0.00585\n",
      "\tval loss: 0.00573\n",
      "epoch 2211 / 20000\n",
      "gradient norm: 0.08376454329845728, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00586\n",
      "\tval loss: 0.00575\n",
      "epoch 2212 / 20000\n",
      "gradient norm: 0.040385440457612276, minimum ratio: 2.492105263157895\n",
      "\ttrain loss: 0.00586\n",
      "\tval loss: 0.00574\n",
      "epoch 2213 / 20000\n",
      "gradient norm: 0.08814123898628168, minimum ratio: 2.513157894736842\n",
      "\ttrain loss: 0.00585\n",
      "\tval loss: 0.00574\n",
      "epoch 2214 / 20000\n",
      "gradient norm: 0.08469673874787986, minimum ratio: 2.518421052631579\n",
      "\ttrain loss: 0.00586\n",
      "\tval loss: 0.00574\n",
      "epoch 2215 / 20000\n",
      "gradient norm: 0.02634463008143939, minimum ratio: 2.5236842105263158\n",
      "\ttrain loss: 0.00586\n",
      "\tval loss: 0.00574\n",
      "epoch 2216 / 20000\n",
      "gradient norm: 0.04405671308632009, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00585\n",
      "\tval loss: 0.00575\n",
      "epoch 2217 / 20000\n",
      "gradient norm: 0.07244963824632578, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00585\n",
      "\tval loss: 0.00574\n",
      "epoch 2218 / 20000\n",
      "gradient norm: 0.09824910026509315, minimum ratio: 2.492105263157895\n",
      "\ttrain loss: 0.00585\n",
      "\tval loss: 0.00573\n",
      "epoch 2219 / 20000\n",
      "gradient norm: 0.06652736471733078, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00586\n",
      "\tval loss: 0.00573\n",
      "epoch 2220 / 20000\n",
      "gradient norm: 0.044973655487410724, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00585\n",
      "\tval loss: 0.00575\n",
      "epoch 2221 / 20000\n",
      "gradient norm: 0.07539768819697201, minimum ratio: 2.5210526315789474\n",
      "\ttrain loss: 0.00585\n",
      "\tval loss: 0.00575\n",
      "epoch 2222 / 20000\n",
      "gradient norm: 0.09806437966472004, minimum ratio: 2.5078947368421054\n",
      "\ttrain loss: 0.00587\n",
      "\tval loss: 0.00573\n",
      "epoch 2223 / 20000\n",
      "gradient norm: 0.08414232631912455, minimum ratio: 2.494736842105263\n",
      "\ttrain loss: 0.00587\n",
      "\tval loss: 0.00574\n",
      "epoch 2224 / 20000\n",
      "gradient norm: 0.11736813187599182, minimum ratio: 2.513157894736842\n",
      "\ttrain loss: 0.00586\n",
      "\tval loss: 0.00575\n",
      "epoch 2225 / 20000\n",
      "gradient norm: 0.06632263136270922, minimum ratio: 2.4842105263157896\n",
      "\ttrain loss: 0.00586\n",
      "\tval loss: 0.00573\n",
      "epoch 2226 / 20000\n",
      "gradient norm: 0.03420946834376082, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00586\n",
      "\tval loss: 0.00574\n",
      "epoch 2227 / 20000\n",
      "gradient norm: 0.09693447721656412, minimum ratio: 2.513157894736842\n",
      "\ttrain loss: 0.00585\n",
      "\tval loss: 0.00575\n",
      "epoch 2228 / 20000\n",
      "gradient norm: 0.09837520413566381, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.00587\n",
      "\tval loss: 0.00573\n",
      "epoch 2229 / 20000\n",
      "gradient norm: 0.1128300589043647, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00585\n",
      "\tval loss: 0.00574\n",
      "epoch 2230 / 20000\n",
      "gradient norm: 0.10681251488858834, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00587\n",
      "\tval loss: 0.00573\n",
      "epoch 2231 / 20000\n",
      "gradient norm: 0.08768414138467051, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00586\n",
      "\tval loss: 0.00574\n",
      "epoch 2232 / 20000\n",
      "gradient norm: 0.0517874871584354, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.00586\n",
      "\tval loss: 0.00576\n",
      "epoch 2233 / 20000\n",
      "gradient norm: 0.07116800756193697, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00586\n",
      "\tval loss: 0.00573\n",
      "epoch 2234 / 20000\n",
      "gradient norm: 0.04330127142020501, minimum ratio: 2.5105263157894737\n",
      "\ttrain loss: 0.00586\n",
      "\tval loss: 0.00573\n",
      "epoch 2235 / 20000\n",
      "gradient norm: 0.13793151185382158, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00588\n",
      "\tval loss: 0.00574\n",
      "epoch 2236 / 20000\n",
      "gradient norm: 0.0328594162419904, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00586\n",
      "\tval loss: 0.00575\n",
      "epoch 2237 / 20000\n",
      "gradient norm: 0.103821204698761, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00587\n",
      "\tval loss: 0.00573\n",
      "epoch 2238 / 20000\n",
      "gradient norm: 0.08372437114303466, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00585\n",
      "\tval loss: 0.00575\n",
      "epoch 2239 / 20000\n",
      "gradient norm: 0.02789707730698865, minimum ratio: 2.5105263157894733\n",
      "\ttrain loss: 0.00586\n",
      "\tval loss: 0.00573\n",
      "epoch 2240 / 20000\n",
      "gradient norm: 0.050918430380988866, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00586\n",
      "\tval loss: 0.00573\n",
      "epoch 2241 / 20000\n",
      "gradient norm: 0.09528357756789774, minimum ratio: 2.518421052631579\n",
      "\ttrain loss: 0.00585\n",
      "\tval loss: 0.00574\n",
      "epoch 2242 / 20000\n",
      "gradient norm: 0.05095180243370123, minimum ratio: 2.5210526315789474\n",
      "\ttrain loss: 0.00585\n",
      "\tval loss: 0.00574\n",
      "epoch 2243 / 20000\n",
      "gradient norm: 0.056632256077136844, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00584\n",
      "\tval loss: 0.00573\n",
      "epoch 2244 / 20000\n",
      "gradient norm: 0.09380289823457133, minimum ratio: 2.518421052631579\n",
      "\ttrain loss: 0.00587\n",
      "\tval loss: 0.00573\n",
      "epoch 2245 / 20000\n",
      "gradient norm: 0.0691768566321116, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00585\n",
      "\tval loss: 0.00575\n",
      "epoch 2246 / 20000\n",
      "gradient norm: 0.050233543501235545, minimum ratio: 2.5157894736842104\n",
      "\ttrain loss: 0.00586\n",
      "\tval loss: 0.00574\n",
      "epoch 2247 / 20000\n",
      "gradient norm: 0.07628489240596537, minimum ratio: 2.4815789473684213\n",
      "\ttrain loss: 0.00585\n",
      "\tval loss: 0.00574\n",
      "epoch 2248 / 20000\n",
      "gradient norm: 0.0513826638343744, minimum ratio: 2.5026315789473688\n",
      "\ttrain loss: 0.00585\n",
      "\tval loss: 0.00573\n",
      "epoch 2249 / 20000\n",
      "gradient norm: 0.06412066228222102, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00586\n",
      "\tval loss: 0.00573\n",
      "epoch 2250 / 20000\n",
      "gradient norm: 0.06782782328082249, minimum ratio: 2.5157894736842104\n",
      "\ttrain loss: 0.00586\n",
      "\tval loss: 0.00574\n",
      "epoch 2251 / 20000\n",
      "gradient norm: 0.08555573492776603, minimum ratio: 2.5131578947368416\n",
      "\ttrain loss: 0.00585\n",
      "\tval loss: 0.00573\n",
      "epoch 2252 / 20000\n",
      "gradient norm: 0.11666110798250884, minimum ratio: 2.539473684210526\n",
      "\ttrain loss: 0.00585\n",
      "\tval loss: 0.00573\n",
      "epoch 2253 / 20000\n",
      "gradient norm: 0.08008707861881703, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00586\n",
      "\tval loss: 0.00574\n",
      "epoch 2254 / 20000\n",
      "gradient norm: 0.0903304576058872, minimum ratio: 2.5105263157894737\n",
      "\ttrain loss: 0.00585\n",
      "\tval loss: 0.00573\n",
      "epoch 2255 / 20000\n",
      "gradient norm: 0.09964677051175386, minimum ratio: 2.507894736842105\n",
      "\ttrain loss: 0.00585\n",
      "\tval loss: 0.00574\n",
      "epoch 2256 / 20000\n",
      "gradient norm: 0.02213846761151217, minimum ratio: 2.492105263157895\n",
      "\ttrain loss: 0.00584\n",
      "\tval loss: 0.00573\n",
      "epoch 2257 / 20000\n",
      "gradient norm: 0.12581068859435618, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00585\n",
      "\tval loss: 0.00573\n",
      "epoch 2258 / 20000\n",
      "gradient norm: 0.10892410296946764, minimum ratio: 2.5105263157894737\n",
      "\ttrain loss: 0.00585\n",
      "\tval loss: 0.00574\n",
      "epoch 2259 / 20000\n",
      "gradient norm: 0.056815407166141085, minimum ratio: 2.5105263157894737\n",
      "\ttrain loss: 0.00584\n",
      "\tval loss: 0.00573\n",
      "epoch 2260 / 20000\n",
      "gradient norm: 0.08462711388710886, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00585\n",
      "\tval loss: 0.00573\n",
      "epoch 2261 / 20000\n",
      "gradient norm: 0.10641555435722694, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00585\n",
      "\tval loss: 0.00574\n",
      "epoch 2262 / 20000\n",
      "gradient norm: 0.055405340863217134, minimum ratio: 2.507894736842105\n",
      "\ttrain loss: 0.00584\n",
      "\tval loss: 0.00572\n",
      "epoch 2263 / 20000\n",
      "gradient norm: 0.05010766308987513, minimum ratio: 2.515789473684211\n",
      "\ttrain loss: 0.00585\n",
      "\tval loss: 0.00573\n",
      "epoch 2264 / 20000\n",
      "gradient norm: 0.017157849069917575, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00585\n",
      "\tval loss: 0.00573\n",
      "epoch 2265 / 20000\n",
      "gradient norm: 0.11073378729633987, minimum ratio: 2.505263157894737\n",
      "\ttrain loss: 0.00586\n",
      "\tval loss: 0.00573\n",
      "epoch 2266 / 20000\n",
      "gradient norm: 0.08636302946251817, minimum ratio: 2.5078947368421054\n",
      "\ttrain loss: 0.00586\n",
      "\tval loss: 0.00572\n",
      "epoch 2267 / 20000\n",
      "gradient norm: 0.0683653331361711, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00586\n",
      "\tval loss: 0.00574\n",
      "epoch 2268 / 20000\n",
      "gradient norm: 0.09100185625720769, minimum ratio: 2.4868421052631584\n",
      "\ttrain loss: 0.00586\n",
      "\tval loss: 0.00574\n",
      "epoch 2269 / 20000\n",
      "gradient norm: 0.07759988667385187, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00584\n",
      "\tval loss: 0.00574\n",
      "epoch 2270 / 20000\n",
      "gradient norm: 0.03224187779414933, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00585\n",
      "\tval loss: 0.00573\n",
      "epoch 2271 / 20000\n",
      "gradient norm: 0.03942279703915119, minimum ratio: 2.492105263157895\n",
      "\ttrain loss: 0.00586\n",
      "\tval loss: 0.00573\n",
      "epoch 2272 / 20000\n",
      "gradient norm: 0.04828174723661505, minimum ratio: 2.5105263157894737\n",
      "\ttrain loss: 0.00585\n",
      "\tval loss: 0.00573\n",
      "epoch 2273 / 20000\n",
      "gradient norm: 0.04569202943821438, minimum ratio: 2.5078947368421054\n",
      "\ttrain loss: 0.00585\n",
      "\tval loss: 0.00574\n",
      "epoch 2274 / 20000\n",
      "gradient norm: 0.0958397586364299, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00583\n",
      "\tval loss: 0.00573\n",
      "epoch 2275 / 20000\n",
      "gradient norm: 0.06688210769789293, minimum ratio: 2.505263157894737\n",
      "\ttrain loss: 0.00585\n",
      "\tval loss: 0.00572\n",
      "epoch 2276 / 20000\n",
      "gradient norm: 0.07225398003356531, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00585\n",
      "\tval loss: 0.00573\n",
      "epoch 2277 / 20000\n",
      "gradient norm: 0.04839488002471626, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00586\n",
      "\tval loss: 0.00573\n",
      "epoch 2278 / 20000\n",
      "gradient norm: 0.04387813548964914, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00585\n",
      "\tval loss: 0.00573\n",
      "epoch 2279 / 20000\n",
      "gradient norm: 0.0943663373182062, minimum ratio: 2.5184210526315787\n",
      "\ttrain loss: 0.00585\n",
      "\tval loss: 0.00574\n",
      "epoch 2280 / 20000\n",
      "gradient norm: 0.07105529075488448, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00583\n",
      "\tval loss: 0.00572\n",
      "epoch 2281 / 20000\n",
      "gradient norm: 0.0723223311943002, minimum ratio: 2.515789473684211\n",
      "\ttrain loss: 0.00585\n",
      "\tval loss: 0.00572\n",
      "epoch 2282 / 20000\n",
      "gradient norm: 0.06514009356033057, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00584\n",
      "\tval loss: 0.00575\n",
      "epoch 2283 / 20000\n",
      "gradient norm: 0.09136245271656662, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00586\n",
      "\tval loss: 0.00573\n",
      "epoch 2284 / 20000\n",
      "gradient norm: 0.0829505150395562, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00585\n",
      "\tval loss: 0.00573\n",
      "epoch 2285 / 20000\n",
      "gradient norm: 0.039991837795241736, minimum ratio: 2.4815789473684213\n",
      "\ttrain loss: 0.00585\n",
      "\tval loss: 0.00573\n",
      "epoch 2286 / 20000\n",
      "gradient norm: 0.06380831924616359, minimum ratio: 2.513157894736842\n",
      "\ttrain loss: 0.00584\n",
      "\tval loss: 0.00573\n",
      "epoch 2287 / 20000\n",
      "gradient norm: 0.06628371542319655, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00585\n",
      "\tval loss: 0.00574\n",
      "epoch 2288 / 20000\n",
      "gradient norm: 0.038320409948937595, minimum ratio: 2.507894736842105\n",
      "\ttrain loss: 0.00583\n",
      "\tval loss: 0.00573\n",
      "epoch 2289 / 20000\n",
      "gradient norm: 0.05320295222918503, minimum ratio: 2.5078947368421054\n",
      "\ttrain loss: 0.00585\n",
      "\tval loss: 0.00572\n",
      "epoch 2290 / 20000\n",
      "gradient norm: 0.07374604512006044, minimum ratio: 2.5105263157894737\n",
      "\ttrain loss: 0.00585\n",
      "\tval loss: 0.00573\n",
      "epoch 2291 / 20000\n",
      "gradient norm: 0.04092414473416284, minimum ratio: 2.492105263157895\n",
      "\ttrain loss: 0.00585\n",
      "\tval loss: 0.00574\n",
      "epoch 2292 / 20000\n",
      "gradient norm: 0.11886885535204783, minimum ratio: 2.507894736842105\n",
      "\ttrain loss: 0.00585\n",
      "\tval loss: 0.00572\n",
      "epoch 2293 / 20000\n",
      "gradient norm: 0.02071652462473139, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00584\n",
      "\tval loss: 0.00574\n",
      "epoch 2294 / 20000\n",
      "gradient norm: 0.04188828753831331, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00585\n",
      "\tval loss: 0.00573\n",
      "epoch 2295 / 20000\n",
      "gradient norm: 0.1545827881200239, minimum ratio: 2.5105263157894733\n",
      "\ttrain loss: 0.00586\n",
      "\tval loss: 0.00572\n",
      "epoch 2296 / 20000\n",
      "gradient norm: 0.05431014331406914, minimum ratio: 2.531578947368421\n",
      "\ttrain loss: 0.00584\n",
      "\tval loss: 0.00573\n",
      "epoch 2297 / 20000\n",
      "gradient norm: 0.0491997396457009, minimum ratio: 2.513157894736842\n",
      "\ttrain loss: 0.00585\n",
      "\tval loss: 0.00574\n",
      "epoch 2298 / 20000\n",
      "gradient norm: 0.04075893829576671, minimum ratio: 2.5236842105263158\n",
      "\ttrain loss: 0.00584\n",
      "\tval loss: 0.00573\n",
      "epoch 2299 / 20000\n",
      "gradient norm: 0.03299123651959235, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00584\n",
      "\tval loss: 0.00572\n",
      "epoch 2300 / 20000\n",
      "gradient norm: 0.037923701747786254, minimum ratio: 2.507894736842105\n",
      "\ttrain loss: 0.00586\n",
      "\tval loss: 0.00573\n",
      "epoch 2301 / 20000\n",
      "gradient norm: 0.11114185419864953, minimum ratio: 2.536842105263158\n",
      "\ttrain loss: 0.00585\n",
      "\tval loss: 0.00573\n",
      "epoch 2302 / 20000\n",
      "gradient norm: 0.15113137755542994, minimum ratio: 2.5078947368421054\n",
      "\ttrain loss: 0.00589\n",
      "\tval loss: 0.00572\n",
      "epoch 2303 / 20000\n",
      "gradient norm: 0.04135459166718647, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00584\n",
      "\tval loss: 0.00574\n",
      "epoch 2304 / 20000\n",
      "gradient norm: 0.10611867188708857, minimum ratio: 2.5078947368421054\n",
      "\ttrain loss: 0.00586\n",
      "\tval loss: 0.00575\n",
      "epoch 2305 / 20000\n",
      "gradient norm: 0.07242113251413684, minimum ratio: 2.4868421052631584\n",
      "\ttrain loss: 0.00583\n",
      "\tval loss: 0.00572\n",
      "epoch 2306 / 20000\n",
      "gradient norm: 0.06951550912344828, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00585\n",
      "\tval loss: 0.00572\n",
      "epoch 2307 / 20000\n",
      "gradient norm: 0.027595307859883178, minimum ratio: 2.5078947368421054\n",
      "\ttrain loss: 0.00584\n",
      "\tval loss: 0.00574\n",
      "epoch 2308 / 20000\n",
      "gradient norm: 0.04827598118572496, minimum ratio: 2.5236842105263158\n",
      "\ttrain loss: 0.00585\n",
      "\tval loss: 0.00574\n",
      "epoch 2309 / 20000\n",
      "gradient norm: 0.06782164548349101, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00585\n",
      "\tval loss: 0.00572\n",
      "epoch 2310 / 20000\n",
      "gradient norm: 0.030159420624841005, minimum ratio: 2.518421052631579\n",
      "\ttrain loss: 0.00585\n",
      "\tval loss: 0.00572\n",
      "epoch 2311 / 20000\n",
      "gradient norm: 0.10314478387590498, minimum ratio: 2.526315789473684\n",
      "\ttrain loss: 0.00584\n",
      "\tval loss: 0.00574\n",
      "epoch 2312 / 20000\n",
      "gradient norm: 0.07110959268175066, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.00584\n",
      "\tval loss: 0.00572\n",
      "epoch 2313 / 20000\n",
      "gradient norm: 0.05424724787008017, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00585\n",
      "\tval loss: 0.00572\n",
      "epoch 2314 / 20000\n",
      "gradient norm: 0.08238473162055016, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00584\n",
      "\tval loss: 0.00574\n",
      "epoch 2315 / 20000\n",
      "gradient norm: 0.052451182797085494, minimum ratio: 2.494736842105263\n",
      "\ttrain loss: 0.00584\n",
      "\tval loss: 0.00572\n",
      "epoch 2316 / 20000\n",
      "gradient norm: 0.0345629195071524, minimum ratio: 2.513157894736842\n",
      "\ttrain loss: 0.00585\n",
      "\tval loss: 0.00572\n",
      "epoch 2317 / 20000\n",
      "gradient norm: 0.057622960601293016, minimum ratio: 2.507894736842105\n",
      "\ttrain loss: 0.00584\n",
      "\tval loss: 0.00572\n",
      "epoch 2318 / 20000\n",
      "gradient norm: 0.09728039987385273, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00585\n",
      "\tval loss: 0.00572\n",
      "epoch 2319 / 20000\n",
      "gradient norm: 0.09119996073422953, minimum ratio: 2.521052631578947\n",
      "\ttrain loss: 0.00585\n",
      "\tval loss: 0.00573\n",
      "epoch 2320 / 20000\n",
      "gradient norm: 0.10048229090170935, minimum ratio: 2.5157894736842104\n",
      "\ttrain loss: 0.00585\n",
      "\tval loss: 0.00572\n",
      "epoch 2321 / 20000\n",
      "gradient norm: 0.05784047837369144, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00585\n",
      "\tval loss: 0.00574\n",
      "epoch 2322 / 20000\n",
      "gradient norm: 0.13042670651338995, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00587\n",
      "\tval loss: 0.00572\n",
      "epoch 2323 / 20000\n",
      "gradient norm: 0.023181660304544494, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00585\n",
      "\tval loss: 0.00573\n",
      "epoch 2324 / 20000\n",
      "gradient norm: 0.09009098832029849, minimum ratio: 2.5078947368421054\n",
      "\ttrain loss: 0.00585\n",
      "\tval loss: 0.00574\n",
      "epoch 2325 / 20000\n",
      "gradient norm: 0.05328592218575068, minimum ratio: 2.5210526315789474\n",
      "\ttrain loss: 0.00585\n",
      "\tval loss: 0.00572\n",
      "epoch 2326 / 20000\n",
      "gradient norm: 0.08086768552311696, minimum ratio: 2.5210526315789474\n",
      "\ttrain loss: 0.00585\n",
      "\tval loss: 0.00572\n",
      "epoch 2327 / 20000\n",
      "gradient norm: 0.056727357587078586, minimum ratio: 2.513157894736842\n",
      "\ttrain loss: 0.00584\n",
      "\tval loss: 0.00575\n",
      "epoch 2328 / 20000\n",
      "gradient norm: 0.06154203764162958, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00585\n",
      "\tval loss: 0.00572\n",
      "epoch 2329 / 20000\n",
      "gradient norm: 0.12662280444055796, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00584\n",
      "\tval loss: 0.00572\n",
      "epoch 2330 / 20000\n",
      "gradient norm: 0.04483315696415957, minimum ratio: 2.5105263157894737\n",
      "\ttrain loss: 0.00584\n",
      "\tval loss: 0.00573\n",
      "epoch 2331 / 20000\n",
      "gradient norm: 0.06653502082917839, minimum ratio: 2.4868421052631584\n",
      "\ttrain loss: 0.00584\n",
      "\tval loss: 0.00573\n",
      "epoch 2332 / 20000\n",
      "gradient norm: 0.04867670906241983, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00585\n",
      "\tval loss: 0.00572\n",
      "epoch 2333 / 20000\n",
      "gradient norm: 0.02716736738511827, minimum ratio: 2.526315789473684\n",
      "\ttrain loss: 0.00585\n",
      "\tval loss: 0.00572\n",
      "epoch 2334 / 20000\n",
      "gradient norm: 0.04241759004071355, minimum ratio: 2.5105263157894737\n",
      "\ttrain loss: 0.00584\n",
      "\tval loss: 0.00573\n",
      "epoch 2335 / 20000\n",
      "gradient norm: 0.05170215730322525, minimum ratio: 2.526315789473684\n",
      "\ttrain loss: 0.00585\n",
      "\tval loss: 0.00572\n",
      "epoch 2336 / 20000\n",
      "gradient norm: 0.10105192646733485, minimum ratio: 2.5105263157894733\n",
      "\ttrain loss: 0.00584\n",
      "\tval loss: 0.00572\n",
      "epoch 2337 / 20000\n",
      "gradient norm: 0.038727272796677426, minimum ratio: 2.507894736842105\n",
      "\ttrain loss: 0.00585\n",
      "\tval loss: 0.00572\n",
      "epoch 2338 / 20000\n",
      "gradient norm: 0.030413383137783967, minimum ratio: 2.510526315789474\n",
      "\ttrain loss: 0.00585\n",
      "\tval loss: 0.00573\n",
      "epoch 2339 / 20000\n",
      "gradient norm: 0.06695224501891062, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00584\n",
      "\tval loss: 0.00572\n",
      "epoch 2340 / 20000\n",
      "gradient norm: 0.07301602780353278, minimum ratio: 2.5157894736842104\n",
      "\ttrain loss: 0.00585\n",
      "\tval loss: 0.00572\n",
      "epoch 2341 / 20000\n",
      "gradient norm: 0.05138985445955768, minimum ratio: 2.513157894736842\n",
      "\ttrain loss: 0.00584\n",
      "\tval loss: 0.00573\n",
      "epoch 2342 / 20000\n",
      "gradient norm: 0.060662697833322454, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00585\n",
      "\tval loss: 0.00572\n",
      "epoch 2343 / 20000\n",
      "gradient norm: 0.018677818472497165, minimum ratio: 2.528947368421053\n",
      "\ttrain loss: 0.00584\n",
      "\tval loss: 0.00572\n",
      "epoch 2344 / 20000\n",
      "gradient norm: 0.06781730835791677, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00585\n",
      "\tval loss: 0.00572\n",
      "epoch 2345 / 20000\n",
      "gradient norm: 0.10407517314888537, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00585\n",
      "\tval loss: 0.00573\n",
      "epoch 2346 / 20000\n",
      "gradient norm: 0.0510759670578409, minimum ratio: 2.510526315789474\n",
      "\ttrain loss: 0.00584\n",
      "\tval loss: 0.00572\n",
      "epoch 2347 / 20000\n",
      "gradient norm: 0.04897869494743645, minimum ratio: 2.526315789473684\n",
      "\ttrain loss: 0.00584\n",
      "\tval loss: 0.00571\n",
      "epoch 2348 / 20000\n",
      "gradient norm: 0.047920553712174296, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.00585\n",
      "\tval loss: 0.00572\n",
      "epoch 2349 / 20000\n",
      "gradient norm: 0.03953872268903069, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00584\n",
      "\tval loss: 0.00573\n",
      "epoch 2350 / 20000\n",
      "gradient norm: 0.0796321602538228, minimum ratio: 2.5236842105263158\n",
      "\ttrain loss: 0.00584\n",
      "\tval loss: 0.00572\n",
      "epoch 2351 / 20000\n",
      "gradient norm: 0.029639903848874383, minimum ratio: 2.507894736842105\n",
      "\ttrain loss: 0.00585\n",
      "\tval loss: 0.00572\n",
      "epoch 2352 / 20000\n",
      "gradient norm: 0.06392004276858643, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00585\n",
      "\tval loss: 0.00572\n",
      "epoch 2353 / 20000\n",
      "gradient norm: 0.08752685139188543, minimum ratio: 2.518421052631579\n",
      "\ttrain loss: 0.00584\n",
      "\tval loss: 0.00574\n",
      "epoch 2354 / 20000\n",
      "gradient norm: 0.12877833656966686, minimum ratio: 2.515789473684211\n",
      "\ttrain loss: 0.00587\n",
      "\tval loss: 0.00571\n",
      "epoch 2355 / 20000\n",
      "gradient norm: 0.09799573459895328, minimum ratio: 2.518421052631579\n",
      "\ttrain loss: 0.00584\n",
      "\tval loss: 0.00572\n",
      "epoch 2356 / 20000\n",
      "gradient norm: 0.038191032770555466, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00584\n",
      "\tval loss: 0.00573\n",
      "epoch 2357 / 20000\n",
      "gradient norm: 0.03862717348965816, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00585\n",
      "\tval loss: 0.00572\n",
      "epoch 2358 / 20000\n",
      "gradient norm: 0.07169010920915753, minimum ratio: 2.5236842105263158\n",
      "\ttrain loss: 0.00585\n",
      "\tval loss: 0.00572\n",
      "epoch 2359 / 20000\n",
      "gradient norm: 0.038571750235860236, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00583\n",
      "\tval loss: 0.00572\n",
      "epoch 2360 / 20000\n",
      "gradient norm: 0.04730648503755219, minimum ratio: 2.5157894736842104\n",
      "\ttrain loss: 0.00582\n",
      "\tval loss: 0.00572\n",
      "epoch 2361 / 20000\n",
      "gradient norm: 0.05660967147559859, minimum ratio: 2.5210526315789474\n",
      "\ttrain loss: 0.00584\n",
      "\tval loss: 0.00571\n",
      "epoch 2362 / 20000\n",
      "gradient norm: 0.08151728709344752, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00584\n",
      "\tval loss: 0.00573\n",
      "epoch 2363 / 20000\n",
      "gradient norm: 0.03889018204063177, minimum ratio: 2.5078947368421054\n",
      "\ttrain loss: 0.00583\n",
      "\tval loss: 0.00572\n",
      "epoch 2364 / 20000\n",
      "gradient norm: 0.060456834064098075, minimum ratio: 2.492105263157895\n",
      "\ttrain loss: 0.00583\n",
      "\tval loss: 0.00571\n",
      "epoch 2365 / 20000\n",
      "gradient norm: 0.02425048236909788, minimum ratio: 2.5210526315789474\n",
      "\ttrain loss: 0.00584\n",
      "\tval loss: 0.00572\n",
      "epoch 2366 / 20000\n",
      "gradient norm: 0.04015315984725021, minimum ratio: 2.507894736842105\n",
      "\ttrain loss: 0.00584\n",
      "\tval loss: 0.00573\n",
      "epoch 2367 / 20000\n",
      "gradient norm: 0.0503088983532507, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00585\n",
      "\tval loss: 0.00571\n",
      "epoch 2368 / 20000\n",
      "gradient norm: 0.08997960854321718, minimum ratio: 2.526315789473684\n",
      "\ttrain loss: 0.00584\n",
      "\tval loss: 0.00571\n",
      "epoch 2369 / 20000\n",
      "gradient norm: 0.07928452400665265, minimum ratio: 2.5342105263157895\n",
      "\ttrain loss: 0.00585\n",
      "\tval loss: 0.00573\n",
      "epoch 2370 / 20000\n",
      "gradient norm: 0.03717724203306716, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00585\n",
      "\tval loss: 0.00572\n",
      "epoch 2371 / 20000\n",
      "gradient norm: 0.05981024308130145, minimum ratio: 2.5105263157894737\n",
      "\ttrain loss: 0.00583\n",
      "\tval loss: 0.00571\n",
      "epoch 2372 / 20000\n",
      "gradient norm: 0.06820108549436554, minimum ratio: 2.5105263157894737\n",
      "\ttrain loss: 0.00583\n",
      "\tval loss: 0.00571\n",
      "epoch 2373 / 20000\n",
      "gradient norm: 0.05057050415780395, minimum ratio: 2.5342105263157895\n",
      "\ttrain loss: 0.00582\n",
      "\tval loss: 0.00572\n",
      "epoch 2374 / 20000\n",
      "gradient norm: 0.03676758732763119, minimum ratio: 2.513157894736842\n",
      "\ttrain loss: 0.00583\n",
      "\tval loss: 0.00572\n",
      "epoch 2375 / 20000\n",
      "gradient norm: 0.05215669405879453, minimum ratio: 2.5105263157894737\n",
      "\ttrain loss: 0.00583\n",
      "\tval loss: 0.00571\n",
      "epoch 2376 / 20000\n",
      "gradient norm: 0.11644418584182858, minimum ratio: 2.5105263157894733\n",
      "\ttrain loss: 0.00585\n",
      "\tval loss: 0.00571\n",
      "epoch 2377 / 20000\n",
      "gradient norm: 0.04438132495852187, minimum ratio: 2.5184210526315787\n",
      "\ttrain loss: 0.00585\n",
      "\tval loss: 0.00574\n",
      "epoch 2378 / 20000\n",
      "gradient norm: 0.06471124096424319, minimum ratio: 2.5210526315789474\n",
      "\ttrain loss: 0.00585\n",
      "\tval loss: 0.00572\n",
      "epoch 2379 / 20000\n",
      "gradient norm: 0.024762443281360902, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00583\n",
      "\tval loss: 0.00571\n",
      "epoch 2380 / 20000\n",
      "gradient norm: 0.08685638889437541, minimum ratio: 2.515789473684211\n",
      "\ttrain loss: 0.00585\n",
      "\tval loss: 0.00572\n",
      "epoch 2381 / 20000\n",
      "gradient norm: 0.04939415681292303, minimum ratio: 2.5342105263157895\n",
      "\ttrain loss: 0.00583\n",
      "\tval loss: 0.00571\n",
      "epoch 2382 / 20000\n",
      "gradient norm: 0.0708057057345286, minimum ratio: 2.4868421052631575\n",
      "\ttrain loss: 0.00584\n",
      "\tval loss: 0.00572\n",
      "epoch 2383 / 20000\n",
      "gradient norm: 0.0799884284788277, minimum ratio: 2.5394736842105265\n",
      "\ttrain loss: 0.00585\n",
      "\tval loss: 0.00571\n",
      "epoch 2384 / 20000\n",
      "gradient norm: 0.04453994166397024, minimum ratio: 2.5105263157894733\n",
      "\ttrain loss: 0.00583\n",
      "\tval loss: 0.00572\n",
      "epoch 2385 / 20000\n",
      "gradient norm: 0.0691162291332148, minimum ratio: 2.5342105263157895\n",
      "\ttrain loss: 0.00584\n",
      "\tval loss: 0.00572\n",
      "epoch 2386 / 20000\n",
      "gradient norm: 0.08848572615534067, minimum ratio: 2.5078947368421054\n",
      "\ttrain loss: 0.00584\n",
      "\tval loss: 0.00571\n",
      "epoch 2387 / 20000\n",
      "gradient norm: 0.10339562001172453, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00584\n",
      "\tval loss: 0.00571\n",
      "epoch 2388 / 20000\n",
      "gradient norm: 0.06566518900217488, minimum ratio: 2.507894736842105\n",
      "\ttrain loss: 0.00583\n",
      "\tval loss: 0.00574\n",
      "epoch 2389 / 20000\n",
      "gradient norm: 0.11000277037965134, minimum ratio: 2.5105263157894733\n",
      "\ttrain loss: 0.00584\n",
      "\tval loss: 0.00571\n",
      "epoch 2390 / 20000\n",
      "gradient norm: 0.09603462240193039, minimum ratio: 2.526315789473684\n",
      "\ttrain loss: 0.00585\n",
      "\tval loss: 0.00570\n",
      "epoch 2391 / 20000\n",
      "gradient norm: 0.07265939394710585, minimum ratio: 2.5210526315789474\n",
      "\ttrain loss: 0.00583\n",
      "\tval loss: 0.00573\n",
      "epoch 2392 / 20000\n",
      "gradient norm: 0.0689341431716457, minimum ratio: 2.5210526315789474\n",
      "\ttrain loss: 0.00585\n",
      "\tval loss: 0.00573\n",
      "epoch 2393 / 20000\n",
      "gradient norm: 0.10880454219295643, minimum ratio: 2.513157894736842\n",
      "\ttrain loss: 0.00584\n",
      "\tval loss: 0.00570\n",
      "epoch 2394 / 20000\n",
      "gradient norm: 0.04814909282140434, minimum ratio: 2.513157894736842\n",
      "\ttrain loss: 0.00584\n",
      "\tval loss: 0.00572\n",
      "epoch 2395 / 20000\n",
      "gradient norm: 0.06525985916960053, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00584\n",
      "\tval loss: 0.00573\n",
      "epoch 2396 / 20000\n",
      "gradient norm: 0.059692831011489034, minimum ratio: 2.5105263157894737\n",
      "\ttrain loss: 0.00583\n",
      "\tval loss: 0.00571\n",
      "epoch 2397 / 20000\n",
      "gradient norm: 0.059802690462674946, minimum ratio: 2.518421052631579\n",
      "\ttrain loss: 0.00584\n",
      "\tval loss: 0.00571\n",
      "epoch 2398 / 20000\n",
      "gradient norm: 0.06026529462542385, minimum ratio: 2.513157894736842\n",
      "\ttrain loss: 0.00583\n",
      "\tval loss: 0.00572\n",
      "epoch 2399 / 20000\n",
      "gradient norm: 0.09691704611759633, minimum ratio: 2.5236842105263158\n",
      "\ttrain loss: 0.00584\n",
      "\tval loss: 0.00572\n",
      "epoch 2400 / 20000\n",
      "gradient norm: 0.04073594411602244, minimum ratio: 2.5184210526315787\n",
      "\ttrain loss: 0.00583\n",
      "\tval loss: 0.00571\n",
      "epoch 2401 / 20000\n",
      "gradient norm: 0.05091876914957538, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00583\n",
      "\tval loss: 0.00571\n",
      "epoch 2402 / 20000\n",
      "gradient norm: 0.025330193107947707, minimum ratio: 2.5236842105263158\n",
      "\ttrain loss: 0.00583\n",
      "\tval loss: 0.00572\n",
      "epoch 2403 / 20000\n",
      "gradient norm: 0.041412786551518366, minimum ratio: 2.531578947368421\n",
      "\ttrain loss: 0.00583\n",
      "\tval loss: 0.00571\n",
      "epoch 2404 / 20000\n",
      "gradient norm: 0.0749650940997526, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00584\n",
      "\tval loss: 0.00572\n",
      "epoch 2405 / 20000\n",
      "gradient norm: 0.07555824032169767, minimum ratio: 2.507894736842105\n",
      "\ttrain loss: 0.00584\n",
      "\tval loss: 0.00570\n",
      "epoch 2406 / 20000\n",
      "gradient norm: 0.1214075597235933, minimum ratio: 2.5105263157894733\n",
      "\ttrain loss: 0.00583\n",
      "\tval loss: 0.00572\n",
      "epoch 2407 / 20000\n",
      "gradient norm: 0.08825896924827248, minimum ratio: 2.539473684210526\n",
      "\ttrain loss: 0.00584\n",
      "\tval loss: 0.00573\n",
      "epoch 2408 / 20000\n",
      "gradient norm: 0.03482593010994606, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00583\n",
      "\tval loss: 0.00571\n",
      "epoch 2409 / 20000\n",
      "gradient norm: 0.08692498790333048, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00582\n",
      "\tval loss: 0.00570\n",
      "epoch 2410 / 20000\n",
      "gradient norm: 0.026017377618700266, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00583\n",
      "\tval loss: 0.00571\n",
      "epoch 2411 / 20000\n",
      "gradient norm: 0.11905282724183053, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00585\n",
      "\tval loss: 0.00573\n",
      "epoch 2412 / 20000\n",
      "gradient norm: 0.0552069780533202, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.00584\n",
      "\tval loss: 0.00570\n",
      "epoch 2413 / 20000\n",
      "gradient norm: 0.08233490222482942, minimum ratio: 2.5105263157894737\n",
      "\ttrain loss: 0.00585\n",
      "\tval loss: 0.00570\n",
      "epoch 2414 / 20000\n",
      "gradient norm: 0.07560055988142267, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00583\n",
      "\tval loss: 0.00573\n",
      "epoch 2415 / 20000\n",
      "gradient norm: 0.059994421317242086, minimum ratio: 2.5078947368421054\n",
      "\ttrain loss: 0.00584\n",
      "\tval loss: 0.00572\n",
      "epoch 2416 / 20000\n",
      "gradient norm: 0.04858321859501302, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00582\n",
      "\tval loss: 0.00571\n",
      "epoch 2417 / 20000\n",
      "gradient norm: 0.08824647002620623, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00584\n",
      "\tval loss: 0.00571\n",
      "epoch 2418 / 20000\n",
      "gradient norm: 0.07732868083985522, minimum ratio: 2.5289473684210524\n",
      "\ttrain loss: 0.00584\n",
      "\tval loss: 0.00571\n",
      "epoch 2419 / 20000\n",
      "gradient norm: 0.0718175366637297, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00583\n",
      "\tval loss: 0.00573\n",
      "epoch 2420 / 20000\n",
      "gradient norm: 0.02921312375110574, minimum ratio: 2.5236842105263158\n",
      "\ttrain loss: 0.00582\n",
      "\tval loss: 0.00571\n",
      "epoch 2421 / 20000\n",
      "gradient norm: 0.0488965786062181, minimum ratio: 2.5131578947368425\n",
      "\ttrain loss: 0.00583\n",
      "\tval loss: 0.00570\n",
      "epoch 2422 / 20000\n",
      "gradient norm: 0.02245300740469247, minimum ratio: 2.513157894736842\n",
      "\ttrain loss: 0.00583\n",
      "\tval loss: 0.00572\n",
      "epoch 2423 / 20000\n",
      "gradient norm: 0.030553586344467476, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00583\n",
      "\tval loss: 0.00572\n",
      "epoch 2424 / 20000\n",
      "gradient norm: 0.038602598491706885, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00583\n",
      "\tval loss: 0.00571\n",
      "epoch 2425 / 20000\n",
      "gradient norm: 0.04266794287832454, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00583\n",
      "\tval loss: 0.00571\n",
      "epoch 2426 / 20000\n",
      "gradient norm: 0.036147134262137115, minimum ratio: 2.5105263157894733\n",
      "\ttrain loss: 0.00584\n",
      "\tval loss: 0.00571\n",
      "epoch 2427 / 20000\n",
      "gradient norm: 0.0758755516144447, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00584\n",
      "\tval loss: 0.00570\n",
      "epoch 2428 / 20000\n",
      "gradient norm: 0.06333387132326607, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00583\n",
      "\tval loss: 0.00573\n",
      "epoch 2429 / 20000\n",
      "gradient norm: 0.046422840241575614, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00583\n",
      "\tval loss: 0.00571\n",
      "epoch 2430 / 20000\n",
      "gradient norm: 0.045352729386650026, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00583\n",
      "\tval loss: 0.00571\n",
      "epoch 2431 / 20000\n",
      "gradient norm: 0.031129207782214507, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00581\n",
      "\tval loss: 0.00571\n",
      "epoch 2432 / 20000\n",
      "gradient norm: 0.07516118453349918, minimum ratio: 2.513157894736842\n",
      "\ttrain loss: 0.00582\n",
      "\tval loss: 0.00571\n",
      "epoch 2433 / 20000\n",
      "gradient norm: 0.07949788949918002, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00583\n",
      "\tval loss: 0.00571\n",
      "epoch 2434 / 20000\n",
      "gradient norm: 0.06073590449523181, minimum ratio: 2.5184210526315787\n",
      "\ttrain loss: 0.00585\n",
      "\tval loss: 0.00570\n",
      "epoch 2435 / 20000\n",
      "gradient norm: 0.11251610633917153, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00584\n",
      "\tval loss: 0.00571\n",
      "epoch 2436 / 20000\n",
      "gradient norm: 0.09630471980199218, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00584\n",
      "\tval loss: 0.00574\n",
      "epoch 2437 / 20000\n",
      "gradient norm: 0.12257556739496067, minimum ratio: 2.513157894736842\n",
      "\ttrain loss: 0.00585\n",
      "\tval loss: 0.00570\n",
      "epoch 2438 / 20000\n",
      "gradient norm: 0.05112264241324738, minimum ratio: 2.5368421052631582\n",
      "\ttrain loss: 0.00584\n",
      "\tval loss: 0.00571\n",
      "epoch 2439 / 20000\n",
      "gradient norm: 0.08666953246574849, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00584\n",
      "\tval loss: 0.00573\n",
      "epoch 2440 / 20000\n",
      "gradient norm: 0.09540009166812524, minimum ratio: 2.507894736842105\n",
      "\ttrain loss: 0.00584\n",
      "\tval loss: 0.00572\n",
      "epoch 2441 / 20000\n",
      "gradient norm: 0.13163264084141701, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00586\n",
      "\tval loss: 0.00570\n",
      "epoch 2442 / 20000\n",
      "gradient norm: 0.0708031304529868, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00585\n",
      "\tval loss: 0.00573\n",
      "epoch 2443 / 20000\n",
      "gradient norm: 0.07597703055944294, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00584\n",
      "\tval loss: 0.00572\n",
      "epoch 2444 / 20000\n",
      "gradient norm: 0.06955279014073312, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00583\n",
      "\tval loss: 0.00570\n",
      "epoch 2445 / 20000\n",
      "gradient norm: 0.06568018606049009, minimum ratio: 2.5078947368421054\n",
      "\ttrain loss: 0.00583\n",
      "\tval loss: 0.00570\n",
      "epoch 2446 / 20000\n",
      "gradient norm: 0.1044237309251912, minimum ratio: 2.518421052631579\n",
      "\ttrain loss: 0.00584\n",
      "\tval loss: 0.00574\n",
      "epoch 2447 / 20000\n",
      "gradient norm: 0.046121844003209844, minimum ratio: 2.5105263157894737\n",
      "\ttrain loss: 0.00583\n",
      "\tval loss: 0.00570\n",
      "epoch 2448 / 20000\n",
      "gradient norm: 0.06483287166338414, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00585\n",
      "\tval loss: 0.00570\n",
      "epoch 2449 / 20000\n",
      "gradient norm: 0.07938251312589273, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00584\n",
      "\tval loss: 0.00572\n",
      "epoch 2450 / 20000\n",
      "gradient norm: 0.07459357881452888, minimum ratio: 2.5105263157894733\n",
      "\ttrain loss: 0.00583\n",
      "\tval loss: 0.00571\n",
      "epoch 2451 / 20000\n",
      "gradient norm: 0.07381051225820556, minimum ratio: 2.5157894736842104\n",
      "\ttrain loss: 0.00582\n",
      "\tval loss: 0.00571\n",
      "epoch 2452 / 20000\n",
      "gradient norm: 0.07565752006485127, minimum ratio: 2.5210526315789474\n",
      "\ttrain loss: 0.00585\n",
      "\tval loss: 0.00570\n",
      "epoch 2453 / 20000\n",
      "gradient norm: 0.04373857160680927, minimum ratio: 2.4868421052631575\n",
      "\ttrain loss: 0.00583\n",
      "\tval loss: 0.00571\n",
      "epoch 2454 / 20000\n",
      "gradient norm: 0.06892499123932794, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00581\n",
      "\tval loss: 0.00571\n",
      "epoch 2455 / 20000\n",
      "gradient norm: 0.07618985569570214, minimum ratio: 2.4894736842105267\n",
      "\ttrain loss: 0.00582\n",
      "\tval loss: 0.00570\n",
      "epoch 2456 / 20000\n",
      "gradient norm: 0.09093566588126123, minimum ratio: 2.507894736842105\n",
      "\ttrain loss: 0.00584\n",
      "\tval loss: 0.00572\n",
      "epoch 2457 / 20000\n",
      "gradient norm: 0.04789330088533461, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00583\n",
      "\tval loss: 0.00571\n",
      "epoch 2458 / 20000\n",
      "gradient norm: 0.053850058451644145, minimum ratio: 2.507894736842105\n",
      "\ttrain loss: 0.00582\n",
      "\tval loss: 0.00570\n",
      "epoch 2459 / 20000\n",
      "gradient norm: 0.03588378621498123, minimum ratio: 2.5105263157894737\n",
      "\ttrain loss: 0.00583\n",
      "\tval loss: 0.00571\n",
      "epoch 2460 / 20000\n",
      "gradient norm: 0.07306365430122241, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00583\n",
      "\tval loss: 0.00570\n",
      "epoch 2461 / 20000\n",
      "gradient norm: 0.07072133288602345, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00583\n",
      "\tval loss: 0.00572\n",
      "epoch 2462 / 20000\n",
      "gradient norm: 0.0499609002872603, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00583\n",
      "\tval loss: 0.00570\n",
      "epoch 2463 / 20000\n",
      "gradient norm: 0.08183907408965752, minimum ratio: 2.5157894736842104\n",
      "\ttrain loss: 0.00583\n",
      "\tval loss: 0.00570\n",
      "epoch 2464 / 20000\n",
      "gradient norm: 0.034383138932753354, minimum ratio: 2.5105263157894733\n",
      "\ttrain loss: 0.00582\n",
      "\tval loss: 0.00571\n",
      "epoch 2465 / 20000\n",
      "gradient norm: 0.04824170027859509, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00582\n",
      "\tval loss: 0.00570\n",
      "epoch 2466 / 20000\n",
      "gradient norm: 0.09632003522710875, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00582\n",
      "\tval loss: 0.00571\n",
      "epoch 2467 / 20000\n",
      "gradient norm: 0.05293281901685987, minimum ratio: 2.526315789473684\n",
      "\ttrain loss: 0.00583\n",
      "\tval loss: 0.00570\n",
      "epoch 2468 / 20000\n",
      "gradient norm: 0.06917418178636581, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00582\n",
      "\tval loss: 0.00570\n",
      "epoch 2469 / 20000\n",
      "gradient norm: 0.055416322546079755, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00582\n",
      "\tval loss: 0.00571\n",
      "epoch 2470 / 20000\n",
      "gradient norm: 0.07549534871941432, minimum ratio: 2.515789473684211\n",
      "\ttrain loss: 0.00583\n",
      "\tval loss: 0.00570\n",
      "epoch 2471 / 20000\n",
      "gradient norm: 0.10633852239698172, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00583\n",
      "\tval loss: 0.00571\n",
      "epoch 2472 / 20000\n",
      "gradient norm: 0.05882503330940381, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00582\n",
      "\tval loss: 0.00569\n",
      "epoch 2473 / 20000\n",
      "gradient norm: 0.03331521607469767, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00584\n",
      "\tval loss: 0.00570\n",
      "epoch 2474 / 20000\n",
      "gradient norm: 0.124629947822541, minimum ratio: 2.507894736842105\n",
      "\ttrain loss: 0.00583\n",
      "\tval loss: 0.00572\n",
      "epoch 2475 / 20000\n",
      "gradient norm: 0.08548108924878761, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00584\n",
      "\tval loss: 0.00570\n",
      "epoch 2476 / 20000\n",
      "gradient norm: 0.07835575408535078, minimum ratio: 2.5236842105263158\n",
      "\ttrain loss: 0.00582\n",
      "\tval loss: 0.00570\n",
      "epoch 2477 / 20000\n",
      "gradient norm: 0.05207685327332001, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00582\n",
      "\tval loss: 0.00570\n",
      "epoch 2478 / 20000\n",
      "gradient norm: 0.025107326764555182, minimum ratio: 2.507894736842105\n",
      "\ttrain loss: 0.00583\n",
      "\tval loss: 0.00571\n",
      "epoch 2479 / 20000\n",
      "gradient norm: 0.07969460566528141, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00582\n",
      "\tval loss: 0.00571\n",
      "epoch 2480 / 20000\n",
      "gradient norm: 0.017700381220493, minimum ratio: 2.528947368421053\n",
      "\ttrain loss: 0.00583\n",
      "\tval loss: 0.00570\n",
      "epoch 2481 / 20000\n",
      "gradient norm: 0.06750897545134649, minimum ratio: 2.5210526315789474\n",
      "\ttrain loss: 0.00583\n",
      "\tval loss: 0.00570\n",
      "epoch 2482 / 20000\n",
      "gradient norm: 0.05303664191160351, minimum ratio: 2.5105263157894737\n",
      "\ttrain loss: 0.00581\n",
      "\tval loss: 0.00570\n",
      "epoch 2483 / 20000\n",
      "gradient norm: 0.04437262305873446, minimum ratio: 2.5078947368421054\n",
      "\ttrain loss: 0.00582\n",
      "\tval loss: 0.00570\n",
      "epoch 2484 / 20000\n",
      "gradient norm: 0.04010485022445209, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00583\n",
      "\tval loss: 0.00570\n",
      "epoch 2485 / 20000\n",
      "gradient norm: 0.10444538504816592, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00583\n",
      "\tval loss: 0.00571\n",
      "epoch 2486 / 20000\n",
      "gradient norm: 0.08567089471034706, minimum ratio: 2.5289473684210524\n",
      "\ttrain loss: 0.00582\n",
      "\tval loss: 0.00570\n",
      "epoch 2487 / 20000\n",
      "gradient norm: 0.07579591608373448, minimum ratio: 2.5315789473684207\n",
      "\ttrain loss: 0.00583\n",
      "\tval loss: 0.00570\n",
      "epoch 2488 / 20000\n",
      "gradient norm: 0.049841119383927435, minimum ratio: 2.5210526315789474\n",
      "\ttrain loss: 0.00583\n",
      "\tval loss: 0.00571\n",
      "epoch 2489 / 20000\n",
      "gradient norm: 0.0508614125137683, minimum ratio: 2.513157894736842\n",
      "\ttrain loss: 0.00582\n",
      "\tval loss: 0.00571\n",
      "epoch 2490 / 20000\n",
      "gradient norm: 0.10760175331961364, minimum ratio: 2.5342105263157895\n",
      "\ttrain loss: 0.00583\n",
      "\tval loss: 0.00569\n",
      "epoch 2491 / 20000\n",
      "gradient norm: 0.06083141692215577, minimum ratio: 2.531578947368421\n",
      "\ttrain loss: 0.00584\n",
      "\tval loss: 0.00570\n",
      "epoch 2492 / 20000\n",
      "gradient norm: 0.04979506420204416, minimum ratio: 2.5157894736842104\n",
      "\ttrain loss: 0.00582\n",
      "\tval loss: 0.00572\n",
      "epoch 2493 / 20000\n",
      "gradient norm: 0.07550436537712812, minimum ratio: 2.5105263157894737\n",
      "\ttrain loss: 0.00582\n",
      "\tval loss: 0.00571\n",
      "epoch 2494 / 20000\n",
      "gradient norm: 0.11898187987389974, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00581\n",
      "\tval loss: 0.00570\n",
      "epoch 2495 / 20000\n",
      "gradient norm: 0.10589839657768607, minimum ratio: 2.526315789473684\n",
      "\ttrain loss: 0.00584\n",
      "\tval loss: 0.00570\n",
      "epoch 2496 / 20000\n",
      "gradient norm: 0.03761904127895832, minimum ratio: 2.5184210526315787\n",
      "\ttrain loss: 0.00582\n",
      "\tval loss: 0.00570\n",
      "epoch 2497 / 20000\n",
      "gradient norm: 0.02373178134439513, minimum ratio: 2.513157894736842\n",
      "\ttrain loss: 0.00582\n",
      "\tval loss: 0.00570\n",
      "epoch 2498 / 20000\n",
      "gradient norm: 0.035173216136172414, minimum ratio: 2.5236842105263158\n",
      "\ttrain loss: 0.00583\n",
      "\tval loss: 0.00570\n",
      "epoch 2499 / 20000\n",
      "gradient norm: 0.027841367045766674, minimum ratio: 2.507894736842105\n",
      "\ttrain loss: 0.00582\n",
      "\tval loss: 0.00570\n",
      "epoch 2500 / 20000\n",
      "gradient norm: 0.043727832788135856, minimum ratio: 2.518421052631579\n",
      "\ttrain loss: 0.00583\n",
      "\tval loss: 0.00570\n",
      "epoch 2501 / 20000\n",
      "gradient norm: 0.08394947700435296, minimum ratio: 2.5236842105263158\n",
      "\ttrain loss: 0.00582\n",
      "\tval loss: 0.00571\n",
      "epoch 2502 / 20000\n",
      "gradient norm: 0.04510825951001607, minimum ratio: 2.5289473684210524\n",
      "\ttrain loss: 0.00582\n",
      "\tval loss: 0.00570\n",
      "epoch 2503 / 20000\n",
      "gradient norm: 0.08300439838785678, minimum ratio: 2.5210526315789474\n",
      "\ttrain loss: 0.00582\n",
      "\tval loss: 0.00569\n",
      "epoch 2504 / 20000\n",
      "gradient norm: 0.10948766639921814, minimum ratio: 2.5236842105263158\n",
      "\ttrain loss: 0.00582\n",
      "\tval loss: 0.00571\n",
      "epoch 2505 / 20000\n",
      "gradient norm: 0.0581112191430293, minimum ratio: 2.518421052631579\n",
      "\ttrain loss: 0.00582\n",
      "\tval loss: 0.00570\n",
      "epoch 2506 / 20000\n",
      "gradient norm: 0.07904576106375316, minimum ratio: 2.526315789473684\n",
      "\ttrain loss: 0.00582\n",
      "\tval loss: 0.00569\n",
      "epoch 2507 / 20000\n",
      "gradient norm: 0.13572525593917817, minimum ratio: 2.492105263157895\n",
      "\ttrain loss: 0.00583\n",
      "\tval loss: 0.00569\n",
      "epoch 2508 / 20000\n",
      "gradient norm: 0.04949830565601587, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00582\n",
      "\tval loss: 0.00571\n",
      "epoch 2509 / 20000\n",
      "gradient norm: 0.09654742071870714, minimum ratio: 2.5184210526315787\n",
      "\ttrain loss: 0.00583\n",
      "\tval loss: 0.00570\n",
      "epoch 2510 / 20000\n",
      "gradient norm: 0.04746744273870718, minimum ratio: 2.534210526315789\n",
      "\ttrain loss: 0.00583\n",
      "\tval loss: 0.00570\n",
      "epoch 2511 / 20000\n",
      "gradient norm: 0.0332898213819135, minimum ratio: 2.526315789473684\n",
      "\ttrain loss: 0.00581\n",
      "\tval loss: 0.00569\n",
      "epoch 2512 / 20000\n",
      "gradient norm: 0.1045110222621588, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00583\n",
      "\tval loss: 0.00570\n",
      "epoch 2513 / 20000\n",
      "gradient norm: 0.057762684038607404, minimum ratio: 2.5315789473684207\n",
      "\ttrain loss: 0.00583\n",
      "\tval loss: 0.00571\n",
      "epoch 2514 / 20000\n",
      "gradient norm: 0.07795785664347932, minimum ratio: 2.513157894736842\n",
      "\ttrain loss: 0.00582\n",
      "\tval loss: 0.00570\n",
      "epoch 2515 / 20000\n",
      "gradient norm: 0.05218078079633415, minimum ratio: 2.5105263157894737\n",
      "\ttrain loss: 0.00581\n",
      "\tval loss: 0.00569\n",
      "epoch 2516 / 20000\n",
      "gradient norm: 0.043950938183115795, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00583\n",
      "\tval loss: 0.00570\n",
      "epoch 2517 / 20000\n",
      "gradient norm: 0.025854985433397815, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00580\n",
      "\tval loss: 0.00571\n",
      "epoch 2518 / 20000\n",
      "gradient norm: 0.06150731910020113, minimum ratio: 2.526315789473684\n",
      "\ttrain loss: 0.00581\n",
      "\tval loss: 0.00570\n",
      "epoch 2519 / 20000\n",
      "gradient norm: 0.0718288102070801, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00582\n",
      "\tval loss: 0.00569\n",
      "epoch 2520 / 20000\n",
      "gradient norm: 0.07968433265341446, minimum ratio: 2.5210526315789474\n",
      "\ttrain loss: 0.00582\n",
      "\tval loss: 0.00571\n",
      "epoch 2521 / 20000\n",
      "gradient norm: 0.05344121315283701, minimum ratio: 2.513157894736842\n",
      "\ttrain loss: 0.00582\n",
      "\tval loss: 0.00569\n",
      "epoch 2522 / 20000\n",
      "gradient norm: 0.11937999495421536, minimum ratio: 2.5289473684210524\n",
      "\ttrain loss: 0.00584\n",
      "\tval loss: 0.00569\n",
      "epoch 2523 / 20000\n",
      "gradient norm: 0.07157367980107665, minimum ratio: 2.5342105263157895\n",
      "\ttrain loss: 0.00582\n",
      "\tval loss: 0.00571\n",
      "epoch 2524 / 20000\n",
      "gradient norm: 0.08073946757940575, minimum ratio: 2.513157894736842\n",
      "\ttrain loss: 0.00584\n",
      "\tval loss: 0.00572\n",
      "epoch 2525 / 20000\n",
      "gradient norm: 0.08351571339881048, minimum ratio: 2.5131578947368425\n",
      "\ttrain loss: 0.00583\n",
      "\tval loss: 0.00569\n",
      "epoch 2526 / 20000\n",
      "gradient norm: 0.06458023042068817, minimum ratio: 2.515789473684211\n",
      "\ttrain loss: 0.00584\n",
      "\tval loss: 0.00569\n",
      "epoch 2527 / 20000\n",
      "gradient norm: 0.10609143285546452, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00584\n",
      "\tval loss: 0.00573\n",
      "epoch 2528 / 20000\n",
      "gradient norm: 0.05640464325551875, minimum ratio: 2.5210526315789474\n",
      "\ttrain loss: 0.00583\n",
      "\tval loss: 0.00569\n",
      "epoch 2529 / 20000\n",
      "gradient norm: 0.06638785504037514, minimum ratio: 2.518421052631579\n",
      "\ttrain loss: 0.00582\n",
      "\tval loss: 0.00569\n",
      "epoch 2530 / 20000\n",
      "gradient norm: 0.05362674665229861, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00583\n",
      "\tval loss: 0.00570\n",
      "epoch 2531 / 20000\n",
      "gradient norm: 0.07494849240174517, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.00583\n",
      "\tval loss: 0.00571\n",
      "epoch 2532 / 20000\n",
      "gradient norm: 0.06764537678100169, minimum ratio: 2.518421052631579\n",
      "\ttrain loss: 0.00582\n",
      "\tval loss: 0.00569\n",
      "epoch 2533 / 20000\n",
      "gradient norm: 0.1340538861695677, minimum ratio: 2.5105263157894733\n",
      "\ttrain loss: 0.00582\n",
      "\tval loss: 0.00569\n",
      "epoch 2534 / 20000\n",
      "gradient norm: 0.0798280086601153, minimum ratio: 2.5210526315789474\n",
      "\ttrain loss: 0.00582\n",
      "\tval loss: 0.00569\n",
      "epoch 2535 / 20000\n",
      "gradient norm: 0.06069494801340625, minimum ratio: 2.5184210526315787\n",
      "\ttrain loss: 0.00582\n",
      "\tval loss: 0.00571\n",
      "epoch 2536 / 20000\n",
      "gradient norm: 0.045685103512369096, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00580\n",
      "\tval loss: 0.00570\n",
      "epoch 2537 / 20000\n",
      "gradient norm: 0.0644774817628786, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00582\n",
      "\tval loss: 0.00569\n",
      "epoch 2538 / 20000\n",
      "gradient norm: 0.06096529384376481, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00583\n",
      "\tval loss: 0.00569\n",
      "epoch 2539 / 20000\n",
      "gradient norm: 0.05203461788187269, minimum ratio: 2.5315789473684207\n",
      "\ttrain loss: 0.00581\n",
      "\tval loss: 0.00571\n",
      "epoch 2540 / 20000\n",
      "gradient norm: 0.01627033035038039, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00583\n",
      "\tval loss: 0.00569\n",
      "epoch 2541 / 20000\n",
      "gradient norm: 0.02639214863302186, minimum ratio: 2.513157894736842\n",
      "\ttrain loss: 0.00582\n",
      "\tval loss: 0.00569\n",
      "epoch 2542 / 20000\n",
      "gradient norm: 0.049830825882963836, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00582\n",
      "\tval loss: 0.00570\n",
      "epoch 2543 / 20000\n",
      "gradient norm: 0.07638074591523036, minimum ratio: 2.5210526315789474\n",
      "\ttrain loss: 0.00582\n",
      "\tval loss: 0.00570\n",
      "epoch 2544 / 20000\n",
      "gradient norm: 0.097008322190959, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00582\n",
      "\tval loss: 0.00570\n",
      "epoch 2545 / 20000\n",
      "gradient norm: 0.08369304740335792, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00582\n",
      "\tval loss: 0.00569\n",
      "epoch 2546 / 20000\n",
      "gradient norm: 0.07539393880870193, minimum ratio: 2.531578947368421\n",
      "\ttrain loss: 0.00583\n",
      "\tval loss: 0.00569\n",
      "epoch 2547 / 20000\n",
      "gradient norm: 0.031027143108076416, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00582\n",
      "\tval loss: 0.00570\n",
      "epoch 2548 / 20000\n",
      "gradient norm: 0.04782909859204665, minimum ratio: 2.518421052631579\n",
      "\ttrain loss: 0.00582\n",
      "\tval loss: 0.00570\n",
      "epoch 2549 / 20000\n",
      "gradient norm: 0.039847268955782056, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00583\n",
      "\tval loss: 0.00569\n",
      "epoch 2550 / 20000\n",
      "gradient norm: 0.061510935658589005, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00582\n",
      "\tval loss: 0.00569\n",
      "epoch 2551 / 20000\n",
      "gradient norm: 0.06985555829305667, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00582\n",
      "\tval loss: 0.00571\n",
      "epoch 2552 / 20000\n",
      "gradient norm: 0.03529842378338799, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00582\n",
      "\tval loss: 0.00569\n",
      "epoch 2553 / 20000\n",
      "gradient norm: 0.09686664055334404, minimum ratio: 2.494736842105263\n",
      "\ttrain loss: 0.00583\n",
      "\tval loss: 0.00569\n",
      "epoch 2554 / 20000\n",
      "gradient norm: 0.11657261213986203, minimum ratio: 2.5131578947368425\n",
      "\ttrain loss: 0.00584\n",
      "\tval loss: 0.00572\n",
      "epoch 2555 / 20000\n",
      "gradient norm: 0.04160745118861087, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00582\n",
      "\tval loss: 0.00569\n",
      "epoch 2556 / 20000\n",
      "gradient norm: 0.06638341027428396, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00582\n",
      "\tval loss: 0.00569\n",
      "epoch 2557 / 20000\n",
      "gradient norm: 0.07093600746884476, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00583\n",
      "\tval loss: 0.00570\n",
      "epoch 2558 / 20000\n",
      "gradient norm: 0.05087540397653356, minimum ratio: 2.5078947368421054\n",
      "\ttrain loss: 0.00581\n",
      "\tval loss: 0.00569\n",
      "epoch 2559 / 20000\n",
      "gradient norm: 0.06438568269368261, minimum ratio: 2.5157894736842104\n",
      "\ttrain loss: 0.00583\n",
      "\tval loss: 0.00569\n",
      "epoch 2560 / 20000\n",
      "gradient norm: 0.051735389220993966, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00583\n",
      "\tval loss: 0.00569\n",
      "epoch 2561 / 20000\n",
      "gradient norm: 0.04690364209818654, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00582\n",
      "\tval loss: 0.00571\n",
      "epoch 2562 / 20000\n",
      "gradient norm: 0.08200675825355574, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00582\n",
      "\tval loss: 0.00569\n",
      "epoch 2563 / 20000\n",
      "gradient norm: 0.057510679529514164, minimum ratio: 2.5157894736842104\n",
      "\ttrain loss: 0.00581\n",
      "\tval loss: 0.00568\n",
      "epoch 2564 / 20000\n",
      "gradient norm: 0.06580455036601052, minimum ratio: 2.513157894736842\n",
      "\ttrain loss: 0.00582\n",
      "\tval loss: 0.00569\n",
      "epoch 2565 / 20000\n",
      "gradient norm: 0.06261547887697816, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.00582\n",
      "\tval loss: 0.00571\n",
      "epoch 2566 / 20000\n",
      "gradient norm: 0.08680166868725792, minimum ratio: 2.513157894736842\n",
      "\ttrain loss: 0.00581\n",
      "\tval loss: 0.00570\n",
      "epoch 2567 / 20000\n",
      "gradient norm: 0.076386882486986, minimum ratio: 2.505263157894737\n",
      "\ttrain loss: 0.00582\n",
      "\tval loss: 0.00568\n",
      "epoch 2568 / 20000\n",
      "gradient norm: 0.06109255936462432, minimum ratio: 2.513157894736842\n",
      "\ttrain loss: 0.00582\n",
      "\tval loss: 0.00569\n",
      "epoch 2569 / 20000\n",
      "gradient norm: 0.059277073334669694, minimum ratio: 2.5105263157894733\n",
      "\ttrain loss: 0.00583\n",
      "\tval loss: 0.00572\n",
      "epoch 2570 / 20000\n",
      "gradient norm: 0.07241315563442186, minimum ratio: 2.5236842105263158\n",
      "\ttrain loss: 0.00583\n",
      "\tval loss: 0.00569\n",
      "epoch 2571 / 20000\n",
      "gradient norm: 0.10696886689402163, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00582\n",
      "\tval loss: 0.00568\n",
      "epoch 2572 / 20000\n",
      "gradient norm: 0.07330765019287355, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.00581\n",
      "\tval loss: 0.00570\n",
      "epoch 2573 / 20000\n",
      "gradient norm: 0.02370211032393854, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00581\n",
      "\tval loss: 0.00569\n",
      "epoch 2574 / 20000\n",
      "gradient norm: 0.04363091036793776, minimum ratio: 2.4868421052631575\n",
      "\ttrain loss: 0.00582\n",
      "\tval loss: 0.00568\n",
      "epoch 2575 / 20000\n",
      "gradient norm: 0.08823254736489616, minimum ratio: 2.5131578947368416\n",
      "\ttrain loss: 0.00581\n",
      "\tval loss: 0.00570\n",
      "epoch 2576 / 20000\n",
      "gradient norm: 0.053694470872869715, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00581\n",
      "\tval loss: 0.00569\n",
      "epoch 2577 / 20000\n",
      "gradient norm: 0.06708392818109132, minimum ratio: 2.4894736842105267\n",
      "\ttrain loss: 0.00582\n",
      "\tval loss: 0.00569\n",
      "epoch 2578 / 20000\n",
      "gradient norm: 0.06660821168043185, minimum ratio: 2.4894736842105267\n",
      "\ttrain loss: 0.00582\n",
      "\tval loss: 0.00570\n",
      "epoch 2579 / 20000\n",
      "gradient norm: 0.046847579709719867, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00582\n",
      "\tval loss: 0.00569\n",
      "epoch 2580 / 20000\n",
      "gradient norm: 0.06051841107546352, minimum ratio: 2.5078947368421054\n",
      "\ttrain loss: 0.00583\n",
      "\tval loss: 0.00568\n",
      "epoch 2581 / 20000\n",
      "gradient norm: 0.02210475894389674, minimum ratio: 2.515789473684211\n",
      "\ttrain loss: 0.00581\n",
      "\tval loss: 0.00570\n",
      "epoch 2582 / 20000\n",
      "gradient norm: 0.05288959518657066, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00582\n",
      "\tval loss: 0.00570\n",
      "epoch 2583 / 20000\n",
      "gradient norm: 0.07283933728467673, minimum ratio: 2.5078947368421054\n",
      "\ttrain loss: 0.00580\n",
      "\tval loss: 0.00569\n",
      "epoch 2584 / 20000\n",
      "gradient norm: 0.08922149962745607, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.00582\n",
      "\tval loss: 0.00568\n",
      "epoch 2585 / 20000\n",
      "gradient norm: 0.06138510329765268, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.00582\n",
      "\tval loss: 0.00569\n",
      "epoch 2586 / 20000\n",
      "gradient norm: 0.04206231651187409, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00582\n",
      "\tval loss: 0.00570\n",
      "epoch 2587 / 20000\n",
      "gradient norm: 0.06126306232181378, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00582\n",
      "\tval loss: 0.00569\n",
      "epoch 2588 / 20000\n",
      "gradient norm: 0.038490554827149026, minimum ratio: 2.5105263157894737\n",
      "\ttrain loss: 0.00582\n",
      "\tval loss: 0.00568\n",
      "epoch 2589 / 20000\n",
      "gradient norm: 0.0497939670458436, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00582\n",
      "\tval loss: 0.00569\n",
      "epoch 2590 / 20000\n",
      "gradient norm: 0.04985374381067231, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00581\n",
      "\tval loss: 0.00570\n",
      "epoch 2591 / 20000\n",
      "gradient norm: 0.06836870437837206, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00582\n",
      "\tval loss: 0.00569\n",
      "epoch 2592 / 20000\n",
      "gradient norm: 0.07371710648294538, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00580\n",
      "\tval loss: 0.00569\n",
      "epoch 2593 / 20000\n",
      "gradient norm: 0.07061115989927202, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00581\n",
      "\tval loss: 0.00569\n",
      "epoch 2594 / 20000\n",
      "gradient norm: 0.02551809762371704, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00582\n",
      "\tval loss: 0.00569\n",
      "epoch 2595 / 20000\n",
      "gradient norm: 0.06590892223175615, minimum ratio: 2.5131578947368425\n",
      "\ttrain loss: 0.00582\n",
      "\tval loss: 0.00569\n",
      "epoch 2596 / 20000\n",
      "gradient norm: 0.11911326250992715, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00581\n",
      "\tval loss: 0.00569\n",
      "epoch 2597 / 20000\n",
      "gradient norm: 0.08705757740972331, minimum ratio: 2.5236842105263158\n",
      "\ttrain loss: 0.00583\n",
      "\tval loss: 0.00568\n",
      "epoch 2598 / 20000\n",
      "gradient norm: 0.04084260534727946, minimum ratio: 2.5105263157894737\n",
      "\ttrain loss: 0.00581\n",
      "\tval loss: 0.00569\n",
      "epoch 2599 / 20000\n",
      "gradient norm: 0.05589099602366332, minimum ratio: 2.515789473684211\n",
      "\ttrain loss: 0.00581\n",
      "\tval loss: 0.00569\n",
      "epoch 2600 / 20000\n",
      "gradient norm: 0.06895085069118068, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00582\n",
      "\tval loss: 0.00569\n",
      "epoch 2601 / 20000\n",
      "gradient norm: 0.07246881170431152, minimum ratio: 2.492105263157895\n",
      "\ttrain loss: 0.00581\n",
      "\tval loss: 0.00568\n",
      "epoch 2602 / 20000\n",
      "gradient norm: 0.10381907076225616, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.00581\n",
      "\tval loss: 0.00569\n",
      "epoch 2603 / 20000\n",
      "gradient norm: 0.11922666279133409, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00581\n",
      "\tval loss: 0.00570\n",
      "epoch 2604 / 20000\n",
      "gradient norm: 0.033569351049663965, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00582\n",
      "\tval loss: 0.00568\n",
      "epoch 2605 / 20000\n",
      "gradient norm: 0.06620251425192691, minimum ratio: 2.5078947368421054\n",
      "\ttrain loss: 0.00581\n",
      "\tval loss: 0.00569\n",
      "epoch 2606 / 20000\n",
      "gradient norm: 0.036965327948564664, minimum ratio: 2.5210526315789474\n",
      "\ttrain loss: 0.00580\n",
      "\tval loss: 0.00569\n",
      "epoch 2607 / 20000\n",
      "gradient norm: 0.03174108584062196, minimum ratio: 2.4868421052631575\n",
      "\ttrain loss: 0.00581\n",
      "\tval loss: 0.00569\n",
      "epoch 2608 / 20000\n",
      "gradient norm: 0.07726309733698145, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00581\n",
      "\tval loss: 0.00568\n",
      "epoch 2609 / 20000\n",
      "gradient norm: 0.040329176728846505, minimum ratio: 2.4736842105263155\n",
      "\ttrain loss: 0.00580\n",
      "\tval loss: 0.00568\n",
      "epoch 2610 / 20000\n",
      "gradient norm: 0.0656446508364752, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00582\n",
      "\tval loss: 0.00569\n",
      "epoch 2611 / 20000\n",
      "gradient norm: 0.10536675347248092, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00582\n",
      "\tval loss: 0.00569\n",
      "epoch 2612 / 20000\n",
      "gradient norm: 0.05446231507812627, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00581\n",
      "\tval loss: 0.00568\n",
      "epoch 2613 / 20000\n",
      "gradient norm: 0.08633223897777498, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00581\n",
      "\tval loss: 0.00569\n",
      "epoch 2614 / 20000\n",
      "gradient norm: 0.03439159507979639, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00580\n",
      "\tval loss: 0.00569\n",
      "epoch 2615 / 20000\n",
      "gradient norm: 0.06333673518383875, minimum ratio: 2.4868421052631575\n",
      "\ttrain loss: 0.00582\n",
      "\tval loss: 0.00568\n",
      "epoch 2616 / 20000\n",
      "gradient norm: 0.08708187362208264, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00582\n",
      "\tval loss: 0.00569\n",
      "epoch 2617 / 20000\n",
      "gradient norm: 0.0799288668204099, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00583\n",
      "\tval loss: 0.00571\n",
      "epoch 2618 / 20000\n",
      "gradient norm: 0.04650424869032577, minimum ratio: 2.5105263157894737\n",
      "\ttrain loss: 0.00582\n",
      "\tval loss: 0.00568\n",
      "epoch 2619 / 20000\n",
      "gradient norm: 0.10819493775488809, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00581\n",
      "\tval loss: 0.00568\n",
      "epoch 2620 / 20000\n",
      "gradient norm: 0.08111226931214333, minimum ratio: 2.515789473684211\n",
      "\ttrain loss: 0.00582\n",
      "\tval loss: 0.00570\n",
      "epoch 2621 / 20000\n",
      "gradient norm: 0.09367497358471155, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00582\n",
      "\tval loss: 0.00569\n",
      "epoch 2622 / 20000\n",
      "gradient norm: 0.09110342177154962, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.00581\n",
      "\tval loss: 0.00568\n",
      "epoch 2623 / 20000\n",
      "gradient norm: 0.07162486169545446, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00581\n",
      "\tval loss: 0.00569\n",
      "epoch 2624 / 20000\n",
      "gradient norm: 0.04230335622560233, minimum ratio: 2.4868421052631575\n",
      "\ttrain loss: 0.00582\n",
      "\tval loss: 0.00568\n",
      "epoch 2625 / 20000\n",
      "gradient norm: 0.055878864048281685, minimum ratio: 2.5131578947368425\n",
      "\ttrain loss: 0.00582\n",
      "\tval loss: 0.00568\n",
      "epoch 2626 / 20000\n",
      "gradient norm: 0.07183325223741122, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00581\n",
      "\tval loss: 0.00570\n",
      "epoch 2627 / 20000\n",
      "gradient norm: 0.04702960266149603, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00580\n",
      "\tval loss: 0.00568\n",
      "epoch 2628 / 20000\n",
      "gradient norm: 0.028261371262487955, minimum ratio: 2.492105263157895\n",
      "\ttrain loss: 0.00579\n",
      "\tval loss: 0.00568\n",
      "epoch 2629 / 20000\n",
      "gradient norm: 0.06562629831023514, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00581\n",
      "\tval loss: 0.00569\n",
      "epoch 2630 / 20000\n",
      "gradient norm: 0.08687356818700209, minimum ratio: 2.5105263157894737\n",
      "\ttrain loss: 0.00582\n",
      "\tval loss: 0.00568\n",
      "epoch 2631 / 20000\n",
      "gradient norm: 0.0642097212257795, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00582\n",
      "\tval loss: 0.00570\n",
      "epoch 2632 / 20000\n",
      "gradient norm: 0.1225104316836223, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00582\n",
      "\tval loss: 0.00569\n",
      "epoch 2633 / 20000\n",
      "gradient norm: 0.10738336213398725, minimum ratio: 2.5131578947368425\n",
      "\ttrain loss: 0.00582\n",
      "\tval loss: 0.00567\n",
      "epoch 2634 / 20000\n",
      "gradient norm: 0.06152155523886904, minimum ratio: 2.5157894736842104\n",
      "\ttrain loss: 0.00581\n",
      "\tval loss: 0.00569\n",
      "epoch 2635 / 20000\n",
      "gradient norm: 0.04785571081447415, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00582\n",
      "\tval loss: 0.00569\n",
      "epoch 2636 / 20000\n",
      "gradient norm: 0.023830553240259178, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00581\n",
      "\tval loss: 0.00568\n",
      "epoch 2637 / 20000\n",
      "gradient norm: 0.06937478907639161, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00581\n",
      "\tval loss: 0.00568\n",
      "epoch 2638 / 20000\n",
      "gradient norm: 0.04513455480628181, minimum ratio: 2.5236842105263158\n",
      "\ttrain loss: 0.00581\n",
      "\tval loss: 0.00568\n",
      "epoch 2639 / 20000\n",
      "gradient norm: 0.030233113138820045, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00581\n",
      "\tval loss: 0.00569\n",
      "epoch 2640 / 20000\n",
      "gradient norm: 0.06819120539876167, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00582\n",
      "\tval loss: 0.00568\n",
      "epoch 2641 / 20000\n",
      "gradient norm: 0.05414583452511579, minimum ratio: 2.5157894736842104\n",
      "\ttrain loss: 0.00582\n",
      "\tval loss: 0.00568\n",
      "epoch 2642 / 20000\n",
      "gradient norm: 0.06602203141665086, minimum ratio: 2.489473684210526\n",
      "\ttrain loss: 0.00581\n",
      "\tval loss: 0.00570\n",
      "epoch 2643 / 20000\n",
      "gradient norm: 0.06590216350741684, minimum ratio: 2.515789473684211\n",
      "\ttrain loss: 0.00581\n",
      "\tval loss: 0.00568\n",
      "epoch 2644 / 20000\n",
      "gradient norm: 0.051869749382603914, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00581\n",
      "\tval loss: 0.00568\n",
      "epoch 2645 / 20000\n",
      "gradient norm: 0.03703868112643249, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00581\n",
      "\tval loss: 0.00568\n",
      "epoch 2646 / 20000\n",
      "gradient norm: 0.057055443234276026, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00579\n",
      "\tval loss: 0.00568\n",
      "epoch 2647 / 20000\n",
      "gradient norm: 0.06030668845050968, minimum ratio: 2.515789473684211\n",
      "\ttrain loss: 0.00582\n",
      "\tval loss: 0.00568\n",
      "epoch 2648 / 20000\n",
      "gradient norm: 0.08219180040759966, minimum ratio: 2.5105263157894737\n",
      "\ttrain loss: 0.00580\n",
      "\tval loss: 0.00568\n",
      "epoch 2649 / 20000\n",
      "gradient norm: 0.12202074259403162, minimum ratio: 2.5210526315789474\n",
      "\ttrain loss: 0.00583\n",
      "\tval loss: 0.00570\n",
      "epoch 2650 / 20000\n",
      "gradient norm: 0.044283475042902865, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00581\n",
      "\tval loss: 0.00567\n",
      "epoch 2651 / 20000\n",
      "gradient norm: 0.059574375045485795, minimum ratio: 2.526315789473684\n",
      "\ttrain loss: 0.00581\n",
      "\tval loss: 0.00568\n",
      "epoch 2652 / 20000\n",
      "gradient norm: 0.09611773572396487, minimum ratio: 2.4868421052631584\n",
      "\ttrain loss: 0.00581\n",
      "\tval loss: 0.00569\n",
      "epoch 2653 / 20000\n",
      "gradient norm: 0.05433573049958795, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00581\n",
      "\tval loss: 0.00568\n",
      "epoch 2654 / 20000\n",
      "gradient norm: 0.04201675282092765, minimum ratio: 2.489473684210526\n",
      "\ttrain loss: 0.00581\n",
      "\tval loss: 0.00568\n",
      "epoch 2655 / 20000\n",
      "gradient norm: 0.04035251692403108, minimum ratio: 2.5210526315789474\n",
      "\ttrain loss: 0.00580\n",
      "\tval loss: 0.00568\n",
      "epoch 2656 / 20000\n",
      "gradient norm: 0.050866558391135186, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00580\n",
      "\tval loss: 0.00568\n",
      "epoch 2657 / 20000\n",
      "gradient norm: 0.061921862361487, minimum ratio: 2.518421052631579\n",
      "\ttrain loss: 0.00581\n",
      "\tval loss: 0.00569\n",
      "epoch 2658 / 20000\n",
      "gradient norm: 0.02562484284862876, minimum ratio: 2.5236842105263158\n",
      "\ttrain loss: 0.00581\n",
      "\tval loss: 0.00569\n",
      "epoch 2659 / 20000\n",
      "gradient norm: 0.05150761897675693, minimum ratio: 2.5105263157894733\n",
      "\ttrain loss: 0.00580\n",
      "\tval loss: 0.00568\n",
      "epoch 2660 / 20000\n",
      "gradient norm: 0.04351917133317329, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00580\n",
      "\tval loss: 0.00568\n",
      "epoch 2661 / 20000\n",
      "gradient norm: 0.037982531008310616, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00580\n",
      "\tval loss: 0.00568\n",
      "epoch 2662 / 20000\n",
      "gradient norm: 0.056866715392970946, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00581\n",
      "\tval loss: 0.00568\n",
      "epoch 2663 / 20000\n",
      "gradient norm: 0.07687558268662542, minimum ratio: 2.494736842105263\n",
      "\ttrain loss: 0.00582\n",
      "\tval loss: 0.00568\n",
      "epoch 2664 / 20000\n",
      "gradient norm: 0.06057721399702132, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00581\n",
      "\tval loss: 0.00568\n",
      "epoch 2665 / 20000\n",
      "gradient norm: 0.03180533109116368, minimum ratio: 2.492105263157895\n",
      "\ttrain loss: 0.00580\n",
      "\tval loss: 0.00569\n",
      "epoch 2666 / 20000\n",
      "gradient norm: 0.08369877189397812, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00582\n",
      "\tval loss: 0.00567\n",
      "epoch 2667 / 20000\n",
      "gradient norm: 0.07872760793543421, minimum ratio: 2.492105263157895\n",
      "\ttrain loss: 0.00581\n",
      "\tval loss: 0.00568\n",
      "epoch 2668 / 20000\n",
      "gradient norm: 0.07329605147242546, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00581\n",
      "\tval loss: 0.00568\n",
      "epoch 2669 / 20000\n",
      "gradient norm: 0.06517951237037778, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00581\n",
      "\tval loss: 0.00568\n",
      "epoch 2670 / 20000\n",
      "gradient norm: 0.061644705245271325, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00582\n",
      "\tval loss: 0.00568\n",
      "epoch 2671 / 20000\n",
      "gradient norm: 0.037809363755513914, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00580\n",
      "\tval loss: 0.00569\n",
      "epoch 2672 / 20000\n",
      "gradient norm: 0.048929106909781694, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00581\n",
      "\tval loss: 0.00567\n",
      "epoch 2673 / 20000\n",
      "gradient norm: 0.09159221034497023, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00582\n",
      "\tval loss: 0.00568\n",
      "epoch 2674 / 20000\n",
      "gradient norm: 0.053642419166862965, minimum ratio: 2.528947368421053\n",
      "\ttrain loss: 0.00581\n",
      "\tval loss: 0.00570\n",
      "epoch 2675 / 20000\n",
      "gradient norm: 0.06265942010213621, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00581\n",
      "\tval loss: 0.00568\n",
      "epoch 2676 / 20000\n",
      "gradient norm: 0.06064847038942389, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00580\n",
      "\tval loss: 0.00568\n",
      "epoch 2677 / 20000\n",
      "gradient norm: 0.07876514102099463, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00581\n",
      "\tval loss: 0.00567\n",
      "epoch 2678 / 20000\n",
      "gradient norm: 0.13100495107937604, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00581\n",
      "\tval loss: 0.00569\n",
      "epoch 2679 / 20000\n",
      "gradient norm: 0.07702969445381314, minimum ratio: 2.5289473684210524\n",
      "\ttrain loss: 0.00582\n",
      "\tval loss: 0.00567\n",
      "epoch 2680 / 20000\n",
      "gradient norm: 0.052518696611514315, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00580\n",
      "\tval loss: 0.00568\n",
      "epoch 2681 / 20000\n",
      "gradient norm: 0.06408745658700354, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00581\n",
      "\tval loss: 0.00569\n",
      "epoch 2682 / 20000\n",
      "gradient norm: 0.07185094489250332, minimum ratio: 2.507894736842105\n",
      "\ttrain loss: 0.00580\n",
      "\tval loss: 0.00567\n",
      "epoch 2683 / 20000\n",
      "gradient norm: 0.09309721944737248, minimum ratio: 2.518421052631579\n",
      "\ttrain loss: 0.00583\n",
      "\tval loss: 0.00567\n",
      "epoch 2684 / 20000\n",
      "gradient norm: 0.0894321131054312, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00582\n",
      "\tval loss: 0.00570\n",
      "epoch 2685 / 20000\n",
      "gradient norm: 0.05532200701418333, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00580\n",
      "\tval loss: 0.00568\n",
      "epoch 2686 / 20000\n",
      "gradient norm: 0.05784213672450278, minimum ratio: 2.5210526315789474\n",
      "\ttrain loss: 0.00581\n",
      "\tval loss: 0.00567\n",
      "epoch 2687 / 20000\n",
      "gradient norm: 0.03733097802614793, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00581\n",
      "\tval loss: 0.00568\n",
      "epoch 2688 / 20000\n",
      "gradient norm: 0.10131267571705393, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00580\n",
      "\tval loss: 0.00569\n",
      "epoch 2689 / 20000\n",
      "gradient norm: 0.04116034196340479, minimum ratio: 2.515789473684211\n",
      "\ttrain loss: 0.00580\n",
      "\tval loss: 0.00567\n",
      "epoch 2690 / 20000\n",
      "gradient norm: 0.10712989373132586, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00581\n",
      "\tval loss: 0.00567\n",
      "epoch 2691 / 20000\n",
      "gradient norm: 0.14031721220817417, minimum ratio: 2.5289473684210524\n",
      "\ttrain loss: 0.00581\n",
      "\tval loss: 0.00570\n",
      "epoch 2692 / 20000\n",
      "gradient norm: 0.04102132288971916, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00580\n",
      "\tval loss: 0.00567\n",
      "epoch 2693 / 20000\n",
      "gradient norm: 0.10492693449486978, minimum ratio: 2.5131578947368425\n",
      "\ttrain loss: 0.00580\n",
      "\tval loss: 0.00567\n",
      "epoch 2694 / 20000\n",
      "gradient norm: 0.05378704535542056, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00582\n",
      "\tval loss: 0.00567\n",
      "epoch 2695 / 20000\n",
      "gradient norm: 0.03939858566445764, minimum ratio: 2.492105263157895\n",
      "\ttrain loss: 0.00581\n",
      "\tval loss: 0.00569\n",
      "epoch 2696 / 20000\n",
      "gradient norm: 0.06818504043621942, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00580\n",
      "\tval loss: 0.00568\n",
      "epoch 2697 / 20000\n",
      "gradient norm: 0.033227610008907504, minimum ratio: 2.492105263157895\n",
      "\ttrain loss: 0.00580\n",
      "\tval loss: 0.00567\n",
      "epoch 2698 / 20000\n",
      "gradient norm: 0.043529250513529405, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00581\n",
      "\tval loss: 0.00567\n",
      "epoch 2699 / 20000\n",
      "gradient norm: 0.038602453903877176, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00581\n",
      "\tval loss: 0.00569\n",
      "epoch 2700 / 20000\n",
      "gradient norm: 0.05601178089273162, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00580\n",
      "\tval loss: 0.00568\n",
      "epoch 2701 / 20000\n",
      "gradient norm: 0.05526094324886799, minimum ratio: 2.513157894736842\n",
      "\ttrain loss: 0.00580\n",
      "\tval loss: 0.00567\n",
      "epoch 2702 / 20000\n",
      "gradient norm: 0.05047556047793478, minimum ratio: 2.4842105263157896\n",
      "\ttrain loss: 0.00581\n",
      "\tval loss: 0.00567\n",
      "epoch 2703 / 20000\n",
      "gradient norm: 0.033141017163870856, minimum ratio: 2.5289473684210524\n",
      "\ttrain loss: 0.00580\n",
      "\tval loss: 0.00569\n",
      "epoch 2704 / 20000\n",
      "gradient norm: 0.04340302920900285, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00582\n",
      "\tval loss: 0.00568\n",
      "epoch 2705 / 20000\n",
      "gradient norm: 0.06007547289482318, minimum ratio: 2.513157894736842\n",
      "\ttrain loss: 0.00582\n",
      "\tval loss: 0.00567\n",
      "epoch 2706 / 20000\n",
      "gradient norm: 0.051395622722338885, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00581\n",
      "\tval loss: 0.00568\n",
      "epoch 2707 / 20000\n",
      "gradient norm: 0.08709540637210011, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00581\n",
      "\tval loss: 0.00567\n",
      "epoch 2708 / 20000\n",
      "gradient norm: 0.05683607701212168, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00580\n",
      "\tval loss: 0.00568\n",
      "epoch 2709 / 20000\n",
      "gradient norm: 0.044096728721342515, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00581\n",
      "\tval loss: 0.00567\n",
      "epoch 2710 / 20000\n",
      "gradient norm: 0.010531519288633717, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00580\n",
      "\tval loss: 0.00567\n",
      "epoch 2711 / 20000\n",
      "gradient norm: 0.12095288932323456, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00580\n",
      "\tval loss: 0.00568\n",
      "epoch 2712 / 20000\n",
      "gradient norm: 0.0907931745168753, minimum ratio: 2.5078947368421054\n",
      "\ttrain loss: 0.00579\n",
      "\tval loss: 0.00567\n",
      "epoch 2713 / 20000\n",
      "gradient norm: 0.10744752804748714, minimum ratio: 2.492105263157895\n",
      "\ttrain loss: 0.00582\n",
      "\tval loss: 0.00567\n",
      "epoch 2714 / 20000\n",
      "gradient norm: 0.11018548090942204, minimum ratio: 2.492105263157895\n",
      "\ttrain loss: 0.00581\n",
      "\tval loss: 0.00570\n",
      "epoch 2715 / 20000\n",
      "gradient norm: 0.03735517876339145, minimum ratio: 2.518421052631579\n",
      "\ttrain loss: 0.00580\n",
      "\tval loss: 0.00567\n",
      "epoch 2716 / 20000\n",
      "gradient norm: 0.09053451704676263, minimum ratio: 2.507894736842105\n",
      "\ttrain loss: 0.00579\n",
      "\tval loss: 0.00567\n",
      "epoch 2717 / 20000\n",
      "gradient norm: 0.13912790326867253, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00581\n",
      "\tval loss: 0.00568\n",
      "epoch 2718 / 20000\n",
      "gradient norm: 0.05817445187130943, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00579\n",
      "\tval loss: 0.00567\n",
      "epoch 2719 / 20000\n",
      "gradient norm: 0.05729749894089764, minimum ratio: 2.507894736842105\n",
      "\ttrain loss: 0.00581\n",
      "\tval loss: 0.00567\n",
      "epoch 2720 / 20000\n",
      "gradient norm: 0.03380558392382227, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00579\n",
      "\tval loss: 0.00568\n",
      "epoch 2721 / 20000\n",
      "gradient norm: 0.034298501355806366, minimum ratio: 2.505263157894737\n",
      "\ttrain loss: 0.00580\n",
      "\tval loss: 0.00567\n",
      "epoch 2722 / 20000\n",
      "gradient norm: 0.03941067887353711, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00581\n",
      "\tval loss: 0.00567\n",
      "epoch 2723 / 20000\n",
      "gradient norm: 0.0707142252358608, minimum ratio: 2.492105263157895\n",
      "\ttrain loss: 0.00580\n",
      "\tval loss: 0.00567\n",
      "epoch 2724 / 20000\n",
      "gradient norm: 0.09739463869482279, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00580\n",
      "\tval loss: 0.00568\n",
      "epoch 2725 / 20000\n",
      "gradient norm: 0.02901671320432797, minimum ratio: 2.515789473684211\n",
      "\ttrain loss: 0.00580\n",
      "\tval loss: 0.00567\n",
      "epoch 2726 / 20000\n",
      "gradient norm: 0.0770391778787598, minimum ratio: 2.5131578947368416\n",
      "\ttrain loss: 0.00581\n",
      "\tval loss: 0.00567\n",
      "epoch 2727 / 20000\n",
      "gradient norm: 0.03776556454249658, minimum ratio: 2.5105263157894737\n",
      "\ttrain loss: 0.00580\n",
      "\tval loss: 0.00569\n",
      "epoch 2728 / 20000\n",
      "gradient norm: 0.08280984163866378, minimum ratio: 2.5184210526315787\n",
      "\ttrain loss: 0.00582\n",
      "\tval loss: 0.00568\n",
      "epoch 2729 / 20000\n",
      "gradient norm: 0.06198205699911341, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00579\n",
      "\tval loss: 0.00567\n",
      "epoch 2730 / 20000\n",
      "gradient norm: 0.14967072301078588, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00582\n",
      "\tval loss: 0.00566\n",
      "epoch 2731 / 20000\n",
      "gradient norm: 0.05864701318205334, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00581\n",
      "\tval loss: 0.00570\n",
      "epoch 2732 / 20000\n",
      "gradient norm: 0.09455069020623341, minimum ratio: 2.518421052631579\n",
      "\ttrain loss: 0.00579\n",
      "\tval loss: 0.00567\n",
      "epoch 2733 / 20000\n",
      "gradient norm: 0.05157913464063313, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00580\n",
      "\tval loss: 0.00567\n",
      "epoch 2734 / 20000\n",
      "gradient norm: 0.02557122174766846, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00580\n",
      "\tval loss: 0.00568\n",
      "epoch 2735 / 20000\n",
      "gradient norm: 0.06734207275439985, minimum ratio: 2.4842105263157896\n",
      "\ttrain loss: 0.00581\n",
      "\tval loss: 0.00567\n",
      "epoch 2736 / 20000\n",
      "gradient norm: 0.08653796167345718, minimum ratio: 2.507894736842105\n",
      "\ttrain loss: 0.00580\n",
      "\tval loss: 0.00568\n",
      "epoch 2737 / 20000\n",
      "gradient norm: 0.04975128953810781, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.00579\n",
      "\tval loss: 0.00566\n",
      "epoch 2738 / 20000\n",
      "gradient norm: 0.06081044126767665, minimum ratio: 2.5078947368421054\n",
      "\ttrain loss: 0.00579\n",
      "\tval loss: 0.00567\n",
      "epoch 2739 / 20000\n",
      "gradient norm: 0.08533413097029552, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00580\n",
      "\tval loss: 0.00568\n",
      "epoch 2740 / 20000\n",
      "gradient norm: 0.049681038781272946, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00580\n",
      "\tval loss: 0.00567\n",
      "epoch 2741 / 20000\n",
      "gradient norm: 0.07207713249954395, minimum ratio: 2.515789473684211\n",
      "\ttrain loss: 0.00580\n",
      "\tval loss: 0.00567\n",
      "epoch 2742 / 20000\n",
      "gradient norm: 0.046599753288319334, minimum ratio: 2.492105263157895\n",
      "\ttrain loss: 0.00579\n",
      "\tval loss: 0.00568\n",
      "epoch 2743 / 20000\n",
      "gradient norm: 0.04565835327957757, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00581\n",
      "\tval loss: 0.00567\n",
      "epoch 2744 / 20000\n",
      "gradient norm: 0.06560062734934036, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00580\n",
      "\tval loss: 0.00567\n",
      "epoch 2745 / 20000\n",
      "gradient norm: 0.06485585251357406, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00579\n",
      "\tval loss: 0.00566\n",
      "epoch 2746 / 20000\n",
      "gradient norm: 0.12238952168263495, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00580\n",
      "\tval loss: 0.00568\n",
      "epoch 2747 / 20000\n",
      "gradient norm: 0.059505164972506464, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00579\n",
      "\tval loss: 0.00567\n",
      "epoch 2748 / 20000\n",
      "gradient norm: 0.08868835080647841, minimum ratio: 2.494736842105263\n",
      "\ttrain loss: 0.00580\n",
      "\tval loss: 0.00567\n",
      "epoch 2749 / 20000\n",
      "gradient norm: 0.0493457349948585, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00580\n",
      "\tval loss: 0.00569\n",
      "epoch 2750 / 20000\n",
      "gradient norm: 0.036630151560530066, minimum ratio: 2.5105263157894737\n",
      "\ttrain loss: 0.00580\n",
      "\tval loss: 0.00567\n",
      "epoch 2751 / 20000\n",
      "gradient norm: 0.07567078436841257, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.00580\n",
      "\tval loss: 0.00566\n",
      "epoch 2752 / 20000\n",
      "gradient norm: 0.11591711977962404, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00580\n",
      "\tval loss: 0.00568\n",
      "epoch 2753 / 20000\n",
      "gradient norm: 0.032854624951141886, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00580\n",
      "\tval loss: 0.00566\n",
      "epoch 2754 / 20000\n",
      "gradient norm: 0.044737998221535236, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00581\n",
      "\tval loss: 0.00567\n",
      "epoch 2755 / 20000\n",
      "gradient norm: 0.01909588120179251, minimum ratio: 2.4894736842105267\n",
      "\ttrain loss: 0.00580\n",
      "\tval loss: 0.00568\n",
      "epoch 2756 / 20000\n",
      "gradient norm: 0.07336774130817503, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00580\n",
      "\tval loss: 0.00567\n",
      "epoch 2757 / 20000\n",
      "gradient norm: 0.04961105436086655, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00580\n",
      "\tval loss: 0.00567\n",
      "epoch 2758 / 20000\n",
      "gradient norm: 0.0696293564978987, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00578\n",
      "\tval loss: 0.00566\n",
      "epoch 2759 / 20000\n",
      "gradient norm: 0.07836097045219503, minimum ratio: 2.5105263157894737\n",
      "\ttrain loss: 0.00580\n",
      "\tval loss: 0.00567\n",
      "epoch 2760 / 20000\n",
      "gradient norm: 0.06692921597277746, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00581\n",
      "\tval loss: 0.00567\n",
      "epoch 2761 / 20000\n",
      "gradient norm: 0.11290648905560374, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00582\n",
      "\tval loss: 0.00567\n",
      "epoch 2762 / 20000\n",
      "gradient norm: 0.0667467656021472, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00580\n",
      "\tval loss: 0.00568\n",
      "epoch 2763 / 20000\n",
      "gradient norm: 0.09683846280677244, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00582\n",
      "\tval loss: 0.00566\n",
      "epoch 2764 / 20000\n",
      "gradient norm: 0.10515971528366208, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00580\n",
      "\tval loss: 0.00568\n",
      "epoch 2765 / 20000\n",
      "gradient norm: 0.050525319820735604, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00579\n",
      "\tval loss: 0.00567\n",
      "epoch 2766 / 20000\n",
      "gradient norm: 0.07100709958467633, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00579\n",
      "\tval loss: 0.00567\n",
      "epoch 2767 / 20000\n",
      "gradient norm: 0.05779585341224447, minimum ratio: 2.515789473684211\n",
      "\ttrain loss: 0.00579\n",
      "\tval loss: 0.00568\n",
      "epoch 2768 / 20000\n",
      "gradient norm: 0.08080595429055393, minimum ratio: 2.5157894736842104\n",
      "\ttrain loss: 0.00580\n",
      "\tval loss: 0.00566\n",
      "epoch 2769 / 20000\n",
      "gradient norm: 0.10649530250520911, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00579\n",
      "\tval loss: 0.00567\n",
      "epoch 2770 / 20000\n",
      "gradient norm: 0.03164460725383833, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00579\n",
      "\tval loss: 0.00566\n",
      "epoch 2771 / 20000\n",
      "gradient norm: 0.035185229891794734, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00579\n",
      "\tval loss: 0.00567\n",
      "epoch 2772 / 20000\n",
      "gradient norm: 0.0642097047821153, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.00580\n",
      "\tval loss: 0.00567\n",
      "epoch 2773 / 20000\n",
      "gradient norm: 0.046134701900882646, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00579\n",
      "\tval loss: 0.00567\n",
      "epoch 2774 / 20000\n",
      "gradient norm: 0.09059879009146243, minimum ratio: 2.5289473684210524\n",
      "\ttrain loss: 0.00580\n",
      "\tval loss: 0.00567\n",
      "epoch 2775 / 20000\n",
      "gradient norm: 0.0871251027128892, minimum ratio: 2.518421052631579\n",
      "\ttrain loss: 0.00580\n",
      "\tval loss: 0.00567\n",
      "epoch 2776 / 20000\n",
      "gradient norm: 0.035465854714857414, minimum ratio: 2.5105263157894737\n",
      "\ttrain loss: 0.00579\n",
      "\tval loss: 0.00567\n",
      "epoch 2777 / 20000\n",
      "gradient norm: 0.04382170601456892, minimum ratio: 2.4868421052631575\n",
      "\ttrain loss: 0.00578\n",
      "\tval loss: 0.00566\n",
      "epoch 2778 / 20000\n",
      "gradient norm: 0.054529315733816475, minimum ratio: 2.507894736842105\n",
      "\ttrain loss: 0.00580\n",
      "\tval loss: 0.00566\n",
      "epoch 2779 / 20000\n",
      "gradient norm: 0.06640441110357642, minimum ratio: 2.507894736842105\n",
      "\ttrain loss: 0.00579\n",
      "\tval loss: 0.00568\n",
      "epoch 2780 / 20000\n",
      "gradient norm: 0.08495976432459429, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00581\n",
      "\tval loss: 0.00567\n",
      "epoch 2781 / 20000\n",
      "gradient norm: 0.06685984804062173, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00580\n",
      "\tval loss: 0.00566\n",
      "epoch 2782 / 20000\n",
      "gradient norm: 0.05509791258373298, minimum ratio: 2.4868421052631575\n",
      "\ttrain loss: 0.00578\n",
      "\tval loss: 0.00567\n",
      "epoch 2783 / 20000\n",
      "gradient norm: 0.03726462407212239, minimum ratio: 2.507894736842105\n",
      "\ttrain loss: 0.00579\n",
      "\tval loss: 0.00568\n",
      "epoch 2784 / 20000\n",
      "gradient norm: 0.0773070778377587, minimum ratio: 2.528947368421053\n",
      "\ttrain loss: 0.00579\n",
      "\tval loss: 0.00566\n",
      "epoch 2785 / 20000\n",
      "gradient norm: 0.060565665015019476, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00580\n",
      "\tval loss: 0.00567\n",
      "epoch 2786 / 20000\n",
      "gradient norm: 0.06052239607379306, minimum ratio: 2.5236842105263158\n",
      "\ttrain loss: 0.00580\n",
      "\tval loss: 0.00568\n",
      "epoch 2787 / 20000\n",
      "gradient norm: 0.03193924170045648, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00579\n",
      "\tval loss: 0.00566\n",
      "epoch 2788 / 20000\n",
      "gradient norm: 0.04887173499446362, minimum ratio: 2.4868421052631575\n",
      "\ttrain loss: 0.00580\n",
      "\tval loss: 0.00566\n",
      "epoch 2789 / 20000\n",
      "gradient norm: 0.07476116751786321, minimum ratio: 2.507894736842105\n",
      "\ttrain loss: 0.00580\n",
      "\tval loss: 0.00567\n",
      "epoch 2790 / 20000\n",
      "gradient norm: 0.08392457745503634, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00579\n",
      "\tval loss: 0.00566\n",
      "epoch 2791 / 20000\n",
      "gradient norm: 0.05915628941147588, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00580\n",
      "\tval loss: 0.00566\n",
      "epoch 2792 / 20000\n",
      "gradient norm: 0.058571815432514995, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00581\n",
      "\tval loss: 0.00567\n",
      "epoch 2793 / 20000\n",
      "gradient norm: 0.08402070845477283, minimum ratio: 2.492105263157895\n",
      "\ttrain loss: 0.00581\n",
      "\tval loss: 0.00568\n",
      "epoch 2794 / 20000\n",
      "gradient norm: 0.053631143673555925, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00579\n",
      "\tval loss: 0.00566\n",
      "epoch 2795 / 20000\n",
      "gradient norm: 0.03865885763661936, minimum ratio: 2.510526315789474\n",
      "\ttrain loss: 0.00580\n",
      "\tval loss: 0.00566\n",
      "epoch 2796 / 20000\n",
      "gradient norm: 0.11167926620692015, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00579\n",
      "\tval loss: 0.00567\n",
      "epoch 2797 / 20000\n",
      "gradient norm: 0.03872343563125469, minimum ratio: 2.5105263157894737\n",
      "\ttrain loss: 0.00579\n",
      "\tval loss: 0.00567\n",
      "epoch 2798 / 20000\n",
      "gradient norm: 0.05837912845890969, minimum ratio: 2.518421052631579\n",
      "\ttrain loss: 0.00579\n",
      "\tval loss: 0.00566\n",
      "epoch 2799 / 20000\n",
      "gradient norm: 0.07560784905217588, minimum ratio: 2.4842105263157896\n",
      "\ttrain loss: 0.00579\n",
      "\tval loss: 0.00567\n",
      "epoch 2800 / 20000\n",
      "gradient norm: 0.08879227942088619, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00580\n",
      "\tval loss: 0.00566\n",
      "epoch 2801 / 20000\n",
      "gradient norm: 0.046709256144822575, minimum ratio: 2.518421052631579\n",
      "\ttrain loss: 0.00580\n",
      "\tval loss: 0.00566\n",
      "epoch 2802 / 20000\n",
      "gradient norm: 0.10530147299868986, minimum ratio: 2.5105263157894737\n",
      "\ttrain loss: 0.00580\n",
      "\tval loss: 0.00567\n",
      "epoch 2803 / 20000\n",
      "gradient norm: 0.06224928915617056, minimum ratio: 2.5210526315789474\n",
      "\ttrain loss: 0.00578\n",
      "\tval loss: 0.00566\n",
      "epoch 2804 / 20000\n",
      "gradient norm: 0.07915488188154995, minimum ratio: 2.518421052631579\n",
      "\ttrain loss: 0.00581\n",
      "\tval loss: 0.00566\n",
      "epoch 2805 / 20000\n",
      "gradient norm: 0.061982451705262065, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00579\n",
      "\tval loss: 0.00568\n",
      "epoch 2806 / 20000\n",
      "gradient norm: 0.10081114259082824, minimum ratio: 2.505263157894737\n",
      "\ttrain loss: 0.00581\n",
      "\tval loss: 0.00566\n",
      "epoch 2807 / 20000\n",
      "gradient norm: 0.07348090823506936, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00579\n",
      "\tval loss: 0.00567\n",
      "epoch 2808 / 20000\n",
      "gradient norm: 0.05078990579931997, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00578\n",
      "\tval loss: 0.00567\n",
      "epoch 2809 / 20000\n",
      "gradient norm: 0.09686766606318997, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00581\n",
      "\tval loss: 0.00566\n",
      "epoch 2810 / 20000\n",
      "gradient norm: 0.06769523554248735, minimum ratio: 2.4842105263157896\n",
      "\ttrain loss: 0.00580\n",
      "\tval loss: 0.00567\n",
      "epoch 2811 / 20000\n",
      "gradient norm: 0.05915268263197504, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00580\n",
      "\tval loss: 0.00566\n",
      "epoch 2812 / 20000\n",
      "gradient norm: 0.03624142924672924, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00578\n",
      "\tval loss: 0.00566\n",
      "epoch 2813 / 20000\n",
      "gradient norm: 0.08856606588233262, minimum ratio: 2.5105263157894737\n",
      "\ttrain loss: 0.00579\n",
      "\tval loss: 0.00567\n",
      "epoch 2814 / 20000\n",
      "gradient norm: 0.04964686855964828, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00578\n",
      "\tval loss: 0.00566\n",
      "epoch 2815 / 20000\n",
      "gradient norm: 0.09757177880965173, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00580\n",
      "\tval loss: 0.00565\n",
      "epoch 2816 / 20000\n",
      "gradient norm: 0.03688507624610793, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00579\n",
      "\tval loss: 0.00567\n",
      "epoch 2817 / 20000\n",
      "gradient norm: 0.038267765630735084, minimum ratio: 2.513157894736842\n",
      "\ttrain loss: 0.00580\n",
      "\tval loss: 0.00567\n",
      "epoch 2818 / 20000\n",
      "gradient norm: 0.08227464044466615, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00579\n",
      "\tval loss: 0.00566\n",
      "epoch 2819 / 20000\n",
      "gradient norm: 0.06241886780480854, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00579\n",
      "\tval loss: 0.00566\n",
      "epoch 2820 / 20000\n",
      "gradient norm: 0.03125572268618271, minimum ratio: 2.515789473684211\n",
      "\ttrain loss: 0.00580\n",
      "\tval loss: 0.00566\n",
      "epoch 2821 / 20000\n",
      "gradient norm: 0.036886794259771705, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00581\n",
      "\tval loss: 0.00566\n",
      "epoch 2822 / 20000\n",
      "gradient norm: 0.04498627513385145, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00580\n",
      "\tval loss: 0.00567\n",
      "epoch 2823 / 20000\n",
      "gradient norm: 0.0422899077530019, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00580\n",
      "\tval loss: 0.00566\n",
      "epoch 2824 / 20000\n",
      "gradient norm: 0.03693855546589475, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00579\n",
      "\tval loss: 0.00566\n",
      "epoch 2825 / 20000\n",
      "gradient norm: 0.03818702680291608, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00578\n",
      "\tval loss: 0.00566\n",
      "epoch 2826 / 20000\n",
      "gradient norm: 0.08930418954696506, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00579\n",
      "\tval loss: 0.00566\n",
      "epoch 2827 / 20000\n",
      "gradient norm: 0.10425302491057664, minimum ratio: 2.518421052631579\n",
      "\ttrain loss: 0.00581\n",
      "\tval loss: 0.00566\n",
      "epoch 2828 / 20000\n",
      "gradient norm: 0.03504812296887394, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00579\n",
      "\tval loss: 0.00568\n",
      "epoch 2829 / 20000\n",
      "gradient norm: 0.04922894944320433, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00581\n",
      "\tval loss: 0.00567\n",
      "epoch 2830 / 20000\n",
      "gradient norm: 0.05664686237287242, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00578\n",
      "\tval loss: 0.00565\n",
      "epoch 2831 / 20000\n",
      "gradient norm: 0.05873612640425563, minimum ratio: 2.4868421052631584\n",
      "\ttrain loss: 0.00580\n",
      "\tval loss: 0.00566\n",
      "epoch 2832 / 20000\n",
      "gradient norm: 0.03621292182651814, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00579\n",
      "\tval loss: 0.00567\n",
      "epoch 2833 / 20000\n",
      "gradient norm: 0.0473219437408261, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00579\n",
      "\tval loss: 0.00567\n",
      "epoch 2834 / 20000\n",
      "gradient norm: 0.06039356972905807, minimum ratio: 2.5210526315789474\n",
      "\ttrain loss: 0.00579\n",
      "\tval loss: 0.00565\n",
      "epoch 2835 / 20000\n",
      "gradient norm: 0.06313119520200416, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00580\n",
      "\tval loss: 0.00566\n",
      "epoch 2836 / 20000\n",
      "gradient norm: 0.03937000781297684, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00580\n",
      "\tval loss: 0.00567\n",
      "epoch 2837 / 20000\n",
      "gradient norm: 0.06821800558827817, minimum ratio: 2.513157894736842\n",
      "\ttrain loss: 0.00578\n",
      "\tval loss: 0.00566\n",
      "epoch 2838 / 20000\n",
      "gradient norm: 0.0847472291206941, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00580\n",
      "\tval loss: 0.00565\n",
      "epoch 2839 / 20000\n",
      "gradient norm: 0.06238173921883572, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00580\n",
      "\tval loss: 0.00566\n",
      "epoch 2840 / 20000\n",
      "gradient norm: 0.049401351338019595, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00578\n",
      "\tval loss: 0.00568\n",
      "epoch 2841 / 20000\n",
      "gradient norm: 0.1038284971145913, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00580\n",
      "\tval loss: 0.00566\n",
      "epoch 2842 / 20000\n",
      "gradient norm: 0.07310065827914514, minimum ratio: 2.4868421052631575\n",
      "\ttrain loss: 0.00578\n",
      "\tval loss: 0.00566\n",
      "epoch 2843 / 20000\n",
      "gradient norm: 0.10826395091135055, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00580\n",
      "\tval loss: 0.00565\n",
      "epoch 2844 / 20000\n",
      "gradient norm: 0.038884660811163485, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00579\n",
      "\tval loss: 0.00567\n",
      "epoch 2845 / 20000\n",
      "gradient norm: 0.09213538763287943, minimum ratio: 2.5078947368421054\n",
      "\ttrain loss: 0.00579\n",
      "\tval loss: 0.00566\n",
      "epoch 2846 / 20000\n",
      "gradient norm: 0.06200437087682076, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00579\n",
      "\tval loss: 0.00567\n",
      "epoch 2847 / 20000\n",
      "gradient norm: 0.044916075916262344, minimum ratio: 2.5157894736842104\n",
      "\ttrain loss: 0.00580\n",
      "\tval loss: 0.00566\n",
      "epoch 2848 / 20000\n",
      "gradient norm: 0.052023834898136556, minimum ratio: 2.5105263157894737\n",
      "\ttrain loss: 0.00580\n",
      "\tval loss: 0.00565\n",
      "epoch 2849 / 20000\n",
      "gradient norm: 0.040745963546214625, minimum ratio: 2.5078947368421054\n",
      "\ttrain loss: 0.00579\n",
      "\tval loss: 0.00567\n",
      "epoch 2850 / 20000\n",
      "gradient norm: 0.09003459732048213, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00581\n",
      "\tval loss: 0.00566\n",
      "epoch 2851 / 20000\n",
      "gradient norm: 0.07660073303850368, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00579\n",
      "\tval loss: 0.00566\n",
      "epoch 2852 / 20000\n",
      "gradient norm: 0.1214478911133483, minimum ratio: 2.4842105263157896\n",
      "\ttrain loss: 0.00581\n",
      "\tval loss: 0.00565\n",
      "epoch 2853 / 20000\n",
      "gradient norm: 0.02504626798327081, minimum ratio: 2.507894736842105\n",
      "\ttrain loss: 0.00580\n",
      "\tval loss: 0.00567\n",
      "epoch 2854 / 20000\n",
      "gradient norm: 0.05644326648325659, minimum ratio: 2.5157894736842104\n",
      "\ttrain loss: 0.00579\n",
      "\tval loss: 0.00567\n",
      "epoch 2855 / 20000\n",
      "gradient norm: 0.11988512356765568, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00579\n",
      "\tval loss: 0.00565\n",
      "epoch 2856 / 20000\n",
      "gradient norm: 0.05180783891410101, minimum ratio: 2.5236842105263158\n",
      "\ttrain loss: 0.00577\n",
      "\tval loss: 0.00567\n",
      "epoch 2857 / 20000\n",
      "gradient norm: 0.12140475818887353, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00580\n",
      "\tval loss: 0.00568\n",
      "epoch 2858 / 20000\n",
      "gradient norm: 0.11065997031982988, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00579\n",
      "\tval loss: 0.00565\n",
      "epoch 2859 / 20000\n",
      "gradient norm: 0.053091641020728275, minimum ratio: 2.5289473684210524\n",
      "\ttrain loss: 0.00580\n",
      "\tval loss: 0.00566\n",
      "epoch 2860 / 20000\n",
      "gradient norm: 0.06909381435252726, minimum ratio: 2.5078947368421054\n",
      "\ttrain loss: 0.00580\n",
      "\tval loss: 0.00568\n",
      "epoch 2861 / 20000\n",
      "gradient norm: 0.0513600874110125, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00578\n",
      "\tval loss: 0.00565\n",
      "epoch 2862 / 20000\n",
      "gradient norm: 0.07619254087330773, minimum ratio: 2.505263157894737\n",
      "\ttrain loss: 0.00579\n",
      "\tval loss: 0.00565\n",
      "epoch 2863 / 20000\n",
      "gradient norm: 0.06853965780464932, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00579\n",
      "\tval loss: 0.00567\n",
      "epoch 2864 / 20000\n",
      "gradient norm: 0.06937091174768284, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00579\n",
      "\tval loss: 0.00565\n",
      "epoch 2865 / 20000\n",
      "gradient norm: 0.06724251882405952, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00579\n",
      "\tval loss: 0.00565\n",
      "epoch 2866 / 20000\n",
      "gradient norm: 0.04639446520013735, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00580\n",
      "\tval loss: 0.00566\n",
      "epoch 2867 / 20000\n",
      "gradient norm: 0.01967375722597353, minimum ratio: 2.5078947368421054\n",
      "\ttrain loss: 0.00578\n",
      "\tval loss: 0.00566\n",
      "epoch 2868 / 20000\n",
      "gradient norm: 0.08901992611936294, minimum ratio: 2.4868421052631575\n",
      "\ttrain loss: 0.00578\n",
      "\tval loss: 0.00566\n",
      "epoch 2869 / 20000\n",
      "gradient norm: 0.05999293435161235, minimum ratio: 2.4894736842105267\n",
      "\ttrain loss: 0.00578\n",
      "\tval loss: 0.00566\n",
      "epoch 2870 / 20000\n",
      "gradient norm: 0.05206329898283002, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00579\n",
      "\tval loss: 0.00565\n",
      "epoch 2871 / 20000\n",
      "gradient norm: 0.05601428863883484, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00579\n",
      "\tval loss: 0.00565\n",
      "epoch 2872 / 20000\n",
      "gradient norm: 0.08973231283016503, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00578\n",
      "\tval loss: 0.00566\n",
      "epoch 2873 / 20000\n",
      "gradient norm: 0.05780773393053096, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00580\n",
      "\tval loss: 0.00565\n",
      "epoch 2874 / 20000\n",
      "gradient norm: 0.03470461443066597, minimum ratio: 2.4894736842105267\n",
      "\ttrain loss: 0.00579\n",
      "\tval loss: 0.00566\n",
      "epoch 2875 / 20000\n",
      "gradient norm: 0.07524731836747378, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00580\n",
      "\tval loss: 0.00566\n",
      "epoch 2876 / 20000\n",
      "gradient norm: 0.0780451268365141, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00578\n",
      "\tval loss: 0.00566\n",
      "epoch 2877 / 20000\n",
      "gradient norm: 0.04651493040728383, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00579\n",
      "\tval loss: 0.00565\n",
      "epoch 2878 / 20000\n",
      "gradient norm: 0.07703408796805888, minimum ratio: 2.5210526315789474\n",
      "\ttrain loss: 0.00579\n",
      "\tval loss: 0.00565\n",
      "epoch 2879 / 20000\n",
      "gradient norm: 0.04673082570661791, minimum ratio: 2.5210526315789474\n",
      "\ttrain loss: 0.00580\n",
      "\tval loss: 0.00567\n",
      "epoch 2880 / 20000\n",
      "gradient norm: 0.08316011202987283, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00578\n",
      "\tval loss: 0.00566\n",
      "epoch 2881 / 20000\n",
      "gradient norm: 0.03429994665202685, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.00577\n",
      "\tval loss: 0.00565\n",
      "epoch 2882 / 20000\n",
      "gradient norm: 0.05184849014040083, minimum ratio: 2.5105263157894737\n",
      "\ttrain loss: 0.00579\n",
      "\tval loss: 0.00565\n",
      "epoch 2883 / 20000\n",
      "gradient norm: 0.024047286860877648, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00578\n",
      "\tval loss: 0.00566\n",
      "epoch 2884 / 20000\n",
      "gradient norm: 0.08878196842852049, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00578\n",
      "\tval loss: 0.00567\n",
      "epoch 2885 / 20000\n",
      "gradient norm: 0.11231414275243878, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00578\n",
      "\tval loss: 0.00565\n",
      "epoch 2886 / 20000\n",
      "gradient norm: 0.12334878306137398, minimum ratio: 2.505263157894737\n",
      "\ttrain loss: 0.00580\n",
      "\tval loss: 0.00564\n",
      "epoch 2887 / 20000\n",
      "gradient norm: 0.04503955319523811, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00578\n",
      "\tval loss: 0.00569\n",
      "epoch 2888 / 20000\n",
      "gradient norm: 0.09190757782198489, minimum ratio: 2.5131578947368425\n",
      "\ttrain loss: 0.00580\n",
      "\tval loss: 0.00567\n",
      "epoch 2889 / 20000\n",
      "gradient norm: 0.06112323951674625, minimum ratio: 2.507894736842105\n",
      "\ttrain loss: 0.00577\n",
      "\tval loss: 0.00564\n",
      "epoch 2890 / 20000\n",
      "gradient norm: 0.1386205576127395, minimum ratio: 2.507894736842105\n",
      "\ttrain loss: 0.00579\n",
      "\tval loss: 0.00565\n",
      "epoch 2891 / 20000\n",
      "gradient norm: 0.0955582255119225, minimum ratio: 2.5210526315789474\n",
      "\ttrain loss: 0.00581\n",
      "\tval loss: 0.00565\n",
      "epoch 2892 / 20000\n",
      "gradient norm: 0.059106042914208956, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00579\n",
      "\tval loss: 0.00567\n",
      "epoch 2893 / 20000\n",
      "gradient norm: 0.031989067647373304, minimum ratio: 2.518421052631579\n",
      "\ttrain loss: 0.00579\n",
      "\tval loss: 0.00565\n",
      "epoch 2894 / 20000\n",
      "gradient norm: 0.060317352079437114, minimum ratio: 2.494736842105263\n",
      "\ttrain loss: 0.00580\n",
      "\tval loss: 0.00564\n",
      "epoch 2895 / 20000\n",
      "gradient norm: 0.08756999589968473, minimum ratio: 2.5131578947368425\n",
      "\ttrain loss: 0.00579\n",
      "\tval loss: 0.00567\n",
      "epoch 2896 / 20000\n",
      "gradient norm: 0.06005987463868223, minimum ratio: 2.494736842105263\n",
      "\ttrain loss: 0.00579\n",
      "\tval loss: 0.00565\n",
      "epoch 2897 / 20000\n",
      "gradient norm: 0.14139391912613064, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00579\n",
      "\tval loss: 0.00565\n",
      "epoch 2898 / 20000\n",
      "gradient norm: 0.05039439641404897, minimum ratio: 2.5236842105263158\n",
      "\ttrain loss: 0.00580\n",
      "\tval loss: 0.00565\n",
      "epoch 2899 / 20000\n",
      "gradient norm: 0.06724250626575667, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00578\n",
      "\tval loss: 0.00566\n",
      "epoch 2900 / 20000\n",
      "gradient norm: 0.09241411066614091, minimum ratio: 2.5078947368421054\n",
      "\ttrain loss: 0.00579\n",
      "\tval loss: 0.00566\n",
      "epoch 2901 / 20000\n",
      "gradient norm: 0.06539476101170294, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00579\n",
      "\tval loss: 0.00564\n",
      "epoch 2902 / 20000\n",
      "gradient norm: 0.117834557662718, minimum ratio: 2.5157894736842104\n",
      "\ttrain loss: 0.00580\n",
      "\tval loss: 0.00564\n",
      "epoch 2903 / 20000\n",
      "gradient norm: 0.077360332958051, minimum ratio: 2.513157894736842\n",
      "\ttrain loss: 0.00580\n",
      "\tval loss: 0.00569\n",
      "epoch 2904 / 20000\n",
      "gradient norm: 0.06304375000763685, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00579\n",
      "\tval loss: 0.00565\n",
      "epoch 2905 / 20000\n",
      "gradient norm: 0.0956349580665119, minimum ratio: 2.5131578947368425\n",
      "\ttrain loss: 0.00579\n",
      "\tval loss: 0.00564\n",
      "epoch 2906 / 20000\n",
      "gradient norm: 0.10857903573196381, minimum ratio: 2.507894736842105\n",
      "\ttrain loss: 0.00580\n",
      "\tval loss: 0.00564\n",
      "epoch 2907 / 20000\n",
      "gradient norm: 0.09228191908914596, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00578\n",
      "\tval loss: 0.00567\n",
      "epoch 2908 / 20000\n",
      "gradient norm: 0.08466112887253985, minimum ratio: 2.5105263157894737\n",
      "\ttrain loss: 0.00580\n",
      "\tval loss: 0.00565\n",
      "epoch 2909 / 20000\n",
      "gradient norm: 0.062425247801002115, minimum ratio: 2.4868421052631575\n",
      "\ttrain loss: 0.00578\n",
      "\tval loss: 0.00564\n",
      "epoch 2910 / 20000\n",
      "gradient norm: 0.06134617608040571, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00579\n",
      "\tval loss: 0.00566\n",
      "epoch 2911 / 20000\n",
      "gradient norm: 0.04380727914394811, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00578\n",
      "\tval loss: 0.00565\n",
      "epoch 2912 / 20000\n",
      "gradient norm: 0.106570728297811, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00579\n",
      "\tval loss: 0.00565\n",
      "epoch 2913 / 20000\n",
      "gradient norm: 0.05802185579523211, minimum ratio: 2.518421052631579\n",
      "\ttrain loss: 0.00579\n",
      "\tval loss: 0.00565\n",
      "epoch 2914 / 20000\n",
      "gradient norm: 0.07137861999217421, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00578\n",
      "\tval loss: 0.00565\n",
      "epoch 2915 / 20000\n",
      "gradient norm: 0.04546943146851845, minimum ratio: 2.5105263157894737\n",
      "\ttrain loss: 0.00579\n",
      "\tval loss: 0.00565\n",
      "epoch 2916 / 20000\n",
      "gradient norm: 0.05580801219912246, minimum ratio: 2.5078947368421054\n",
      "\ttrain loss: 0.00577\n",
      "\tval loss: 0.00566\n",
      "epoch 2917 / 20000\n",
      "gradient norm: 0.04357129902928136, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00579\n",
      "\tval loss: 0.00565\n",
      "epoch 2918 / 20000\n",
      "gradient norm: 0.12263393320608884, minimum ratio: 2.5105263157894737\n",
      "\ttrain loss: 0.00578\n",
      "\tval loss: 0.00564\n",
      "epoch 2919 / 20000\n",
      "gradient norm: 0.07354050787398592, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00579\n",
      "\tval loss: 0.00565\n",
      "epoch 2920 / 20000\n",
      "gradient norm: 0.03261982515687123, minimum ratio: 2.518421052631579\n",
      "\ttrain loss: 0.00577\n",
      "\tval loss: 0.00565\n",
      "epoch 2921 / 20000\n",
      "gradient norm: 0.043518957623746246, minimum ratio: 2.5289473684210524\n",
      "\ttrain loss: 0.00578\n",
      "\tval loss: 0.00565\n",
      "epoch 2922 / 20000\n",
      "gradient norm: 0.07999177736928686, minimum ratio: 2.5105263157894733\n",
      "\ttrain loss: 0.00578\n",
      "\tval loss: 0.00566\n",
      "epoch 2923 / 20000\n",
      "gradient norm: 0.051562741718953475, minimum ratio: 2.492105263157895\n",
      "\ttrain loss: 0.00579\n",
      "\tval loss: 0.00565\n",
      "epoch 2924 / 20000\n",
      "gradient norm: 0.028200001557706855, minimum ratio: 2.5105263157894737\n",
      "\ttrain loss: 0.00579\n",
      "\tval loss: 0.00565\n",
      "epoch 2925 / 20000\n",
      "gradient norm: 0.031568872364005074, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00578\n",
      "\tval loss: 0.00565\n",
      "epoch 2926 / 20000\n",
      "gradient norm: 0.06028901622630656, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00579\n",
      "\tval loss: 0.00565\n",
      "epoch 2927 / 20000\n",
      "gradient norm: 0.10906548629282042, minimum ratio: 2.518421052631579\n",
      "\ttrain loss: 0.00579\n",
      "\tval loss: 0.00566\n",
      "epoch 2928 / 20000\n",
      "gradient norm: 0.08289195579709485, minimum ratio: 2.513157894736842\n",
      "\ttrain loss: 0.00579\n",
      "\tval loss: 0.00564\n",
      "epoch 2929 / 20000\n",
      "gradient norm: 0.03577445668634027, minimum ratio: 2.544736842105263\n",
      "\ttrain loss: 0.00577\n",
      "\tval loss: 0.00565\n",
      "epoch 2930 / 20000\n",
      "gradient norm: 0.03674550837604329, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00578\n",
      "\tval loss: 0.00566\n",
      "epoch 2931 / 20000\n",
      "gradient norm: 0.016927853648667224, minimum ratio: 2.518421052631579\n",
      "\ttrain loss: 0.00577\n",
      "\tval loss: 0.00565\n",
      "epoch 2932 / 20000\n",
      "gradient norm: 0.036935757962055504, minimum ratio: 2.5105263157894733\n",
      "\ttrain loss: 0.00579\n",
      "\tval loss: 0.00564\n",
      "epoch 2933 / 20000\n",
      "gradient norm: 0.06435736181447282, minimum ratio: 2.5236842105263158\n",
      "\ttrain loss: 0.00578\n",
      "\tval loss: 0.00566\n",
      "epoch 2934 / 20000\n",
      "gradient norm: 0.12908766546752304, minimum ratio: 2.5078947368421054\n",
      "\ttrain loss: 0.00578\n",
      "\tval loss: 0.00566\n",
      "epoch 2935 / 20000\n",
      "gradient norm: 0.03390375687740743, minimum ratio: 2.5236842105263158\n",
      "\ttrain loss: 0.00578\n",
      "\tval loss: 0.00564\n",
      "epoch 2936 / 20000\n",
      "gradient norm: 0.050600770802702755, minimum ratio: 2.515789473684211\n",
      "\ttrain loss: 0.00578\n",
      "\tval loss: 0.00565\n",
      "epoch 2937 / 20000\n",
      "gradient norm: 0.06131295417435467, minimum ratio: 2.507894736842105\n",
      "\ttrain loss: 0.00578\n",
      "\tval loss: 0.00566\n",
      "epoch 2938 / 20000\n",
      "gradient norm: 0.06840975178056397, minimum ratio: 2.492105263157895\n",
      "\ttrain loss: 0.00580\n",
      "\tval loss: 0.00564\n",
      "epoch 2939 / 20000\n",
      "gradient norm: 0.0443439271839452, minimum ratio: 2.5131578947368425\n",
      "\ttrain loss: 0.00577\n",
      "\tval loss: 0.00565\n",
      "epoch 2940 / 20000\n",
      "gradient norm: 0.04928512321203016, minimum ratio: 2.5157894736842104\n",
      "\ttrain loss: 0.00577\n",
      "\tval loss: 0.00565\n",
      "epoch 2941 / 20000\n",
      "gradient norm: 0.09320645991829224, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00580\n",
      "\tval loss: 0.00564\n",
      "epoch 2942 / 20000\n",
      "gradient norm: 0.04802594275679439, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.00578\n",
      "\tval loss: 0.00566\n",
      "epoch 2943 / 20000\n",
      "gradient norm: 0.05537982692476362, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00578\n",
      "\tval loss: 0.00566\n",
      "epoch 2944 / 20000\n",
      "gradient norm: 0.024987978584249504, minimum ratio: 2.518421052631579\n",
      "\ttrain loss: 0.00578\n",
      "\tval loss: 0.00564\n",
      "epoch 2945 / 20000\n",
      "gradient norm: 0.09202236752025783, minimum ratio: 2.515789473684211\n",
      "\ttrain loss: 0.00579\n",
      "\tval loss: 0.00564\n",
      "epoch 2946 / 20000\n",
      "gradient norm: 0.03621974412089912, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00578\n",
      "\tval loss: 0.00567\n",
      "epoch 2947 / 20000\n",
      "gradient norm: 0.06435161828994751, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00579\n",
      "\tval loss: 0.00565\n",
      "epoch 2948 / 20000\n",
      "gradient norm: 0.03634377187700011, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00578\n",
      "\tval loss: 0.00564\n",
      "epoch 2949 / 20000\n",
      "gradient norm: 0.06635745978564955, minimum ratio: 2.5078947368421054\n",
      "\ttrain loss: 0.00578\n",
      "\tval loss: 0.00564\n",
      "epoch 2950 / 20000\n",
      "gradient norm: 0.03513372951420024, minimum ratio: 2.5157894736842104\n",
      "\ttrain loss: 0.00577\n",
      "\tval loss: 0.00566\n",
      "epoch 2951 / 20000\n",
      "gradient norm: 0.05181124672526494, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00577\n",
      "\tval loss: 0.00565\n",
      "epoch 2952 / 20000\n",
      "gradient norm: 0.053580290579702705, minimum ratio: 2.5184210526315787\n",
      "\ttrain loss: 0.00577\n",
      "\tval loss: 0.00564\n",
      "epoch 2953 / 20000\n",
      "gradient norm: 0.06350055948132649, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.00578\n",
      "\tval loss: 0.00565\n",
      "epoch 2954 / 20000\n",
      "gradient norm: 0.07266760017955676, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00579\n",
      "\tval loss: 0.00566\n",
      "epoch 2955 / 20000\n",
      "gradient norm: 0.07020241022109985, minimum ratio: 2.5210526315789474\n",
      "\ttrain loss: 0.00578\n",
      "\tval loss: 0.00564\n",
      "epoch 2956 / 20000\n",
      "gradient norm: 0.08570122206583619, minimum ratio: 2.5131578947368425\n",
      "\ttrain loss: 0.00579\n",
      "\tval loss: 0.00564\n",
      "epoch 2957 / 20000\n",
      "gradient norm: 0.07590588615857996, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00578\n",
      "\tval loss: 0.00566\n",
      "epoch 2958 / 20000\n",
      "gradient norm: 0.07487189740641043, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00578\n",
      "\tval loss: 0.00564\n",
      "epoch 2959 / 20000\n",
      "gradient norm: 0.05455496138893068, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00578\n",
      "\tval loss: 0.00565\n",
      "epoch 2960 / 20000\n",
      "gradient norm: 0.07137624459573999, minimum ratio: 2.513157894736842\n",
      "\ttrain loss: 0.00578\n",
      "\tval loss: 0.00564\n",
      "epoch 2961 / 20000\n",
      "gradient norm: 0.08540725795319304, minimum ratio: 2.5131578947368425\n",
      "\ttrain loss: 0.00579\n",
      "\tval loss: 0.00565\n",
      "epoch 2962 / 20000\n",
      "gradient norm: 0.0737402553204447, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00579\n",
      "\tval loss: 0.00566\n",
      "epoch 2963 / 20000\n",
      "gradient norm: 0.05877761301235296, minimum ratio: 2.526315789473684\n",
      "\ttrain loss: 0.00578\n",
      "\tval loss: 0.00564\n",
      "epoch 2964 / 20000\n",
      "gradient norm: 0.09470588876865804, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00579\n",
      "\tval loss: 0.00564\n",
      "epoch 2965 / 20000\n",
      "gradient norm: 0.056333045242354274, minimum ratio: 2.5078947368421054\n",
      "\ttrain loss: 0.00578\n",
      "\tval loss: 0.00566\n",
      "epoch 2966 / 20000\n",
      "gradient norm: 0.0799723154923413, minimum ratio: 2.5289473684210524\n",
      "\ttrain loss: 0.00579\n",
      "\tval loss: 0.00565\n",
      "epoch 2967 / 20000\n",
      "gradient norm: 0.053047881068778224, minimum ratio: 2.4842105263157896\n",
      "\ttrain loss: 0.00578\n",
      "\tval loss: 0.00564\n",
      "epoch 2968 / 20000\n",
      "gradient norm: 0.059078473248519, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00578\n",
      "\tval loss: 0.00565\n",
      "epoch 2969 / 20000\n",
      "gradient norm: 0.0999572416767478, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00578\n",
      "\tval loss: 0.00566\n",
      "epoch 2970 / 20000\n",
      "gradient norm: 0.08455053484067321, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.00579\n",
      "\tval loss: 0.00563\n",
      "epoch 2971 / 20000\n",
      "gradient norm: 0.11285388842225075, minimum ratio: 2.5184210526315787\n",
      "\ttrain loss: 0.00578\n",
      "\tval loss: 0.00565\n",
      "epoch 2972 / 20000\n",
      "gradient norm: 0.042265848838724196, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00578\n",
      "\tval loss: 0.00564\n",
      "epoch 2973 / 20000\n",
      "gradient norm: 0.03946885818731971, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00578\n",
      "\tval loss: 0.00565\n",
      "epoch 2974 / 20000\n",
      "gradient norm: 0.017505030518805142, minimum ratio: 2.515789473684211\n",
      "\ttrain loss: 0.00578\n",
      "\tval loss: 0.00564\n",
      "epoch 2975 / 20000\n",
      "gradient norm: 0.04370363045018166, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00577\n",
      "\tval loss: 0.00564\n",
      "epoch 2976 / 20000\n",
      "gradient norm: 0.056750882024061866, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00577\n",
      "\tval loss: 0.00564\n",
      "epoch 2977 / 20000\n",
      "gradient norm: 0.02043603472702671, minimum ratio: 2.505263157894737\n",
      "\ttrain loss: 0.00577\n",
      "\tval loss: 0.00564\n",
      "epoch 2978 / 20000\n",
      "gradient norm: 0.01769977994263172, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00579\n",
      "\tval loss: 0.00565\n",
      "epoch 2979 / 20000\n",
      "gradient norm: 0.05377705843420699, minimum ratio: 2.518421052631579\n",
      "\ttrain loss: 0.00576\n",
      "\tval loss: 0.00565\n",
      "epoch 2980 / 20000\n",
      "gradient norm: 0.07265116089547519, minimum ratio: 2.518421052631579\n",
      "\ttrain loss: 0.00577\n",
      "\tval loss: 0.00564\n",
      "epoch 2981 / 20000\n",
      "gradient norm: 0.05663434874441009, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00578\n",
      "\tval loss: 0.00564\n",
      "epoch 2982 / 20000\n",
      "gradient norm: 0.08452106185723096, minimum ratio: 2.518421052631579\n",
      "\ttrain loss: 0.00577\n",
      "\tval loss: 0.00565\n",
      "epoch 2983 / 20000\n",
      "gradient norm: 0.04991817788686603, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.00578\n",
      "\tval loss: 0.00564\n",
      "epoch 2984 / 20000\n",
      "gradient norm: 0.09927188185974956, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00581\n",
      "\tval loss: 0.00564\n",
      "epoch 2985 / 20000\n",
      "gradient norm: 0.058309903513872996, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00579\n",
      "\tval loss: 0.00566\n",
      "epoch 2986 / 20000\n",
      "gradient norm: 0.07861813496128889, minimum ratio: 2.5157894736842104\n",
      "\ttrain loss: 0.00577\n",
      "\tval loss: 0.00564\n",
      "epoch 2987 / 20000\n",
      "gradient norm: 0.0754227259894833, minimum ratio: 2.5236842105263158\n",
      "\ttrain loss: 0.00578\n",
      "\tval loss: 0.00564\n",
      "epoch 2988 / 20000\n",
      "gradient norm: 0.05062236619414762, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00578\n",
      "\tval loss: 0.00564\n",
      "epoch 2989 / 20000\n",
      "gradient norm: 0.08325470067211427, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00578\n",
      "\tval loss: 0.00566\n",
      "epoch 2990 / 20000\n",
      "gradient norm: 0.06162325560580939, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00578\n",
      "\tval loss: 0.00564\n",
      "epoch 2991 / 20000\n",
      "gradient norm: 0.046482351346639916, minimum ratio: 2.513157894736842\n",
      "\ttrain loss: 0.00578\n",
      "\tval loss: 0.00564\n",
      "epoch 2992 / 20000\n",
      "gradient norm: 0.07916440349072218, minimum ratio: 2.5210526315789474\n",
      "\ttrain loss: 0.00578\n",
      "\tval loss: 0.00566\n",
      "epoch 2993 / 20000\n",
      "gradient norm: 0.06757206778274849, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00578\n",
      "\tval loss: 0.00564\n",
      "epoch 2994 / 20000\n",
      "gradient norm: 0.07926335345837288, minimum ratio: 2.5131578947368425\n",
      "\ttrain loss: 0.00577\n",
      "\tval loss: 0.00564\n",
      "epoch 2995 / 20000\n",
      "gradient norm: 0.06393679365282878, minimum ratio: 2.505263157894737\n",
      "\ttrain loss: 0.00577\n",
      "\tval loss: 0.00564\n",
      "epoch 2996 / 20000\n",
      "gradient norm: 0.08283146854955703, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00578\n",
      "\tval loss: 0.00564\n",
      "epoch 2997 / 20000\n",
      "gradient norm: 0.09416095650522038, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00578\n",
      "\tval loss: 0.00566\n",
      "epoch 2998 / 20000\n",
      "gradient norm: 0.09443597277277149, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00579\n",
      "\tval loss: 0.00563\n",
      "epoch 2999 / 20000\n",
      "gradient norm: 0.06149485753849149, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00578\n",
      "\tval loss: 0.00565\n",
      "epoch 3000 / 20000\n",
      "gradient norm: 0.060010108281858265, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00578\n",
      "\tval loss: 0.00565\n",
      "epoch 3001 / 20000\n",
      "gradient norm: 0.05577652377542108, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00578\n",
      "\tval loss: 0.00563\n",
      "epoch 3002 / 20000\n",
      "gradient norm: 0.02846476703416556, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00578\n",
      "\tval loss: 0.00565\n",
      "epoch 3003 / 20000\n",
      "gradient norm: 0.040528223384171724, minimum ratio: 2.5157894736842104\n",
      "\ttrain loss: 0.00578\n",
      "\tval loss: 0.00565\n",
      "epoch 3004 / 20000\n",
      "gradient norm: 0.04536636988632381, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00578\n",
      "\tval loss: 0.00564\n",
      "epoch 3005 / 20000\n",
      "gradient norm: 0.060246321867452934, minimum ratio: 2.518421052631579\n",
      "\ttrain loss: 0.00577\n",
      "\tval loss: 0.00564\n",
      "epoch 3006 / 20000\n",
      "gradient norm: 0.08519812696613371, minimum ratio: 2.5210526315789474\n",
      "\ttrain loss: 0.00578\n",
      "\tval loss: 0.00564\n",
      "epoch 3007 / 20000\n",
      "gradient norm: 0.09104421004303731, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00578\n",
      "\tval loss: 0.00565\n",
      "epoch 3008 / 20000\n",
      "gradient norm: 0.06362514664942864, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00579\n",
      "\tval loss: 0.00563\n",
      "epoch 3009 / 20000\n",
      "gradient norm: 0.05279756273375824, minimum ratio: 2.5236842105263158\n",
      "\ttrain loss: 0.00578\n",
      "\tval loss: 0.00563\n",
      "epoch 3010 / 20000\n",
      "gradient norm: 0.05326972954208031, minimum ratio: 2.4842105263157896\n",
      "\ttrain loss: 0.00577\n",
      "\tval loss: 0.00566\n",
      "epoch 3011 / 20000\n",
      "gradient norm: 0.038150520664203214, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00578\n",
      "\tval loss: 0.00564\n",
      "epoch 3012 / 20000\n",
      "gradient norm: 0.08834394218865782, minimum ratio: 2.5131578947368425\n",
      "\ttrain loss: 0.00579\n",
      "\tval loss: 0.00563\n",
      "epoch 3013 / 20000\n",
      "gradient norm: 0.08722910805954598, minimum ratio: 2.518421052631579\n",
      "\ttrain loss: 0.00578\n",
      "\tval loss: 0.00565\n",
      "epoch 3014 / 20000\n",
      "gradient norm: 0.12028780147375073, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00580\n",
      "\tval loss: 0.00563\n",
      "epoch 3015 / 20000\n",
      "gradient norm: 0.04644440609263256, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00578\n",
      "\tval loss: 0.00564\n",
      "epoch 3016 / 20000\n",
      "gradient norm: 0.04264239425538108, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.00578\n",
      "\tval loss: 0.00564\n",
      "epoch 3017 / 20000\n",
      "gradient norm: 0.1398494653403759, minimum ratio: 2.505263157894737\n",
      "\ttrain loss: 0.00576\n",
      "\tval loss: 0.00564\n",
      "epoch 3018 / 20000\n",
      "gradient norm: 0.016189847156056203, minimum ratio: 2.5289473684210524\n",
      "\ttrain loss: 0.00578\n",
      "\tval loss: 0.00564\n",
      "epoch 3019 / 20000\n",
      "gradient norm: 0.0670661628828384, minimum ratio: 2.5078947368421054\n",
      "\ttrain loss: 0.00578\n",
      "\tval loss: 0.00564\n",
      "epoch 3020 / 20000\n",
      "gradient norm: 0.058729981232318096, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00576\n",
      "\tval loss: 0.00563\n",
      "epoch 3021 / 20000\n",
      "gradient norm: 0.06916882723453455, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.00578\n",
      "\tval loss: 0.00563\n",
      "epoch 3022 / 20000\n",
      "gradient norm: 0.09008452529087663, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00579\n",
      "\tval loss: 0.00564\n",
      "epoch 3023 / 20000\n",
      "gradient norm: 0.06117742229253054, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00578\n",
      "\tval loss: 0.00566\n",
      "epoch 3024 / 20000\n",
      "gradient norm: 0.07924778503365815, minimum ratio: 2.494736842105263\n",
      "\ttrain loss: 0.00578\n",
      "\tval loss: 0.00564\n",
      "epoch 3025 / 20000\n",
      "gradient norm: 0.060759678541217, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00577\n",
      "\tval loss: 0.00564\n",
      "epoch 3026 / 20000\n",
      "gradient norm: 0.019175664492649958, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00577\n",
      "\tval loss: 0.00564\n",
      "epoch 3027 / 20000\n",
      "gradient norm: 0.08986332005588338, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00578\n",
      "\tval loss: 0.00564\n",
      "epoch 3028 / 20000\n",
      "gradient norm: 0.02481784063274972, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.00577\n",
      "\tval loss: 0.00564\n",
      "epoch 3029 / 20000\n",
      "gradient norm: 0.06173500750446692, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00578\n",
      "\tval loss: 0.00564\n",
      "epoch 3030 / 20000\n",
      "gradient norm: 0.06147613498615101, minimum ratio: 2.4842105263157896\n",
      "\ttrain loss: 0.00577\n",
      "\tval loss: 0.00564\n",
      "epoch 3031 / 20000\n",
      "gradient norm: 0.11553217156324536, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00578\n",
      "\tval loss: 0.00563\n",
      "epoch 3032 / 20000\n",
      "gradient norm: 0.04001305662677623, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00577\n",
      "\tval loss: 0.00565\n",
      "epoch 3033 / 20000\n",
      "gradient norm: 0.06125458440510556, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00578\n",
      "\tval loss: 0.00564\n",
      "epoch 3034 / 20000\n",
      "gradient norm: 0.05514027155004442, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00578\n",
      "\tval loss: 0.00563\n",
      "epoch 3035 / 20000\n",
      "gradient norm: 0.04546116884739604, minimum ratio: 2.5078947368421054\n",
      "\ttrain loss: 0.00577\n",
      "\tval loss: 0.00564\n",
      "epoch 3036 / 20000\n",
      "gradient norm: 0.05254919041180983, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00578\n",
      "\tval loss: 0.00565\n",
      "epoch 3037 / 20000\n",
      "gradient norm: 0.03378439031075686, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00575\n",
      "\tval loss: 0.00563\n",
      "epoch 3038 / 20000\n",
      "gradient norm: 0.04446716138772899, minimum ratio: 2.5210526315789474\n",
      "\ttrain loss: 0.00577\n",
      "\tval loss: 0.00564\n",
      "epoch 3039 / 20000\n",
      "gradient norm: 0.06940154760377482, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00578\n",
      "\tval loss: 0.00564\n",
      "epoch 3040 / 20000\n",
      "gradient norm: 0.026105066877789795, minimum ratio: 2.5131578947368416\n",
      "\ttrain loss: 0.00578\n",
      "\tval loss: 0.00563\n",
      "epoch 3041 / 20000\n",
      "gradient norm: 0.06160637334687635, minimum ratio: 2.5210526315789474\n",
      "\ttrain loss: 0.00578\n",
      "\tval loss: 0.00563\n",
      "epoch 3042 / 20000\n",
      "gradient norm: 0.05131876314408146, minimum ratio: 2.492105263157895\n",
      "\ttrain loss: 0.00578\n",
      "\tval loss: 0.00565\n",
      "epoch 3043 / 20000\n",
      "gradient norm: 0.04450197736150585, minimum ratio: 2.5210526315789474\n",
      "\ttrain loss: 0.00577\n",
      "\tval loss: 0.00564\n",
      "epoch 3044 / 20000\n",
      "gradient norm: 0.0752968771266751, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00576\n",
      "\tval loss: 0.00563\n",
      "epoch 3045 / 20000\n",
      "gradient norm: 0.11565201132179936, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00578\n",
      "\tval loss: 0.00563\n",
      "epoch 3046 / 20000\n",
      "gradient norm: 0.05061330282478593, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00576\n",
      "\tval loss: 0.00566\n",
      "epoch 3047 / 20000\n",
      "gradient norm: 0.09551614057272673, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00577\n",
      "\tval loss: 0.00563\n",
      "epoch 3048 / 20000\n",
      "gradient norm: 0.07399760955013335, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00577\n",
      "\tval loss: 0.00563\n",
      "epoch 3049 / 20000\n",
      "gradient norm: 0.07740881672361866, minimum ratio: 2.507894736842106\n",
      "\ttrain loss: 0.00578\n",
      "\tval loss: 0.00566\n",
      "epoch 3050 / 20000\n",
      "gradient norm: 0.027337372215697542, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00578\n",
      "\tval loss: 0.00563\n",
      "epoch 3051 / 20000\n",
      "gradient norm: 0.09094221808481961, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00578\n",
      "\tval loss: 0.00564\n",
      "epoch 3052 / 20000\n",
      "gradient norm: 0.11096099100541323, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00576\n",
      "\tval loss: 0.00563\n",
      "epoch 3053 / 20000\n",
      "gradient norm: 0.056347223930060863, minimum ratio: 2.5105263157894737\n",
      "\ttrain loss: 0.00577\n",
      "\tval loss: 0.00565\n",
      "epoch 3054 / 20000\n",
      "gradient norm: 0.09064975619548932, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00579\n",
      "\tval loss: 0.00563\n",
      "epoch 3055 / 20000\n",
      "gradient norm: 0.06836661719717085, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00576\n",
      "\tval loss: 0.00564\n",
      "epoch 3056 / 20000\n",
      "gradient norm: 0.04542639266583137, minimum ratio: 2.518421052631579\n",
      "\ttrain loss: 0.00578\n",
      "\tval loss: 0.00563\n",
      "epoch 3057 / 20000\n",
      "gradient norm: 0.08929828321561217, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00577\n",
      "\tval loss: 0.00564\n",
      "epoch 3058 / 20000\n",
      "gradient norm: 0.1281372785451822, minimum ratio: 2.5105263157894737\n",
      "\ttrain loss: 0.00579\n",
      "\tval loss: 0.00563\n",
      "epoch 3059 / 20000\n",
      "gradient norm: 0.09159364918014035, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00578\n",
      "\tval loss: 0.00566\n",
      "epoch 3060 / 20000\n",
      "gradient norm: 0.08733338536694646, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.00578\n",
      "\tval loss: 0.00563\n",
      "epoch 3061 / 20000\n",
      "gradient norm: 0.06543714908184484, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00577\n",
      "\tval loss: 0.00563\n",
      "epoch 3062 / 20000\n",
      "gradient norm: 0.027816549554700032, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00576\n",
      "\tval loss: 0.00564\n",
      "epoch 3063 / 20000\n",
      "gradient norm: 0.042800086303032, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00577\n",
      "\tval loss: 0.00564\n",
      "epoch 3064 / 20000\n",
      "gradient norm: 0.037734084558906034, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00578\n",
      "\tval loss: 0.00563\n",
      "epoch 3065 / 20000\n",
      "gradient norm: 0.0711883931508055, minimum ratio: 2.5236842105263158\n",
      "\ttrain loss: 0.00576\n",
      "\tval loss: 0.00563\n",
      "epoch 3066 / 20000\n",
      "gradient norm: 0.11442593159154058, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00577\n",
      "\tval loss: 0.00563\n",
      "epoch 3067 / 20000\n",
      "gradient norm: 0.05416621366748586, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00576\n",
      "\tval loss: 0.00564\n",
      "epoch 3068 / 20000\n",
      "gradient norm: 0.047683107666671276, minimum ratio: 2.5210526315789474\n",
      "\ttrain loss: 0.00579\n",
      "\tval loss: 0.00563\n",
      "epoch 3069 / 20000\n",
      "gradient norm: 0.0711268991290126, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00575\n",
      "\tval loss: 0.00563\n",
      "epoch 3070 / 20000\n",
      "gradient norm: 0.04836420828360133, minimum ratio: 2.492105263157895\n",
      "\ttrain loss: 0.00577\n",
      "\tval loss: 0.00563\n",
      "epoch 3071 / 20000\n",
      "gradient norm: 0.09757212572731078, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00576\n",
      "\tval loss: 0.00564\n",
      "epoch 3072 / 20000\n",
      "gradient norm: 0.03456946712685749, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00577\n",
      "\tval loss: 0.00564\n",
      "epoch 3073 / 20000\n",
      "gradient norm: 0.1504216983448714, minimum ratio: 2.4842105263157896\n",
      "\ttrain loss: 0.00579\n",
      "\tval loss: 0.00563\n",
      "epoch 3074 / 20000\n",
      "gradient norm: 0.04571756039513275, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00577\n",
      "\tval loss: 0.00565\n",
      "epoch 3075 / 20000\n",
      "gradient norm: 0.1333547523827292, minimum ratio: 2.4894736842105267\n",
      "\ttrain loss: 0.00579\n",
      "\tval loss: 0.00566\n",
      "epoch 3076 / 20000\n",
      "gradient norm: 0.051698788156500086, minimum ratio: 2.5105263157894733\n",
      "\ttrain loss: 0.00575\n",
      "\tval loss: 0.00563\n",
      "epoch 3077 / 20000\n",
      "gradient norm: 0.14997038675937802, minimum ratio: 2.5210526315789474\n",
      "\ttrain loss: 0.00579\n",
      "\tval loss: 0.00564\n",
      "epoch 3078 / 20000\n",
      "gradient norm: 0.09869030659319833, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00577\n",
      "\tval loss: 0.00564\n",
      "epoch 3079 / 20000\n",
      "gradient norm: 0.026084467011969537, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00577\n",
      "\tval loss: 0.00563\n",
      "epoch 3080 / 20000\n",
      "gradient norm: 0.062115684093441814, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00577\n",
      "\tval loss: 0.00563\n",
      "epoch 3081 / 20000\n",
      "gradient norm: 0.0699664838030003, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00576\n",
      "\tval loss: 0.00563\n",
      "epoch 3082 / 20000\n",
      "gradient norm: 0.03904606525611598, minimum ratio: 2.507894736842105\n",
      "\ttrain loss: 0.00578\n",
      "\tval loss: 0.00564\n",
      "epoch 3083 / 20000\n",
      "gradient norm: 0.06784643424907699, minimum ratio: 2.5236842105263158\n",
      "\ttrain loss: 0.00576\n",
      "\tval loss: 0.00564\n",
      "epoch 3084 / 20000\n",
      "gradient norm: 0.05051120100688422, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00577\n",
      "\tval loss: 0.00563\n",
      "epoch 3085 / 20000\n",
      "gradient norm: 0.028933545429026708, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00575\n",
      "\tval loss: 0.00563\n",
      "epoch 3086 / 20000\n",
      "gradient norm: 0.09511052875313908, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00575\n",
      "\tval loss: 0.00565\n",
      "epoch 3087 / 20000\n",
      "gradient norm: 0.0648873187310528, minimum ratio: 2.4868421052631584\n",
      "\ttrain loss: 0.00576\n",
      "\tval loss: 0.00563\n",
      "epoch 3088 / 20000\n",
      "gradient norm: 0.14046503824647516, minimum ratio: 2.5394736842105265\n",
      "\ttrain loss: 0.00578\n",
      "\tval loss: 0.00562\n",
      "epoch 3089 / 20000\n",
      "gradient norm: 0.07116643860354088, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00577\n",
      "\tval loss: 0.00566\n",
      "epoch 3090 / 20000\n",
      "gradient norm: 0.07501141628017649, minimum ratio: 2.5131578947368425\n",
      "\ttrain loss: 0.00577\n",
      "\tval loss: 0.00564\n",
      "epoch 3091 / 20000\n",
      "gradient norm: 0.07233046065084636, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00577\n",
      "\tval loss: 0.00562\n",
      "epoch 3092 / 20000\n",
      "gradient norm: 0.0481889778166078, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00578\n",
      "\tval loss: 0.00564\n",
      "epoch 3093 / 20000\n",
      "gradient norm: 0.05569293105509132, minimum ratio: 2.5078947368421054\n",
      "\ttrain loss: 0.00577\n",
      "\tval loss: 0.00565\n",
      "epoch 3094 / 20000\n",
      "gradient norm: 0.10497147461865097, minimum ratio: 2.4868421052631575\n",
      "\ttrain loss: 0.00578\n",
      "\tval loss: 0.00563\n",
      "epoch 3095 / 20000\n",
      "gradient norm: 0.024391570994339418, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00577\n",
      "\tval loss: 0.00563\n",
      "epoch 3096 / 20000\n",
      "gradient norm: 0.03462468192446977, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00577\n",
      "\tval loss: 0.00564\n",
      "epoch 3097 / 20000\n",
      "gradient norm: 0.03155582048930228, minimum ratio: 2.5078947368421054\n",
      "\ttrain loss: 0.00577\n",
      "\tval loss: 0.00563\n",
      "epoch 3098 / 20000\n",
      "gradient norm: 0.07474981731502339, minimum ratio: 2.492105263157895\n",
      "\ttrain loss: 0.00577\n",
      "\tval loss: 0.00563\n",
      "epoch 3099 / 20000\n",
      "gradient norm: 0.062164810369722545, minimum ratio: 2.5078947368421054\n",
      "\ttrain loss: 0.00577\n",
      "\tval loss: 0.00563\n",
      "epoch 3100 / 20000\n",
      "gradient norm: 0.07592861872399226, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00576\n",
      "\tval loss: 0.00564\n",
      "epoch 3101 / 20000\n",
      "gradient norm: 0.08242749062628718, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00577\n",
      "\tval loss: 0.00563\n",
      "epoch 3102 / 20000\n",
      "gradient norm: 0.08319068641867489, minimum ratio: 2.494736842105263\n",
      "\ttrain loss: 0.00578\n",
      "\tval loss: 0.00563\n",
      "epoch 3103 / 20000\n",
      "gradient norm: 0.02619548594520893, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00577\n",
      "\tval loss: 0.00563\n",
      "epoch 3104 / 20000\n",
      "gradient norm: 0.02946566253740457, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00576\n",
      "\tval loss: 0.00563\n",
      "epoch 3105 / 20000\n",
      "gradient norm: 0.05647381677408703, minimum ratio: 2.5105263157894737\n",
      "\ttrain loss: 0.00576\n",
      "\tval loss: 0.00563\n",
      "epoch 3106 / 20000\n",
      "gradient norm: 0.023637131846044213, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00576\n",
      "\tval loss: 0.00563\n",
      "epoch 3107 / 20000\n",
      "gradient norm: 0.033962587691348745, minimum ratio: 2.507894736842105\n",
      "\ttrain loss: 0.00576\n",
      "\tval loss: 0.00563\n",
      "epoch 3108 / 20000\n",
      "gradient norm: 0.08398172981105745, minimum ratio: 2.5131578947368425\n",
      "\ttrain loss: 0.00577\n",
      "\tval loss: 0.00563\n",
      "epoch 3109 / 20000\n",
      "gradient norm: 0.12140740844188258, minimum ratio: 2.507894736842105\n",
      "\ttrain loss: 0.00577\n",
      "\tval loss: 0.00565\n",
      "epoch 3110 / 20000\n",
      "gradient norm: 0.05758042325032875, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00577\n",
      "\tval loss: 0.00562\n",
      "epoch 3111 / 20000\n",
      "gradient norm: 0.06915578994085081, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00578\n",
      "\tval loss: 0.00562\n",
      "epoch 3112 / 20000\n",
      "gradient norm: 0.06085132202133536, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00578\n",
      "\tval loss: 0.00565\n",
      "epoch 3113 / 20000\n",
      "gradient norm: 0.08018152607837692, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00578\n",
      "\tval loss: 0.00563\n",
      "epoch 3114 / 20000\n",
      "gradient norm: 0.03543633896333631, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00576\n",
      "\tval loss: 0.00563\n",
      "epoch 3115 / 20000\n",
      "gradient norm: 0.03941900790960062, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00575\n",
      "\tval loss: 0.00563\n",
      "epoch 3116 / 20000\n",
      "gradient norm: 0.06877168826758862, minimum ratio: 2.4868421052631575\n",
      "\ttrain loss: 0.00577\n",
      "\tval loss: 0.00563\n",
      "epoch 3117 / 20000\n",
      "gradient norm: 0.028819901366659906, minimum ratio: 2.518421052631579\n",
      "\ttrain loss: 0.00576\n",
      "\tval loss: 0.00563\n",
      "epoch 3118 / 20000\n",
      "gradient norm: 0.10649011342320591, minimum ratio: 2.528947368421053\n",
      "\ttrain loss: 0.00577\n",
      "\tval loss: 0.00563\n",
      "epoch 3119 / 20000\n",
      "gradient norm: 0.03503207330140867, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00577\n",
      "\tval loss: 0.00563\n",
      "epoch 3120 / 20000\n",
      "gradient norm: 0.055012473225360736, minimum ratio: 2.5210526315789474\n",
      "\ttrain loss: 0.00577\n",
      "\tval loss: 0.00563\n",
      "epoch 3121 / 20000\n",
      "gradient norm: 0.10993387152120704, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00578\n",
      "\tval loss: 0.00563\n",
      "epoch 3122 / 20000\n",
      "gradient norm: 0.055058371217455715, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00576\n",
      "\tval loss: 0.00565\n",
      "epoch 3123 / 20000\n",
      "gradient norm: 0.10132054117275402, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00578\n",
      "\tval loss: 0.00562\n",
      "epoch 3124 / 20000\n",
      "gradient norm: 0.06742756336461753, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00575\n",
      "\tval loss: 0.00563\n",
      "epoch 3125 / 20000\n",
      "gradient norm: 0.053499884612392634, minimum ratio: 2.518421052631579\n",
      "\ttrain loss: 0.00577\n",
      "\tval loss: 0.00563\n",
      "epoch 3126 / 20000\n",
      "gradient norm: 0.0565239120478509, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00576\n",
      "\tval loss: 0.00563\n",
      "epoch 3127 / 20000\n",
      "gradient norm: 0.05280356598086655, minimum ratio: 2.507894736842105\n",
      "\ttrain loss: 0.00578\n",
      "\tval loss: 0.00562\n",
      "epoch 3128 / 20000\n",
      "gradient norm: 0.08050925814313814, minimum ratio: 2.492105263157895\n",
      "\ttrain loss: 0.00578\n",
      "\tval loss: 0.00564\n",
      "epoch 3129 / 20000\n",
      "gradient norm: 0.07292500635958277, minimum ratio: 2.4842105263157896\n",
      "\ttrain loss: 0.00577\n",
      "\tval loss: 0.00563\n",
      "epoch 3130 / 20000\n",
      "gradient norm: 0.08901062730001286, minimum ratio: 2.507894736842105\n",
      "\ttrain loss: 0.00575\n",
      "\tval loss: 0.00562\n",
      "epoch 3131 / 20000\n",
      "gradient norm: 0.07759148156037554, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00577\n",
      "\tval loss: 0.00564\n",
      "epoch 3132 / 20000\n",
      "gradient norm: 0.081292776245391, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00577\n",
      "\tval loss: 0.00562\n",
      "epoch 3133 / 20000\n",
      "gradient norm: 0.06633359531406313, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00576\n",
      "\tval loss: 0.00563\n",
      "epoch 3134 / 20000\n",
      "gradient norm: 0.057245924122980796, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00576\n",
      "\tval loss: 0.00564\n",
      "epoch 3135 / 20000\n",
      "gradient norm: 0.0426500748435501, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00576\n",
      "\tval loss: 0.00563\n",
      "epoch 3136 / 20000\n",
      "gradient norm: 0.06287675944622606, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00577\n",
      "\tval loss: 0.00563\n",
      "epoch 3137 / 20000\n",
      "gradient norm: 0.032816803104651626, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00576\n",
      "\tval loss: 0.00563\n",
      "epoch 3138 / 20000\n",
      "gradient norm: 0.0940298578934744, minimum ratio: 2.5105263157894737\n",
      "\ttrain loss: 0.00577\n",
      "\tval loss: 0.00564\n",
      "epoch 3139 / 20000\n",
      "gradient norm: 0.06350620641023852, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00577\n",
      "\tval loss: 0.00562\n",
      "epoch 3140 / 20000\n",
      "gradient norm: 0.06477755220839754, minimum ratio: 2.4894736842105267\n",
      "\ttrain loss: 0.00577\n",
      "\tval loss: 0.00562\n",
      "epoch 3141 / 20000\n",
      "gradient norm: 0.12479898246238008, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00577\n",
      "\tval loss: 0.00567\n",
      "epoch 3142 / 20000\n",
      "gradient norm: 0.13224571431055665, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00575\n",
      "\tval loss: 0.00562\n",
      "epoch 3143 / 20000\n",
      "gradient norm: 0.08616544347023591, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00576\n",
      "\tval loss: 0.00562\n",
      "epoch 3144 / 20000\n",
      "gradient norm: 0.057809154386632144, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00576\n",
      "\tval loss: 0.00564\n",
      "epoch 3145 / 20000\n",
      "gradient norm: 0.07619582043844275, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00577\n",
      "\tval loss: 0.00565\n",
      "epoch 3146 / 20000\n",
      "gradient norm: 0.02644767593301367, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00575\n",
      "\tval loss: 0.00562\n",
      "epoch 3147 / 20000\n",
      "gradient norm: 0.0883047254756093, minimum ratio: 2.5210526315789474\n",
      "\ttrain loss: 0.00576\n",
      "\tval loss: 0.00562\n",
      "epoch 3148 / 20000\n",
      "gradient norm: 0.05798603099538013, minimum ratio: 2.513157894736842\n",
      "\ttrain loss: 0.00575\n",
      "\tval loss: 0.00563\n",
      "epoch 3149 / 20000\n",
      "gradient norm: 0.08780254353769124, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00578\n",
      "\tval loss: 0.00564\n",
      "epoch 3150 / 20000\n",
      "gradient norm: 0.09898970345966518, minimum ratio: 2.510526315789474\n",
      "\ttrain loss: 0.00578\n",
      "\tval loss: 0.00562\n",
      "epoch 3151 / 20000\n",
      "gradient norm: 0.05969380401074886, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00578\n",
      "\tval loss: 0.00562\n",
      "epoch 3152 / 20000\n",
      "gradient norm: 0.11431552027352154, minimum ratio: 2.5105263157894737\n",
      "\ttrain loss: 0.00578\n",
      "\tval loss: 0.00567\n",
      "epoch 3153 / 20000\n",
      "gradient norm: 0.038774649117840454, minimum ratio: 2.507894736842105\n",
      "\ttrain loss: 0.00576\n",
      "\tval loss: 0.00562\n",
      "epoch 3154 / 20000\n",
      "gradient norm: 0.08537833986338228, minimum ratio: 2.5105263157894737\n",
      "\ttrain loss: 0.00578\n",
      "\tval loss: 0.00562\n",
      "epoch 3155 / 20000\n",
      "gradient norm: 0.033862083713756874, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00577\n",
      "\tval loss: 0.00564\n",
      "epoch 3156 / 20000\n",
      "gradient norm: 0.062384274729993194, minimum ratio: 2.5289473684210524\n",
      "\ttrain loss: 0.00576\n",
      "\tval loss: 0.00564\n",
      "epoch 3157 / 20000\n",
      "gradient norm: 0.055143837846117094, minimum ratio: 2.5105263157894737\n",
      "\ttrain loss: 0.00575\n",
      "\tval loss: 0.00562\n",
      "epoch 3158 / 20000\n",
      "gradient norm: 0.06575166224502027, minimum ratio: 2.4868421052631575\n",
      "\ttrain loss: 0.00578\n",
      "\tval loss: 0.00562\n",
      "epoch 3159 / 20000\n",
      "gradient norm: 0.07570058638521004, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00577\n",
      "\tval loss: 0.00564\n",
      "epoch 3160 / 20000\n",
      "gradient norm: 0.052931087666365784, minimum ratio: 2.5078947368421054\n",
      "\ttrain loss: 0.00577\n",
      "\tval loss: 0.00562\n",
      "epoch 3161 / 20000\n",
      "gradient norm: 0.04875557474588277, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00575\n",
      "\tval loss: 0.00562\n",
      "epoch 3162 / 20000\n",
      "gradient norm: 0.11379783623851836, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00577\n",
      "\tval loss: 0.00563\n",
      "epoch 3163 / 20000\n",
      "gradient norm: 0.09790734900161624, minimum ratio: 2.5131578947368425\n",
      "\ttrain loss: 0.00576\n",
      "\tval loss: 0.00563\n",
      "epoch 3164 / 20000\n",
      "gradient norm: 0.10219137649983168, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00576\n",
      "\tval loss: 0.00562\n",
      "epoch 3165 / 20000\n",
      "gradient norm: 0.09020036115543917, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00577\n",
      "\tval loss: 0.00563\n",
      "epoch 3166 / 20000\n",
      "gradient norm: 0.09713182505220175, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00577\n",
      "\tval loss: 0.00562\n",
      "epoch 3167 / 20000\n",
      "gradient norm: 0.026157604712352622, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00577\n",
      "\tval loss: 0.00563\n",
      "epoch 3168 / 20000\n",
      "gradient norm: 0.0805651485134149, minimum ratio: 2.4894736842105267\n",
      "\ttrain loss: 0.00577\n",
      "\tval loss: 0.00563\n",
      "epoch 3169 / 20000\n",
      "gradient norm: 0.02624171899515204, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00576\n",
      "\tval loss: 0.00562\n",
      "epoch 3170 / 20000\n",
      "gradient norm: 0.06253107759403065, minimum ratio: 2.518421052631579\n",
      "\ttrain loss: 0.00577\n",
      "\tval loss: 0.00562\n",
      "epoch 3171 / 20000\n",
      "gradient norm: 0.03889292242820375, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00577\n",
      "\tval loss: 0.00563\n",
      "epoch 3172 / 20000\n",
      "gradient norm: 0.16459381475578994, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00578\n",
      "\tval loss: 0.00563\n",
      "epoch 3173 / 20000\n",
      "gradient norm: 0.058656938461354, minimum ratio: 2.4842105263157896\n",
      "\ttrain loss: 0.00576\n",
      "\tval loss: 0.00562\n",
      "epoch 3174 / 20000\n",
      "gradient norm: 0.039395998552208766, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00577\n",
      "\tval loss: 0.00562\n",
      "epoch 3175 / 20000\n",
      "gradient norm: 0.10899714019615203, minimum ratio: 2.5236842105263158\n",
      "\ttrain loss: 0.00575\n",
      "\tval loss: 0.00563\n",
      "epoch 3176 / 20000\n",
      "gradient norm: 0.08591352391522378, minimum ratio: 2.4868421052631575\n",
      "\ttrain loss: 0.00578\n",
      "\tval loss: 0.00563\n",
      "epoch 3177 / 20000\n",
      "gradient norm: 0.047496547747869045, minimum ratio: 2.531578947368421\n",
      "\ttrain loss: 0.00576\n",
      "\tval loss: 0.00562\n",
      "epoch 3178 / 20000\n",
      "gradient norm: 0.09039340031449683, minimum ratio: 2.5105263157894737\n",
      "\ttrain loss: 0.00576\n",
      "\tval loss: 0.00563\n",
      "epoch 3179 / 20000\n",
      "gradient norm: 0.07148003505426459, minimum ratio: 2.5236842105263158\n",
      "\ttrain loss: 0.00577\n",
      "\tval loss: 0.00563\n",
      "epoch 3180 / 20000\n",
      "gradient norm: 0.017298248363658786, minimum ratio: 2.528947368421053\n",
      "\ttrain loss: 0.00577\n",
      "\tval loss: 0.00562\n",
      "epoch 3181 / 20000\n",
      "gradient norm: 0.03707874895189889, minimum ratio: 2.4894736842105267\n",
      "\ttrain loss: 0.00576\n",
      "\tval loss: 0.00562\n",
      "epoch 3182 / 20000\n",
      "gradient norm: 0.05560075060930103, minimum ratio: 2.5105263157894737\n",
      "\ttrain loss: 0.00576\n",
      "\tval loss: 0.00562\n",
      "epoch 3183 / 20000\n",
      "gradient norm: 0.08913508930709213, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00575\n",
      "\tval loss: 0.00562\n",
      "epoch 3184 / 20000\n",
      "gradient norm: 0.03577255271375179, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00576\n",
      "\tval loss: 0.00562\n",
      "epoch 3185 / 20000\n",
      "gradient norm: 0.05217738717328757, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00576\n",
      "\tval loss: 0.00563\n",
      "epoch 3186 / 20000\n",
      "gradient norm: 0.04365527135087177, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.00577\n",
      "\tval loss: 0.00562\n",
      "epoch 3187 / 20000\n",
      "gradient norm: 0.06752857957326341, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00577\n",
      "\tval loss: 0.00562\n",
      "epoch 3188 / 20000\n",
      "gradient norm: 0.04044906661147252, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00575\n",
      "\tval loss: 0.00563\n",
      "epoch 3189 / 20000\n",
      "gradient norm: 0.047975338355172426, minimum ratio: 2.5078947368421054\n",
      "\ttrain loss: 0.00576\n",
      "\tval loss: 0.00562\n",
      "epoch 3190 / 20000\n",
      "gradient norm: 0.08299049630295485, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00577\n",
      "\tval loss: 0.00562\n",
      "epoch 3191 / 20000\n",
      "gradient norm: 0.05135018890723586, minimum ratio: 2.5131578947368425\n",
      "\ttrain loss: 0.00577\n",
      "\tval loss: 0.00562\n",
      "epoch 3192 / 20000\n",
      "gradient norm: 0.03398511654813774, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00577\n",
      "\tval loss: 0.00562\n",
      "epoch 3193 / 20000\n",
      "gradient norm: 0.039876521652331576, minimum ratio: 2.5105263157894733\n",
      "\ttrain loss: 0.00576\n",
      "\tval loss: 0.00562\n",
      "epoch 3194 / 20000\n",
      "gradient norm: 0.06728095503058285, minimum ratio: 2.5236842105263158\n",
      "\ttrain loss: 0.00576\n",
      "\tval loss: 0.00562\n",
      "epoch 3195 / 20000\n",
      "gradient norm: 0.07070572921657003, minimum ratio: 2.515789473684211\n",
      "\ttrain loss: 0.00576\n",
      "\tval loss: 0.00564\n",
      "epoch 3196 / 20000\n",
      "gradient norm: 0.057016830309294164, minimum ratio: 2.526315789473684\n",
      "\ttrain loss: 0.00576\n",
      "\tval loss: 0.00562\n",
      "epoch 3197 / 20000\n",
      "gradient norm: 0.048003739007981494, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00576\n",
      "\tval loss: 0.00561\n",
      "epoch 3198 / 20000\n",
      "gradient norm: 0.055016101396176964, minimum ratio: 2.507894736842105\n",
      "\ttrain loss: 0.00577\n",
      "\tval loss: 0.00563\n",
      "epoch 3199 / 20000\n",
      "gradient norm: 0.0587643796170596, minimum ratio: 2.507894736842105\n",
      "\ttrain loss: 0.00576\n",
      "\tval loss: 0.00563\n",
      "epoch 3200 / 20000\n",
      "gradient norm: 0.12050661141984165, minimum ratio: 2.5105263157894737\n",
      "\ttrain loss: 0.00578\n",
      "\tval loss: 0.00561\n",
      "epoch 3201 / 20000\n",
      "gradient norm: 0.04769473732449114, minimum ratio: 2.5131578947368425\n",
      "\ttrain loss: 0.00578\n",
      "\tval loss: 0.00563\n",
      "epoch 3202 / 20000\n",
      "gradient norm: 0.06874711616546847, minimum ratio: 2.513157894736842\n",
      "\ttrain loss: 0.00575\n",
      "\tval loss: 0.00564\n",
      "epoch 3203 / 20000\n",
      "gradient norm: 0.07865578118071426, minimum ratio: 2.492105263157895\n",
      "\ttrain loss: 0.00577\n",
      "\tval loss: 0.00561\n",
      "epoch 3204 / 20000\n",
      "gradient norm: 0.04421879518486094, minimum ratio: 2.5105263157894733\n",
      "\ttrain loss: 0.00576\n",
      "\tval loss: 0.00562\n",
      "epoch 3205 / 20000\n",
      "gradient norm: 0.05371528559771832, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00577\n",
      "\tval loss: 0.00563\n",
      "epoch 3206 / 20000\n",
      "gradient norm: 0.0358814942301251, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.00576\n",
      "\tval loss: 0.00562\n",
      "epoch 3207 / 20000\n",
      "gradient norm: 0.026870894304011017, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00576\n",
      "\tval loss: 0.00562\n",
      "epoch 3208 / 20000\n",
      "gradient norm: 0.08681567766325315, minimum ratio: 2.5236842105263158\n",
      "\ttrain loss: 0.00577\n",
      "\tval loss: 0.00562\n",
      "epoch 3209 / 20000\n",
      "gradient norm: 0.07563688945811009, minimum ratio: 2.5078947368421054\n",
      "\ttrain loss: 0.00577\n",
      "\tval loss: 0.00562\n",
      "epoch 3210 / 20000\n",
      "gradient norm: 0.09587377007119358, minimum ratio: 2.5394736842105265\n",
      "\ttrain loss: 0.00576\n",
      "\tval loss: 0.00562\n",
      "epoch 3211 / 20000\n",
      "gradient norm: 0.09395976760424674, minimum ratio: 2.510526315789474\n",
      "\ttrain loss: 0.00575\n",
      "\tval loss: 0.00562\n",
      "epoch 3212 / 20000\n",
      "gradient norm: 0.06871782799134962, minimum ratio: 2.515789473684211\n",
      "\ttrain loss: 0.00576\n",
      "\tval loss: 0.00563\n",
      "epoch 3213 / 20000\n",
      "gradient norm: 0.06347551039652899, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00577\n",
      "\tval loss: 0.00561\n",
      "epoch 3214 / 20000\n",
      "gradient norm: 0.06650958949467167, minimum ratio: 2.5078947368421054\n",
      "\ttrain loss: 0.00576\n",
      "\tval loss: 0.00562\n",
      "epoch 3215 / 20000\n",
      "gradient norm: 0.048194407107075676, minimum ratio: 2.515789473684211\n",
      "\ttrain loss: 0.00577\n",
      "\tval loss: 0.00563\n",
      "epoch 3216 / 20000\n",
      "gradient norm: 0.05425328714773059, minimum ratio: 2.515789473684211\n",
      "\ttrain loss: 0.00574\n",
      "\tval loss: 0.00562\n",
      "epoch 3217 / 20000\n",
      "gradient norm: 0.08891696069622412, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00576\n",
      "\tval loss: 0.00561\n",
      "epoch 3218 / 20000\n",
      "gradient norm: 0.04781680672385846, minimum ratio: 2.5078947368421054\n",
      "\ttrain loss: 0.00576\n",
      "\tval loss: 0.00563\n",
      "epoch 3219 / 20000\n",
      "gradient norm: 0.1014899248839356, minimum ratio: 2.507894736842105\n",
      "\ttrain loss: 0.00577\n",
      "\tval loss: 0.00563\n",
      "epoch 3220 / 20000\n",
      "gradient norm: 0.048667318566003814, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00576\n",
      "\tval loss: 0.00562\n",
      "epoch 3221 / 20000\n",
      "gradient norm: 0.04134428582619876, minimum ratio: 2.5105263157894737\n",
      "\ttrain loss: 0.00575\n",
      "\tval loss: 0.00561\n",
      "epoch 3222 / 20000\n",
      "gradient norm: 0.03228521914570592, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00576\n",
      "\tval loss: 0.00562\n",
      "epoch 3223 / 20000\n",
      "gradient norm: 0.06384467711905017, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00576\n",
      "\tval loss: 0.00562\n",
      "epoch 3224 / 20000\n",
      "gradient norm: 0.08069650433026254, minimum ratio: 2.4868421052631575\n",
      "\ttrain loss: 0.00576\n",
      "\tval loss: 0.00563\n",
      "epoch 3225 / 20000\n",
      "gradient norm: 0.08210362636600621, minimum ratio: 2.513157894736842\n",
      "\ttrain loss: 0.00577\n",
      "\tval loss: 0.00561\n",
      "epoch 3226 / 20000\n",
      "gradient norm: 0.08571774343727157, minimum ratio: 2.518421052631579\n",
      "\ttrain loss: 0.00577\n",
      "\tval loss: 0.00563\n",
      "epoch 3227 / 20000\n",
      "gradient norm: 0.036203651572577655, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00575\n",
      "\tval loss: 0.00563\n",
      "epoch 3228 / 20000\n",
      "gradient norm: 0.05978745996253565, minimum ratio: 2.513157894736842\n",
      "\ttrain loss: 0.00575\n",
      "\tval loss: 0.00562\n",
      "epoch 3229 / 20000\n",
      "gradient norm: 0.1123985325684771, minimum ratio: 2.513157894736842\n",
      "\ttrain loss: 0.00578\n",
      "\tval loss: 0.00561\n",
      "epoch 3230 / 20000\n",
      "gradient norm: 0.03997456136858091, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00576\n",
      "\tval loss: 0.00563\n",
      "epoch 3231 / 20000\n",
      "gradient norm: 0.06843501020921394, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00576\n",
      "\tval loss: 0.00563\n",
      "epoch 3232 / 20000\n",
      "gradient norm: 0.11445654020644724, minimum ratio: 2.518421052631579\n",
      "\ttrain loss: 0.00576\n",
      "\tval loss: 0.00561\n",
      "epoch 3233 / 20000\n",
      "gradient norm: 0.02533846981532406, minimum ratio: 2.507894736842105\n",
      "\ttrain loss: 0.00576\n",
      "\tval loss: 0.00562\n",
      "epoch 3234 / 20000\n",
      "gradient norm: 0.056663171882973984, minimum ratio: 2.5105263157894737\n",
      "\ttrain loss: 0.00577\n",
      "\tval loss: 0.00562\n",
      "epoch 3235 / 20000\n",
      "gradient norm: 0.04214255401166156, minimum ratio: 2.513157894736842\n",
      "\ttrain loss: 0.00575\n",
      "\tval loss: 0.00563\n",
      "epoch 3236 / 20000\n",
      "gradient norm: 0.0765075835515745, minimum ratio: 2.5289473684210524\n",
      "\ttrain loss: 0.00575\n",
      "\tval loss: 0.00561\n",
      "epoch 3237 / 20000\n",
      "gradient norm: 0.042340283980593085, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00577\n",
      "\tval loss: 0.00561\n",
      "epoch 3238 / 20000\n",
      "gradient norm: 0.08231860835803673, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00576\n",
      "\tval loss: 0.00563\n",
      "epoch 3239 / 20000\n",
      "gradient norm: 0.08654003305127844, minimum ratio: 2.5131578947368425\n",
      "\ttrain loss: 0.00576\n",
      "\tval loss: 0.00561\n",
      "epoch 3240 / 20000\n",
      "gradient norm: 0.02769713185261935, minimum ratio: 2.518421052631579\n",
      "\ttrain loss: 0.00575\n",
      "\tval loss: 0.00562\n",
      "epoch 3241 / 20000\n",
      "gradient norm: 0.12269024201668799, minimum ratio: 2.515789473684211\n",
      "\ttrain loss: 0.00574\n",
      "\tval loss: 0.00562\n",
      "epoch 3242 / 20000\n",
      "gradient norm: 0.07136060181073844, minimum ratio: 2.5289473684210524\n",
      "\ttrain loss: 0.00576\n",
      "\tval loss: 0.00563\n",
      "epoch 3243 / 20000\n",
      "gradient norm: 0.04398338796454482, minimum ratio: 2.5236842105263158\n",
      "\ttrain loss: 0.00576\n",
      "\tval loss: 0.00561\n",
      "epoch 3244 / 20000\n",
      "gradient norm: 0.08463296329136938, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00578\n",
      "\tval loss: 0.00561\n",
      "epoch 3245 / 20000\n",
      "gradient norm: 0.07091576998936944, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00575\n",
      "\tval loss: 0.00564\n",
      "epoch 3246 / 20000\n",
      "gradient norm: 0.03828396598692052, minimum ratio: 2.505263157894737\n",
      "\ttrain loss: 0.00576\n",
      "\tval loss: 0.00562\n",
      "epoch 3247 / 20000\n",
      "gradient norm: 0.1008171371940989, minimum ratio: 2.5078947368421054\n",
      "\ttrain loss: 0.00578\n",
      "\tval loss: 0.00561\n",
      "epoch 3248 / 20000\n",
      "gradient norm: 0.10419593891128898, minimum ratio: 2.513157894736842\n",
      "\ttrain loss: 0.00575\n",
      "\tval loss: 0.00564\n",
      "epoch 3249 / 20000\n",
      "gradient norm: 0.0838811902794987, minimum ratio: 2.5131578947368425\n",
      "\ttrain loss: 0.00576\n",
      "\tval loss: 0.00562\n",
      "epoch 3250 / 20000\n",
      "gradient norm: 0.041766834969166666, minimum ratio: 2.515789473684211\n",
      "\ttrain loss: 0.00575\n",
      "\tval loss: 0.00561\n",
      "epoch 3251 / 20000\n",
      "gradient norm: 0.1263395386049524, minimum ratio: 2.5210526315789474\n",
      "\ttrain loss: 0.00576\n",
      "\tval loss: 0.00562\n",
      "epoch 3252 / 20000\n",
      "gradient norm: 0.07512229430722073, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00576\n",
      "\tval loss: 0.00562\n",
      "epoch 3253 / 20000\n",
      "gradient norm: 0.07258036657003686, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00575\n",
      "\tval loss: 0.00562\n",
      "epoch 3254 / 20000\n",
      "gradient norm: 0.030710127524798736, minimum ratio: 2.513157894736842\n",
      "\ttrain loss: 0.00576\n",
      "\tval loss: 0.00561\n",
      "epoch 3255 / 20000\n",
      "gradient norm: 0.08726235089125112, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00575\n",
      "\tval loss: 0.00561\n",
      "epoch 3256 / 20000\n",
      "gradient norm: 0.09625864314148203, minimum ratio: 2.513157894736842\n",
      "\ttrain loss: 0.00577\n",
      "\tval loss: 0.00561\n",
      "epoch 3257 / 20000\n",
      "gradient norm: 0.10775153990834951, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00577\n",
      "\tval loss: 0.00564\n",
      "epoch 3258 / 20000\n",
      "gradient norm: 0.06393742602085695, minimum ratio: 2.5105263157894733\n",
      "\ttrain loss: 0.00575\n",
      "\tval loss: 0.00561\n",
      "epoch 3259 / 20000\n",
      "gradient norm: 0.0974176813615486, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00577\n",
      "\tval loss: 0.00561\n",
      "epoch 3260 / 20000\n",
      "gradient norm: 0.03564576921053231, minimum ratio: 2.5105263157894737\n",
      "\ttrain loss: 0.00576\n",
      "\tval loss: 0.00564\n",
      "epoch 3261 / 20000\n",
      "gradient norm: 0.12283856584690511, minimum ratio: 2.507894736842105\n",
      "\ttrain loss: 0.00576\n",
      "\tval loss: 0.00563\n",
      "epoch 3262 / 20000\n",
      "gradient norm: 0.04837015114026144, minimum ratio: 2.507894736842105\n",
      "\ttrain loss: 0.00575\n",
      "\tval loss: 0.00561\n",
      "epoch 3263 / 20000\n",
      "gradient norm: 0.1056480489205569, minimum ratio: 2.5210526315789474\n",
      "\ttrain loss: 0.00574\n",
      "\tval loss: 0.00561\n",
      "epoch 3264 / 20000\n",
      "gradient norm: 0.07770360290305689, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00575\n",
      "\tval loss: 0.00563\n",
      "epoch 3265 / 20000\n",
      "gradient norm: 0.06344616861315444, minimum ratio: 2.513157894736842\n",
      "\ttrain loss: 0.00577\n",
      "\tval loss: 0.00562\n",
      "epoch 3266 / 20000\n",
      "gradient norm: 0.0743462058599107, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00575\n",
      "\tval loss: 0.00561\n",
      "epoch 3267 / 20000\n",
      "gradient norm: 0.06529771280474961, minimum ratio: 2.515789473684211\n",
      "\ttrain loss: 0.00576\n",
      "\tval loss: 0.00562\n",
      "epoch 3268 / 20000\n",
      "gradient norm: 0.08656430587871, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00576\n",
      "\tval loss: 0.00561\n",
      "epoch 3269 / 20000\n",
      "gradient norm: 0.05232041678391397, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00574\n",
      "\tval loss: 0.00562\n",
      "epoch 3270 / 20000\n",
      "gradient norm: 0.10067150020040572, minimum ratio: 2.5078947368421054\n",
      "\ttrain loss: 0.00576\n",
      "\tval loss: 0.00561\n",
      "epoch 3271 / 20000\n",
      "gradient norm: 0.059776332826004364, minimum ratio: 2.513157894736842\n",
      "\ttrain loss: 0.00575\n",
      "\tval loss: 0.00562\n",
      "epoch 3272 / 20000\n",
      "gradient norm: 0.08831488544819877, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00577\n",
      "\tval loss: 0.00561\n",
      "epoch 3273 / 20000\n",
      "gradient norm: 0.03635735367424786, minimum ratio: 2.5078947368421054\n",
      "\ttrain loss: 0.00575\n",
      "\tval loss: 0.00562\n",
      "epoch 3274 / 20000\n",
      "gradient norm: 0.05438345186121296, minimum ratio: 2.536842105263158\n",
      "\ttrain loss: 0.00576\n",
      "\tval loss: 0.00561\n",
      "epoch 3275 / 20000\n",
      "gradient norm: 0.06248749326914549, minimum ratio: 2.5236842105263158\n",
      "\ttrain loss: 0.00574\n",
      "\tval loss: 0.00562\n",
      "epoch 3276 / 20000\n",
      "gradient norm: 0.09366534516448155, minimum ratio: 2.518421052631579\n",
      "\ttrain loss: 0.00575\n",
      "\tval loss: 0.00562\n",
      "epoch 3277 / 20000\n",
      "gradient norm: 0.10134971217485145, minimum ratio: 2.5157894736842104\n",
      "\ttrain loss: 0.00576\n",
      "\tval loss: 0.00562\n",
      "epoch 3278 / 20000\n",
      "gradient norm: 0.06718011823249981, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00575\n",
      "\tval loss: 0.00561\n",
      "epoch 3279 / 20000\n",
      "gradient norm: 0.03946193782030605, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00576\n",
      "\tval loss: 0.00561\n",
      "epoch 3280 / 20000\n",
      "gradient norm: 0.0864707040018402, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00575\n",
      "\tval loss: 0.00562\n",
      "epoch 3281 / 20000\n",
      "gradient norm: 0.05197763345495332, minimum ratio: 2.4842105263157896\n",
      "\ttrain loss: 0.00575\n",
      "\tval loss: 0.00562\n",
      "epoch 3282 / 20000\n",
      "gradient norm: 0.10774541913997382, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00576\n",
      "\tval loss: 0.00561\n",
      "epoch 3283 / 20000\n",
      "gradient norm: 0.08842261997051537, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00574\n",
      "\tval loss: 0.00562\n",
      "epoch 3284 / 20000\n",
      "gradient norm: 0.04082555667264387, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00575\n",
      "\tval loss: 0.00562\n",
      "epoch 3285 / 20000\n",
      "gradient norm: 0.12410478619858623, minimum ratio: 2.513157894736842\n",
      "\ttrain loss: 0.00576\n",
      "\tval loss: 0.00560\n",
      "epoch 3286 / 20000\n",
      "gradient norm: 0.07146515185013413, minimum ratio: 2.528947368421053\n",
      "\ttrain loss: 0.00575\n",
      "\tval loss: 0.00563\n",
      "epoch 3287 / 20000\n",
      "gradient norm: 0.03597088312380947, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00575\n",
      "\tval loss: 0.00561\n",
      "epoch 3288 / 20000\n",
      "gradient norm: 0.1173934812832158, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00575\n",
      "\tval loss: 0.00561\n",
      "epoch 3289 / 20000\n",
      "gradient norm: 0.05179851088905707, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00575\n",
      "\tval loss: 0.00561\n",
      "epoch 3290 / 20000\n",
      "gradient norm: 0.02836312190629542, minimum ratio: 2.5236842105263158\n",
      "\ttrain loss: 0.00576\n",
      "\tval loss: 0.00561\n",
      "epoch 3291 / 20000\n",
      "gradient norm: 0.042898753948975354, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00575\n",
      "\tval loss: 0.00562\n",
      "epoch 3292 / 20000\n",
      "gradient norm: 0.07806163046916481, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00575\n",
      "\tval loss: 0.00562\n",
      "epoch 3293 / 20000\n",
      "gradient norm: 0.06915765878511593, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00576\n",
      "\tval loss: 0.00560\n",
      "epoch 3294 / 20000\n",
      "gradient norm: 0.028898737553390674, minimum ratio: 2.4868421052631575\n",
      "\ttrain loss: 0.00575\n",
      "\tval loss: 0.00562\n",
      "epoch 3295 / 20000\n",
      "gradient norm: 0.044155823372420855, minimum ratio: 2.5210526315789474\n",
      "\ttrain loss: 0.00575\n",
      "\tval loss: 0.00562\n",
      "epoch 3296 / 20000\n",
      "gradient norm: 0.03150493033172097, minimum ratio: 2.5210526315789474\n",
      "\ttrain loss: 0.00574\n",
      "\tval loss: 0.00561\n",
      "epoch 3297 / 20000\n",
      "gradient norm: 0.14071764901746064, minimum ratio: 2.494736842105263\n",
      "\ttrain loss: 0.00577\n",
      "\tval loss: 0.00560\n",
      "epoch 3298 / 20000\n",
      "gradient norm: 0.07412601623218507, minimum ratio: 2.5157894736842104\n",
      "\ttrain loss: 0.00577\n",
      "\tval loss: 0.00562\n",
      "epoch 3299 / 20000\n",
      "gradient norm: 0.11404046561801806, minimum ratio: 2.505263157894737\n",
      "\ttrain loss: 0.00578\n",
      "\tval loss: 0.00565\n",
      "epoch 3300 / 20000\n",
      "gradient norm: 0.06888760223228019, minimum ratio: 2.507894736842105\n",
      "\ttrain loss: 0.00575\n",
      "\tval loss: 0.00560\n",
      "epoch 3301 / 20000\n",
      "gradient norm: 0.12527990259695798, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00579\n",
      "\tval loss: 0.00560\n",
      "epoch 3302 / 20000\n",
      "gradient norm: 0.06861869833664969, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00577\n",
      "\tval loss: 0.00565\n",
      "epoch 3303 / 20000\n",
      "gradient norm: 0.10959664802066982, minimum ratio: 2.515789473684211\n",
      "\ttrain loss: 0.00576\n",
      "\tval loss: 0.00561\n",
      "epoch 3304 / 20000\n",
      "gradient norm: 0.030523151071975008, minimum ratio: 2.5105263157894733\n",
      "\ttrain loss: 0.00575\n",
      "\tval loss: 0.00560\n",
      "epoch 3305 / 20000\n",
      "gradient norm: 0.11400594329461455, minimum ratio: 2.507894736842105\n",
      "\ttrain loss: 0.00576\n",
      "\tval loss: 0.00561\n",
      "epoch 3306 / 20000\n",
      "gradient norm: 0.12884395150467753, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00575\n",
      "\tval loss: 0.00562\n",
      "epoch 3307 / 20000\n",
      "gradient norm: 0.0999722103588283, minimum ratio: 2.515789473684211\n",
      "\ttrain loss: 0.00574\n",
      "\tval loss: 0.00561\n",
      "epoch 3308 / 20000\n",
      "gradient norm: 0.0595248885510955, minimum ratio: 2.5105263157894733\n",
      "\ttrain loss: 0.00576\n",
      "\tval loss: 0.00560\n",
      "epoch 3309 / 20000\n",
      "gradient norm: 0.0888644689694047, minimum ratio: 2.515789473684211\n",
      "\ttrain loss: 0.00576\n",
      "\tval loss: 0.00561\n",
      "epoch 3310 / 20000\n",
      "gradient norm: 0.06079982512164861, minimum ratio: 2.518421052631579\n",
      "\ttrain loss: 0.00574\n",
      "\tval loss: 0.00564\n",
      "epoch 3311 / 20000\n",
      "gradient norm: 0.11294799269671785, minimum ratio: 2.5131578947368416\n",
      "\ttrain loss: 0.00577\n",
      "\tval loss: 0.00561\n",
      "epoch 3312 / 20000\n",
      "gradient norm: 0.08766238822136074, minimum ratio: 2.5157894736842104\n",
      "\ttrain loss: 0.00575\n",
      "\tval loss: 0.00560\n",
      "epoch 3313 / 20000\n",
      "gradient norm: 0.08620023465482518, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00577\n",
      "\tval loss: 0.00561\n",
      "epoch 3314 / 20000\n",
      "gradient norm: 0.05099929345306009, minimum ratio: 2.4868421052631575\n",
      "\ttrain loss: 0.00576\n",
      "\tval loss: 0.00563\n",
      "epoch 3315 / 20000\n",
      "gradient norm: 0.04750502301612869, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00574\n",
      "\tval loss: 0.00561\n",
      "epoch 3316 / 20000\n",
      "gradient norm: 0.11173409508774057, minimum ratio: 2.5210526315789474\n",
      "\ttrain loss: 0.00577\n",
      "\tval loss: 0.00560\n",
      "epoch 3317 / 20000\n",
      "gradient norm: 0.05998247134266421, minimum ratio: 2.5236842105263158\n",
      "\ttrain loss: 0.00576\n",
      "\tval loss: 0.00563\n",
      "epoch 3318 / 20000\n",
      "gradient norm: 0.08780349773587659, minimum ratio: 2.5105263157894737\n",
      "\ttrain loss: 0.00575\n",
      "\tval loss: 0.00563\n",
      "epoch 3319 / 20000\n",
      "gradient norm: 0.11868120974395424, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.00574\n",
      "\tval loss: 0.00560\n",
      "epoch 3320 / 20000\n",
      "gradient norm: 0.08780921471770853, minimum ratio: 2.507894736842105\n",
      "\ttrain loss: 0.00576\n",
      "\tval loss: 0.00560\n",
      "epoch 3321 / 20000\n",
      "gradient norm: 0.09114814101485536, minimum ratio: 2.518421052631579\n",
      "\ttrain loss: 0.00577\n",
      "\tval loss: 0.00564\n",
      "epoch 3322 / 20000\n",
      "gradient norm: 0.05264115470345132, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00575\n",
      "\tval loss: 0.00561\n",
      "epoch 3323 / 20000\n",
      "gradient norm: 0.07383129303343594, minimum ratio: 2.5105263157894733\n",
      "\ttrain loss: 0.00576\n",
      "\tval loss: 0.00560\n",
      "epoch 3324 / 20000\n",
      "gradient norm: 0.06358265561721055, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.00576\n",
      "\tval loss: 0.00562\n",
      "epoch 3325 / 20000\n",
      "gradient norm: 0.10235625202767551, minimum ratio: 2.513157894736842\n",
      "\ttrain loss: 0.00575\n",
      "\tval loss: 0.00563\n",
      "epoch 3326 / 20000\n",
      "gradient norm: 0.12884328165091574, minimum ratio: 2.5078947368421054\n",
      "\ttrain loss: 0.00576\n",
      "\tval loss: 0.00560\n",
      "epoch 3327 / 20000\n",
      "gradient norm: 0.06133934669196606, minimum ratio: 2.507894736842105\n",
      "\ttrain loss: 0.00576\n",
      "\tval loss: 0.00561\n",
      "epoch 3328 / 20000\n",
      "gradient norm: 0.06974445679225028, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00575\n",
      "\tval loss: 0.00562\n",
      "epoch 3329 / 20000\n",
      "gradient norm: 0.08491858461638913, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00576\n",
      "\tval loss: 0.00561\n",
      "epoch 3330 / 20000\n",
      "gradient norm: 0.033028892386937514, minimum ratio: 2.536842105263158\n",
      "\ttrain loss: 0.00575\n",
      "\tval loss: 0.00561\n",
      "epoch 3331 / 20000\n",
      "gradient norm: 0.0555084323277697, minimum ratio: 2.5105263157894737\n",
      "\ttrain loss: 0.00574\n",
      "\tval loss: 0.00561\n",
      "epoch 3332 / 20000\n",
      "gradient norm: 0.026801753396284766, minimum ratio: 2.510526315789474\n",
      "\ttrain loss: 0.00575\n",
      "\tval loss: 0.00561\n",
      "epoch 3333 / 20000\n",
      "gradient norm: 0.05053960916120559, minimum ratio: 2.507894736842105\n",
      "\ttrain loss: 0.00575\n",
      "\tval loss: 0.00561\n",
      "epoch 3334 / 20000\n",
      "gradient norm: 0.06661913456628099, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00575\n",
      "\tval loss: 0.00562\n",
      "epoch 3335 / 20000\n",
      "gradient norm: 0.09365291587891988, minimum ratio: 2.4868421052631575\n",
      "\ttrain loss: 0.00574\n",
      "\tval loss: 0.00561\n",
      "epoch 3336 / 20000\n",
      "gradient norm: 0.10791435511782765, minimum ratio: 2.5157894736842104\n",
      "\ttrain loss: 0.00577\n",
      "\tval loss: 0.00560\n",
      "epoch 3337 / 20000\n",
      "gradient norm: 0.04024828453839291, minimum ratio: 2.5342105263157895\n",
      "\ttrain loss: 0.00575\n",
      "\tval loss: 0.00561\n",
      "epoch 3338 / 20000\n",
      "gradient norm: 0.15219230321235955, minimum ratio: 2.507894736842105\n",
      "\ttrain loss: 0.00578\n",
      "\tval loss: 0.00564\n",
      "epoch 3339 / 20000\n",
      "gradient norm: 0.11861990951001644, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00575\n",
      "\tval loss: 0.00560\n",
      "epoch 3340 / 20000\n",
      "gradient norm: 0.07920763769652694, minimum ratio: 2.5105263157894737\n",
      "\ttrain loss: 0.00576\n",
      "\tval loss: 0.00560\n",
      "epoch 3341 / 20000\n",
      "gradient norm: 0.047185891220578924, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00576\n",
      "\tval loss: 0.00562\n",
      "epoch 3342 / 20000\n",
      "gradient norm: 0.06360708508873358, minimum ratio: 2.494736842105263\n",
      "\ttrain loss: 0.00575\n",
      "\tval loss: 0.00562\n",
      "epoch 3343 / 20000\n",
      "gradient norm: 0.036026375280926004, minimum ratio: 2.494736842105263\n",
      "\ttrain loss: 0.00575\n",
      "\tval loss: 0.00560\n",
      "epoch 3344 / 20000\n",
      "gradient norm: 0.07094605849124491, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00576\n",
      "\tval loss: 0.00560\n",
      "epoch 3345 / 20000\n",
      "gradient norm: 0.0607750742638018, minimum ratio: 2.513157894736842\n",
      "\ttrain loss: 0.00575\n",
      "\tval loss: 0.00561\n",
      "epoch 3346 / 20000\n",
      "gradient norm: 0.09357827441999689, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00574\n",
      "\tval loss: 0.00561\n",
      "epoch 3347 / 20000\n",
      "gradient norm: 0.04630231129704043, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00574\n",
      "\tval loss: 0.00561\n",
      "epoch 3348 / 20000\n",
      "gradient norm: 0.0833479015273042, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00575\n",
      "\tval loss: 0.00561\n",
      "epoch 3349 / 20000\n",
      "gradient norm: 0.05287785310065374, minimum ratio: 2.518421052631579\n",
      "\ttrain loss: 0.00575\n",
      "\tval loss: 0.00562\n",
      "epoch 3350 / 20000\n",
      "gradient norm: 0.05150380817940459, minimum ratio: 2.513157894736842\n",
      "\ttrain loss: 0.00576\n",
      "\tval loss: 0.00560\n",
      "epoch 3351 / 20000\n",
      "gradient norm: 0.03568726163939573, minimum ratio: 2.5184210526315787\n",
      "\ttrain loss: 0.00575\n",
      "\tval loss: 0.00561\n",
      "epoch 3352 / 20000\n",
      "gradient norm: 0.08372119194245897, minimum ratio: 2.5210526315789474\n",
      "\ttrain loss: 0.00575\n",
      "\tval loss: 0.00561\n",
      "epoch 3353 / 20000\n",
      "gradient norm: 0.028666935075307265, minimum ratio: 2.518421052631579\n",
      "\ttrain loss: 0.00576\n",
      "\tval loss: 0.00561\n",
      "epoch 3354 / 20000\n",
      "gradient norm: 0.11376258020754904, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00574\n",
      "\tval loss: 0.00562\n",
      "epoch 3355 / 20000\n",
      "gradient norm: 0.06738691765349358, minimum ratio: 2.5105263157894737\n",
      "\ttrain loss: 0.00576\n",
      "\tval loss: 0.00560\n",
      "epoch 3356 / 20000\n",
      "gradient norm: 0.08736206927278545, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.00575\n",
      "\tval loss: 0.00560\n",
      "epoch 3357 / 20000\n",
      "gradient norm: 0.08435415336862206, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00575\n",
      "\tval loss: 0.00562\n",
      "epoch 3358 / 20000\n",
      "gradient norm: 0.0712278942373814, minimum ratio: 2.5342105263157895\n",
      "\ttrain loss: 0.00576\n",
      "\tval loss: 0.00561\n",
      "epoch 3359 / 20000\n",
      "gradient norm: 0.060898062511114404, minimum ratio: 2.518421052631579\n",
      "\ttrain loss: 0.00573\n",
      "\tval loss: 0.00560\n",
      "epoch 3360 / 20000\n",
      "gradient norm: 0.058557785145239905, minimum ratio: 2.507894736842105\n",
      "\ttrain loss: 0.00575\n",
      "\tval loss: 0.00561\n",
      "epoch 3361 / 20000\n",
      "gradient norm: 0.03686007877695374, minimum ratio: 2.515789473684211\n",
      "\ttrain loss: 0.00575\n",
      "\tval loss: 0.00561\n",
      "epoch 3362 / 20000\n",
      "gradient norm: 0.0427698582643643, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00576\n",
      "\tval loss: 0.00561\n",
      "epoch 3363 / 20000\n",
      "gradient norm: 0.030154215957736596, minimum ratio: 2.5157894736842104\n",
      "\ttrain loss: 0.00574\n",
      "\tval loss: 0.00561\n",
      "epoch 3364 / 20000\n",
      "gradient norm: 0.04452534810116049, minimum ratio: 2.494736842105263\n",
      "\ttrain loss: 0.00574\n",
      "\tval loss: 0.00561\n",
      "epoch 3365 / 20000\n",
      "gradient norm: 0.029362825458520092, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00574\n",
      "\tval loss: 0.00561\n",
      "epoch 3366 / 20000\n",
      "gradient norm: 0.04920755318016745, minimum ratio: 2.5131578947368416\n",
      "\ttrain loss: 0.00575\n",
      "\tval loss: 0.00560\n",
      "epoch 3367 / 20000\n",
      "gradient norm: 0.04797297524055466, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00574\n",
      "\tval loss: 0.00560\n",
      "epoch 3368 / 20000\n",
      "gradient norm: 0.06355492965667509, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00575\n",
      "\tval loss: 0.00562\n",
      "epoch 3369 / 20000\n",
      "gradient norm: 0.08795978513080627, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00576\n",
      "\tval loss: 0.00560\n",
      "epoch 3370 / 20000\n",
      "gradient norm: 0.049086857921793126, minimum ratio: 2.5394736842105265\n",
      "\ttrain loss: 0.00575\n",
      "\tval loss: 0.00561\n",
      "epoch 3371 / 20000\n",
      "gradient norm: 0.07200506018125452, minimum ratio: 2.5078947368421054\n",
      "\ttrain loss: 0.00575\n",
      "\tval loss: 0.00561\n",
      "epoch 3372 / 20000\n",
      "gradient norm: 0.0940867897006683, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00576\n",
      "\tval loss: 0.00560\n",
      "epoch 3373 / 20000\n",
      "gradient norm: 0.07740977671346627, minimum ratio: 2.492105263157895\n",
      "\ttrain loss: 0.00575\n",
      "\tval loss: 0.00561\n",
      "epoch 3374 / 20000\n",
      "gradient norm: 0.05903489519550931, minimum ratio: 2.513157894736842\n",
      "\ttrain loss: 0.00575\n",
      "\tval loss: 0.00561\n",
      "epoch 3375 / 20000\n",
      "gradient norm: 0.07617161027155817, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.00573\n",
      "\tval loss: 0.00561\n",
      "epoch 3376 / 20000\n",
      "gradient norm: 0.04709288472076878, minimum ratio: 2.4868421052631575\n",
      "\ttrain loss: 0.00574\n",
      "\tval loss: 0.00561\n",
      "epoch 3377 / 20000\n",
      "gradient norm: 0.08134108077501878, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00574\n",
      "\tval loss: 0.00560\n",
      "epoch 3378 / 20000\n",
      "gradient norm: 0.0488081582589075, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00575\n",
      "\tval loss: 0.00560\n",
      "epoch 3379 / 20000\n",
      "gradient norm: 0.04767483221075963, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00576\n",
      "\tval loss: 0.00562\n",
      "epoch 3380 / 20000\n",
      "gradient norm: 0.058691069192718714, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.00575\n",
      "\tval loss: 0.00560\n",
      "epoch 3381 / 20000\n",
      "gradient norm: 0.064149703757721, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00574\n",
      "\tval loss: 0.00560\n",
      "epoch 3382 / 20000\n",
      "gradient norm: 0.042160691646131454, minimum ratio: 2.5210526315789474\n",
      "\ttrain loss: 0.00573\n",
      "\tval loss: 0.00561\n",
      "epoch 3383 / 20000\n",
      "gradient norm: 0.04943997511873022, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00574\n",
      "\tval loss: 0.00560\n",
      "epoch 3384 / 20000\n",
      "gradient norm: 0.04515220741450321, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00575\n",
      "\tval loss: 0.00561\n",
      "epoch 3385 / 20000\n",
      "gradient norm: 0.05974216712638736, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00574\n",
      "\tval loss: 0.00561\n",
      "epoch 3386 / 20000\n",
      "gradient norm: 0.03359519520017784, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00574\n",
      "\tval loss: 0.00561\n",
      "epoch 3387 / 20000\n",
      "gradient norm: 0.10036992028472014, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00577\n",
      "\tval loss: 0.00560\n",
      "epoch 3388 / 20000\n",
      "gradient norm: 0.05889872057014145, minimum ratio: 2.515789473684211\n",
      "\ttrain loss: 0.00574\n",
      "\tval loss: 0.00561\n",
      "epoch 3389 / 20000\n",
      "gradient norm: 0.08464083191938698, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00574\n",
      "\tval loss: 0.00561\n",
      "epoch 3390 / 20000\n",
      "gradient norm: 0.038784615477197804, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00574\n",
      "\tval loss: 0.00561\n",
      "epoch 3391 / 20000\n",
      "gradient norm: 0.039899803763546515, minimum ratio: 2.5210526315789474\n",
      "\ttrain loss: 0.00576\n",
      "\tval loss: 0.00560\n",
      "epoch 3392 / 20000\n",
      "gradient norm: 0.07065154728479683, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00574\n",
      "\tval loss: 0.00561\n",
      "epoch 3393 / 20000\n",
      "gradient norm: 0.03215879561321344, minimum ratio: 2.5105263157894733\n",
      "\ttrain loss: 0.00575\n",
      "\tval loss: 0.00561\n",
      "epoch 3394 / 20000\n",
      "gradient norm: 0.06535408360650763, minimum ratio: 2.513157894736842\n",
      "\ttrain loss: 0.00574\n",
      "\tval loss: 0.00560\n",
      "epoch 3395 / 20000\n",
      "gradient norm: 0.054949645535089076, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00575\n",
      "\tval loss: 0.00561\n",
      "epoch 3396 / 20000\n",
      "gradient norm: 0.05370766101987101, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00575\n",
      "\tval loss: 0.00561\n",
      "epoch 3397 / 20000\n",
      "gradient norm: 0.026623759484209586, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.00574\n",
      "\tval loss: 0.00560\n",
      "epoch 3398 / 20000\n",
      "gradient norm: 0.09200985712232068, minimum ratio: 2.5078947368421054\n",
      "\ttrain loss: 0.00576\n",
      "\tval loss: 0.00559\n",
      "epoch 3399 / 20000\n",
      "gradient norm: 0.03735636608325876, minimum ratio: 2.492105263157895\n",
      "\ttrain loss: 0.00574\n",
      "\tval loss: 0.00562\n",
      "epoch 3400 / 20000\n",
      "gradient norm: 0.05821678671054542, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00574\n",
      "\tval loss: 0.00561\n",
      "epoch 3401 / 20000\n",
      "gradient norm: 0.09273306198883802, minimum ratio: 2.5105263157894737\n",
      "\ttrain loss: 0.00574\n",
      "\tval loss: 0.00560\n",
      "epoch 3402 / 20000\n",
      "gradient norm: 0.06916256312979385, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00576\n",
      "\tval loss: 0.00560\n",
      "epoch 3403 / 20000\n",
      "gradient norm: 0.06564404105301946, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00575\n",
      "\tval loss: 0.00561\n",
      "epoch 3404 / 20000\n",
      "gradient norm: 0.07990523547050543, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00575\n",
      "\tval loss: 0.00560\n",
      "epoch 3405 / 20000\n",
      "gradient norm: 0.031063365109730512, minimum ratio: 2.5236842105263158\n",
      "\ttrain loss: 0.00576\n",
      "\tval loss: 0.00561\n",
      "epoch 3406 / 20000\n",
      "gradient norm: 0.03364423429593444, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00574\n",
      "\tval loss: 0.00560\n",
      "epoch 3407 / 20000\n",
      "gradient norm: 0.02594327284168685, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00574\n",
      "\tval loss: 0.00560\n",
      "epoch 3408 / 20000\n",
      "gradient norm: 0.08512159931706265, minimum ratio: 2.513157894736842\n",
      "\ttrain loss: 0.00576\n",
      "\tval loss: 0.00561\n",
      "epoch 3409 / 20000\n",
      "gradient norm: 0.06028841048828326, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00574\n",
      "\tval loss: 0.00560\n",
      "epoch 3410 / 20000\n",
      "gradient norm: 0.06603417673613876, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00576\n",
      "\tval loss: 0.00560\n",
      "epoch 3411 / 20000\n",
      "gradient norm: 0.07200931374973152, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00575\n",
      "\tval loss: 0.00560\n",
      "epoch 3412 / 20000\n",
      "gradient norm: 0.08762048307107762, minimum ratio: 2.5210526315789474\n",
      "\ttrain loss: 0.00574\n",
      "\tval loss: 0.00561\n",
      "epoch 3413 / 20000\n",
      "gradient norm: 0.07597052393248305, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00573\n",
      "\tval loss: 0.00560\n",
      "epoch 3414 / 20000\n",
      "gradient norm: 0.08142131939530373, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00576\n",
      "\tval loss: 0.00560\n",
      "epoch 3415 / 20000\n",
      "gradient norm: 0.030479087814455852, minimum ratio: 2.5078947368421054\n",
      "\ttrain loss: 0.00574\n",
      "\tval loss: 0.00561\n",
      "epoch 3416 / 20000\n",
      "gradient norm: 0.05526193268451607, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00574\n",
      "\tval loss: 0.00560\n",
      "epoch 3417 / 20000\n",
      "gradient norm: 0.11697068021749146, minimum ratio: 2.4815789473684213\n",
      "\ttrain loss: 0.00573\n",
      "\tval loss: 0.00560\n",
      "epoch 3418 / 20000\n",
      "gradient norm: 0.08419202454388142, minimum ratio: 2.507894736842105\n",
      "\ttrain loss: 0.00576\n",
      "\tval loss: 0.00559\n",
      "epoch 3419 / 20000\n",
      "gradient norm: 0.040715842915233225, minimum ratio: 2.492105263157895\n",
      "\ttrain loss: 0.00575\n",
      "\tval loss: 0.00562\n",
      "epoch 3420 / 20000\n",
      "gradient norm: 0.09678037313278764, minimum ratio: 2.531578947368421\n",
      "\ttrain loss: 0.00574\n",
      "\tval loss: 0.00562\n",
      "epoch 3421 / 20000\n",
      "gradient norm: 0.03345912085205782, minimum ratio: 2.5078947368421054\n",
      "\ttrain loss: 0.00573\n",
      "\tval loss: 0.00559\n",
      "epoch 3422 / 20000\n",
      "gradient norm: 0.06335209513781592, minimum ratio: 2.528947368421053\n",
      "\ttrain loss: 0.00574\n",
      "\tval loss: 0.00559\n",
      "epoch 3423 / 20000\n",
      "gradient norm: 0.055917360572493635, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00574\n",
      "\tval loss: 0.00561\n",
      "epoch 3424 / 20000\n",
      "gradient norm: 0.05693120196519885, minimum ratio: 2.492105263157895\n",
      "\ttrain loss: 0.00574\n",
      "\tval loss: 0.00561\n",
      "epoch 3425 / 20000\n",
      "gradient norm: 0.10269429249456152, minimum ratio: 2.5210526315789474\n",
      "\ttrain loss: 0.00576\n",
      "\tval loss: 0.00559\n",
      "epoch 3426 / 20000\n",
      "gradient norm: 0.08895731200755108, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00575\n",
      "\tval loss: 0.00561\n",
      "epoch 3427 / 20000\n",
      "gradient norm: 0.055673999595455825, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00573\n",
      "\tval loss: 0.00560\n",
      "epoch 3428 / 20000\n",
      "gradient norm: 0.0893153053621063, minimum ratio: 2.5105263157894737\n",
      "\ttrain loss: 0.00575\n",
      "\tval loss: 0.00560\n",
      "epoch 3429 / 20000\n",
      "gradient norm: 0.022386978060239926, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00575\n",
      "\tval loss: 0.00560\n",
      "epoch 3430 / 20000\n",
      "gradient norm: 0.06859552337846253, minimum ratio: 2.492105263157895\n",
      "\ttrain loss: 0.00574\n",
      "\tval loss: 0.00561\n",
      "epoch 3431 / 20000\n",
      "gradient norm: 0.03247485328029143, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00573\n",
      "\tval loss: 0.00560\n",
      "epoch 3432 / 20000\n",
      "gradient norm: 0.035206389118684456, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00575\n",
      "\tval loss: 0.00560\n",
      "epoch 3433 / 20000\n",
      "gradient norm: 0.032462912568007596, minimum ratio: 2.5078947368421054\n",
      "\ttrain loss: 0.00574\n",
      "\tval loss: 0.00561\n",
      "epoch 3434 / 20000\n",
      "gradient norm: 0.07099655040656216, minimum ratio: 2.5157894736842104\n",
      "\ttrain loss: 0.00574\n",
      "\tval loss: 0.00561\n",
      "epoch 3435 / 20000\n",
      "gradient norm: 0.03560163434303831, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00573\n",
      "\tval loss: 0.00560\n",
      "epoch 3436 / 20000\n",
      "gradient norm: 0.041011878493009135, minimum ratio: 2.492105263157895\n",
      "\ttrain loss: 0.00576\n",
      "\tval loss: 0.00560\n",
      "epoch 3437 / 20000\n",
      "gradient norm: 0.10886009002570063, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00575\n",
      "\tval loss: 0.00560\n",
      "epoch 3438 / 20000\n",
      "gradient norm: 0.06252870906610042, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00575\n",
      "\tval loss: 0.00562\n",
      "epoch 3439 / 20000\n",
      "gradient norm: 0.06627430632943287, minimum ratio: 2.5105263157894733\n",
      "\ttrain loss: 0.00574\n",
      "\tval loss: 0.00559\n",
      "epoch 3440 / 20000\n",
      "gradient norm: 0.09844069893006235, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00575\n",
      "\tval loss: 0.00559\n",
      "epoch 3441 / 20000\n",
      "gradient norm: 0.0639303955831565, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.00574\n",
      "\tval loss: 0.00562\n",
      "epoch 3442 / 20000\n",
      "gradient norm: 0.0829344152007252, minimum ratio: 2.515789473684211\n",
      "\ttrain loss: 0.00574\n",
      "\tval loss: 0.00561\n",
      "epoch 3443 / 20000\n",
      "gradient norm: 0.05151245959859807, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.00574\n",
      "\tval loss: 0.00559\n",
      "epoch 3444 / 20000\n",
      "gradient norm: 0.058522436185739934, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00575\n",
      "\tval loss: 0.00559\n",
      "epoch 3445 / 20000\n",
      "gradient norm: 0.046950643707532436, minimum ratio: 2.4973684210526312\n",
      "\ttrain loss: 0.00574\n",
      "\tval loss: 0.00561\n",
      "epoch 3446 / 20000\n",
      "gradient norm: 0.04475347089464776, minimum ratio: 2.5210526315789474\n",
      "\ttrain loss: 0.00574\n",
      "\tval loss: 0.00560\n",
      "epoch 3447 / 20000\n",
      "gradient norm: 0.055637432204093784, minimum ratio: 2.515789473684211\n",
      "\ttrain loss: 0.00573\n",
      "\tval loss: 0.00559\n",
      "epoch 3448 / 20000\n",
      "gradient norm: 0.029662231405382045, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00573\n",
      "\tval loss: 0.00560\n",
      "epoch 3449 / 20000\n",
      "gradient norm: 0.05444031101069413, minimum ratio: 2.518421052631579\n",
      "\ttrain loss: 0.00574\n",
      "\tval loss: 0.00561\n",
      "epoch 3450 / 20000\n",
      "gradient norm: 0.05791916081216186, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00574\n",
      "\tval loss: 0.00559\n",
      "epoch 3451 / 20000\n",
      "gradient norm: 0.05130943888798356, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00576\n",
      "\tval loss: 0.00559\n",
      "epoch 3452 / 20000\n",
      "gradient norm: 0.038611112293438055, minimum ratio: 2.505263157894737\n",
      "\ttrain loss: 0.00574\n",
      "\tval loss: 0.00561\n",
      "epoch 3453 / 20000\n",
      "gradient norm: 0.04419693897943944, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00575\n",
      "\tval loss: 0.00561\n",
      "epoch 3454 / 20000\n",
      "gradient norm: 0.03789214277639985, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00575\n",
      "\tval loss: 0.00560\n",
      "epoch 3455 / 20000\n",
      "gradient norm: 0.04054850057582371, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00575\n",
      "\tval loss: 0.00560\n",
      "epoch 3456 / 20000\n",
      "gradient norm: 0.09881191584281623, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00574\n",
      "\tval loss: 0.00560\n",
      "epoch 3457 / 20000\n",
      "gradient norm: 0.08626728772651404, minimum ratio: 2.515789473684211\n",
      "\ttrain loss: 0.00573\n",
      "\tval loss: 0.00561\n",
      "epoch 3458 / 20000\n",
      "gradient norm: 0.06815702636959031, minimum ratio: 2.518421052631579\n",
      "\ttrain loss: 0.00574\n",
      "\tval loss: 0.00560\n",
      "epoch 3459 / 20000\n",
      "gradient norm: 0.06698516325559467, minimum ratio: 2.515789473684211\n",
      "\ttrain loss: 0.00573\n",
      "\tval loss: 0.00560\n",
      "epoch 3460 / 20000\n",
      "gradient norm: 0.10353584412951022, minimum ratio: 2.5105263157894737\n",
      "\ttrain loss: 0.00573\n",
      "\tval loss: 0.00560\n",
      "epoch 3461 / 20000\n",
      "gradient norm: 0.0599745567451464, minimum ratio: 2.518421052631579\n",
      "\ttrain loss: 0.00573\n",
      "\tval loss: 0.00559\n",
      "epoch 3462 / 20000\n",
      "gradient norm: 0.09026492241537198, minimum ratio: 2.5105263157894737\n",
      "\ttrain loss: 0.00574\n",
      "\tval loss: 0.00560\n",
      "epoch 3463 / 20000\n",
      "gradient norm: 0.041470157681033015, minimum ratio: 2.536842105263158\n",
      "\ttrain loss: 0.00575\n",
      "\tval loss: 0.00560\n",
      "epoch 3464 / 20000\n",
      "gradient norm: 0.026574442570563406, minimum ratio: 2.513157894736842\n",
      "\ttrain loss: 0.00574\n",
      "\tval loss: 0.00560\n",
      "epoch 3465 / 20000\n",
      "gradient norm: 0.057778053218498826, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00574\n",
      "\tval loss: 0.00560\n",
      "epoch 3466 / 20000\n",
      "gradient norm: 0.06682254938641563, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00573\n",
      "\tval loss: 0.00559\n",
      "epoch 3467 / 20000\n",
      "gradient norm: 0.07934244233183563, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00575\n",
      "\tval loss: 0.00559\n",
      "epoch 3468 / 20000\n",
      "gradient norm: 0.07399426971096545, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00573\n",
      "\tval loss: 0.00561\n",
      "epoch 3469 / 20000\n",
      "gradient norm: 0.0677297517831903, minimum ratio: 2.515789473684211\n",
      "\ttrain loss: 0.00576\n",
      "\tval loss: 0.00559\n",
      "epoch 3470 / 20000\n",
      "gradient norm: 0.09002174709166866, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.00575\n",
      "\tval loss: 0.00560\n",
      "epoch 3471 / 20000\n",
      "gradient norm: 0.11640964180696756, minimum ratio: 2.513157894736842\n",
      "\ttrain loss: 0.00576\n",
      "\tval loss: 0.00559\n",
      "epoch 3472 / 20000\n",
      "gradient norm: 0.0449795018939767, minimum ratio: 2.518421052631579\n",
      "\ttrain loss: 0.00575\n",
      "\tval loss: 0.00561\n",
      "epoch 3473 / 20000\n",
      "gradient norm: 0.1259044036269188, minimum ratio: 2.5236842105263158\n",
      "\ttrain loss: 0.00575\n",
      "\tval loss: 0.00561\n",
      "epoch 3474 / 20000\n",
      "gradient norm: 0.08392021933104843, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00575\n",
      "\tval loss: 0.00559\n",
      "epoch 3475 / 20000\n",
      "gradient norm: 0.054835509035910945, minimum ratio: 2.507894736842105\n",
      "\ttrain loss: 0.00575\n",
      "\tval loss: 0.00560\n",
      "epoch 3476 / 20000\n",
      "gradient norm: 0.07522328420600388, minimum ratio: 2.513157894736842\n",
      "\ttrain loss: 0.00575\n",
      "\tval loss: 0.00561\n",
      "epoch 3477 / 20000\n",
      "gradient norm: 0.08172436221502721, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00574\n",
      "\tval loss: 0.00559\n",
      "epoch 3478 / 20000\n",
      "gradient norm: 0.09620698430808261, minimum ratio: 2.5289473684210524\n",
      "\ttrain loss: 0.00574\n",
      "\tval loss: 0.00560\n",
      "epoch 3479 / 20000\n",
      "gradient norm: 0.01332114428805653, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00573\n",
      "\tval loss: 0.00560\n",
      "epoch 3480 / 20000\n",
      "gradient norm: 0.07388783025089651, minimum ratio: 2.518421052631579\n",
      "\ttrain loss: 0.00575\n",
      "\tval loss: 0.00560\n",
      "epoch 3481 / 20000\n",
      "gradient norm: 0.055401692690793425, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00575\n",
      "\tval loss: 0.00559\n",
      "epoch 3482 / 20000\n",
      "gradient norm: 0.06908636228763498, minimum ratio: 2.5105263157894737\n",
      "\ttrain loss: 0.00574\n",
      "\tval loss: 0.00560\n",
      "epoch 3483 / 20000\n",
      "gradient norm: 0.07851555576780811, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00574\n",
      "\tval loss: 0.00560\n",
      "epoch 3484 / 20000\n",
      "gradient norm: 0.023686230459134094, minimum ratio: 2.507894736842105\n",
      "\ttrain loss: 0.00574\n",
      "\tval loss: 0.00560\n",
      "epoch 3485 / 20000\n",
      "gradient norm: 0.028483105765189976, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00573\n",
      "\tval loss: 0.00559\n",
      "epoch 3486 / 20000\n",
      "gradient norm: 0.11767485784366727, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00575\n",
      "\tval loss: 0.00559\n",
      "epoch 3487 / 20000\n",
      "gradient norm: 0.03535937698325142, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00574\n",
      "\tval loss: 0.00560\n",
      "epoch 3488 / 20000\n",
      "gradient norm: 0.0670257592573762, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00560\n",
      "epoch 3489 / 20000\n",
      "gradient norm: 0.07796711404807866, minimum ratio: 2.5078947368421054\n",
      "\ttrain loss: 0.00573\n",
      "\tval loss: 0.00559\n",
      "epoch 3490 / 20000\n",
      "gradient norm: 0.07372269197367132, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00574\n",
      "\tval loss: 0.00560\n",
      "epoch 3491 / 20000\n",
      "gradient norm: 0.08875274518504739, minimum ratio: 2.5078947368421054\n",
      "\ttrain loss: 0.00573\n",
      "\tval loss: 0.00559\n",
      "epoch 3492 / 20000\n",
      "gradient norm: 0.08277463520062156, minimum ratio: 2.5026315789473688\n",
      "\ttrain loss: 0.00574\n",
      "\tval loss: 0.00559\n",
      "epoch 3493 / 20000\n",
      "gradient norm: 0.08339926300686784, minimum ratio: 2.534210526315789\n",
      "\ttrain loss: 0.00575\n",
      "\tval loss: 0.00560\n",
      "epoch 3494 / 20000\n",
      "gradient norm: 0.05598032282432541, minimum ratio: 2.5157894736842104\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00560\n",
      "epoch 3495 / 20000\n",
      "gradient norm: 0.03121220825414639, minimum ratio: 2.5105263157894737\n",
      "\ttrain loss: 0.00573\n",
      "\tval loss: 0.00559\n",
      "epoch 3496 / 20000\n",
      "gradient norm: 0.05790155330032576, minimum ratio: 2.5342105263157895\n",
      "\ttrain loss: 0.00574\n",
      "\tval loss: 0.00559\n",
      "epoch 3497 / 20000\n",
      "gradient norm: 0.06602566062065307, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00574\n",
      "\tval loss: 0.00561\n",
      "epoch 3498 / 20000\n",
      "gradient norm: 0.047632048939703964, minimum ratio: 2.518421052631579\n",
      "\ttrain loss: 0.00575\n",
      "\tval loss: 0.00560\n",
      "epoch 3499 / 20000\n",
      "gradient norm: 0.05634731498139445, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00574\n",
      "\tval loss: 0.00559\n",
      "epoch 3500 / 20000\n",
      "gradient norm: 0.07319083547918126, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00574\n",
      "\tval loss: 0.00561\n",
      "epoch 3501 / 20000\n",
      "gradient norm: 0.08274164570320863, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00573\n",
      "\tval loss: 0.00560\n",
      "epoch 3502 / 20000\n",
      "gradient norm: 0.069818746909732, minimum ratio: 2.4868421052631575\n",
      "\ttrain loss: 0.00574\n",
      "\tval loss: 0.00559\n",
      "epoch 3503 / 20000\n",
      "gradient norm: 0.04848271136870608, minimum ratio: 2.507894736842105\n",
      "\ttrain loss: 0.00575\n",
      "\tval loss: 0.00560\n",
      "epoch 3504 / 20000\n",
      "gradient norm: 0.07769683311926201, minimum ratio: 2.513157894736842\n",
      "\ttrain loss: 0.00574\n",
      "\tval loss: 0.00560\n",
      "epoch 3505 / 20000\n",
      "gradient norm: 0.04932377349177841, minimum ratio: 2.513157894736842\n",
      "\ttrain loss: 0.00575\n",
      "\tval loss: 0.00559\n",
      "epoch 3506 / 20000\n",
      "gradient norm: 0.02594149182550609, minimum ratio: 2.5236842105263158\n",
      "\ttrain loss: 0.00573\n",
      "\tval loss: 0.00560\n",
      "epoch 3507 / 20000\n",
      "gradient norm: 0.05843788851052523, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00574\n",
      "\tval loss: 0.00560\n",
      "epoch 3508 / 20000\n",
      "gradient norm: 0.021814314444782212, minimum ratio: 2.492105263157894\n",
      "\ttrain loss: 0.00574\n",
      "\tval loss: 0.00559\n",
      "epoch 3509 / 20000\n",
      "gradient norm: 0.07548635196872056, minimum ratio: 2.5236842105263158\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00560\n",
      "epoch 3510 / 20000\n",
      "gradient norm: 0.04601276302128099, minimum ratio: 2.5131578947368425\n",
      "\ttrain loss: 0.00574\n",
      "\tval loss: 0.00559\n",
      "epoch 3511 / 20000\n",
      "gradient norm: 0.09487192459346261, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00575\n",
      "\tval loss: 0.00560\n",
      "epoch 3512 / 20000\n",
      "gradient norm: 0.11888628875021823, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00574\n",
      "\tval loss: 0.00560\n",
      "epoch 3513 / 20000\n",
      "gradient norm: 0.09842044196557254, minimum ratio: 2.5210526315789474\n",
      "\ttrain loss: 0.00575\n",
      "\tval loss: 0.00558\n",
      "epoch 3514 / 20000\n",
      "gradient norm: 0.03693137830123305, minimum ratio: 2.523684210526316\n",
      "\ttrain loss: 0.00573\n",
      "\tval loss: 0.00560\n",
      "epoch 3515 / 20000\n",
      "gradient norm: 0.07870931946672499, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00575\n",
      "\tval loss: 0.00561\n",
      "epoch 3516 / 20000\n",
      "gradient norm: 0.08402380929328501, minimum ratio: 2.542105263157895\n",
      "\ttrain loss: 0.00574\n",
      "\tval loss: 0.00558\n",
      "epoch 3517 / 20000\n",
      "gradient norm: 0.08803297093254514, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.00575\n",
      "\tval loss: 0.00559\n",
      "epoch 3518 / 20000\n",
      "gradient norm: 0.03812257191748358, minimum ratio: 2.5131578947368425\n",
      "\ttrain loss: 0.00575\n",
      "\tval loss: 0.00560\n",
      "epoch 3519 / 20000\n",
      "gradient norm: 0.059382514911703765, minimum ratio: 2.492105263157895\n",
      "\ttrain loss: 0.00574\n",
      "\tval loss: 0.00559\n",
      "epoch 3520 / 20000\n",
      "gradient norm: 0.08600467030191794, minimum ratio: 2.5105263157894737\n",
      "\ttrain loss: 0.00574\n",
      "\tval loss: 0.00559\n",
      "epoch 3521 / 20000\n",
      "gradient norm: 0.034509122429881245, minimum ratio: 2.513157894736842\n",
      "\ttrain loss: 0.00574\n",
      "\tval loss: 0.00559\n",
      "epoch 3522 / 20000\n",
      "gradient norm: 0.03989262339018751, minimum ratio: 2.5236842105263158\n",
      "\ttrain loss: 0.00573\n",
      "\tval loss: 0.00560\n",
      "epoch 3523 / 20000\n",
      "gradient norm: 0.06363870314089581, minimum ratio: 2.507894736842105\n",
      "\ttrain loss: 0.00574\n",
      "\tval loss: 0.00559\n",
      "epoch 3524 / 20000\n",
      "gradient norm: 0.061982387967873365, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00575\n",
      "\tval loss: 0.00559\n",
      "epoch 3525 / 20000\n",
      "gradient norm: 0.053481490060221404, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00575\n",
      "\tval loss: 0.00558\n",
      "epoch 3526 / 20000\n",
      "gradient norm: 0.09307854236976709, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00575\n",
      "\tval loss: 0.00559\n",
      "epoch 3527 / 20000\n",
      "gradient norm: 0.05830333399353549, minimum ratio: 2.489473684210526\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00561\n",
      "epoch 3528 / 20000\n",
      "gradient norm: 0.08447281015105546, minimum ratio: 2.518421052631579\n",
      "\ttrain loss: 0.00574\n",
      "\tval loss: 0.00559\n",
      "epoch 3529 / 20000\n",
      "gradient norm: 0.11728284403216094, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00575\n",
      "\tval loss: 0.00558\n",
      "epoch 3530 / 20000\n",
      "gradient norm: 0.09047322621336207, minimum ratio: 2.518421052631579\n",
      "\ttrain loss: 0.00573\n",
      "\tval loss: 0.00561\n",
      "epoch 3531 / 20000\n",
      "gradient norm: 0.054781702696345747, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00575\n",
      "\tval loss: 0.00559\n",
      "epoch 3532 / 20000\n",
      "gradient norm: 0.02605642309936229, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00559\n",
      "epoch 3533 / 20000\n",
      "gradient norm: 0.07539020827971399, minimum ratio: 2.492105263157895\n",
      "\ttrain loss: 0.00575\n",
      "\tval loss: 0.00559\n",
      "epoch 3534 / 20000\n",
      "gradient norm: 0.09840590370004065, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00574\n",
      "\tval loss: 0.00561\n",
      "epoch 3535 / 20000\n",
      "gradient norm: 0.10611031114240177, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00575\n",
      "\tval loss: 0.00558\n",
      "epoch 3536 / 20000\n",
      "gradient norm: 0.050652866484597325, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00575\n",
      "\tval loss: 0.00559\n",
      "epoch 3537 / 20000\n",
      "gradient norm: 0.058067656704224646, minimum ratio: 2.5105263157894737\n",
      "\ttrain loss: 0.00574\n",
      "\tval loss: 0.00560\n",
      "epoch 3538 / 20000\n",
      "gradient norm: 0.07661504775751382, minimum ratio: 2.518421052631579\n",
      "\ttrain loss: 0.00575\n",
      "\tval loss: 0.00560\n",
      "epoch 3539 / 20000\n",
      "gradient norm: 0.07435023866128176, minimum ratio: 2.5105263157894733\n",
      "\ttrain loss: 0.00574\n",
      "\tval loss: 0.00558\n",
      "epoch 3540 / 20000\n",
      "gradient norm: 0.08138514898018911, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.00573\n",
      "\tval loss: 0.00560\n",
      "epoch 3541 / 20000\n",
      "gradient norm: 0.08702155266655609, minimum ratio: 2.5184210526315787\n",
      "\ttrain loss: 0.00573\n",
      "\tval loss: 0.00560\n",
      "epoch 3542 / 20000\n",
      "gradient norm: 0.05066622418235056, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00573\n",
      "\tval loss: 0.00558\n",
      "epoch 3543 / 20000\n",
      "gradient norm: 0.0648096454096958, minimum ratio: 2.5105263157894737\n",
      "\ttrain loss: 0.00574\n",
      "\tval loss: 0.00560\n",
      "epoch 3544 / 20000\n",
      "gradient norm: 0.0725844242842868, minimum ratio: 2.5105263157894737\n",
      "\ttrain loss: 0.00573\n",
      "\tval loss: 0.00560\n",
      "epoch 3545 / 20000\n",
      "gradient norm: 0.08920113163185306, minimum ratio: 2.5289473684210524\n",
      "\ttrain loss: 0.00574\n",
      "\tval loss: 0.00559\n",
      "epoch 3546 / 20000\n",
      "gradient norm: 0.06126623065210879, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00574\n",
      "\tval loss: 0.00559\n",
      "epoch 3547 / 20000\n",
      "gradient norm: 0.04307585663627833, minimum ratio: 2.5105263157894737\n",
      "\ttrain loss: 0.00574\n",
      "\tval loss: 0.00561\n",
      "epoch 3548 / 20000\n",
      "gradient norm: 0.08059046106063761, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00575\n",
      "\tval loss: 0.00559\n",
      "epoch 3549 / 20000\n",
      "gradient norm: 0.02857655062689446, minimum ratio: 2.5078947368421054\n",
      "\ttrain loss: 0.00574\n",
      "\tval loss: 0.00559\n",
      "epoch 3550 / 20000\n",
      "gradient norm: 0.027224358840612695, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.00574\n",
      "\tval loss: 0.00559\n",
      "epoch 3551 / 20000\n",
      "gradient norm: 0.0506363650856656, minimum ratio: 2.5078947368421054\n",
      "\ttrain loss: 0.00573\n",
      "\tval loss: 0.00559\n",
      "epoch 3552 / 20000\n",
      "gradient norm: 0.10535508539760485, minimum ratio: 2.5105263157894737\n",
      "\ttrain loss: 0.00575\n",
      "\tval loss: 0.00559\n",
      "epoch 3553 / 20000\n",
      "gradient norm: 0.0396310884389095, minimum ratio: 2.518421052631579\n",
      "\ttrain loss: 0.00573\n",
      "\tval loss: 0.00560\n",
      "epoch 3554 / 20000\n",
      "gradient norm: 0.11751354846637696, minimum ratio: 2.507894736842105\n",
      "\ttrain loss: 0.00573\n",
      "\tval loss: 0.00559\n",
      "epoch 3555 / 20000\n",
      "gradient norm: 0.06918850250076503, minimum ratio: 2.4868421052631575\n",
      "\ttrain loss: 0.00574\n",
      "\tval loss: 0.00560\n",
      "epoch 3556 / 20000\n",
      "gradient norm: 0.041801746061537415, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00574\n",
      "\tval loss: 0.00559\n",
      "epoch 3557 / 20000\n",
      "gradient norm: 0.03227528213756159, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00574\n",
      "\tval loss: 0.00559\n",
      "epoch 3558 / 20000\n",
      "gradient norm: 0.0431609395891428, minimum ratio: 2.518421052631579\n",
      "\ttrain loss: 0.00573\n",
      "\tval loss: 0.00559\n",
      "epoch 3559 / 20000\n",
      "gradient norm: 0.10059390484821051, minimum ratio: 2.5184210526315787\n",
      "\ttrain loss: 0.00574\n",
      "\tval loss: 0.00559\n",
      "epoch 3560 / 20000\n",
      "gradient norm: 0.12075553485192358, minimum ratio: 2.5105263157894733\n",
      "\ttrain loss: 0.00574\n",
      "\tval loss: 0.00558\n",
      "epoch 3561 / 20000\n",
      "gradient norm: 0.022705158524331637, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00574\n",
      "\tval loss: 0.00560\n",
      "epoch 3562 / 20000\n",
      "gradient norm: 0.07665369665483013, minimum ratio: 2.5105263157894737\n",
      "\ttrain loss: 0.00573\n",
      "\tval loss: 0.00559\n",
      "epoch 3563 / 20000\n",
      "gradient norm: 0.0922188324329909, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00574\n",
      "\tval loss: 0.00559\n",
      "epoch 3564 / 20000\n",
      "gradient norm: 0.0565080025116913, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00573\n",
      "\tval loss: 0.00559\n",
      "epoch 3565 / 20000\n",
      "gradient norm: 0.032825707690790296, minimum ratio: 2.5210526315789474\n",
      "\ttrain loss: 0.00573\n",
      "\tval loss: 0.00559\n",
      "epoch 3566 / 20000\n",
      "gradient norm: 0.041843318482278846, minimum ratio: 2.513157894736842\n",
      "\ttrain loss: 0.00573\n",
      "\tval loss: 0.00559\n",
      "epoch 3567 / 20000\n",
      "gradient norm: 0.10733853466808796, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00573\n",
      "\tval loss: 0.00560\n",
      "epoch 3568 / 20000\n",
      "gradient norm: 0.11562746157869697, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00573\n",
      "\tval loss: 0.00559\n",
      "epoch 3569 / 20000\n",
      "gradient norm: 0.0741333746118471, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00573\n",
      "\tval loss: 0.00559\n",
      "epoch 3570 / 20000\n",
      "gradient norm: 0.03895939199719578, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00573\n",
      "\tval loss: 0.00560\n",
      "epoch 3571 / 20000\n",
      "gradient norm: 0.06648511375533417, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00573\n",
      "\tval loss: 0.00560\n",
      "epoch 3572 / 20000\n",
      "gradient norm: 0.06752888159826398, minimum ratio: 2.4894736842105267\n",
      "\ttrain loss: 0.00574\n",
      "\tval loss: 0.00559\n",
      "epoch 3573 / 20000\n",
      "gradient norm: 0.08327518601436168, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00573\n",
      "\tval loss: 0.00559\n",
      "epoch 3574 / 20000\n",
      "gradient norm: 0.05594616488087922, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00574\n",
      "\tval loss: 0.00559\n",
      "epoch 3575 / 20000\n",
      "gradient norm: 0.06016740121413022, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00574\n",
      "\tval loss: 0.00559\n",
      "epoch 3576 / 20000\n",
      "gradient norm: 0.08908569371851627, minimum ratio: 2.515789473684211\n",
      "\ttrain loss: 0.00575\n",
      "\tval loss: 0.00559\n",
      "epoch 3577 / 20000\n",
      "gradient norm: 0.05628882965538651, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00574\n",
      "\tval loss: 0.00558\n",
      "epoch 3578 / 20000\n",
      "gradient norm: 0.04933876845461782, minimum ratio: 2.528947368421053\n",
      "\ttrain loss: 0.00574\n",
      "\tval loss: 0.00559\n",
      "epoch 3579 / 20000\n",
      "gradient norm: 0.046128413479891606, minimum ratio: 2.5236842105263158\n",
      "\ttrain loss: 0.00574\n",
      "\tval loss: 0.00560\n",
      "epoch 3580 / 20000\n",
      "gradient norm: 0.07997364830225706, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00574\n",
      "\tval loss: 0.00558\n",
      "epoch 3581 / 20000\n",
      "gradient norm: 0.04210777327534743, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00574\n",
      "\tval loss: 0.00559\n",
      "epoch 3582 / 20000\n",
      "gradient norm: 0.038229605692322366, minimum ratio: 2.5131578947368425\n",
      "\ttrain loss: 0.00573\n",
      "\tval loss: 0.00559\n",
      "epoch 3583 / 20000\n",
      "gradient norm: 0.06002409152279142, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00574\n",
      "\tval loss: 0.00559\n",
      "epoch 3584 / 20000\n",
      "gradient norm: 0.048880712703976315, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00574\n",
      "\tval loss: 0.00559\n",
      "epoch 3585 / 20000\n",
      "gradient norm: 0.0849858090368798, minimum ratio: 2.507894736842105\n",
      "\ttrain loss: 0.00573\n",
      "\tval loss: 0.00559\n",
      "epoch 3586 / 20000\n",
      "gradient norm: 0.1446737291989848, minimum ratio: 2.528947368421053\n",
      "\ttrain loss: 0.00573\n",
      "\tval loss: 0.00559\n",
      "epoch 3587 / 20000\n",
      "gradient norm: 0.06797015760093927, minimum ratio: 2.518421052631579\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00560\n",
      "epoch 3588 / 20000\n",
      "gradient norm: 0.048038850422017276, minimum ratio: 2.5078947368421054\n",
      "\ttrain loss: 0.00573\n",
      "\tval loss: 0.00559\n",
      "epoch 3589 / 20000\n",
      "gradient norm: 0.0717255002236925, minimum ratio: 2.513157894736842\n",
      "\ttrain loss: 0.00573\n",
      "\tval loss: 0.00558\n",
      "epoch 3590 / 20000\n",
      "gradient norm: 0.04142743902048096, minimum ratio: 2.513157894736842\n",
      "\ttrain loss: 0.00573\n",
      "\tval loss: 0.00559\n",
      "epoch 3591 / 20000\n",
      "gradient norm: 0.09515147772617638, minimum ratio: 2.505263157894737\n",
      "\ttrain loss: 0.00573\n",
      "\tval loss: 0.00559\n",
      "epoch 3592 / 20000\n",
      "gradient norm: 0.09006564982701093, minimum ratio: 2.513157894736842\n",
      "\ttrain loss: 0.00575\n",
      "\tval loss: 0.00560\n",
      "epoch 3593 / 20000\n",
      "gradient norm: 0.03776455357728992, minimum ratio: 2.507894736842105\n",
      "\ttrain loss: 0.00573\n",
      "\tval loss: 0.00558\n",
      "epoch 3594 / 20000\n",
      "gradient norm: 0.09775766328675672, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00575\n",
      "\tval loss: 0.00558\n",
      "epoch 3595 / 20000\n",
      "gradient norm: 0.09352041489910334, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00574\n",
      "\tval loss: 0.00561\n",
      "epoch 3596 / 20000\n",
      "gradient norm: 0.07480796688469127, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00574\n",
      "\tval loss: 0.00558\n",
      "epoch 3597 / 20000\n",
      "gradient norm: 0.06261034094495699, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00573\n",
      "\tval loss: 0.00558\n",
      "epoch 3598 / 20000\n",
      "gradient norm: 0.05256065310095437, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00574\n",
      "\tval loss: 0.00560\n",
      "epoch 3599 / 20000\n",
      "gradient norm: 0.04645657417131588, minimum ratio: 2.507894736842105\n",
      "\ttrain loss: 0.00574\n",
      "\tval loss: 0.00559\n",
      "epoch 3600 / 20000\n",
      "gradient norm: 0.056235737007227726, minimum ratio: 2.5105263157894737\n",
      "\ttrain loss: 0.00574\n",
      "\tval loss: 0.00558\n",
      "epoch 3601 / 20000\n",
      "gradient norm: 0.0430215677479282, minimum ratio: 2.4894736842105267\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00559\n",
      "epoch 3602 / 20000\n",
      "gradient norm: 0.03685170924291015, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00573\n",
      "\tval loss: 0.00559\n",
      "epoch 3603 / 20000\n",
      "gradient norm: 0.05585661990335211, minimum ratio: 2.5184210526315787\n",
      "\ttrain loss: 0.00574\n",
      "\tval loss: 0.00558\n",
      "epoch 3604 / 20000\n",
      "gradient norm: 0.017306556343100965, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00574\n",
      "\tval loss: 0.00559\n",
      "epoch 3605 / 20000\n",
      "gradient norm: 0.039447314782592, minimum ratio: 2.4868421052631575\n",
      "\ttrain loss: 0.00573\n",
      "\tval loss: 0.00559\n",
      "epoch 3606 / 20000\n",
      "gradient norm: 0.026202218898106366, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00573\n",
      "\tval loss: 0.00559\n",
      "epoch 3607 / 20000\n",
      "gradient norm: 0.03395934368018061, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00574\n",
      "\tval loss: 0.00559\n",
      "epoch 3608 / 20000\n",
      "gradient norm: 0.06119309464702383, minimum ratio: 2.536842105263158\n",
      "\ttrain loss: 0.00574\n",
      "\tval loss: 0.00558\n",
      "epoch 3609 / 20000\n",
      "gradient norm: 0.024018331430852413, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00573\n",
      "\tval loss: 0.00559\n",
      "epoch 3610 / 20000\n",
      "gradient norm: 0.06863398463610793, minimum ratio: 2.4894736842105267\n",
      "\ttrain loss: 0.00573\n",
      "\tval loss: 0.00559\n",
      "epoch 3611 / 20000\n",
      "gradient norm: 0.03191274373966735, minimum ratio: 2.4868421052631575\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00559\n",
      "epoch 3612 / 20000\n",
      "gradient norm: 0.08002190236584283, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00574\n",
      "\tval loss: 0.00558\n",
      "epoch 3613 / 20000\n",
      "gradient norm: 0.060053441498894244, minimum ratio: 2.513157894736842\n",
      "\ttrain loss: 0.00574\n",
      "\tval loss: 0.00559\n",
      "epoch 3614 / 20000\n",
      "gradient norm: 0.048046249692561105, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00573\n",
      "\tval loss: 0.00560\n",
      "epoch 3615 / 20000\n",
      "gradient norm: 0.07648569188313559, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00574\n",
      "\tval loss: 0.00558\n",
      "epoch 3616 / 20000\n",
      "gradient norm: 0.06223299674456939, minimum ratio: 2.5105263157894737\n",
      "\ttrain loss: 0.00573\n",
      "\tval loss: 0.00558\n",
      "epoch 3617 / 20000\n",
      "gradient norm: 0.0653162729286123, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00573\n",
      "\tval loss: 0.00560\n",
      "epoch 3618 / 20000\n",
      "gradient norm: 0.06051930403918959, minimum ratio: 2.5105263157894737\n",
      "\ttrain loss: 0.00574\n",
      "\tval loss: 0.00559\n",
      "epoch 3619 / 20000\n",
      "gradient norm: 0.08073543512728065, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00558\n",
      "epoch 3620 / 20000\n",
      "gradient norm: 0.04494892354705371, minimum ratio: 2.5078947368421054\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00559\n",
      "epoch 3621 / 20000\n",
      "gradient norm: 0.10808971803635359, minimum ratio: 2.5078947368421054\n",
      "\ttrain loss: 0.00574\n",
      "\tval loss: 0.00560\n",
      "epoch 3622 / 20000\n",
      "gradient norm: 0.08445290713279974, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00573\n",
      "\tval loss: 0.00558\n",
      "epoch 3623 / 20000\n",
      "gradient norm: 0.06470359704690054, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00573\n",
      "\tval loss: 0.00558\n",
      "epoch 3624 / 20000\n",
      "gradient norm: 0.06506875727791339, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00573\n",
      "\tval loss: 0.00559\n",
      "epoch 3625 / 20000\n",
      "gradient norm: 0.044339976098854095, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00558\n",
      "epoch 3626 / 20000\n",
      "gradient norm: 0.1007668316597119, minimum ratio: 2.494736842105263\n",
      "\ttrain loss: 0.00573\n",
      "\tval loss: 0.00558\n",
      "epoch 3627 / 20000\n",
      "gradient norm: 0.08073797659017146, minimum ratio: 2.5078947368421054\n",
      "\ttrain loss: 0.00574\n",
      "\tval loss: 0.00558\n",
      "epoch 3628 / 20000\n",
      "gradient norm: 0.09569946955889463, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00574\n",
      "\tval loss: 0.00559\n",
      "epoch 3629 / 20000\n",
      "gradient norm: 0.039805348293157294, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00559\n",
      "epoch 3630 / 20000\n",
      "gradient norm: 0.03335227377829142, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00573\n",
      "\tval loss: 0.00558\n",
      "epoch 3631 / 20000\n",
      "gradient norm: 0.0703596165694762, minimum ratio: 2.489473684210526\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00558\n",
      "epoch 3632 / 20000\n",
      "gradient norm: 0.029304565985512454, minimum ratio: 2.507894736842105\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00559\n",
      "epoch 3633 / 20000\n",
      "gradient norm: 0.05268343072384596, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00559\n",
      "epoch 3634 / 20000\n",
      "gradient norm: 0.08087842934764922, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00573\n",
      "\tval loss: 0.00558\n",
      "epoch 3635 / 20000\n",
      "gradient norm: 0.05424610925547313, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00574\n",
      "\tval loss: 0.00558\n",
      "epoch 3636 / 20000\n",
      "gradient norm: 0.05293631009408273, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00574\n",
      "\tval loss: 0.00560\n",
      "epoch 3637 / 20000\n",
      "gradient norm: 0.04046644397021737, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00558\n",
      "epoch 3638 / 20000\n",
      "gradient norm: 0.11586708834511228, minimum ratio: 2.510526315789474\n",
      "\ttrain loss: 0.00574\n",
      "\tval loss: 0.00557\n",
      "epoch 3639 / 20000\n",
      "gradient norm: 0.0820150070649106, minimum ratio: 2.5026315789473688\n",
      "\ttrain loss: 0.00573\n",
      "\tval loss: 0.00561\n",
      "epoch 3640 / 20000\n",
      "gradient norm: 0.05261223530396819, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00558\n",
      "epoch 3641 / 20000\n",
      "gradient norm: 0.12620772398076952, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00577\n",
      "\tval loss: 0.00557\n",
      "epoch 3642 / 20000\n",
      "gradient norm: 0.08057955221738666, minimum ratio: 2.5210526315789474\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00561\n",
      "epoch 3643 / 20000\n",
      "gradient norm: 0.0964724654040765, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00575\n",
      "\tval loss: 0.00559\n",
      "epoch 3644 / 20000\n",
      "gradient norm: 0.06171596438798588, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00573\n",
      "\tval loss: 0.00557\n",
      "epoch 3645 / 20000\n",
      "gradient norm: 0.04655998115777038, minimum ratio: 2.492105263157895\n",
      "\ttrain loss: 0.00573\n",
      "\tval loss: 0.00559\n",
      "epoch 3646 / 20000\n",
      "gradient norm: 0.1021071671275422, minimum ratio: 2.492105263157895\n",
      "\ttrain loss: 0.00573\n",
      "\tval loss: 0.00559\n",
      "epoch 3647 / 20000\n",
      "gradient norm: 0.06127190316328779, minimum ratio: 2.492105263157895\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00559\n",
      "epoch 3648 / 20000\n",
      "gradient norm: 0.06172401050571352, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00573\n",
      "\tval loss: 0.00558\n",
      "epoch 3649 / 20000\n",
      "gradient norm: 0.05229491219506599, minimum ratio: 2.492105263157895\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00558\n",
      "epoch 3650 / 20000\n",
      "gradient norm: 0.07453420740785077, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00573\n",
      "\tval loss: 0.00558\n",
      "epoch 3651 / 20000\n",
      "gradient norm: 0.06897168353316374, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00573\n",
      "\tval loss: 0.00559\n",
      "epoch 3652 / 20000\n",
      "gradient norm: 0.06472243467578664, minimum ratio: 2.492105263157895\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00558\n",
      "epoch 3653 / 20000\n",
      "gradient norm: 0.06288914737524465, minimum ratio: 2.4842105263157896\n",
      "\ttrain loss: 0.00573\n",
      "\tval loss: 0.00558\n",
      "epoch 3654 / 20000\n",
      "gradient norm: 0.06787406001240015, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00559\n",
      "epoch 3655 / 20000\n",
      "gradient norm: 0.07673541708936682, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00574\n",
      "\tval loss: 0.00557\n",
      "epoch 3656 / 20000\n",
      "gradient norm: 0.10678781010210514, minimum ratio: 2.5315789473684207\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00558\n",
      "epoch 3657 / 20000\n",
      "gradient norm: 0.10608504596166313, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00573\n",
      "\tval loss: 0.00559\n",
      "epoch 3658 / 20000\n",
      "gradient norm: 0.07932617783080786, minimum ratio: 2.4868421052631575\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00558\n",
      "epoch 3659 / 20000\n",
      "gradient norm: 0.09908728109439835, minimum ratio: 2.492105263157895\n",
      "\ttrain loss: 0.00574\n",
      "\tval loss: 0.00557\n",
      "epoch 3660 / 20000\n",
      "gradient norm: 0.14094855135772377, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00574\n",
      "\tval loss: 0.00560\n",
      "epoch 3661 / 20000\n",
      "gradient norm: 0.05194415058940649, minimum ratio: 2.518421052631579\n",
      "\ttrain loss: 0.00574\n",
      "\tval loss: 0.00558\n",
      "epoch 3662 / 20000\n",
      "gradient norm: 0.10344920482020825, minimum ratio: 2.4894736842105267\n",
      "\ttrain loss: 0.00574\n",
      "\tval loss: 0.00557\n",
      "epoch 3663 / 20000\n",
      "gradient norm: 0.039931874453031924, minimum ratio: 2.494736842105263\n",
      "\ttrain loss: 0.00573\n",
      "\tval loss: 0.00560\n",
      "epoch 3664 / 20000\n",
      "gradient norm: 0.10134260047925636, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00573\n",
      "\tval loss: 0.00560\n",
      "epoch 3665 / 20000\n",
      "gradient norm: 0.062442839494906366, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00557\n",
      "epoch 3666 / 20000\n",
      "gradient norm: 0.10597001964924857, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00575\n",
      "\tval loss: 0.00557\n",
      "epoch 3667 / 20000\n",
      "gradient norm: 0.0591347316512838, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00562\n",
      "epoch 3668 / 20000\n",
      "gradient norm: 0.1352000025799498, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00575\n",
      "\tval loss: 0.00558\n",
      "epoch 3669 / 20000\n",
      "gradient norm: 0.08181434060679749, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00573\n",
      "\tval loss: 0.00558\n",
      "epoch 3670 / 20000\n",
      "gradient norm: 0.05040809349156916, minimum ratio: 2.5157894736842104\n",
      "\ttrain loss: 0.00573\n",
      "\tval loss: 0.00558\n",
      "epoch 3671 / 20000\n",
      "gradient norm: 0.029416132005280815, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00558\n",
      "epoch 3672 / 20000\n",
      "gradient norm: 0.09975723942625336, minimum ratio: 2.46578947368421\n",
      "\ttrain loss: 0.00575\n",
      "\tval loss: 0.00557\n",
      "epoch 3673 / 20000\n",
      "gradient norm: 0.10347818012814969, minimum ratio: 2.4842105263157896\n",
      "\ttrain loss: 0.00573\n",
      "\tval loss: 0.00560\n",
      "epoch 3674 / 20000\n",
      "gradient norm: 0.06300022841605823, minimum ratio: 2.518421052631579\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00558\n",
      "epoch 3675 / 20000\n",
      "gradient norm: 0.08443959537544288, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00574\n",
      "\tval loss: 0.00557\n",
      "epoch 3676 / 20000\n",
      "gradient norm: 0.02829536548233591, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00573\n",
      "\tval loss: 0.00558\n",
      "epoch 3677 / 20000\n",
      "gradient norm: 0.06686457624891773, minimum ratio: 2.515789473684211\n",
      "\ttrain loss: 0.00573\n",
      "\tval loss: 0.00560\n",
      "epoch 3678 / 20000\n",
      "gradient norm: 0.11909336014650762, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00573\n",
      "\tval loss: 0.00558\n",
      "epoch 3679 / 20000\n",
      "gradient norm: 0.07695585169130936, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00574\n",
      "\tval loss: 0.00557\n",
      "epoch 3680 / 20000\n",
      "gradient norm: 0.04102136738947593, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00574\n",
      "\tval loss: 0.00559\n",
      "epoch 3681 / 20000\n",
      "gradient norm: 0.08028773980913684, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00561\n",
      "epoch 3682 / 20000\n",
      "gradient norm: 0.025938397579011507, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00573\n",
      "\tval loss: 0.00557\n",
      "epoch 3683 / 20000\n",
      "gradient norm: 0.0706184598384425, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00573\n",
      "\tval loss: 0.00557\n",
      "epoch 3684 / 20000\n",
      "gradient norm: 0.13678200612775981, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00573\n",
      "\tval loss: 0.00559\n",
      "epoch 3685 / 20000\n",
      "gradient norm: 0.05396413925336674, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00574\n",
      "\tval loss: 0.00559\n",
      "epoch 3686 / 20000\n",
      "gradient norm: 0.09876256028655916, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00574\n",
      "\tval loss: 0.00557\n",
      "epoch 3687 / 20000\n",
      "gradient norm: 0.05796551133971661, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00559\n",
      "epoch 3688 / 20000\n",
      "gradient norm: 0.09852308046538383, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00559\n",
      "epoch 3689 / 20000\n",
      "gradient norm: 0.05605167042813264, minimum ratio: 2.5394736842105265\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00558\n",
      "epoch 3690 / 20000\n",
      "gradient norm: 0.08164854941423982, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00558\n",
      "epoch 3691 / 20000\n",
      "gradient norm: 0.09095781436190009, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00573\n",
      "\tval loss: 0.00559\n",
      "epoch 3692 / 20000\n",
      "gradient norm: 0.03715536356321536, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00558\n",
      "epoch 3693 / 20000\n",
      "gradient norm: 0.07552867382764816, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00573\n",
      "\tval loss: 0.00557\n",
      "epoch 3694 / 20000\n",
      "gradient norm: 0.050489470188040286, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00573\n",
      "\tval loss: 0.00560\n",
      "epoch 3695 / 20000\n",
      "gradient norm: 0.09047361317789182, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.00574\n",
      "\tval loss: 0.00558\n",
      "epoch 3696 / 20000\n",
      "gradient norm: 0.06342172162840143, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00558\n",
      "epoch 3697 / 20000\n",
      "gradient norm: 0.05178260621687514, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00558\n",
      "epoch 3698 / 20000\n",
      "gradient norm: 0.02938205339887645, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00558\n",
      "epoch 3699 / 20000\n",
      "gradient norm: 0.11692825256614015, minimum ratio: 2.507894736842105\n",
      "\ttrain loss: 0.00573\n",
      "\tval loss: 0.00558\n",
      "epoch 3700 / 20000\n",
      "gradient norm: 0.09217843029182404, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00573\n",
      "\tval loss: 0.00557\n",
      "epoch 3701 / 20000\n",
      "gradient norm: 0.05390220615663566, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00573\n",
      "\tval loss: 0.00559\n",
      "epoch 3702 / 20000\n",
      "gradient norm: 0.13567069033160806, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00574\n",
      "\tval loss: 0.00559\n",
      "epoch 3703 / 20000\n",
      "gradient norm: 0.03120942716486752, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00558\n",
      "epoch 3704 / 20000\n",
      "gradient norm: 0.014372806443134323, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00573\n",
      "\tval loss: 0.00558\n",
      "epoch 3705 / 20000\n",
      "gradient norm: 0.07769434171495959, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00559\n",
      "epoch 3706 / 20000\n",
      "gradient norm: 0.050274723063921556, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00557\n",
      "epoch 3707 / 20000\n",
      "gradient norm: 0.0717768254398834, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00573\n",
      "\tval loss: 0.00557\n",
      "epoch 3708 / 20000\n",
      "gradient norm: 0.04852455953368917, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00574\n",
      "\tval loss: 0.00558\n",
      "epoch 3709 / 20000\n",
      "gradient norm: 0.10720335802761838, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00574\n",
      "\tval loss: 0.00558\n",
      "epoch 3710 / 20000\n",
      "gradient norm: 0.0614930092706345, minimum ratio: 2.492105263157895\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00558\n",
      "epoch 3711 / 20000\n",
      "gradient norm: 0.10110428067855537, minimum ratio: 2.492105263157895\n",
      "\ttrain loss: 0.00574\n",
      "\tval loss: 0.00558\n",
      "epoch 3712 / 20000\n",
      "gradient norm: 0.037579576805001125, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00573\n",
      "\tval loss: 0.00558\n",
      "epoch 3713 / 20000\n",
      "gradient norm: 0.03156947248498909, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00558\n",
      "epoch 3714 / 20000\n",
      "gradient norm: 0.04238652851199731, minimum ratio: 2.4868421052631575\n",
      "\ttrain loss: 0.00573\n",
      "\tval loss: 0.00558\n",
      "epoch 3715 / 20000\n",
      "gradient norm: 0.0418373585343943, minimum ratio: 2.4894736842105267\n",
      "\ttrain loss: 0.00574\n",
      "\tval loss: 0.00558\n",
      "epoch 3716 / 20000\n",
      "gradient norm: 0.05634456156985834, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00558\n",
      "epoch 3717 / 20000\n",
      "gradient norm: 0.04575845100043807, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00558\n",
      "epoch 3718 / 20000\n",
      "gradient norm: 0.04688974402961321, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00573\n",
      "\tval loss: 0.00558\n",
      "epoch 3719 / 20000\n",
      "gradient norm: 0.06463597918627784, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00573\n",
      "\tval loss: 0.00557\n",
      "epoch 3720 / 20000\n",
      "gradient norm: 0.06599940254818648, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00573\n",
      "\tval loss: 0.00558\n",
      "epoch 3721 / 20000\n",
      "gradient norm: 0.14972225890960544, minimum ratio: 2.5236842105263158\n",
      "\ttrain loss: 0.00574\n",
      "\tval loss: 0.00560\n",
      "epoch 3722 / 20000\n",
      "gradient norm: 0.09191262716194615, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.00573\n",
      "\tval loss: 0.00557\n",
      "epoch 3723 / 20000\n",
      "gradient norm: 0.06784473193692975, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00573\n",
      "\tval loss: 0.00557\n",
      "epoch 3724 / 20000\n",
      "gradient norm: 0.05543982837116346, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00573\n",
      "\tval loss: 0.00560\n",
      "epoch 3725 / 20000\n",
      "gradient norm: 0.08453135192394257, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00573\n",
      "\tval loss: 0.00558\n",
      "epoch 3726 / 20000\n",
      "gradient norm: 0.0809025454800576, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00574\n",
      "\tval loss: 0.00557\n",
      "epoch 3727 / 20000\n",
      "gradient norm: 0.050899162713903934, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00573\n",
      "\tval loss: 0.00558\n",
      "epoch 3728 / 20000\n",
      "gradient norm: 0.07067203443148173, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00560\n",
      "epoch 3729 / 20000\n",
      "gradient norm: 0.07760914805112407, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00574\n",
      "\tval loss: 0.00557\n",
      "epoch 3730 / 20000\n",
      "gradient norm: 0.06590474434779026, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00558\n",
      "epoch 3731 / 20000\n",
      "gradient norm: 0.08471561473561451, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00559\n",
      "epoch 3732 / 20000\n",
      "gradient norm: 0.042389926995383576, minimum ratio: 2.492105263157895\n",
      "\ttrain loss: 0.00573\n",
      "\tval loss: 0.00558\n",
      "epoch 3733 / 20000\n",
      "gradient norm: 0.06059453176567331, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00573\n",
      "\tval loss: 0.00558\n",
      "epoch 3734 / 20000\n",
      "gradient norm: 0.09016479694400914, minimum ratio: 2.5184210526315787\n",
      "\ttrain loss: 0.00575\n",
      "\tval loss: 0.00557\n",
      "epoch 3735 / 20000\n",
      "gradient norm: 0.062231195683125407, minimum ratio: 2.5105263157894737\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00559\n",
      "epoch 3736 / 20000\n",
      "gradient norm: 0.06677403088542633, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00573\n",
      "\tval loss: 0.00558\n",
      "epoch 3737 / 20000\n",
      "gradient norm: 0.04950113783706911, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00557\n",
      "epoch 3738 / 20000\n",
      "gradient norm: 0.03875713958404958, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00558\n",
      "epoch 3739 / 20000\n",
      "gradient norm: 0.11813110252842307, minimum ratio: 2.518421052631579\n",
      "\ttrain loss: 0.00573\n",
      "\tval loss: 0.00558\n",
      "epoch 3740 / 20000\n",
      "gradient norm: 0.10407372273039073, minimum ratio: 2.5210526315789474\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00560\n",
      "epoch 3741 / 20000\n",
      "gradient norm: 0.05811766526312567, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00557\n",
      "epoch 3742 / 20000\n",
      "gradient norm: 0.04967763222521171, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00573\n",
      "\tval loss: 0.00557\n",
      "epoch 3743 / 20000\n",
      "gradient norm: 0.10821478767320514, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00573\n",
      "\tval loss: 0.00558\n",
      "epoch 3744 / 20000\n",
      "gradient norm: 0.056572866218630224, minimum ratio: 2.4973684210526312\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00558\n",
      "epoch 3745 / 20000\n",
      "gradient norm: 0.09395416709594429, minimum ratio: 2.492105263157895\n",
      "\ttrain loss: 0.00573\n",
      "\tval loss: 0.00559\n",
      "epoch 3746 / 20000\n",
      "gradient norm: 0.11532146437093616, minimum ratio: 2.4868421052631575\n",
      "\ttrain loss: 0.00573\n",
      "\tval loss: 0.00557\n",
      "epoch 3747 / 20000\n",
      "gradient norm: 0.04509157908614725, minimum ratio: 2.492105263157895\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00558\n",
      "epoch 3748 / 20000\n",
      "gradient norm: 0.07839691691333428, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00573\n",
      "\tval loss: 0.00558\n",
      "epoch 3749 / 20000\n",
      "gradient norm: 0.05845013071666472, minimum ratio: 2.5078947368421054\n",
      "\ttrain loss: 0.00573\n",
      "\tval loss: 0.00557\n",
      "epoch 3750 / 20000\n",
      "gradient norm: 0.032780165813164786, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00558\n",
      "epoch 3751 / 20000\n",
      "gradient norm: 0.02566964390280191, minimum ratio: 2.4842105263157896\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00557\n",
      "epoch 3752 / 20000\n",
      "gradient norm: 0.04378088272642344, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00558\n",
      "epoch 3753 / 20000\n",
      "gradient norm: 0.05305287611554377, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00558\n",
      "epoch 3754 / 20000\n",
      "gradient norm: 0.050077946158126, minimum ratio: 2.5157894736842104\n",
      "\ttrain loss: 0.00574\n",
      "\tval loss: 0.00557\n",
      "epoch 3755 / 20000\n",
      "gradient norm: 0.07800437428522855, minimum ratio: 2.492105263157895\n",
      "\ttrain loss: 0.00574\n",
      "\tval loss: 0.00557\n",
      "epoch 3756 / 20000\n",
      "gradient norm: 0.07391216806718148, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.00573\n",
      "\tval loss: 0.00559\n",
      "epoch 3757 / 20000\n",
      "gradient norm: 0.07310347387101501, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00573\n",
      "\tval loss: 0.00558\n",
      "epoch 3758 / 20000\n",
      "gradient norm: 0.029930957622127607, minimum ratio: 2.518421052631579\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00557\n",
      "epoch 3759 / 20000\n",
      "gradient norm: 0.057447339058853686, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00558\n",
      "epoch 3760 / 20000\n",
      "gradient norm: 0.024300711695104837, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00558\n",
      "epoch 3761 / 20000\n",
      "gradient norm: 0.08387640968430787, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00573\n",
      "\tval loss: 0.00557\n",
      "epoch 3762 / 20000\n",
      "gradient norm: 0.05789530940819532, minimum ratio: 2.518421052631579\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00559\n",
      "epoch 3763 / 20000\n",
      "gradient norm: 0.0955232348642312, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00574\n",
      "\tval loss: 0.00557\n",
      "epoch 3764 / 20000\n",
      "gradient norm: 0.05064871412469074, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00573\n",
      "\tval loss: 0.00559\n",
      "epoch 3765 / 20000\n",
      "gradient norm: 0.03377921108040027, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00557\n",
      "epoch 3766 / 20000\n",
      "gradient norm: 0.05498458044894505, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00573\n",
      "\tval loss: 0.00557\n",
      "epoch 3767 / 20000\n",
      "gradient norm: 0.02393319054681342, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00557\n",
      "epoch 3768 / 20000\n",
      "gradient norm: 0.10878978780237958, minimum ratio: 2.4842105263157896\n",
      "\ttrain loss: 0.00573\n",
      "\tval loss: 0.00558\n",
      "epoch 3769 / 20000\n",
      "gradient norm: 0.06562694589956664, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00558\n",
      "epoch 3770 / 20000\n",
      "gradient norm: 0.04125280884181848, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00558\n",
      "epoch 3771 / 20000\n",
      "gradient norm: 0.10485853694262914, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00574\n",
      "\tval loss: 0.00556\n",
      "epoch 3772 / 20000\n",
      "gradient norm: 0.08096919680247083, minimum ratio: 2.5078947368421054\n",
      "\ttrain loss: 0.00573\n",
      "\tval loss: 0.00558\n",
      "epoch 3773 / 20000\n",
      "gradient norm: 0.07459455312346108, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00559\n",
      "epoch 3774 / 20000\n",
      "gradient norm: 0.04583493531390559, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00557\n",
      "epoch 3775 / 20000\n",
      "gradient norm: 0.08806616213405505, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00557\n",
      "epoch 3776 / 20000\n",
      "gradient norm: 0.052959147200454026, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00557\n",
      "epoch 3777 / 20000\n",
      "gradient norm: 0.04434514729655348, minimum ratio: 2.4815789473684213\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00559\n",
      "epoch 3778 / 20000\n",
      "gradient norm: 0.0944888237863779, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00573\n",
      "\tval loss: 0.00557\n",
      "epoch 3779 / 20000\n",
      "gradient norm: 0.04842116092913784, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00558\n",
      "epoch 3780 / 20000\n",
      "gradient norm: 0.07160239014774561, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00557\n",
      "epoch 3781 / 20000\n",
      "gradient norm: 0.04859460412990302, minimum ratio: 2.5105263157894737\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00557\n",
      "epoch 3782 / 20000\n",
      "gradient norm: 0.02014686913753394, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00573\n",
      "\tval loss: 0.00557\n",
      "epoch 3783 / 20000\n",
      "gradient norm: 0.05395377494278364, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00573\n",
      "\tval loss: 0.00558\n",
      "epoch 3784 / 20000\n",
      "gradient norm: 0.10828586691059172, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00573\n",
      "\tval loss: 0.00557\n",
      "epoch 3785 / 20000\n",
      "gradient norm: 0.06945076177362353, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00559\n",
      "epoch 3786 / 20000\n",
      "gradient norm: 0.05605671613011509, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00557\n",
      "epoch 3787 / 20000\n",
      "gradient norm: 0.06055781652685255, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00557\n",
      "epoch 3788 / 20000\n",
      "gradient norm: 0.0218497856403701, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00573\n",
      "\tval loss: 0.00557\n",
      "epoch 3789 / 20000\n",
      "gradient norm: 0.039122192945796996, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00574\n",
      "\tval loss: 0.00557\n",
      "epoch 3790 / 20000\n",
      "gradient norm: 0.07081156023195945, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00558\n",
      "epoch 3791 / 20000\n",
      "gradient norm: 0.021964973042486235, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00573\n",
      "\tval loss: 0.00557\n",
      "epoch 3792 / 20000\n",
      "gradient norm: 0.11055285367183387, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00557\n",
      "epoch 3793 / 20000\n",
      "gradient norm: 0.07703421785845421, minimum ratio: 2.5105263157894737\n",
      "\ttrain loss: 0.00573\n",
      "\tval loss: 0.00557\n",
      "epoch 3794 / 20000\n",
      "gradient norm: 0.07577604142716154, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00559\n",
      "epoch 3795 / 20000\n",
      "gradient norm: 0.11381186603102833, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00557\n",
      "epoch 3796 / 20000\n",
      "gradient norm: 0.04101129199261777, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00573\n",
      "\tval loss: 0.00557\n",
      "epoch 3797 / 20000\n",
      "gradient norm: 0.04659201381582534, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00558\n",
      "epoch 3798 / 20000\n",
      "gradient norm: 0.04727456645923667, minimum ratio: 2.492105263157895\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00558\n",
      "epoch 3799 / 20000\n",
      "gradient norm: 0.046800958283711225, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00557\n",
      "epoch 3800 / 20000\n",
      "gradient norm: 0.0667255622392986, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00557\n",
      "epoch 3801 / 20000\n",
      "gradient norm: 0.09871423110598698, minimum ratio: 2.4868421052631575\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00558\n",
      "epoch 3802 / 20000\n",
      "gradient norm: 0.05356251339253504, minimum ratio: 2.494736842105263\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00557\n",
      "epoch 3803 / 20000\n",
      "gradient norm: 0.10709963244153187, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00574\n",
      "\tval loss: 0.00557\n",
      "epoch 3804 / 20000\n",
      "gradient norm: 0.0818858485436067, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00573\n",
      "\tval loss: 0.00560\n",
      "epoch 3805 / 20000\n",
      "gradient norm: 0.12338186404667795, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00557\n",
      "epoch 3806 / 20000\n",
      "gradient norm: 0.03486419687396847, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00557\n",
      "epoch 3807 / 20000\n",
      "gradient norm: 0.08363944676239043, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00573\n",
      "\tval loss: 0.00557\n",
      "epoch 3808 / 20000\n",
      "gradient norm: 0.06708127161255106, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00559\n",
      "epoch 3809 / 20000\n",
      "gradient norm: 0.026334875088650733, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00557\n",
      "epoch 3810 / 20000\n",
      "gradient norm: 0.07408813544316217, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00573\n",
      "\tval loss: 0.00556\n",
      "epoch 3811 / 20000\n",
      "gradient norm: 0.05681406956864521, minimum ratio: 2.4868421052631575\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00558\n",
      "epoch 3812 / 20000\n",
      "gradient norm: 0.11280499052372761, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.00573\n",
      "\tval loss: 0.00559\n",
      "epoch 3813 / 20000\n",
      "gradient norm: 0.06455351607291959, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00556\n",
      "epoch 3814 / 20000\n",
      "gradient norm: 0.06042168126441538, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00573\n",
      "\tval loss: 0.00557\n",
      "epoch 3815 / 20000\n",
      "gradient norm: 0.04349869937868789, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00559\n",
      "epoch 3816 / 20000\n",
      "gradient norm: 0.0663928507710807, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00558\n",
      "epoch 3817 / 20000\n",
      "gradient norm: 0.04074673308059573, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00557\n",
      "epoch 3818 / 20000\n",
      "gradient norm: 0.05318666901439428, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00557\n",
      "epoch 3819 / 20000\n",
      "gradient norm: 0.06682029366493225, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00558\n",
      "epoch 3820 / 20000\n",
      "gradient norm: 0.07884794031269848, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00557\n",
      "epoch 3821 / 20000\n",
      "gradient norm: 0.04208449328143615, minimum ratio: 2.507894736842105\n",
      "\ttrain loss: 0.00573\n",
      "\tval loss: 0.00558\n",
      "epoch 3822 / 20000\n",
      "gradient norm: 0.0783864971017465, minimum ratio: 2.534210526315789\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00557\n",
      "epoch 3823 / 20000\n",
      "gradient norm: 0.010825322729942854, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00557\n",
      "epoch 3824 / 20000\n",
      "gradient norm: 0.10015366651350632, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00558\n",
      "epoch 3825 / 20000\n",
      "gradient norm: 0.04966372746275738, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00557\n",
      "epoch 3826 / 20000\n",
      "gradient norm: 0.047715420310851187, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00557\n",
      "epoch 3827 / 20000\n",
      "gradient norm: 0.03425348410382867, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00573\n",
      "\tval loss: 0.00557\n",
      "epoch 3828 / 20000\n",
      "gradient norm: 0.08748552069300786, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00558\n",
      "epoch 3829 / 20000\n",
      "gradient norm: 0.042775935668032616, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00556\n",
      "epoch 3830 / 20000\n",
      "gradient norm: 0.08248199929948896, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00557\n",
      "epoch 3831 / 20000\n",
      "gradient norm: 0.05313746185856871, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00558\n",
      "epoch 3832 / 20000\n",
      "gradient norm: 0.037402089626993984, minimum ratio: 2.4868421052631575\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00557\n",
      "epoch 3833 / 20000\n",
      "gradient norm: 0.042194882640615106, minimum ratio: 2.494736842105263\n",
      "\ttrain loss: 0.00573\n",
      "\tval loss: 0.00557\n",
      "epoch 3834 / 20000\n",
      "gradient norm: 0.04654305096482858, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00557\n",
      "epoch 3835 / 20000\n",
      "gradient norm: 0.07254600847954862, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00557\n",
      "epoch 3836 / 20000\n",
      "gradient norm: 0.06739263520285022, minimum ratio: 2.4815789473684213\n",
      "\ttrain loss: 0.00573\n",
      "\tval loss: 0.00556\n",
      "epoch 3837 / 20000\n",
      "gradient norm: 0.06259400813723914, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00558\n",
      "epoch 3838 / 20000\n",
      "gradient norm: 0.10048915084917098, minimum ratio: 2.5105263157894737\n",
      "\ttrain loss: 0.00573\n",
      "\tval loss: 0.00559\n",
      "epoch 3839 / 20000\n",
      "gradient norm: 0.09306959877721965, minimum ratio: 2.5210526315789474\n",
      "\ttrain loss: 0.00574\n",
      "\tval loss: 0.00556\n",
      "epoch 3840 / 20000\n",
      "gradient norm: 0.07196844409918413, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00573\n",
      "\tval loss: 0.00558\n",
      "epoch 3841 / 20000\n",
      "gradient norm: 0.06412822622223757, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00573\n",
      "\tval loss: 0.00558\n",
      "epoch 3842 / 20000\n",
      "gradient norm: 0.0658666494418867, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00557\n",
      "epoch 3843 / 20000\n",
      "gradient norm: 0.03792968898778781, minimum ratio: 2.507894736842105\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00556\n",
      "epoch 3844 / 20000\n",
      "gradient norm: 0.0515280767576769, minimum ratio: 2.4842105263157896\n",
      "\ttrain loss: 0.00573\n",
      "\tval loss: 0.00557\n",
      "epoch 3845 / 20000\n",
      "gradient norm: 0.06424044887535274, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.00573\n",
      "\tval loss: 0.00558\n",
      "epoch 3846 / 20000\n",
      "gradient norm: 0.03491087231668644, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00557\n",
      "epoch 3847 / 20000\n",
      "gradient norm: 0.07240810427174438, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00557\n",
      "epoch 3848 / 20000\n",
      "gradient norm: 0.11517641285900027, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00556\n",
      "epoch 3849 / 20000\n",
      "gradient norm: 0.06525481474818662, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00558\n",
      "epoch 3850 / 20000\n",
      "gradient norm: 0.04455126920947805, minimum ratio: 2.4868421052631575\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00557\n",
      "epoch 3851 / 20000\n",
      "gradient norm: 0.11134746787138283, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00556\n",
      "epoch 3852 / 20000\n",
      "gradient norm: 0.06108927173772827, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00573\n",
      "\tval loss: 0.00558\n",
      "epoch 3853 / 20000\n",
      "gradient norm: 0.03559270338155329, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00558\n",
      "epoch 3854 / 20000\n",
      "gradient norm: 0.03358031537209172, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00557\n",
      "epoch 3855 / 20000\n",
      "gradient norm: 0.0462933256640099, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00557\n",
      "epoch 3856 / 20000\n",
      "gradient norm: 0.02500605650129728, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00557\n",
      "epoch 3857 / 20000\n",
      "gradient norm: 0.09187804348766804, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00557\n",
      "epoch 3858 / 20000\n",
      "gradient norm: 0.05775492964312434, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00556\n",
      "epoch 3859 / 20000\n",
      "gradient norm: 0.07144255546154454, minimum ratio: 2.4842105263157896\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00556\n",
      "epoch 3860 / 20000\n",
      "gradient norm: 0.056253072049003094, minimum ratio: 2.513157894736842\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00558\n",
      "epoch 3861 / 20000\n",
      "gradient norm: 0.048600042529869825, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00558\n",
      "epoch 3862 / 20000\n",
      "gradient norm: 0.05152816482586786, minimum ratio: 2.5105263157894737\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00556\n",
      "epoch 3863 / 20000\n",
      "gradient norm: 0.10038721974706277, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00557\n",
      "epoch 3864 / 20000\n",
      "gradient norm: 0.029299595960765146, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00556\n",
      "epoch 3865 / 20000\n",
      "gradient norm: 0.08111641480354592, minimum ratio: 2.492105263157895\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00557\n",
      "epoch 3866 / 20000\n",
      "gradient norm: 0.03556282393401489, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00573\n",
      "\tval loss: 0.00557\n",
      "epoch 3867 / 20000\n",
      "gradient norm: 0.04067742844927125, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00556\n",
      "epoch 3868 / 20000\n",
      "gradient norm: 0.053916611010208726, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00558\n",
      "epoch 3869 / 20000\n",
      "gradient norm: 0.09162051501334645, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00573\n",
      "\tval loss: 0.00556\n",
      "epoch 3870 / 20000\n",
      "gradient norm: 0.09891750174574554, minimum ratio: 2.494736842105263\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00557\n",
      "epoch 3871 / 20000\n",
      "gradient norm: 0.05751138801861089, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00557\n",
      "epoch 3872 / 20000\n",
      "gradient norm: 0.03953262171125971, minimum ratio: 2.507894736842105\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00557\n",
      "epoch 3873 / 20000\n",
      "gradient norm: 0.059154262649826705, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00556\n",
      "epoch 3874 / 20000\n",
      "gradient norm: 0.08549361661425792, minimum ratio: 2.5105263157894737\n",
      "\ttrain loss: 0.00573\n",
      "\tval loss: 0.00556\n",
      "epoch 3875 / 20000\n",
      "gradient norm: 0.050353188591543585, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00559\n",
      "epoch 3876 / 20000\n",
      "gradient norm: 0.05844630266074091, minimum ratio: 2.5105263157894737\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00557\n",
      "epoch 3877 / 20000\n",
      "gradient norm: 0.11181001900695264, minimum ratio: 2.489473684210526\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00557\n",
      "epoch 3878 / 20000\n",
      "gradient norm: 0.10197279695421457, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00556\n",
      "epoch 3879 / 20000\n",
      "gradient norm: 0.07587417819013353, minimum ratio: 2.513157894736842\n",
      "\ttrain loss: 0.00573\n",
      "\tval loss: 0.00558\n",
      "epoch 3880 / 20000\n",
      "gradient norm: 0.08912512834649533, minimum ratio: 2.4842105263157896\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00557\n",
      "epoch 3881 / 20000\n",
      "gradient norm: 0.14739308482967317, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00574\n",
      "\tval loss: 0.00556\n",
      "epoch 3882 / 20000\n",
      "gradient norm: 0.10152954561635852, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00573\n",
      "\tval loss: 0.00560\n",
      "epoch 3883 / 20000\n",
      "gradient norm: 0.06250588624970987, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00557\n",
      "epoch 3884 / 20000\n",
      "gradient norm: 0.10946906462777406, minimum ratio: 2.4842105263157896\n",
      "\ttrain loss: 0.00573\n",
      "\tval loss: 0.00556\n",
      "epoch 3885 / 20000\n",
      "gradient norm: 0.08376681385561824, minimum ratio: 2.515789473684211\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00557\n",
      "epoch 3886 / 20000\n",
      "gradient norm: 0.09200055140536278, minimum ratio: 2.513157894736842\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00559\n",
      "epoch 3887 / 20000\n",
      "gradient norm: 0.07460466597694904, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00556\n",
      "epoch 3888 / 20000\n",
      "gradient norm: 0.05683863291051239, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00556\n",
      "epoch 3889 / 20000\n",
      "gradient norm: 0.10053351160604507, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00558\n",
      "epoch 3890 / 20000\n",
      "gradient norm: 0.09591684743645601, minimum ratio: 2.4815789473684213\n",
      "\ttrain loss: 0.00573\n",
      "\tval loss: 0.00556\n",
      "epoch 3891 / 20000\n",
      "gradient norm: 0.08980089583201334, minimum ratio: 2.505263157894737\n",
      "\ttrain loss: 0.00573\n",
      "\tval loss: 0.00556\n",
      "epoch 3892 / 20000\n",
      "gradient norm: 0.10146194195840508, minimum ratio: 2.5078947368421054\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00558\n",
      "epoch 3893 / 20000\n",
      "gradient norm: 0.09482570749241859, minimum ratio: 2.518421052631579\n",
      "\ttrain loss: 0.00573\n",
      "\tval loss: 0.00557\n",
      "epoch 3894 / 20000\n",
      "gradient norm: 0.0655284313543234, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00556\n",
      "epoch 3895 / 20000\n",
      "gradient norm: 0.1215408289572224, minimum ratio: 2.507894736842105\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00558\n",
      "epoch 3896 / 20000\n",
      "gradient norm: 0.054268199659418315, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00556\n",
      "epoch 3897 / 20000\n",
      "gradient norm: 0.1085897657321766, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00573\n",
      "\tval loss: 0.00556\n",
      "epoch 3898 / 20000\n",
      "gradient norm: 0.07784187176730484, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00559\n",
      "epoch 3899 / 20000\n",
      "gradient norm: 0.029945552741992287, minimum ratio: 2.492105263157895\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00556\n",
      "epoch 3900 / 20000\n",
      "gradient norm: 0.09295138157904148, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00556\n",
      "epoch 3901 / 20000\n",
      "gradient norm: 0.04619849915616214, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00557\n",
      "epoch 3902 / 20000\n",
      "gradient norm: 0.051214143488323316, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00558\n",
      "epoch 3903 / 20000\n",
      "gradient norm: 0.08976225578226149, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00556\n",
      "epoch 3904 / 20000\n",
      "gradient norm: 0.10411298915278167, minimum ratio: 2.494736842105263\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00557\n",
      "epoch 3905 / 20000\n",
      "gradient norm: 0.09623088641092181, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00573\n",
      "\tval loss: 0.00556\n",
      "epoch 3906 / 20000\n",
      "gradient norm: 0.0657936945790425, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00558\n",
      "epoch 3907 / 20000\n",
      "gradient norm: 0.07658014434855431, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00556\n",
      "epoch 3908 / 20000\n",
      "gradient norm: 0.05611371388658881, minimum ratio: 2.507894736842105\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00556\n",
      "epoch 3909 / 20000\n",
      "gradient norm: 0.05419820154202171, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00557\n",
      "epoch 3910 / 20000\n",
      "gradient norm: 0.09538503468502313, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00556\n",
      "epoch 3911 / 20000\n",
      "gradient norm: 0.0750740164949093, minimum ratio: 2.507894736842105\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00557\n",
      "epoch 3912 / 20000\n",
      "gradient norm: 0.05868378537707031, minimum ratio: 2.492105263157895\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00557\n",
      "epoch 3913 / 20000\n",
      "gradient norm: 0.04646747125661932, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00573\n",
      "\tval loss: 0.00556\n",
      "epoch 3914 / 20000\n",
      "gradient norm: 0.06467083998722956, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00557\n",
      "epoch 3915 / 20000\n",
      "gradient norm: 0.01961202033999143, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00556\n",
      "epoch 3916 / 20000\n",
      "gradient norm: 0.028245955851161852, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00556\n",
      "epoch 3917 / 20000\n",
      "gradient norm: 0.021136235794983804, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00557\n",
      "epoch 3918 / 20000\n",
      "gradient norm: 0.05505390599137172, minimum ratio: 2.5105263157894733\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00557\n",
      "epoch 3919 / 20000\n",
      "gradient norm: 0.04504832204474951, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00556\n",
      "epoch 3920 / 20000\n",
      "gradient norm: 0.024158396990969777, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00557\n",
      "epoch 3921 / 20000\n",
      "gradient norm: 0.13609675294719636, minimum ratio: 2.4868421052631575\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00558\n",
      "epoch 3922 / 20000\n",
      "gradient norm: 0.07296719442820176, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00574\n",
      "\tval loss: 0.00556\n",
      "epoch 3923 / 20000\n",
      "gradient norm: 0.07294521003495902, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00557\n",
      "epoch 3924 / 20000\n",
      "gradient norm: 0.06385288709134329, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00573\n",
      "\tval loss: 0.00557\n",
      "epoch 3925 / 20000\n",
      "gradient norm: 0.08345854707295075, minimum ratio: 2.507894736842105\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00557\n",
      "epoch 3926 / 20000\n",
      "gradient norm: 0.03937764016154688, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00556\n",
      "epoch 3927 / 20000\n",
      "gradient norm: 0.10193744080606848, minimum ratio: 2.4868421052631575\n",
      "\ttrain loss: 0.00574\n",
      "\tval loss: 0.00556\n",
      "epoch 3928 / 20000\n",
      "gradient norm: 0.025365118985064328, minimum ratio: 2.5157894736842104\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00558\n",
      "epoch 3929 / 20000\n",
      "gradient norm: 0.06469782174099237, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00557\n",
      "epoch 3930 / 20000\n",
      "gradient norm: 0.038397746480768546, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00556\n",
      "epoch 3931 / 20000\n",
      "gradient norm: 0.06773981332662515, minimum ratio: 2.515789473684211\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00556\n",
      "epoch 3932 / 20000\n",
      "gradient norm: 0.0730603935662657, minimum ratio: 2.492105263157895\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00558\n",
      "epoch 3933 / 20000\n",
      "gradient norm: 0.0598973978558206, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00556\n",
      "epoch 3934 / 20000\n",
      "gradient norm: 0.02353440920705907, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00556\n",
      "epoch 3935 / 20000\n",
      "gradient norm: 0.08487667795270681, minimum ratio: 2.489473684210526\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00557\n",
      "epoch 3936 / 20000\n",
      "gradient norm: 0.025305952614871785, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00556\n",
      "epoch 3937 / 20000\n",
      "gradient norm: 0.04037815645278897, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00556\n",
      "epoch 3938 / 20000\n",
      "gradient norm: 0.05290448266896419, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00556\n",
      "epoch 3939 / 20000\n",
      "gradient norm: 0.061440502118784934, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00557\n",
      "epoch 3940 / 20000\n",
      "gradient norm: 0.02597788228013087, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00557\n",
      "epoch 3941 / 20000\n",
      "gradient norm: 0.034192189399618655, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00556\n",
      "epoch 3942 / 20000\n",
      "gradient norm: 0.037685805233195424, minimum ratio: 2.5078947368421054\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00556\n",
      "epoch 3943 / 20000\n",
      "gradient norm: 0.050712529104202986, minimum ratio: 2.507894736842105\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00557\n",
      "epoch 3944 / 20000\n",
      "gradient norm: 0.07843921048333868, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00557\n",
      "epoch 3945 / 20000\n",
      "gradient norm: 0.05586448953545187, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00573\n",
      "\tval loss: 0.00556\n",
      "epoch 3946 / 20000\n",
      "gradient norm: 0.10597656341269612, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00556\n",
      "epoch 3947 / 20000\n",
      "gradient norm: 0.06106236044433899, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00558\n",
      "epoch 3948 / 20000\n",
      "gradient norm: 0.06532613627496175, minimum ratio: 2.4894736842105267\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00556\n",
      "epoch 3949 / 20000\n",
      "gradient norm: 0.06934900616761297, minimum ratio: 2.5236842105263158\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00555\n",
      "epoch 3950 / 20000\n",
      "gradient norm: 0.07408530739485286, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00558\n",
      "epoch 3951 / 20000\n",
      "gradient norm: 0.0807589369796915, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00557\n",
      "epoch 3952 / 20000\n",
      "gradient norm: 0.0606937259726692, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00556\n",
      "epoch 3953 / 20000\n",
      "gradient norm: 0.08359607798047364, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00556\n",
      "epoch 3954 / 20000\n",
      "gradient norm: 0.06892950693145394, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00558\n",
      "epoch 3955 / 20000\n",
      "gradient norm: 0.04643505287822336, minimum ratio: 2.4868421052631575\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00556\n",
      "epoch 3956 / 20000\n",
      "gradient norm: 0.06499313854146749, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00556\n",
      "epoch 3957 / 20000\n",
      "gradient norm: 0.05978142219828442, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00557\n",
      "epoch 3958 / 20000\n",
      "gradient norm: 0.03073604920064099, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00557\n",
      "epoch 3959 / 20000\n",
      "gradient norm: 0.028419039299478754, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00556\n",
      "epoch 3960 / 20000\n",
      "gradient norm: 0.04708105019381037, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00556\n",
      "epoch 3961 / 20000\n",
      "gradient norm: 0.0593205017503351, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00556\n",
      "epoch 3962 / 20000\n",
      "gradient norm: 0.05684462844510563, minimum ratio: 2.492105263157895\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00556\n",
      "epoch 3963 / 20000\n",
      "gradient norm: 0.05593585016322322, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00557\n",
      "epoch 3964 / 20000\n",
      "gradient norm: 0.08242878247983754, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00557\n",
      "epoch 3965 / 20000\n",
      "gradient norm: 0.100145209900802, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00573\n",
      "\tval loss: 0.00555\n",
      "epoch 3966 / 20000\n",
      "gradient norm: 0.06913002749206498, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00557\n",
      "epoch 3967 / 20000\n",
      "gradient norm: 0.07202491880161688, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00557\n",
      "epoch 3968 / 20000\n",
      "gradient norm: 0.036385331011842936, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00556\n",
      "epoch 3969 / 20000\n",
      "gradient norm: 0.0838572807260789, minimum ratio: 2.494736842105263\n",
      "\ttrain loss: 0.00573\n",
      "\tval loss: 0.00555\n",
      "epoch 3970 / 20000\n",
      "gradient norm: 0.04124110905104317, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00558\n",
      "epoch 3971 / 20000\n",
      "gradient norm: 0.05224047813680954, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00557\n",
      "epoch 3972 / 20000\n",
      "gradient norm: 0.04268998184124939, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00555\n",
      "epoch 3973 / 20000\n",
      "gradient norm: 0.06545993039617315, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00556\n",
      "epoch 3974 / 20000\n",
      "gradient norm: 0.08977145666722208, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00573\n",
      "\tval loss: 0.00557\n",
      "epoch 3975 / 20000\n",
      "gradient norm: 0.10856914171017706, minimum ratio: 2.5105263157894737\n",
      "\ttrain loss: 0.00574\n",
      "\tval loss: 0.00555\n",
      "epoch 3976 / 20000\n",
      "gradient norm: 0.08141725783934817, minimum ratio: 2.5078947368421054\n",
      "\ttrain loss: 0.00573\n",
      "\tval loss: 0.00556\n",
      "epoch 3977 / 20000\n",
      "gradient norm: 0.08934374601813033, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00558\n",
      "epoch 3978 / 20000\n",
      "gradient norm: 0.06885104815592058, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00556\n",
      "epoch 3979 / 20000\n",
      "gradient norm: 0.05264453653944656, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00555\n",
      "epoch 3980 / 20000\n",
      "gradient norm: 0.03237275674473494, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00557\n",
      "epoch 3981 / 20000\n",
      "gradient norm: 0.04683559360273648, minimum ratio: 2.4894736842105267\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00557\n",
      "epoch 3982 / 20000\n",
      "gradient norm: 0.034974555659573525, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00556\n",
      "epoch 3983 / 20000\n",
      "gradient norm: 0.040116800140822306, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00556\n",
      "epoch 3984 / 20000\n",
      "gradient norm: 0.08100546471541747, minimum ratio: 2.492105263157895\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00557\n",
      "epoch 3985 / 20000\n",
      "gradient norm: 0.08405386406229809, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00555\n",
      "epoch 3986 / 20000\n",
      "gradient norm: 0.04091798112494871, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00556\n",
      "epoch 3987 / 20000\n",
      "gradient norm: 0.043163579859538004, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00557\n",
      "epoch 3988 / 20000\n",
      "gradient norm: 0.034175843800767325, minimum ratio: 2.4842105263157896\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00557\n",
      "epoch 3989 / 20000\n",
      "gradient norm: 0.0507330434047617, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00573\n",
      "\tval loss: 0.00555\n",
      "epoch 3990 / 20000\n",
      "gradient norm: 0.056224658190330956, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00556\n",
      "epoch 3991 / 20000\n",
      "gradient norm: 0.0777232947293669, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00557\n",
      "epoch 3992 / 20000\n",
      "gradient norm: 0.07663181709358469, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00573\n",
      "\tval loss: 0.00555\n",
      "epoch 3993 / 20000\n",
      "gradient norm: 0.09623943374026567, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00573\n",
      "\tval loss: 0.00556\n",
      "epoch 3994 / 20000\n",
      "gradient norm: 0.09393632155843079, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00560\n",
      "epoch 3995 / 20000\n",
      "gradient norm: 0.08194350090343505, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00556\n",
      "epoch 3996 / 20000\n",
      "gradient norm: 0.08366041362751275, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00555\n",
      "epoch 3997 / 20000\n",
      "gradient norm: 0.06891784153413028, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00557\n",
      "epoch 3998 / 20000\n",
      "gradient norm: 0.10203300905413926, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00558\n",
      "epoch 3999 / 20000\n",
      "gradient norm: 0.05055354145588353, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00556\n",
      "epoch 4000 / 20000\n",
      "gradient norm: 0.0582120802719146, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00555\n",
      "epoch 4001 / 20000\n",
      "gradient norm: 0.06981929554603994, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00556\n",
      "epoch 4002 / 20000\n",
      "gradient norm: 0.056171689298935235, minimum ratio: 2.494736842105263\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00556\n",
      "epoch 4003 / 20000\n",
      "gradient norm: 0.05243995602359064, minimum ratio: 2.4842105263157896\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00556\n",
      "epoch 4004 / 20000\n",
      "gradient norm: 0.05771299549451214, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00556\n",
      "epoch 4005 / 20000\n",
      "gradient norm: 0.04081803493318148, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00557\n",
      "epoch 4006 / 20000\n",
      "gradient norm: 0.050685163703747094, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00556\n",
      "epoch 4007 / 20000\n",
      "gradient norm: 0.04576056951191276, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00556\n",
      "epoch 4008 / 20000\n",
      "gradient norm: 0.07406320082372986, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00556\n",
      "epoch 4009 / 20000\n",
      "gradient norm: 0.0532353978487663, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00557\n",
      "epoch 4010 / 20000\n",
      "gradient norm: 0.05146081108250655, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00555\n",
      "epoch 4011 / 20000\n",
      "gradient norm: 0.07094343268545344, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00556\n",
      "epoch 4012 / 20000\n",
      "gradient norm: 0.037072971143061295, minimum ratio: 2.4894736842105267\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00556\n",
      "epoch 4013 / 20000\n",
      "gradient norm: 0.04010946594644338, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00556\n",
      "epoch 4014 / 20000\n",
      "gradient norm: 0.07794270437443629, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00557\n",
      "epoch 4015 / 20000\n",
      "gradient norm: 0.07531242773984559, minimum ratio: 2.4868421052631575\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00555\n",
      "epoch 4016 / 20000\n",
      "gradient norm: 0.05597720784135163, minimum ratio: 2.4868421052631575\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00556\n",
      "epoch 4017 / 20000\n",
      "gradient norm: 0.04477041286008898, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00556\n",
      "epoch 4018 / 20000\n",
      "gradient norm: 0.05827343123382889, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00556\n",
      "epoch 4019 / 20000\n",
      "gradient norm: 0.05896781691990327, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00556\n",
      "epoch 4020 / 20000\n",
      "gradient norm: 0.048388442606665194, minimum ratio: 2.513157894736842\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00556\n",
      "epoch 4021 / 20000\n",
      "gradient norm: 0.0728265376528725, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00557\n",
      "epoch 4022 / 20000\n",
      "gradient norm: 0.06671073468169197, minimum ratio: 2.494736842105263\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00556\n",
      "epoch 4023 / 20000\n",
      "gradient norm: 0.059017328632762656, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00555\n",
      "epoch 4024 / 20000\n",
      "gradient norm: 0.08940488507505506, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00556\n",
      "epoch 4025 / 20000\n",
      "gradient norm: 0.10042998852441087, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00559\n",
      "epoch 4026 / 20000\n",
      "gradient norm: 0.09677925752475858, minimum ratio: 2.4842105263157896\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00555\n",
      "epoch 4027 / 20000\n",
      "gradient norm: 0.11195681730168872, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00555\n",
      "epoch 4028 / 20000\n",
      "gradient norm: 0.0976964874425903, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00559\n",
      "epoch 4029 / 20000\n",
      "gradient norm: 0.08162704255664721, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00555\n",
      "epoch 4030 / 20000\n",
      "gradient norm: 0.10159986140206456, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00555\n",
      "epoch 4031 / 20000\n",
      "gradient norm: 0.06740965758217499, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00558\n",
      "epoch 4032 / 20000\n",
      "gradient norm: 0.0756896966486238, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00558\n",
      "epoch 4033 / 20000\n",
      "gradient norm: 0.06154839879309293, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00555\n",
      "epoch 4034 / 20000\n",
      "gradient norm: 0.09209177450975403, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00556\n",
      "epoch 4035 / 20000\n",
      "gradient norm: 0.05482263202429749, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00555\n",
      "epoch 4036 / 20000\n",
      "gradient norm: 0.09008666426234413, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00558\n",
      "epoch 4037 / 20000\n",
      "gradient norm: 0.05702945700613782, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00556\n",
      "epoch 4038 / 20000\n",
      "gradient norm: 0.0553620605787728, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00555\n",
      "epoch 4039 / 20000\n",
      "gradient norm: 0.033175301970914006, minimum ratio: 2.4736842105263155\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00556\n",
      "epoch 4040 / 20000\n",
      "gradient norm: 0.0687095500761643, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00557\n",
      "epoch 4041 / 20000\n",
      "gradient norm: 0.07531065307557583, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00555\n",
      "epoch 4042 / 20000\n",
      "gradient norm: 0.09872573509346694, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00573\n",
      "\tval loss: 0.00555\n",
      "epoch 4043 / 20000\n",
      "gradient norm: 0.10812559706391767, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00573\n",
      "\tval loss: 0.00558\n",
      "epoch 4044 / 20000\n",
      "gradient norm: 0.09392492938786745, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00556\n",
      "epoch 4045 / 20000\n",
      "gradient norm: 0.05929755631950684, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00555\n",
      "epoch 4046 / 20000\n",
      "gradient norm: 0.11087577146827243, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00555\n",
      "epoch 4047 / 20000\n",
      "gradient norm: 0.05354365200037137, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00557\n",
      "epoch 4048 / 20000\n",
      "gradient norm: 0.04278762236936018, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00556\n",
      "epoch 4049 / 20000\n",
      "gradient norm: 0.07176680047996342, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00555\n",
      "epoch 4050 / 20000\n",
      "gradient norm: 0.02242316426418256, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00557\n",
      "epoch 4051 / 20000\n",
      "gradient norm: 0.06157765776151791, minimum ratio: 2.494736842105263\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00557\n",
      "epoch 4052 / 20000\n",
      "gradient norm: 0.06438890984281898, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00555\n",
      "epoch 4053 / 20000\n",
      "gradient norm: 0.03964598214952275, minimum ratio: 2.5210526315789474\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00555\n",
      "epoch 4054 / 20000\n",
      "gradient norm: 0.0694788336113561, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00573\n",
      "\tval loss: 0.00558\n",
      "epoch 4055 / 20000\n",
      "gradient norm: 0.07735510109341703, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00555\n",
      "epoch 4056 / 20000\n",
      "gradient norm: 0.04395759629551321, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00555\n",
      "epoch 4057 / 20000\n",
      "gradient norm: 0.023773664550390095, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00556\n",
      "epoch 4058 / 20000\n",
      "gradient norm: 0.04562721180263907, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00556\n",
      "epoch 4059 / 20000\n",
      "gradient norm: 0.058852391404798254, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00555\n",
      "epoch 4060 / 20000\n",
      "gradient norm: 0.044200735428603366, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00555\n",
      "epoch 4061 / 20000\n",
      "gradient norm: 0.08584946155315265, minimum ratio: 2.492105263157895\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00556\n",
      "epoch 4062 / 20000\n",
      "gradient norm: 0.05557773768668994, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00556\n",
      "epoch 4063 / 20000\n",
      "gradient norm: 0.03597153417649679, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00555\n",
      "epoch 4064 / 20000\n",
      "gradient norm: 0.03428333214833401, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00556\n",
      "epoch 4065 / 20000\n",
      "gradient norm: 0.0957475385221187, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00556\n",
      "epoch 4066 / 20000\n",
      "gradient norm: 0.15106762130744755, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00555\n",
      "epoch 4067 / 20000\n",
      "gradient norm: 0.046777925454080105, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00556\n",
      "epoch 4068 / 20000\n",
      "gradient norm: 0.09202350780833513, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00557\n",
      "epoch 4069 / 20000\n",
      "gradient norm: 0.05263495081453584, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00555\n",
      "epoch 4070 / 20000\n",
      "gradient norm: 0.04688187380088493, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00555\n",
      "epoch 4071 / 20000\n",
      "gradient norm: 0.05159844143781811, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00557\n",
      "epoch 4072 / 20000\n",
      "gradient norm: 0.03553867066511884, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00555\n",
      "epoch 4073 / 20000\n",
      "gradient norm: 0.06836803228361532, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00555\n",
      "epoch 4074 / 20000\n",
      "gradient norm: 0.06098331802058965, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00556\n",
      "epoch 4075 / 20000\n",
      "gradient norm: 0.024607648781966418, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00555\n",
      "epoch 4076 / 20000\n",
      "gradient norm: 0.09485330409370363, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00555\n",
      "epoch 4077 / 20000\n",
      "gradient norm: 0.031318148103309795, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00557\n",
      "epoch 4078 / 20000\n",
      "gradient norm: 0.07367921940749511, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00556\n",
      "epoch 4079 / 20000\n",
      "gradient norm: 0.14022150228265673, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00575\n",
      "\tval loss: 0.00554\n",
      "epoch 4080 / 20000\n",
      "gradient norm: 0.01587655312323477, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00558\n",
      "epoch 4081 / 20000\n",
      "gradient norm: 0.10074010048992932, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00573\n",
      "\tval loss: 0.00558\n",
      "epoch 4082 / 20000\n",
      "gradient norm: 0.059357687656302005, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00555\n",
      "epoch 4083 / 20000\n",
      "gradient norm: 0.1368158794939518, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00574\n",
      "\tval loss: 0.00555\n",
      "epoch 4084 / 20000\n",
      "gradient norm: 0.06058968129218556, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00559\n",
      "epoch 4085 / 20000\n",
      "gradient norm: 0.09124432713724673, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00573\n",
      "\tval loss: 0.00557\n",
      "epoch 4086 / 20000\n",
      "gradient norm: 0.1270797373726964, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00555\n",
      "epoch 4087 / 20000\n",
      "gradient norm: 0.09079170657787472, minimum ratio: 2.507894736842105\n",
      "\ttrain loss: 0.00573\n",
      "\tval loss: 0.00555\n",
      "epoch 4088 / 20000\n",
      "gradient norm: 0.037941269649309106, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00558\n",
      "epoch 4089 / 20000\n",
      "gradient norm: 0.06075981550384313, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00556\n",
      "epoch 4090 / 20000\n",
      "gradient norm: 0.04841199089423753, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00555\n",
      "epoch 4091 / 20000\n",
      "gradient norm: 0.06476261225179769, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00556\n",
      "epoch 4092 / 20000\n",
      "gradient norm: 0.06772356264991686, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00556\n",
      "epoch 4093 / 20000\n",
      "gradient norm: 0.08971085958182812, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00555\n",
      "epoch 4094 / 20000\n",
      "gradient norm: 0.08352907322114334, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00555\n",
      "epoch 4095 / 20000\n",
      "gradient norm: 0.0918685239739716, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00555\n",
      "epoch 4096 / 20000\n",
      "gradient norm: 0.13279935205355287, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00555\n",
      "epoch 4097 / 20000\n",
      "gradient norm: 0.06588420434854925, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00557\n",
      "epoch 4098 / 20000\n",
      "gradient norm: 0.10088581015588716, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00556\n",
      "epoch 4099 / 20000\n",
      "gradient norm: 0.045791039417963475, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00555\n",
      "epoch 4100 / 20000\n",
      "gradient norm: 0.05416517565390677, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00556\n",
      "epoch 4101 / 20000\n",
      "gradient norm: 0.01795681192743359, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00556\n",
      "epoch 4102 / 20000\n",
      "gradient norm: 0.046725156338652596, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00555\n",
      "epoch 4103 / 20000\n",
      "gradient norm: 0.14781318587483838, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00575\n",
      "\tval loss: 0.00554\n",
      "epoch 4104 / 20000\n",
      "gradient norm: 0.04806894453940913, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00573\n",
      "\tval loss: 0.00558\n",
      "epoch 4105 / 20000\n",
      "gradient norm: 0.09262316446984187, minimum ratio: 2.4894736842105267\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00557\n",
      "epoch 4106 / 20000\n",
      "gradient norm: 0.09661874655284919, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00573\n",
      "\tval loss: 0.00554\n",
      "epoch 4107 / 20000\n",
      "gradient norm: 0.06844731152523309, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00555\n",
      "epoch 4108 / 20000\n",
      "gradient norm: 0.05114434636197984, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00557\n",
      "epoch 4109 / 20000\n",
      "gradient norm: 0.05127660738071427, minimum ratio: 2.4631578947368427\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00556\n",
      "epoch 4110 / 20000\n",
      "gradient norm: 0.045339098549447954, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00555\n",
      "epoch 4111 / 20000\n",
      "gradient norm: 0.07403409227845259, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00556\n",
      "epoch 4112 / 20000\n",
      "gradient norm: 0.07406956201884896, minimum ratio: 2.4842105263157896\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00556\n",
      "epoch 4113 / 20000\n",
      "gradient norm: 0.06640052112925332, minimum ratio: 2.4868421052631575\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00556\n",
      "epoch 4114 / 20000\n",
      "gradient norm: 0.033347197429975495, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00555\n",
      "epoch 4115 / 20000\n",
      "gradient norm: 0.07161039661878021, minimum ratio: 2.510526315789474\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00555\n",
      "epoch 4116 / 20000\n",
      "gradient norm: 0.039162928151199594, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00555\n",
      "epoch 4117 / 20000\n",
      "gradient norm: 0.06384042603895068, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00556\n",
      "epoch 4118 / 20000\n",
      "gradient norm: 0.043742396010202356, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00555\n",
      "epoch 4119 / 20000\n",
      "gradient norm: 0.02915349931572564, minimum ratio: 2.507894736842105\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00555\n",
      "epoch 4120 / 20000\n",
      "gradient norm: 0.15158395637990907, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00573\n",
      "\tval loss: 0.00555\n",
      "epoch 4121 / 20000\n",
      "gradient norm: 0.0992367013823241, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00559\n",
      "epoch 4122 / 20000\n",
      "gradient norm: 0.05046548078826163, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00555\n",
      "epoch 4123 / 20000\n",
      "gradient norm: 0.08185276278527454, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00554\n",
      "epoch 4124 / 20000\n",
      "gradient norm: 0.05160101846558973, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00555\n",
      "epoch 4125 / 20000\n",
      "gradient norm: 0.06612256937660277, minimum ratio: 2.4868421052631575\n",
      "\ttrain loss: 0.00573\n",
      "\tval loss: 0.00558\n",
      "epoch 4126 / 20000\n",
      "gradient norm: 0.11430937133263797, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00573\n",
      "\tval loss: 0.00555\n",
      "epoch 4127 / 20000\n",
      "gradient norm: 0.06289908476173878, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00555\n",
      "epoch 4128 / 20000\n",
      "gradient norm: 0.10154960479121655, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00556\n",
      "epoch 4129 / 20000\n",
      "gradient norm: 0.062309052678756416, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00556\n",
      "epoch 4130 / 20000\n",
      "gradient norm: 0.07752914365846664, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00555\n",
      "epoch 4131 / 20000\n",
      "gradient norm: 0.06921403325395659, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00554\n",
      "epoch 4132 / 20000\n",
      "gradient norm: 0.03936006859294139, minimum ratio: 2.489473684210526\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00556\n",
      "epoch 4133 / 20000\n",
      "gradient norm: 0.0817778967320919, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00556\n",
      "epoch 4134 / 20000\n",
      "gradient norm: 0.02251248784159543, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00555\n",
      "epoch 4135 / 20000\n",
      "gradient norm: 0.12079895281931385, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00554\n",
      "epoch 4136 / 20000\n",
      "gradient norm: 0.0694593280350091, minimum ratio: 2.518421052631579\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00558\n",
      "epoch 4137 / 20000\n",
      "gradient norm: 0.040988944441778585, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00555\n",
      "epoch 4138 / 20000\n",
      "gradient norm: 0.06499513809103519, minimum ratio: 2.4842105263157896\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00554\n",
      "epoch 4139 / 20000\n",
      "gradient norm: 0.08348071778891608, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00557\n",
      "epoch 4140 / 20000\n",
      "gradient norm: 0.09368895064108074, minimum ratio: 2.4868421052631575\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00555\n",
      "epoch 4141 / 20000\n",
      "gradient norm: 0.035327459074324, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00556\n",
      "epoch 4142 / 20000\n",
      "gradient norm: 0.03724078770028427, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00555\n",
      "epoch 4143 / 20000\n",
      "gradient norm: 0.04440527691622265, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00555\n",
      "epoch 4144 / 20000\n",
      "gradient norm: 0.05701100575970486, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00555\n",
      "epoch 4145 / 20000\n",
      "gradient norm: 0.061228219245094806, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00556\n",
      "epoch 4146 / 20000\n",
      "gradient norm: 0.054536110954359174, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00556\n",
      "epoch 4147 / 20000\n",
      "gradient norm: 0.05238952752551995, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00555\n",
      "epoch 4148 / 20000\n",
      "gradient norm: 0.11393572617089376, minimum ratio: 2.460526315789474\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00554\n",
      "epoch 4149 / 20000\n",
      "gradient norm: 0.1240501303691417, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00557\n",
      "epoch 4150 / 20000\n",
      "gradient norm: 0.12228712090291083, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00555\n",
      "epoch 4151 / 20000\n",
      "gradient norm: 0.09681181430642027, minimum ratio: 2.5105263157894737\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00556\n",
      "epoch 4152 / 20000\n",
      "gradient norm: 0.0845328435243573, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 4153 / 20000\n",
      "gradient norm: 0.046168271961505525, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00555\n",
      "epoch 4154 / 20000\n",
      "gradient norm: 0.053461583564057946, minimum ratio: 2.492105263157895\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00556\n",
      "epoch 4155 / 20000\n",
      "gradient norm: 0.04706872469978407, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00556\n",
      "epoch 4156 / 20000\n",
      "gradient norm: 0.07132607558742166, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00555\n",
      "epoch 4157 / 20000\n",
      "gradient norm: 0.0847019188804552, minimum ratio: 2.4842105263157896\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00556\n",
      "epoch 4158 / 20000\n",
      "gradient norm: 0.06847163988277316, minimum ratio: 2.4868421052631575\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00555\n",
      "epoch 4159 / 20000\n",
      "gradient norm: 0.044124036096036434, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00555\n",
      "epoch 4160 / 20000\n",
      "gradient norm: 0.018502629522117786, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00556\n",
      "epoch 4161 / 20000\n",
      "gradient norm: 0.05885717665660195, minimum ratio: 2.513157894736842\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00556\n",
      "epoch 4162 / 20000\n",
      "gradient norm: 0.029846657169400714, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00554\n",
      "epoch 4163 / 20000\n",
      "gradient norm: 0.08314150344813243, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00555\n",
      "epoch 4164 / 20000\n",
      "gradient norm: 0.08293699042405933, minimum ratio: 2.4894736842105267\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00556\n",
      "epoch 4165 / 20000\n",
      "gradient norm: 0.08190249529434368, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00555\n",
      "epoch 4166 / 20000\n",
      "gradient norm: 0.08616313616221305, minimum ratio: 2.4842105263157896\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00555\n",
      "epoch 4167 / 20000\n",
      "gradient norm: 0.09440612126491033, minimum ratio: 2.4842105263157896\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00556\n",
      "epoch 4168 / 20000\n",
      "gradient norm: 0.08855580596718937, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00555\n",
      "epoch 4169 / 20000\n",
      "gradient norm: 0.07909529001335613, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00554\n",
      "epoch 4170 / 20000\n",
      "gradient norm: 0.07013099832693115, minimum ratio: 2.492105263157895\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00556\n",
      "epoch 4171 / 20000\n",
      "gradient norm: 0.09602210595039651, minimum ratio: 2.4842105263157896\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00558\n",
      "epoch 4172 / 20000\n",
      "gradient norm: 0.05604085314553231, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00554\n",
      "epoch 4173 / 20000\n",
      "gradient norm: 0.12491687736473978, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00555\n",
      "epoch 4174 / 20000\n",
      "gradient norm: 0.0740357682807371, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00556\n",
      "epoch 4175 / 20000\n",
      "gradient norm: 0.04666652300511487, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00555\n",
      "epoch 4176 / 20000\n",
      "gradient norm: 0.038998373471258674, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00555\n",
      "epoch 4177 / 20000\n",
      "gradient norm: 0.0496976142458152, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00555\n",
      "epoch 4178 / 20000\n",
      "gradient norm: 0.07641496809083037, minimum ratio: 2.4815789473684213\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00556\n",
      "epoch 4179 / 20000\n",
      "gradient norm: 0.03280398965580389, minimum ratio: 2.460526315789474\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00555\n",
      "epoch 4180 / 20000\n",
      "gradient norm: 0.07565230614272878, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00555\n",
      "epoch 4181 / 20000\n",
      "gradient norm: 0.049660437274724245, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00555\n",
      "epoch 4182 / 20000\n",
      "gradient norm: 0.02032963137025945, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00555\n",
      "epoch 4183 / 20000\n",
      "gradient norm: 0.07053754391381517, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00556\n",
      "epoch 4184 / 20000\n",
      "gradient norm: 0.04607802855025511, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00555\n",
      "epoch 4185 / 20000\n",
      "gradient norm: 0.06244000926380977, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00554\n",
      "epoch 4186 / 20000\n",
      "gradient norm: 0.04530277076992206, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00556\n",
      "epoch 4187 / 20000\n",
      "gradient norm: 0.0608710941451136, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00555\n",
      "epoch 4188 / 20000\n",
      "gradient norm: 0.056442056433297694, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00555\n",
      "epoch 4189 / 20000\n",
      "gradient norm: 0.08296373453049455, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00555\n",
      "epoch 4190 / 20000\n",
      "gradient norm: 0.07429934793617576, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00556\n",
      "epoch 4191 / 20000\n",
      "gradient norm: 0.05155722179915756, minimum ratio: 2.492105263157895\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00556\n",
      "epoch 4192 / 20000\n",
      "gradient norm: 0.08038424991536885, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00554\n",
      "epoch 4193 / 20000\n",
      "gradient norm: 0.052882596384733915, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00554\n",
      "epoch 4194 / 20000\n",
      "gradient norm: 0.10993105638772249, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00556\n",
      "epoch 4195 / 20000\n",
      "gradient norm: 0.08920488052535802, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00555\n",
      "epoch 4196 / 20000\n",
      "gradient norm: 0.07008527818834409, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00554\n",
      "epoch 4197 / 20000\n",
      "gradient norm: 0.06488803635875229, minimum ratio: 2.4842105263157896\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00556\n",
      "epoch 4198 / 20000\n",
      "gradient norm: 0.04990918282419443, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00556\n",
      "epoch 4199 / 20000\n",
      "gradient norm: 0.07594382925890386, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00554\n",
      "epoch 4200 / 20000\n",
      "gradient norm: 0.07887181371916085, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00555\n",
      "epoch 4201 / 20000\n",
      "gradient norm: 0.06726956999045797, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00556\n",
      "epoch 4202 / 20000\n",
      "gradient norm: 0.10252598242368549, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00554\n",
      "epoch 4203 / 20000\n",
      "gradient norm: 0.053613264579325914, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00555\n",
      "epoch 4204 / 20000\n",
      "gradient norm: 0.08628852089168504, minimum ratio: 2.492105263157895\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00556\n",
      "epoch 4205 / 20000\n",
      "gradient norm: 0.03311462511192076, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00555\n",
      "epoch 4206 / 20000\n",
      "gradient norm: 0.1367630732129328, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00554\n",
      "epoch 4207 / 20000\n",
      "gradient norm: 0.0930691325920634, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00557\n",
      "epoch 4208 / 20000\n",
      "gradient norm: 0.06328355333243962, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00556\n",
      "epoch 4209 / 20000\n",
      "gradient norm: 0.06569860241143033, minimum ratio: 2.460526315789474\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00555\n",
      "epoch 4210 / 20000\n",
      "gradient norm: 0.07344497842132114, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00554\n",
      "epoch 4211 / 20000\n",
      "gradient norm: 0.11130658048205078, minimum ratio: 2.5078947368421054\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00556\n",
      "epoch 4212 / 20000\n",
      "gradient norm: 0.07548432890325785, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00557\n",
      "epoch 4213 / 20000\n",
      "gradient norm: 0.0554337416542694, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00554\n",
      "epoch 4214 / 20000\n",
      "gradient norm: 0.04662912062485702, minimum ratio: 2.4868421052631575\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00554\n",
      "epoch 4215 / 20000\n",
      "gradient norm: 0.06954596715513617, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00556\n",
      "epoch 4216 / 20000\n",
      "gradient norm: 0.05961515387753025, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00556\n",
      "epoch 4217 / 20000\n",
      "gradient norm: 0.07066487887641415, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00554\n",
      "epoch 4218 / 20000\n",
      "gradient norm: 0.06475837278412655, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00556\n",
      "epoch 4219 / 20000\n",
      "gradient norm: 0.10341499137575738, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00555\n",
      "epoch 4220 / 20000\n",
      "gradient norm: 0.05919639387866482, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00556\n",
      "epoch 4221 / 20000\n",
      "gradient norm: 0.02998103221761994, minimum ratio: 2.4578947368421056\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00555\n",
      "epoch 4222 / 20000\n",
      "gradient norm: 0.06688282996765338, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00555\n",
      "epoch 4223 / 20000\n",
      "gradient norm: 0.1186417790595442, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00555\n",
      "epoch 4224 / 20000\n",
      "gradient norm: 0.025573667480784934, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00555\n",
      "epoch 4225 / 20000\n",
      "gradient norm: 0.028329029126325622, minimum ratio: 2.4447368421052627\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00556\n",
      "epoch 4226 / 20000\n",
      "gradient norm: 0.04539777961326763, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00555\n",
      "epoch 4227 / 20000\n",
      "gradient norm: 0.0324317010527011, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00554\n",
      "epoch 4228 / 20000\n",
      "gradient norm: 0.05483952471695375, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00555\n",
      "epoch 4229 / 20000\n",
      "gradient norm: 0.0843437853618525, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00555\n",
      "epoch 4230 / 20000\n",
      "gradient norm: 0.061199716801638715, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00556\n",
      "epoch 4231 / 20000\n",
      "gradient norm: 0.030985068588051945, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00554\n",
      "epoch 4232 / 20000\n",
      "gradient norm: 0.04709569489932619, minimum ratio: 2.4973684210526312\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00554\n",
      "epoch 4233 / 20000\n",
      "gradient norm: 0.08594980239286087, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00556\n",
      "epoch 4234 / 20000\n",
      "gradient norm: 0.04853873685351573, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00555\n",
      "epoch 4235 / 20000\n",
      "gradient norm: 0.06598444102564827, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00554\n",
      "epoch 4236 / 20000\n",
      "gradient norm: 0.05468230589758605, minimum ratio: 2.4684210526315784\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00555\n",
      "epoch 4237 / 20000\n",
      "gradient norm: 0.07152835282613523, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00556\n",
      "epoch 4238 / 20000\n",
      "gradient norm: 0.043137673565070145, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00555\n",
      "epoch 4239 / 20000\n",
      "gradient norm: 0.052456734294537455, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00554\n",
      "epoch 4240 / 20000\n",
      "gradient norm: 0.07390623353421688, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00556\n",
      "epoch 4241 / 20000\n",
      "gradient norm: 0.06126214799587615, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00555\n",
      "epoch 4242 / 20000\n",
      "gradient norm: 0.04522875920520164, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00554\n",
      "epoch 4243 / 20000\n",
      "gradient norm: 0.056447098999342415, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00556\n",
      "epoch 4244 / 20000\n",
      "gradient norm: 0.07059946958906949, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00554\n",
      "epoch 4245 / 20000\n",
      "gradient norm: 0.047212881210725754, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00555\n",
      "epoch 4246 / 20000\n",
      "gradient norm: 0.02111785893794149, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00555\n",
      "epoch 4247 / 20000\n",
      "gradient norm: 0.04525332277989946, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00555\n",
      "epoch 4248 / 20000\n",
      "gradient norm: 0.047913618822349235, minimum ratio: 2.5078947368421054\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 4249 / 20000\n",
      "gradient norm: 0.040934502860181965, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00556\n",
      "epoch 4250 / 20000\n",
      "gradient norm: 0.09192731152870692, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00555\n",
      "epoch 4251 / 20000\n",
      "gradient norm: 0.022857266929349862, minimum ratio: 2.4868421052631575\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00554\n",
      "epoch 4252 / 20000\n",
      "gradient norm: 0.048790644155815244, minimum ratio: 2.492105263157895\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00555\n",
      "epoch 4253 / 20000\n",
      "gradient norm: 0.07852252083830535, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00555\n",
      "epoch 4254 / 20000\n",
      "gradient norm: 0.045141482216422446, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00555\n",
      "epoch 4255 / 20000\n",
      "gradient norm: 0.0803486305376282, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00555\n",
      "epoch 4256 / 20000\n",
      "gradient norm: 0.09011047548847273, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00555\n",
      "epoch 4257 / 20000\n",
      "gradient norm: 0.07905413070693612, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00554\n",
      "epoch 4258 / 20000\n",
      "gradient norm: 0.07121044816449285, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00555\n",
      "epoch 4259 / 20000\n",
      "gradient norm: 0.042198626208119094, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00556\n",
      "epoch 4260 / 20000\n",
      "gradient norm: 0.032655691480613314, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00555\n",
      "epoch 4261 / 20000\n",
      "gradient norm: 0.11332544730976224, minimum ratio: 2.4894736842105267\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00554\n",
      "epoch 4262 / 20000\n",
      "gradient norm: 0.06382667490834137, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00555\n",
      "epoch 4263 / 20000\n",
      "gradient norm: 0.05267703275603708, minimum ratio: 2.505263157894737\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00555\n",
      "epoch 4264 / 20000\n",
      "gradient norm: 0.0344495979079511, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00554\n",
      "epoch 4265 / 20000\n",
      "gradient norm: 0.08066837256774306, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00555\n",
      "epoch 4266 / 20000\n",
      "gradient norm: 0.1316990356426686, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00554\n",
      "epoch 4267 / 20000\n",
      "gradient norm: 0.0962427009944804, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00557\n",
      "epoch 4268 / 20000\n",
      "gradient norm: 0.142975565220695, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00573\n",
      "\tval loss: 0.00554\n",
      "epoch 4269 / 20000\n",
      "gradient norm: 0.11954972753301263, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00556\n",
      "epoch 4270 / 20000\n",
      "gradient norm: 0.08022249522036873, minimum ratio: 2.505263157894737\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00556\n",
      "epoch 4271 / 20000\n",
      "gradient norm: 0.06570257374551147, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00554\n",
      "epoch 4272 / 20000\n",
      "gradient norm: 0.04994031699607149, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00554\n",
      "epoch 4273 / 20000\n",
      "gradient norm: 0.03457227849867195, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00556\n",
      "epoch 4274 / 20000\n",
      "gradient norm: 0.05863304575905204, minimum ratio: 2.460526315789474\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00555\n",
      "epoch 4275 / 20000\n",
      "gradient norm: 0.0796941292937845, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00555\n",
      "epoch 4276 / 20000\n",
      "gradient norm: 0.0682533229701221, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00554\n",
      "epoch 4277 / 20000\n",
      "gradient norm: 0.054430459218565375, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00554\n",
      "epoch 4278 / 20000\n",
      "gradient norm: 0.06278209679294378, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00557\n",
      "epoch 4279 / 20000\n",
      "gradient norm: 0.07462456979556009, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00554\n",
      "epoch 4280 / 20000\n",
      "gradient norm: 0.06752740254160017, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 4281 / 20000\n",
      "gradient norm: 0.03791755822021514, minimum ratio: 2.492105263157894\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00554\n",
      "epoch 4282 / 20000\n",
      "gradient norm: 0.07890110771404579, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00555\n",
      "epoch 4283 / 20000\n",
      "gradient norm: 0.07745619359775446, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00556\n",
      "epoch 4284 / 20000\n",
      "gradient norm: 0.069667782925535, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00554\n",
      "epoch 4285 / 20000\n",
      "gradient norm: 0.08625449577812105, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00554\n",
      "epoch 4286 / 20000\n",
      "gradient norm: 0.08096234424738213, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00556\n",
      "epoch 4287 / 20000\n",
      "gradient norm: 0.0762665694928728, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00555\n",
      "epoch 4288 / 20000\n",
      "gradient norm: 0.03810579502169276, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00554\n",
      "epoch 4289 / 20000\n",
      "gradient norm: 0.06442161643644795, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00555\n",
      "epoch 4290 / 20000\n",
      "gradient norm: 0.051384275226155296, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00555\n",
      "epoch 4291 / 20000\n",
      "gradient norm: 0.08915438229450956, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00555\n",
      "epoch 4292 / 20000\n",
      "gradient norm: 0.053079465054906905, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 4293 / 20000\n",
      "gradient norm: 0.08093620144063607, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00555\n",
      "epoch 4294 / 20000\n",
      "gradient norm: 0.09190422506071627, minimum ratio: 2.4736842105263155\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00555\n",
      "epoch 4295 / 20000\n",
      "gradient norm: 0.06167546639335342, minimum ratio: 2.4736842105263155\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00555\n",
      "epoch 4296 / 20000\n",
      "gradient norm: 0.028557095676660538, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00554\n",
      "epoch 4297 / 20000\n",
      "gradient norm: 0.04262857511639595, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00554\n",
      "epoch 4298 / 20000\n",
      "gradient norm: 0.1228424062137492, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00557\n",
      "epoch 4299 / 20000\n",
      "gradient norm: 0.10218311709468253, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00573\n",
      "\tval loss: 0.00553\n",
      "epoch 4300 / 20000\n",
      "gradient norm: 0.05263409003964625, minimum ratio: 2.460526315789474\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00555\n",
      "epoch 4301 / 20000\n",
      "gradient norm: 0.06159648357424885, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00555\n",
      "epoch 4302 / 20000\n",
      "gradient norm: 0.04090095611172728, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00555\n",
      "epoch 4303 / 20000\n",
      "gradient norm: 0.048470700276084244, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00554\n",
      "epoch 4304 / 20000\n",
      "gradient norm: 0.06302861328003928, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00555\n",
      "epoch 4305 / 20000\n",
      "gradient norm: 0.06067513124435209, minimum ratio: 2.46578947368421\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00556\n",
      "epoch 4306 / 20000\n",
      "gradient norm: 0.04785847320454195, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00555\n",
      "epoch 4307 / 20000\n",
      "gradient norm: 0.05525845644297078, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00554\n",
      "epoch 4308 / 20000\n",
      "gradient norm: 0.08465610747225583, minimum ratio: 2.494736842105263\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00554\n",
      "epoch 4309 / 20000\n",
      "gradient norm: 0.08816823072265834, minimum ratio: 2.5131578947368425\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00558\n",
      "epoch 4310 / 20000\n",
      "gradient norm: 0.06617590790847316, minimum ratio: 2.5078947368421054\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 4311 / 20000\n",
      "gradient norm: 0.13912380847614259, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00573\n",
      "\tval loss: 0.00553\n",
      "epoch 4312 / 20000\n",
      "gradient norm: 0.09059586393414065, minimum ratio: 2.4894736842105267\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00557\n",
      "epoch 4313 / 20000\n",
      "gradient norm: 0.055764930686564185, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00555\n",
      "epoch 4314 / 20000\n",
      "gradient norm: 0.1116817855508998, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00554\n",
      "epoch 4315 / 20000\n",
      "gradient norm: 0.04560627494356595, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00555\n",
      "epoch 4316 / 20000\n",
      "gradient norm: 0.050641786569030955, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00555\n",
      "epoch 4317 / 20000\n",
      "gradient norm: 0.050182668390334584, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00555\n",
      "epoch 4318 / 20000\n",
      "gradient norm: 0.0969152853358537, minimum ratio: 2.460526315789474\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00554\n",
      "epoch 4319 / 20000\n",
      "gradient norm: 0.10075008688727394, minimum ratio: 2.492105263157895\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00556\n",
      "epoch 4320 / 20000\n",
      "gradient norm: 0.04232454739394598, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00554\n",
      "epoch 4321 / 20000\n",
      "gradient norm: 0.07116699908510782, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00554\n",
      "epoch 4322 / 20000\n",
      "gradient norm: 0.0365185099944938, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00555\n",
      "epoch 4323 / 20000\n",
      "gradient norm: 0.06266284876619466, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00555\n",
      "epoch 4324 / 20000\n",
      "gradient norm: 0.04565999167971313, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00554\n",
      "epoch 4325 / 20000\n",
      "gradient norm: 0.12307506540673785, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00573\n",
      "\tval loss: 0.00554\n",
      "epoch 4326 / 20000\n",
      "gradient norm: 0.057488818107231054, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00556\n",
      "epoch 4327 / 20000\n",
      "gradient norm: 0.11200531048234552, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00556\n",
      "epoch 4328 / 20000\n",
      "gradient norm: 0.021692980102670845, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 4329 / 20000\n",
      "gradient norm: 0.07088457810459659, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00554\n",
      "epoch 4330 / 20000\n",
      "gradient norm: 0.06457090051844716, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00556\n",
      "epoch 4331 / 20000\n",
      "gradient norm: 0.0690339756256435, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00555\n",
      "epoch 4332 / 20000\n",
      "gradient norm: 0.08735663478728384, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00553\n",
      "epoch 4333 / 20000\n",
      "gradient norm: 0.06446500058518723, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00555\n",
      "epoch 4334 / 20000\n",
      "gradient norm: 0.0667726009269245, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00555\n",
      "epoch 4335 / 20000\n",
      "gradient norm: 0.0708846032503061, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00554\n",
      "epoch 4336 / 20000\n",
      "gradient norm: 0.05944380030268803, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 4337 / 20000\n",
      "gradient norm: 0.04891898689675145, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 4338 / 20000\n",
      "gradient norm: 0.07628847903106362, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00555\n",
      "epoch 4339 / 20000\n",
      "gradient norm: 0.06236318309674971, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00555\n",
      "epoch 4340 / 20000\n",
      "gradient norm: 0.07343446707818657, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00555\n",
      "epoch 4341 / 20000\n",
      "gradient norm: 0.07466715830378234, minimum ratio: 2.4815789473684213\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00554\n",
      "epoch 4342 / 20000\n",
      "gradient norm: 0.03778405551565811, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00554\n",
      "epoch 4343 / 20000\n",
      "gradient norm: 0.028010360634652898, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00555\n",
      "epoch 4344 / 20000\n",
      "gradient norm: 0.10442804615013301, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00555\n",
      "epoch 4345 / 20000\n",
      "gradient norm: 0.13041825912659988, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00573\n",
      "\tval loss: 0.00553\n",
      "epoch 4346 / 20000\n",
      "gradient norm: 0.02774093739571981, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00555\n",
      "epoch 4347 / 20000\n",
      "gradient norm: 0.08470860897796229, minimum ratio: 2.4815789473684213\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00557\n",
      "epoch 4348 / 20000\n",
      "gradient norm: 0.09731744340388104, minimum ratio: 2.507894736842105\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00554\n",
      "epoch 4349 / 20000\n",
      "gradient norm: 0.0704303381498903, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00554\n",
      "epoch 4350 / 20000\n",
      "gradient norm: 0.07405735040083528, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00556\n",
      "epoch 4351 / 20000\n",
      "gradient norm: 0.046673966106027365, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00555\n",
      "epoch 4352 / 20000\n",
      "gradient norm: 0.07230563959456049, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00553\n",
      "epoch 4353 / 20000\n",
      "gradient norm: 0.07049194409046322, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00555\n",
      "epoch 4354 / 20000\n",
      "gradient norm: 0.06477302045095712, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00557\n",
      "epoch 4355 / 20000\n",
      "gradient norm: 0.0664415275095962, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00554\n",
      "epoch 4356 / 20000\n",
      "gradient norm: 0.0540814896376105, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00554\n",
      "epoch 4357 / 20000\n",
      "gradient norm: 0.05246684196754359, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00555\n",
      "epoch 4358 / 20000\n",
      "gradient norm: 0.06932494443026371, minimum ratio: 2.4842105263157896\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00554\n",
      "epoch 4359 / 20000\n",
      "gradient norm: 0.05478691018652171, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 4360 / 20000\n",
      "gradient norm: 0.03852349612861872, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00554\n",
      "epoch 4361 / 20000\n",
      "gradient norm: 0.03577893695910461, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00555\n",
      "epoch 4362 / 20000\n",
      "gradient norm: 0.08163260572473519, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00555\n",
      "epoch 4363 / 20000\n",
      "gradient norm: 0.09694420942105353, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00553\n",
      "epoch 4364 / 20000\n",
      "gradient norm: 0.06729926159459865, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00555\n",
      "epoch 4365 / 20000\n",
      "gradient norm: 0.04906379400927108, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00555\n",
      "epoch 4366 / 20000\n",
      "gradient norm: 0.053598467784468085, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 4367 / 20000\n",
      "gradient norm: 0.05919382013962604, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00554\n",
      "epoch 4368 / 20000\n",
      "gradient norm: 0.05610014824196696, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00555\n",
      "epoch 4369 / 20000\n",
      "gradient norm: 0.041023891855729744, minimum ratio: 2.5105263157894733\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 4370 / 20000\n",
      "gradient norm: 0.04039095593907405, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 4371 / 20000\n",
      "gradient norm: 0.06770470324408961, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00554\n",
      "epoch 4372 / 20000\n",
      "gradient norm: 0.09214462013915181, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00555\n",
      "epoch 4373 / 20000\n",
      "gradient norm: 0.08017627464141697, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 4374 / 20000\n",
      "gradient norm: 0.0290913853677921, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00554\n",
      "epoch 4375 / 20000\n",
      "gradient norm: 0.038171268584846985, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00554\n",
      "epoch 4376 / 20000\n",
      "gradient norm: 0.0648918654769659, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00554\n",
      "epoch 4377 / 20000\n",
      "gradient norm: 0.03590466413879767, minimum ratio: 2.494736842105263\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00554\n",
      "epoch 4378 / 20000\n",
      "gradient norm: 0.0689497483544983, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 4379 / 20000\n",
      "gradient norm: 0.07257915829541162, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 4380 / 20000\n",
      "gradient norm: 0.06027105182874948, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00554\n",
      "epoch 4381 / 20000\n",
      "gradient norm: 0.07507904013618827, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00555\n",
      "epoch 4382 / 20000\n",
      "gradient norm: 0.038389011984691024, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 4383 / 20000\n",
      "gradient norm: 0.07603657747677062, minimum ratio: 2.492105263157895\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00554\n",
      "epoch 4384 / 20000\n",
      "gradient norm: 0.07789077877532691, minimum ratio: 2.505263157894737\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00554\n",
      "epoch 4385 / 20000\n",
      "gradient norm: 0.13751988695003092, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00555\n",
      "epoch 4386 / 20000\n",
      "gradient norm: 0.16664514783769846, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00556\n",
      "epoch 4387 / 20000\n",
      "gradient norm: 0.03512688569026068, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 4388 / 20000\n",
      "gradient norm: 0.11206904181744903, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00553\n",
      "epoch 4389 / 20000\n",
      "gradient norm: 0.06767737708287314, minimum ratio: 2.492105263157895\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00556\n",
      "epoch 4390 / 20000\n",
      "gradient norm: 0.12894084968138486, minimum ratio: 2.4868421052631575\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00558\n",
      "epoch 4391 / 20000\n",
      "gradient norm: 0.06808148301206529, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00553\n",
      "epoch 4392 / 20000\n",
      "gradient norm: 0.07737515005283058, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00553\n",
      "epoch 4393 / 20000\n",
      "gradient norm: 0.06690476450603455, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00556\n",
      "epoch 4394 / 20000\n",
      "gradient norm: 0.07973060724907555, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00554\n",
      "epoch 4395 / 20000\n",
      "gradient norm: 0.03909245185786858, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 4396 / 20000\n",
      "gradient norm: 0.08065490634180605, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00553\n",
      "epoch 4397 / 20000\n",
      "gradient norm: 0.10676820296794176, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00556\n",
      "epoch 4398 / 20000\n",
      "gradient norm: 0.10036257997853681, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00554\n",
      "epoch 4399 / 20000\n",
      "gradient norm: 0.05305083200801164, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00553\n",
      "epoch 4400 / 20000\n",
      "gradient norm: 0.03534206669428386, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00554\n",
      "epoch 4401 / 20000\n",
      "gradient norm: 0.12805718753952533, minimum ratio: 2.4894736842105267\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00557\n",
      "epoch 4402 / 20000\n",
      "gradient norm: 0.08844086481258273, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00553\n",
      "epoch 4403 / 20000\n",
      "gradient norm: 0.10965605126693845, minimum ratio: 2.5236842105263158\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00554\n",
      "epoch 4404 / 20000\n",
      "gradient norm: 0.07266613282263279, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00555\n",
      "epoch 4405 / 20000\n",
      "gradient norm: 0.10711122478824109, minimum ratio: 2.492105263157895\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00554\n",
      "epoch 4406 / 20000\n",
      "gradient norm: 0.06902189215179533, minimum ratio: 2.4868421052631575\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00555\n",
      "epoch 4407 / 20000\n",
      "gradient norm: 0.0497669605538249, minimum ratio: 2.492105263157895\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 4408 / 20000\n",
      "gradient norm: 0.09200762491673231, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00553\n",
      "epoch 4409 / 20000\n",
      "gradient norm: 0.10673349146964028, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00555\n",
      "epoch 4410 / 20000\n",
      "gradient norm: 0.07049489739438286, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00554\n",
      "epoch 4411 / 20000\n",
      "gradient norm: 0.04884732136270031, minimum ratio: 2.4868421052631575\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 4412 / 20000\n",
      "gradient norm: 0.044312910264125094, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 4413 / 20000\n",
      "gradient norm: 0.12001981015782803, minimum ratio: 2.518421052631579\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00556\n",
      "epoch 4414 / 20000\n",
      "gradient norm: 0.07096176932100207, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00553\n",
      "epoch 4415 / 20000\n",
      "gradient norm: 0.05707400670507923, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00554\n",
      "epoch 4416 / 20000\n",
      "gradient norm: 0.14176585100358352, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00557\n",
      "epoch 4417 / 20000\n",
      "gradient norm: 0.06051982336794026, minimum ratio: 2.4973684210526312\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00553\n",
      "epoch 4418 / 20000\n",
      "gradient norm: 0.1064121361123398, minimum ratio: 2.505263157894737\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00553\n",
      "epoch 4419 / 20000\n",
      "gradient norm: 0.05653631794848479, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00555\n",
      "epoch 4420 / 20000\n",
      "gradient norm: 0.05353824744815938, minimum ratio: 2.5078947368421054\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 4421 / 20000\n",
      "gradient norm: 0.0737188229104504, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00553\n",
      "epoch 4422 / 20000\n",
      "gradient norm: 0.06786904484033585, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00555\n",
      "epoch 4423 / 20000\n",
      "gradient norm: 0.08150738477706909, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00555\n",
      "epoch 4424 / 20000\n",
      "gradient norm: 0.07443404577497859, minimum ratio: 2.4842105263157896\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 4425 / 20000\n",
      "gradient norm: 0.0844855603063479, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00554\n",
      "epoch 4426 / 20000\n",
      "gradient norm: 0.08776033320464194, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00556\n",
      "epoch 4427 / 20000\n",
      "gradient norm: 0.07607078633736819, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00554\n",
      "epoch 4428 / 20000\n",
      "gradient norm: 0.065144257619977, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 4429 / 20000\n",
      "gradient norm: 0.06981785543030128, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00553\n",
      "epoch 4430 / 20000\n",
      "gradient norm: 0.06245416187448427, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00555\n",
      "epoch 4431 / 20000\n",
      "gradient norm: 0.07366970513248816, minimum ratio: 2.507894736842105\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00555\n",
      "epoch 4432 / 20000\n",
      "gradient norm: 0.09140429995022714, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00554\n",
      "epoch 4433 / 20000\n",
      "gradient norm: 0.08492682166979648, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 4434 / 20000\n",
      "gradient norm: 0.047148946119705215, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 4435 / 20000\n",
      "gradient norm: 0.11432378058088943, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00554\n",
      "epoch 4436 / 20000\n",
      "gradient norm: 0.10933091351762414, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00556\n",
      "epoch 4437 / 20000\n",
      "gradient norm: 0.080800186668057, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 4438 / 20000\n",
      "gradient norm: 0.08139419442159124, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 4439 / 20000\n",
      "gradient norm: 0.08188317372696474, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00553\n",
      "epoch 4440 / 20000\n",
      "gradient norm: 0.040477119910065085, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00556\n",
      "epoch 4441 / 20000\n",
      "gradient norm: 0.08883017592597753, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00554\n",
      "epoch 4442 / 20000\n",
      "gradient norm: 0.07697248621843755, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 4443 / 20000\n",
      "gradient norm: 0.05216212727827951, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00553\n",
      "epoch 4444 / 20000\n",
      "gradient norm: 0.12766525382176042, minimum ratio: 2.4842105263157896\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00554\n",
      "epoch 4445 / 20000\n",
      "gradient norm: 0.07628159556770697, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00557\n",
      "epoch 4446 / 20000\n",
      "gradient norm: 0.1328602550784126, minimum ratio: 2.4868421052631575\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00553\n",
      "epoch 4447 / 20000\n",
      "gradient norm: 0.09076098771765828, minimum ratio: 2.5184210526315787\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00554\n",
      "epoch 4448 / 20000\n",
      "gradient norm: 0.10617998376255855, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00556\n",
      "epoch 4449 / 20000\n",
      "gradient norm: 0.028664006895269267, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00553\n",
      "epoch 4450 / 20000\n",
      "gradient norm: 0.08647622822900303, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00553\n",
      "epoch 4451 / 20000\n",
      "gradient norm: 0.05628777638776228, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00556\n",
      "epoch 4452 / 20000\n",
      "gradient norm: 0.057673368719406426, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00554\n",
      "epoch 4453 / 20000\n",
      "gradient norm: 0.04450476125930436, minimum ratio: 2.492105263157895\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00553\n",
      "epoch 4454 / 20000\n",
      "gradient norm: 0.016027004123316146, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00555\n",
      "epoch 4455 / 20000\n",
      "gradient norm: 0.08151211385848, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00555\n",
      "epoch 4456 / 20000\n",
      "gradient norm: 0.030000600265339017, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 4457 / 20000\n",
      "gradient norm: 0.07438628398813307, minimum ratio: 2.4842105263157896\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00553\n",
      "epoch 4458 / 20000\n",
      "gradient norm: 0.08064308081520721, minimum ratio: 2.5078947368421054\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00553\n",
      "epoch 4459 / 20000\n",
      "gradient norm: 0.0642058250377886, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00556\n",
      "epoch 4460 / 20000\n",
      "gradient norm: 0.10283043253002688, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00554\n",
      "epoch 4461 / 20000\n",
      "gradient norm: 0.047346740640932694, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 4462 / 20000\n",
      "gradient norm: 0.04608997283503413, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00554\n",
      "epoch 4463 / 20000\n",
      "gradient norm: 0.05879439046839252, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00554\n",
      "epoch 4464 / 20000\n",
      "gradient norm: 0.06631804438075051, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 4465 / 20000\n",
      "gradient norm: 0.08712758403271437, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00554\n",
      "epoch 4466 / 20000\n",
      "gradient norm: 0.06771147725521587, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 4467 / 20000\n",
      "gradient norm: 0.025544895652274136, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00554\n",
      "epoch 4468 / 20000\n",
      "gradient norm: 0.04397258270182647, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 4469 / 20000\n",
      "gradient norm: 0.036933474300894886, minimum ratio: 2.507894736842105\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 4470 / 20000\n",
      "gradient norm: 0.07637519322452135, minimum ratio: 2.4815789473684213\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00553\n",
      "epoch 4471 / 20000\n",
      "gradient norm: 0.042756320763146505, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00556\n",
      "epoch 4472 / 20000\n",
      "gradient norm: 0.07722696871496737, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00553\n",
      "epoch 4473 / 20000\n",
      "gradient norm: 0.08134498872095719, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00553\n",
      "epoch 4474 / 20000\n",
      "gradient norm: 0.024542867759009823, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00555\n",
      "epoch 4475 / 20000\n",
      "gradient norm: 0.07194511737907305, minimum ratio: 2.46578947368421\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 4476 / 20000\n",
      "gradient norm: 0.08396427804837003, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 4477 / 20000\n",
      "gradient norm: 0.06647720461478457, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 4478 / 20000\n",
      "gradient norm: 0.036697601521154866, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 4479 / 20000\n",
      "gradient norm: 0.09043808246497065, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00553\n",
      "epoch 4480 / 20000\n",
      "gradient norm: 0.07541904610116035, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00554\n",
      "epoch 4481 / 20000\n",
      "gradient norm: 0.07653040695004165, minimum ratio: 2.4868421052631575\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00556\n",
      "epoch 4482 / 20000\n",
      "gradient norm: 0.05342760506027844, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00553\n",
      "epoch 4483 / 20000\n",
      "gradient norm: 0.04772323655197397, minimum ratio: 2.492105263157895\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 4484 / 20000\n",
      "gradient norm: 0.12352913315407932, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00555\n",
      "epoch 4485 / 20000\n",
      "gradient norm: 0.05891382190748118, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00553\n",
      "epoch 4486 / 20000\n",
      "gradient norm: 0.02533705238602124, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 4487 / 20000\n",
      "gradient norm: 0.05117767205229029, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00555\n",
      "epoch 4488 / 20000\n",
      "gradient norm: 0.06684254913125187, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00555\n",
      "epoch 4489 / 20000\n",
      "gradient norm: 0.047524533118121326, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 4490 / 20000\n",
      "gradient norm: 0.1011578700854443, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00555\n",
      "epoch 4491 / 20000\n",
      "gradient norm: 0.14955401059705764, minimum ratio: 2.4815789473684213\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00555\n",
      "epoch 4492 / 20000\n",
      "gradient norm: 0.06237475294619799, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00553\n",
      "epoch 4493 / 20000\n",
      "gradient norm: 0.06306478212354705, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 4494 / 20000\n",
      "gradient norm: 0.08803206513402984, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00556\n",
      "epoch 4495 / 20000\n",
      "gradient norm: 0.04969711136072874, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 4496 / 20000\n",
      "gradient norm: 0.059873467311263084, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00553\n",
      "epoch 4497 / 20000\n",
      "gradient norm: 0.06601039061933989, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00554\n",
      "epoch 4498 / 20000\n",
      "gradient norm: 0.040238287270767614, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00555\n",
      "epoch 4499 / 20000\n",
      "gradient norm: 0.02762342817732133, minimum ratio: 2.507894736842105\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00554\n",
      "epoch 4500 / 20000\n",
      "gradient norm: 0.06549851997988299, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00553\n",
      "epoch 4501 / 20000\n",
      "gradient norm: 0.08133000013185665, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00555\n",
      "epoch 4502 / 20000\n",
      "gradient norm: 0.0739780698204413, minimum ratio: 2.492105263157895\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 4503 / 20000\n",
      "gradient norm: 0.09252767183352262, minimum ratio: 2.4842105263157896\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00553\n",
      "epoch 4504 / 20000\n",
      "gradient norm: 0.11092515726340935, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00556\n",
      "epoch 4505 / 20000\n",
      "gradient norm: 0.08693583676358685, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00553\n",
      "epoch 4506 / 20000\n",
      "gradient norm: 0.04133475062553771, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 4507 / 20000\n",
      "gradient norm: 0.10897137527354062, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00556\n",
      "epoch 4508 / 20000\n",
      "gradient norm: 0.07161580689717084, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 4509 / 20000\n",
      "gradient norm: 0.06531206611543894, minimum ratio: 2.492105263157895\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 4510 / 20000\n",
      "gradient norm: 0.0934394394280389, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00555\n",
      "epoch 4511 / 20000\n",
      "gradient norm: 0.08032907074084505, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00555\n",
      "epoch 4512 / 20000\n",
      "gradient norm: 0.031158483732724562, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 4513 / 20000\n",
      "gradient norm: 0.08352544467197731, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00553\n",
      "epoch 4514 / 20000\n",
      "gradient norm: 0.10300625127274543, minimum ratio: 2.4842105263157896\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00556\n",
      "epoch 4515 / 20000\n",
      "gradient norm: 0.06292236648732796, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00553\n",
      "epoch 4516 / 20000\n",
      "gradient norm: 0.04669347975868732, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00553\n",
      "epoch 4517 / 20000\n",
      "gradient norm: 0.07989075419027358, minimum ratio: 2.5105263157894737\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00554\n",
      "epoch 4518 / 20000\n",
      "gradient norm: 0.04323519123136066, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 4519 / 20000\n",
      "gradient norm: 0.035418887506239116, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 4520 / 20000\n",
      "gradient norm: 0.014981349508161657, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 4521 / 20000\n",
      "gradient norm: 0.107380880828714, minimum ratio: 2.505263157894737\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 4522 / 20000\n",
      "gradient norm: 0.03817352143232711, minimum ratio: 2.492105263157895\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00555\n",
      "epoch 4523 / 20000\n",
      "gradient norm: 0.07349470630288124, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 4524 / 20000\n",
      "gradient norm: 0.029277249399456196, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00554\n",
      "epoch 4525 / 20000\n",
      "gradient norm: 0.06150361674372107, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 4526 / 20000\n",
      "gradient norm: 0.08599731809226796, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00553\n",
      "epoch 4527 / 20000\n",
      "gradient norm: 0.07086448854533955, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00556\n",
      "epoch 4528 / 20000\n",
      "gradient norm: 0.0695954889524728, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00553\n",
      "epoch 4529 / 20000\n",
      "gradient norm: 0.05654595070518553, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00553\n",
      "epoch 4530 / 20000\n",
      "gradient norm: 0.09023421736856108, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00555\n",
      "epoch 4531 / 20000\n",
      "gradient norm: 0.09604259626939893, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 4532 / 20000\n",
      "gradient norm: 0.09145005425671116, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 4533 / 20000\n",
      "gradient norm: 0.11039868916850537, minimum ratio: 2.4842105263157896\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00555\n",
      "epoch 4534 / 20000\n",
      "gradient norm: 0.07854158419650048, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 4535 / 20000\n",
      "gradient norm: 0.050048494173097424, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00553\n",
      "epoch 4536 / 20000\n",
      "gradient norm: 0.060298916418105364, minimum ratio: 2.460526315789474\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00555\n",
      "epoch 4537 / 20000\n",
      "gradient norm: 0.0354072863701731, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00553\n",
      "epoch 4538 / 20000\n",
      "gradient norm: 0.05523274064762518, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 4539 / 20000\n",
      "gradient norm: 0.06422222149558365, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 4540 / 20000\n",
      "gradient norm: 0.07752754602188361, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 4541 / 20000\n",
      "gradient norm: 0.10237786429934204, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00553\n",
      "epoch 4542 / 20000\n",
      "gradient norm: 0.04922395138419233, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00555\n",
      "epoch 4543 / 20000\n",
      "gradient norm: 0.04573559186246712, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00554\n",
      "epoch 4544 / 20000\n",
      "gradient norm: 0.06918525922810659, minimum ratio: 2.5105263157894737\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 4545 / 20000\n",
      "gradient norm: 0.0882446737959981, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00554\n",
      "epoch 4546 / 20000\n",
      "gradient norm: 0.12677412596531212, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00553\n",
      "epoch 4547 / 20000\n",
      "gradient norm: 0.0514120971201919, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00556\n",
      "epoch 4548 / 20000\n",
      "gradient norm: 0.07036363036604598, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00554\n",
      "epoch 4549 / 20000\n",
      "gradient norm: 0.08333274847245775, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 4550 / 20000\n",
      "gradient norm: 0.0734534045914188, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 4551 / 20000\n",
      "gradient norm: 0.06989239057293162, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00555\n",
      "epoch 4552 / 20000\n",
      "gradient norm: 0.08303856750717387, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00555\n",
      "epoch 4553 / 20000\n",
      "gradient norm: 0.09906204574508592, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00553\n",
      "epoch 4554 / 20000\n",
      "gradient norm: 0.06400941527681425, minimum ratio: 2.494736842105263\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 4555 / 20000\n",
      "gradient norm: 0.07089026454195846, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 4556 / 20000\n",
      "gradient norm: 0.08725766607676633, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 4557 / 20000\n",
      "gradient norm: 0.03679386436124332, minimum ratio: 2.494736842105263\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00554\n",
      "epoch 4558 / 20000\n",
      "gradient norm: 0.05301353269896936, minimum ratio: 2.4868421052631575\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00555\n",
      "epoch 4559 / 20000\n",
      "gradient norm: 0.08336240275821183, minimum ratio: 2.489473684210526\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 4560 / 20000\n",
      "gradient norm: 0.07739604113157839, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 4561 / 20000\n",
      "gradient norm: 0.08610392059199512, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00553\n",
      "epoch 4562 / 20000\n",
      "gradient norm: 0.07468734943540767, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 4563 / 20000\n",
      "gradient norm: 0.02628994401311502, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00555\n",
      "epoch 4564 / 20000\n",
      "gradient norm: 0.05346550402464345, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00554\n",
      "epoch 4565 / 20000\n",
      "gradient norm: 0.040661876897502225, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 4566 / 20000\n",
      "gradient norm: 0.055798400804633275, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 4567 / 20000\n",
      "gradient norm: 0.036993605172028765, minimum ratio: 2.5078947368421054\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 4568 / 20000\n",
      "gradient norm: 0.02519114779715892, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 4569 / 20000\n",
      "gradient norm: 0.039753566787112504, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 4570 / 20000\n",
      "gradient norm: 0.03528945118159754, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 4571 / 20000\n",
      "gradient norm: 0.038908710033865646, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 4572 / 20000\n",
      "gradient norm: 0.023799562390195206, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 4573 / 20000\n",
      "gradient norm: 0.08509412669809535, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 4574 / 20000\n",
      "gradient norm: 0.14784052304457873, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00553\n",
      "epoch 4575 / 20000\n",
      "gradient norm: 0.0616859276778996, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00555\n",
      "epoch 4576 / 20000\n",
      "gradient norm: 0.12961174367228523, minimum ratio: 2.5105263157894737\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00553\n",
      "epoch 4577 / 20000\n",
      "gradient norm: 0.06989674083888531, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00554\n",
      "epoch 4578 / 20000\n",
      "gradient norm: 0.05253153663943522, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 4579 / 20000\n",
      "gradient norm: 0.08786870312178507, minimum ratio: 2.4842105263157896\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 4580 / 20000\n",
      "gradient norm: 0.14727854472585022, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00556\n",
      "epoch 4581 / 20000\n",
      "gradient norm: 0.13136985898017883, minimum ratio: 2.507894736842105\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00553\n",
      "epoch 4582 / 20000\n",
      "gradient norm: 0.06581474009726662, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00553\n",
      "epoch 4583 / 20000\n",
      "gradient norm: 0.11710280692204833, minimum ratio: 2.5078947368421054\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00554\n",
      "epoch 4584 / 20000\n",
      "gradient norm: 0.053127964958548546, minimum ratio: 2.4868421052631575\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00555\n",
      "epoch 4585 / 20000\n",
      "gradient norm: 0.11528931511566043, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 4586 / 20000\n",
      "gradient norm: 0.07517994049703702, minimum ratio: 2.5157894736842104\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00553\n",
      "epoch 4587 / 20000\n",
      "gradient norm: 0.059493690030649304, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 4588 / 20000\n",
      "gradient norm: 0.05358922347659245, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 4589 / 20000\n",
      "gradient norm: 0.08464513748185709, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00553\n",
      "epoch 4590 / 20000\n",
      "gradient norm: 0.07958016789052635, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 4591 / 20000\n",
      "gradient norm: 0.06628918819478713, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00555\n",
      "epoch 4592 / 20000\n",
      "gradient norm: 0.07366364257177338, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00553\n",
      "epoch 4593 / 20000\n",
      "gradient norm: 0.06376375639229082, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 4594 / 20000\n",
      "gradient norm: 0.042732379835797474, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00554\n",
      "epoch 4595 / 20000\n",
      "gradient norm: 0.06729912562877871, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 4596 / 20000\n",
      "gradient norm: 0.12967920093797147, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00553\n",
      "epoch 4597 / 20000\n",
      "gradient norm: 0.0370923328155186, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00555\n",
      "epoch 4598 / 20000\n",
      "gradient norm: 0.10887996212113649, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00555\n",
      "epoch 4599 / 20000\n",
      "gradient norm: 0.07450274366419762, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00553\n",
      "epoch 4600 / 20000\n",
      "gradient norm: 0.06723755865823478, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 4601 / 20000\n",
      "gradient norm: 0.07866375258890912, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00556\n",
      "epoch 4602 / 20000\n",
      "gradient norm: 0.04434227581077721, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00553\n",
      "epoch 4603 / 20000\n",
      "gradient norm: 0.09159899898804724, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00553\n",
      "epoch 4604 / 20000\n",
      "gradient norm: 0.06408508156891912, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00556\n",
      "epoch 4605 / 20000\n",
      "gradient norm: 0.051790168683510274, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00554\n",
      "epoch 4606 / 20000\n",
      "gradient norm: 0.0595566821139073, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 4607 / 20000\n",
      "gradient norm: 0.09075222973478958, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00553\n",
      "epoch 4608 / 20000\n",
      "gradient norm: 0.051275786478072405, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00556\n",
      "epoch 4609 / 20000\n",
      "gradient norm: 0.06965722411405295, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 4610 / 20000\n",
      "gradient norm: 0.05547353357542306, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 4611 / 20000\n",
      "gradient norm: 0.04357093555154279, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00554\n",
      "epoch 4612 / 20000\n",
      "gradient norm: 0.061236188805196434, minimum ratio: 2.4736842105263155\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00555\n",
      "epoch 4613 / 20000\n",
      "gradient norm: 0.08900387620087713, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 4614 / 20000\n",
      "gradient norm: 0.06648183771176264, minimum ratio: 2.5078947368421054\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 4615 / 20000\n",
      "gradient norm: 0.06314614020084264, minimum ratio: 2.4736842105263155\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 4616 / 20000\n",
      "gradient norm: 0.06236720259767026, minimum ratio: 2.5105263157894737\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00555\n",
      "epoch 4617 / 20000\n",
      "gradient norm: 0.10089038120349869, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00553\n",
      "epoch 4618 / 20000\n",
      "gradient norm: 0.0811996187112527, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00554\n",
      "epoch 4619 / 20000\n",
      "gradient norm: 0.04926451982464641, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00553\n",
      "epoch 4620 / 20000\n",
      "gradient norm: 0.0376397876534611, minimum ratio: 2.465789473684211\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 4621 / 20000\n",
      "gradient norm: 0.07338665321003646, minimum ratio: 2.492105263157895\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00554\n",
      "epoch 4622 / 20000\n",
      "gradient norm: 0.030192489706678316, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 4623 / 20000\n",
      "gradient norm: 0.031747683984576724, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 4624 / 20000\n",
      "gradient norm: 0.1424732208251953, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 4625 / 20000\n",
      "gradient norm: 0.061007801588857546, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 4626 / 20000\n",
      "gradient norm: 0.036825359042268246, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00553\n",
      "epoch 4627 / 20000\n",
      "gradient norm: 0.09520850732224062, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00553\n",
      "epoch 4628 / 20000\n",
      "gradient norm: 0.029323537921300158, minimum ratio: 2.5078947368421054\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00555\n",
      "epoch 4629 / 20000\n",
      "gradient norm: 0.07182235666550696, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00554\n",
      "epoch 4630 / 20000\n",
      "gradient norm: 0.05709757794102188, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 4631 / 20000\n",
      "gradient norm: 0.05189733917359263, minimum ratio: 2.4868421052631575\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 4632 / 20000\n",
      "gradient norm: 0.05345923878485337, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 4633 / 20000\n",
      "gradient norm: 0.09824609238421544, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00555\n",
      "epoch 4634 / 20000\n",
      "gradient norm: 0.11356710485415533, minimum ratio: 2.4894736842105267\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00553\n",
      "epoch 4635 / 20000\n",
      "gradient norm: 0.06175390968564898, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00554\n",
      "epoch 4636 / 20000\n",
      "gradient norm: 0.07117250078590587, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 4637 / 20000\n",
      "gradient norm: 0.07773493979766499, minimum ratio: 2.4868421052631575\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 4638 / 20000\n",
      "gradient norm: 0.05175344826420769, minimum ratio: 2.494736842105263\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 4639 / 20000\n",
      "gradient norm: 0.07877562579960795, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 4640 / 20000\n",
      "gradient norm: 0.05053683783626184, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 4641 / 20000\n",
      "gradient norm: 0.07853322465962265, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 4642 / 20000\n",
      "gradient norm: 0.09699154034024104, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00554\n",
      "epoch 4643 / 20000\n",
      "gradient norm: 0.07582307551638223, minimum ratio: 2.4842105263157896\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00552\n",
      "epoch 4644 / 20000\n",
      "gradient norm: 0.04834530598600395, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 4645 / 20000\n",
      "gradient norm: 0.11217892938293517, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 4646 / 20000\n",
      "gradient norm: 0.048608205921482295, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00554\n",
      "epoch 4647 / 20000\n",
      "gradient norm: 0.055044813780114055, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00553\n",
      "epoch 4648 / 20000\n",
      "gradient norm: 0.0671484632184729, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 4649 / 20000\n",
      "gradient norm: 0.08688334468752146, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 4650 / 20000\n",
      "gradient norm: 0.0708289543108549, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 4651 / 20000\n",
      "gradient norm: 0.05751994048478082, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 4652 / 20000\n",
      "gradient norm: 0.08355929038953036, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00555\n",
      "epoch 4653 / 20000\n",
      "gradient norm: 0.10129108896944672, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00552\n",
      "epoch 4654 / 20000\n",
      "gradient norm: 0.05244591931113973, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 4655 / 20000\n",
      "gradient norm: 0.06419204545090906, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 4656 / 20000\n",
      "gradient norm: 0.04319267019309336, minimum ratio: 2.460526315789474\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 4657 / 20000\n",
      "gradient norm: 0.026521498104557395, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 4658 / 20000\n",
      "gradient norm: 0.05022572570305783, minimum ratio: 2.492105263157894\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00553\n",
      "epoch 4659 / 20000\n",
      "gradient norm: 0.04363734304206446, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00554\n",
      "epoch 4660 / 20000\n",
      "gradient norm: 0.0577453100704588, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 4661 / 20000\n",
      "gradient norm: 0.05720469904190395, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 4662 / 20000\n",
      "gradient norm: 0.10373436639201827, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 4663 / 20000\n",
      "gradient norm: 0.056338548005442135, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 4664 / 20000\n",
      "gradient norm: 0.0833257301710546, minimum ratio: 2.4842105263157896\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00553\n",
      "epoch 4665 / 20000\n",
      "gradient norm: 0.08631830474769231, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00555\n",
      "epoch 4666 / 20000\n",
      "gradient norm: 0.06931100296787918, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 4667 / 20000\n",
      "gradient norm: 0.06516799615928903, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00553\n",
      "epoch 4668 / 20000\n",
      "gradient norm: 0.059540821705013514, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00554\n",
      "epoch 4669 / 20000\n",
      "gradient norm: 0.02491461270255968, minimum ratio: 2.4868421052631584\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00553\n",
      "epoch 4670 / 20000\n",
      "gradient norm: 0.04676791294332361, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 4671 / 20000\n",
      "gradient norm: 0.07541615748777986, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00554\n",
      "epoch 4672 / 20000\n",
      "gradient norm: 0.06999260679003783, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 4673 / 20000\n",
      "gradient norm: 0.037613125634379685, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 4674 / 20000\n",
      "gradient norm: 0.07942457246826962, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 4675 / 20000\n",
      "gradient norm: 0.06782726812525652, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00553\n",
      "epoch 4676 / 20000\n",
      "gradient norm: 0.07397121394751593, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 4677 / 20000\n",
      "gradient norm: 0.0723002783197444, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00554\n",
      "epoch 4678 / 20000\n",
      "gradient norm: 0.1330812581581995, minimum ratio: 2.492105263157895\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00552\n",
      "epoch 4679 / 20000\n",
      "gradient norm: 0.10127299468149431, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00556\n",
      "epoch 4680 / 20000\n",
      "gradient norm: 0.0951706066261977, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 4681 / 20000\n",
      "gradient norm: 0.13238042942248285, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00552\n",
      "epoch 4682 / 20000\n",
      "gradient norm: 0.045010613423073664, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00555\n",
      "epoch 4683 / 20000\n",
      "gradient norm: 0.07466913254756946, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 4684 / 20000\n",
      "gradient norm: 0.08243253803811967, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 4685 / 20000\n",
      "gradient norm: 0.02946900637471117, minimum ratio: 2.492105263157895\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 4686 / 20000\n",
      "gradient norm: 0.11354935103008756, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 4687 / 20000\n",
      "gradient norm: 0.04876164416782558, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 4688 / 20000\n",
      "gradient norm: 0.0658672533754725, minimum ratio: 2.4842105263157896\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 4689 / 20000\n",
      "gradient norm: 0.04773431799549144, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00553\n",
      "epoch 4690 / 20000\n",
      "gradient norm: 0.08287776110228151, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00554\n",
      "epoch 4691 / 20000\n",
      "gradient norm: 0.04076555056963116, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 4692 / 20000\n",
      "gradient norm: 0.10775619489140809, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 4693 / 20000\n",
      "gradient norm: 0.0862741157761775, minimum ratio: 2.4868421052631575\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 4694 / 20000\n",
      "gradient norm: 0.02934263611678034, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 4695 / 20000\n",
      "gradient norm: 0.06796584086259827, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 4696 / 20000\n",
      "gradient norm: 0.07100359967444092, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 4697 / 20000\n",
      "gradient norm: 0.0361173854325898, minimum ratio: 2.4868421052631575\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00553\n",
      "epoch 4698 / 20000\n",
      "gradient norm: 0.10309349896851927, minimum ratio: 2.5105263157894737\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00553\n",
      "epoch 4699 / 20000\n",
      "gradient norm: 0.05769596341997385, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00556\n",
      "epoch 4700 / 20000\n",
      "gradient norm: 0.07502600061707199, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00553\n",
      "epoch 4701 / 20000\n",
      "gradient norm: 0.06303441422642209, minimum ratio: 2.492105263157895\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 4702 / 20000\n",
      "gradient norm: 0.06607650747173466, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 4703 / 20000\n",
      "gradient norm: 0.021398855169536546, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 4704 / 20000\n",
      "gradient norm: 0.045754132559522986, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 4705 / 20000\n",
      "gradient norm: 0.04833515878999606, minimum ratio: 2.46578947368421\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00554\n",
      "epoch 4706 / 20000\n",
      "gradient norm: 0.16167305933777243, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00556\n",
      "epoch 4707 / 20000\n",
      "gradient norm: 0.04608972834830638, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 4708 / 20000\n",
      "gradient norm: 0.11940610111923888, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 4709 / 20000\n",
      "gradient norm: 0.036228888609912246, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00555\n",
      "epoch 4710 / 20000\n",
      "gradient norm: 0.05497407683287747, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 4711 / 20000\n",
      "gradient norm: 0.04939976235618815, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 4712 / 20000\n",
      "gradient norm: 0.07914321793941781, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 4713 / 20000\n",
      "gradient norm: 0.07538570830365643, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 4714 / 20000\n",
      "gradient norm: 0.06781727931229398, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00553\n",
      "epoch 4715 / 20000\n",
      "gradient norm: 0.050206674699438736, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00553\n",
      "epoch 4716 / 20000\n",
      "gradient norm: 0.02643058393005049, minimum ratio: 2.4842105263157896\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 4717 / 20000\n",
      "gradient norm: 0.07805945209111087, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 4718 / 20000\n",
      "gradient norm: 0.053906465487671085, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 4719 / 20000\n",
      "gradient norm: 0.03168283659033477, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 4720 / 20000\n",
      "gradient norm: 0.04964287506300025, minimum ratio: 2.478947368421053\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 4721 / 20000\n",
      "gradient norm: 0.09084738744422793, minimum ratio: 2.452631578947368\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 4722 / 20000\n",
      "gradient norm: 0.0573355378000997, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 4723 / 20000\n",
      "gradient norm: 0.04853913217084482, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 4724 / 20000\n",
      "gradient norm: 0.09764178050681949, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00553\n",
      "epoch 4725 / 20000\n",
      "gradient norm: 0.0284724542798358, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 4726 / 20000\n",
      "gradient norm: 0.0616914028651081, minimum ratio: 2.4894736842105267\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 4727 / 20000\n",
      "gradient norm: 0.07873295113677159, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 4728 / 20000\n",
      "gradient norm: 0.061343129782471806, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 4729 / 20000\n",
      "gradient norm: 0.08419652737211436, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00553\n",
      "epoch 4730 / 20000\n",
      "gradient norm: 0.029711344745010138, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 4731 / 20000\n",
      "gradient norm: 0.05041077148052864, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 4732 / 20000\n",
      "gradient norm: 0.10264802590245381, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 4733 / 20000\n",
      "gradient norm: 0.06437562353676185, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00553\n",
      "epoch 4734 / 20000\n",
      "gradient norm: 0.06975404877448454, minimum ratio: 2.4842105263157896\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 4735 / 20000\n",
      "gradient norm: 0.03982468732283451, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 4736 / 20000\n",
      "gradient norm: 0.06540135142859071, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 4737 / 20000\n",
      "gradient norm: 0.12744003906846046, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 4738 / 20000\n",
      "gradient norm: 0.05796961892338004, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 4739 / 20000\n",
      "gradient norm: 0.07300033533829264, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00552\n",
      "epoch 4740 / 20000\n",
      "gradient norm: 0.083408486796543, minimum ratio: 2.494736842105263\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00555\n",
      "epoch 4741 / 20000\n",
      "gradient norm: 0.05358577988226898, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 4742 / 20000\n",
      "gradient norm: 0.04696721270738635, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 4743 / 20000\n",
      "gradient norm: 0.05094859433847887, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 4744 / 20000\n",
      "gradient norm: 0.05309748090803623, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00553\n",
      "epoch 4745 / 20000\n",
      "gradient norm: 0.03890520063578151, minimum ratio: 2.4842105263157896\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 4746 / 20000\n",
      "gradient norm: 0.10279701621038839, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 4747 / 20000\n",
      "gradient norm: 0.07873889576876536, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 4748 / 20000\n",
      "gradient norm: 0.09764664154499769, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00553\n",
      "epoch 4749 / 20000\n",
      "gradient norm: 0.06122378632426262, minimum ratio: 2.460526315789474\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 4750 / 20000\n",
      "gradient norm: 0.06857513680006377, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00552\n",
      "epoch 4751 / 20000\n",
      "gradient norm: 0.035197579010855407, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 4752 / 20000\n",
      "gradient norm: 0.053215741587337106, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 4753 / 20000\n",
      "gradient norm: 0.031189625569822965, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 4754 / 20000\n",
      "gradient norm: 0.1008103474159725, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00553\n",
      "epoch 4755 / 20000\n",
      "gradient norm: 0.052855610323604196, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00555\n",
      "epoch 4756 / 20000\n",
      "gradient norm: 0.06230349180987105, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 4757 / 20000\n",
      "gradient norm: 0.08477254188619554, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 4758 / 20000\n",
      "gradient norm: 0.03793293979833834, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 4759 / 20000\n",
      "gradient norm: 0.09074983120081015, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 4760 / 20000\n",
      "gradient norm: 0.09031924078590237, minimum ratio: 2.460526315789474\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 4761 / 20000\n",
      "gradient norm: 0.043750742508564144, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 4762 / 20000\n",
      "gradient norm: 0.06318331077636685, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 4763 / 20000\n",
      "gradient norm: 0.05494276390527375, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00554\n",
      "epoch 4764 / 20000\n",
      "gradient norm: 0.07278114894870669, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00553\n",
      "epoch 4765 / 20000\n",
      "gradient norm: 0.040186067184549756, minimum ratio: 2.4815789473684213\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 4766 / 20000\n",
      "gradient norm: 0.09510860336013138, minimum ratio: 2.507894736842105\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 4767 / 20000\n",
      "gradient norm: 0.0916561393532902, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00555\n",
      "epoch 4768 / 20000\n",
      "gradient norm: 0.052082382258959115, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 4769 / 20000\n",
      "gradient norm: 0.10261515679303557, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 4770 / 20000\n",
      "gradient norm: 0.07755100826034322, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00555\n",
      "epoch 4771 / 20000\n",
      "gradient norm: 0.05675349369994365, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 4772 / 20000\n",
      "gradient norm: 0.1261503779096529, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 4773 / 20000\n",
      "gradient norm: 0.06756076675083023, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00552\n",
      "epoch 4774 / 20000\n",
      "gradient norm: 0.03791299616568722, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00553\n",
      "epoch 4775 / 20000\n",
      "gradient norm: 0.08321274467743933, minimum ratio: 2.4842105263157896\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00556\n",
      "epoch 4776 / 20000\n",
      "gradient norm: 0.08258399280020967, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00552\n",
      "epoch 4777 / 20000\n",
      "gradient norm: 0.07672190095763654, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 4778 / 20000\n",
      "gradient norm: 0.09405395714566112, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 4779 / 20000\n",
      "gradient norm: 0.05799798388034105, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00553\n",
      "epoch 4780 / 20000\n",
      "gradient norm: 0.09319067583419383, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 4781 / 20000\n",
      "gradient norm: 0.06477215024642646, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 4782 / 20000\n",
      "gradient norm: 0.08354302530642599, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 4783 / 20000\n",
      "gradient norm: 0.062276634213048965, minimum ratio: 2.489473684210526\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 4784 / 20000\n",
      "gradient norm: 0.09148568502860144, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00552\n",
      "epoch 4785 / 20000\n",
      "gradient norm: 0.028700730981654488, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 4786 / 20000\n",
      "gradient norm: 0.12608588149305433, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00553\n",
      "epoch 4787 / 20000\n",
      "gradient norm: 0.039890418585855514, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00553\n",
      "epoch 4788 / 20000\n",
      "gradient norm: 0.06835610547568649, minimum ratio: 2.4868421052631575\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 4789 / 20000\n",
      "gradient norm: 0.07216484670061618, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 4790 / 20000\n",
      "gradient norm: 0.1159610201139003, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00555\n",
      "epoch 4791 / 20000\n",
      "gradient norm: 0.0343436808034312, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 4792 / 20000\n",
      "gradient norm: 0.03821051467093639, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 4793 / 20000\n",
      "gradient norm: 0.04441289296664763, minimum ratio: 2.507894736842105\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 4794 / 20000\n",
      "gradient norm: 0.09467836027033627, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 4795 / 20000\n",
      "gradient norm: 0.04810135340085253, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 4796 / 20000\n",
      "gradient norm: 0.08072487953177188, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00553\n",
      "epoch 4797 / 20000\n",
      "gradient norm: 0.038688730157446116, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 4798 / 20000\n",
      "gradient norm: 0.08397580811288208, minimum ratio: 2.4815789473684213\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00553\n",
      "epoch 4799 / 20000\n",
      "gradient norm: 0.06002653785981238, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 4800 / 20000\n",
      "gradient norm: 0.0955814782064408, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 4801 / 20000\n",
      "gradient norm: 0.06905420811381191, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 4802 / 20000\n",
      "gradient norm: 0.05573823628947139, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 4803 / 20000\n",
      "gradient norm: 0.1139184080529958, minimum ratio: 2.5105263157894733\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00552\n",
      "epoch 4804 / 20000\n",
      "gradient norm: 0.0726296013162937, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00555\n",
      "epoch 4805 / 20000\n",
      "gradient norm: 0.04084772628266364, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 4806 / 20000\n",
      "gradient norm: 0.06947722600307316, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 4807 / 20000\n",
      "gradient norm: 0.04226474557071924, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 4808 / 20000\n",
      "gradient norm: 0.0965426875045523, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00555\n",
      "epoch 4809 / 20000\n",
      "gradient norm: 0.11775179818505421, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 4810 / 20000\n",
      "gradient norm: 0.07949969242326915, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00552\n",
      "epoch 4811 / 20000\n",
      "gradient norm: 0.057410874287597835, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 4812 / 20000\n",
      "gradient norm: 0.07572799315676093, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 4813 / 20000\n",
      "gradient norm: 0.046637144463602453, minimum ratio: 2.460526315789474\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 4814 / 20000\n",
      "gradient norm: 0.06664745783200487, minimum ratio: 2.5078947368421054\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 4815 / 20000\n",
      "gradient norm: 0.03887287003453821, minimum ratio: 2.4842105263157896\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 4816 / 20000\n",
      "gradient norm: 0.07532715157140046, minimum ratio: 2.494736842105263\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00555\n",
      "epoch 4817 / 20000\n",
      "gradient norm: 0.037671842583222315, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00552\n",
      "epoch 4818 / 20000\n",
      "gradient norm: 0.06449987640371546, minimum ratio: 2.5131578947368425\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 4819 / 20000\n",
      "gradient norm: 0.07823959982488304, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00555\n",
      "epoch 4820 / 20000\n",
      "gradient norm: 0.07257722748909146, minimum ratio: 2.4894736842105267\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00553\n",
      "epoch 4821 / 20000\n",
      "gradient norm: 0.03887641217443161, minimum ratio: 2.494736842105263\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 4822 / 20000\n",
      "gradient norm: 0.056566563638625666, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 4823 / 20000\n",
      "gradient norm: 0.05204687414516229, minimum ratio: 2.4842105263157896\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00554\n",
      "epoch 4824 / 20000\n",
      "gradient norm: 0.06711473144241609, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 4825 / 20000\n",
      "gradient norm: 0.03946415848622564, minimum ratio: 2.489473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 4826 / 20000\n",
      "gradient norm: 0.10423686378635466, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 4827 / 20000\n",
      "gradient norm: 0.07368857745314017, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00552\n",
      "epoch 4828 / 20000\n",
      "gradient norm: 0.0742841781466268, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 4829 / 20000\n",
      "gradient norm: 0.05273471065447666, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 4830 / 20000\n",
      "gradient norm: 0.04250754660461098, minimum ratio: 2.492105263157895\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 4831 / 20000\n",
      "gradient norm: 0.07053311017807573, minimum ratio: 2.460526315789474\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 4832 / 20000\n",
      "gradient norm: 0.12766872529755346, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00556\n",
      "epoch 4833 / 20000\n",
      "gradient norm: 0.04719657459645532, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 4834 / 20000\n",
      "gradient norm: 0.0922942299512215, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00552\n",
      "epoch 4835 / 20000\n",
      "gradient norm: 0.09863247070461512, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00556\n",
      "epoch 4836 / 20000\n",
      "gradient norm: 0.0534327898058109, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 4837 / 20000\n",
      "gradient norm: 0.07154950982658193, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 4838 / 20000\n",
      "gradient norm: 0.05590816435869783, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 4839 / 20000\n",
      "gradient norm: 0.06381918949773535, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 4840 / 20000\n",
      "gradient norm: 0.08212052687304094, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 4841 / 20000\n",
      "gradient norm: 0.09036853219731711, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 4842 / 20000\n",
      "gradient norm: 0.04329154721926898, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00554\n",
      "epoch 4843 / 20000\n",
      "gradient norm: 0.06266413489356637, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 4844 / 20000\n",
      "gradient norm: 0.04970240395050496, minimum ratio: 2.460526315789474\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00552\n",
      "epoch 4845 / 20000\n",
      "gradient norm: 0.0590385265822988, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 4846 / 20000\n",
      "gradient norm: 0.06343100918456912, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 4847 / 20000\n",
      "gradient norm: 0.06904065288836136, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 4848 / 20000\n",
      "gradient norm: 0.05932956573087722, minimum ratio: 2.492105263157895\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 4849 / 20000\n",
      "gradient norm: 0.08289584284648299, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 4850 / 20000\n",
      "gradient norm: 0.0628045565681532, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 4851 / 20000\n",
      "gradient norm: 0.04225556227902416, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00553\n",
      "epoch 4852 / 20000\n",
      "gradient norm: 0.022736000828444958, minimum ratio: 2.489473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 4853 / 20000\n",
      "gradient norm: 0.07469825207954273, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 4854 / 20000\n",
      "gradient norm: 0.06649688186007552, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00552\n",
      "epoch 4855 / 20000\n",
      "gradient norm: 0.0745963459048653, minimum ratio: 2.5105263157894737\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 4856 / 20000\n",
      "gradient norm: 0.08724018966313452, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 4857 / 20000\n",
      "gradient norm: 0.06346942106029019, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 4858 / 20000\n",
      "gradient norm: 0.07750951088382863, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 4859 / 20000\n",
      "gradient norm: 0.0911261971341446, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00556\n",
      "epoch 4860 / 20000\n",
      "gradient norm: 0.052677703730296344, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 4861 / 20000\n",
      "gradient norm: 0.07041166839189827, minimum ratio: 2.4842105263157896\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 4862 / 20000\n",
      "gradient norm: 0.06309956242330372, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 4863 / 20000\n",
      "gradient norm: 0.10284862027037889, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00554\n",
      "epoch 4864 / 20000\n",
      "gradient norm: 0.08597408793866634, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00552\n",
      "epoch 4865 / 20000\n",
      "gradient norm: 0.0840156499762088, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 4866 / 20000\n",
      "gradient norm: 0.07706133992178366, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00554\n",
      "epoch 4867 / 20000\n",
      "gradient norm: 0.04896392367663793, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00552\n",
      "epoch 4868 / 20000\n",
      "gradient norm: 0.07516537912306376, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 4869 / 20000\n",
      "gradient norm: 0.10301870986586437, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 4870 / 20000\n",
      "gradient norm: 0.07788066240027547, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 4871 / 20000\n",
      "gradient norm: 0.07053899846505374, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 4872 / 20000\n",
      "gradient norm: 0.02885884340503253, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00554\n",
      "epoch 4873 / 20000\n",
      "gradient norm: 0.07684711238835007, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 4874 / 20000\n",
      "gradient norm: 0.031093532423255965, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 4875 / 20000\n",
      "gradient norm: 0.05342094134539366, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 4876 / 20000\n",
      "gradient norm: 0.08414690050267382, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 4877 / 20000\n",
      "gradient norm: 0.046891652935300954, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00553\n",
      "epoch 4878 / 20000\n",
      "gradient norm: 0.026213471792289056, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 4879 / 20000\n",
      "gradient norm: 0.07202893611975014, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 4880 / 20000\n",
      "gradient norm: 0.05528172763297334, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 4881 / 20000\n",
      "gradient norm: 0.061581230140291154, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 4882 / 20000\n",
      "gradient norm: 0.1215078025998082, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00552\n",
      "epoch 4883 / 20000\n",
      "gradient norm: 0.0695108967483975, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00555\n",
      "epoch 4884 / 20000\n",
      "gradient norm: 0.11727592960232869, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00554\n",
      "epoch 4885 / 20000\n",
      "gradient norm: 0.1276329734828323, minimum ratio: 2.4868421052631575\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00552\n",
      "epoch 4886 / 20000\n",
      "gradient norm: 0.04961636394727975, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00553\n",
      "epoch 4887 / 20000\n",
      "gradient norm: 0.07474440801888704, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00556\n",
      "epoch 4888 / 20000\n",
      "gradient norm: 0.07961009195423685, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00552\n",
      "epoch 4889 / 20000\n",
      "gradient norm: 0.06991686118999496, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 4890 / 20000\n",
      "gradient norm: 0.0652641131891869, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 4891 / 20000\n",
      "gradient norm: 0.06225832796189934, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 4892 / 20000\n",
      "gradient norm: 0.06533636142557953, minimum ratio: 2.4868421052631575\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 4893 / 20000\n",
      "gradient norm: 0.05278791626915336, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 4894 / 20000\n",
      "gradient norm: 0.11510778672527522, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 4895 / 20000\n",
      "gradient norm: 0.05972957154153846, minimum ratio: 2.4815789473684213\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 4896 / 20000\n",
      "gradient norm: 0.035402918394538574, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 4897 / 20000\n",
      "gradient norm: 0.014731877134181559, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 4898 / 20000\n",
      "gradient norm: 0.08899190588272177, minimum ratio: 2.492105263157895\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 4899 / 20000\n",
      "gradient norm: 0.04629662068327889, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00555\n",
      "epoch 4900 / 20000\n",
      "gradient norm: 0.059066019573947415, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 4901 / 20000\n",
      "gradient norm: 0.05108856825972907, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 4902 / 20000\n",
      "gradient norm: 0.07828795944806188, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00553\n",
      "epoch 4903 / 20000\n",
      "gradient norm: 0.04466032287746202, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00554\n",
      "epoch 4904 / 20000\n",
      "gradient norm: 0.08268797962227836, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 4905 / 20000\n",
      "gradient norm: 0.01102267341411789, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 4906 / 20000\n",
      "gradient norm: 0.0590594616078306, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00553\n",
      "epoch 4907 / 20000\n",
      "gradient norm: 0.025934676465112716, minimum ratio: 2.494736842105263\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 4908 / 20000\n",
      "gradient norm: 0.09516358442488126, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 4909 / 20000\n",
      "gradient norm: 0.03554205087129958, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 4910 / 20000\n",
      "gradient norm: 0.0391822459132527, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 4911 / 20000\n",
      "gradient norm: 0.0835179120185785, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00554\n",
      "epoch 4912 / 20000\n",
      "gradient norm: 0.06836929108249024, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 4913 / 20000\n",
      "gradient norm: 0.07167690896312706, minimum ratio: 2.513157894736842\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 4914 / 20000\n",
      "gradient norm: 0.08750040762242861, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 4915 / 20000\n",
      "gradient norm: 0.021779807604616508, minimum ratio: 2.4868421052631575\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 4916 / 20000\n",
      "gradient norm: 0.07347109774127603, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 4917 / 20000\n",
      "gradient norm: 0.073361819551792, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 4918 / 20000\n",
      "gradient norm: 0.050714563025394455, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 4919 / 20000\n",
      "gradient norm: 0.04838406870840117, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 4920 / 20000\n",
      "gradient norm: 0.08595904911635444, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 4921 / 20000\n",
      "gradient norm: 0.059155676572117954, minimum ratio: 2.4842105263157896\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 4922 / 20000\n",
      "gradient norm: 0.05271014547906816, minimum ratio: 2.492105263157895\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 4923 / 20000\n",
      "gradient norm: 0.03780979233852122, minimum ratio: 2.5078947368421054\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00553\n",
      "epoch 4924 / 20000\n",
      "gradient norm: 0.05322348646586761, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 4925 / 20000\n",
      "gradient norm: 0.061272672784980386, minimum ratio: 2.4842105263157896\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 4926 / 20000\n",
      "gradient norm: 0.04035673062026035, minimum ratio: 2.4815789473684213\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 4927 / 20000\n",
      "gradient norm: 0.10044089838629588, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00552\n",
      "epoch 4928 / 20000\n",
      "gradient norm: 0.06055802310584113, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 4929 / 20000\n",
      "gradient norm: 0.09877161448821425, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00553\n",
      "epoch 4930 / 20000\n",
      "gradient norm: 0.03604254891979508, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 4931 / 20000\n",
      "gradient norm: 0.0315588972880505, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 4932 / 20000\n",
      "gradient norm: 0.039302097575273365, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 4933 / 20000\n",
      "gradient norm: 0.022232938528759405, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 4934 / 20000\n",
      "gradient norm: 0.07024985656607896, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 4935 / 20000\n",
      "gradient norm: 0.1007657420122996, minimum ratio: 2.4842105263157896\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00554\n",
      "epoch 4936 / 20000\n",
      "gradient norm: 0.04670643399003893, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 4937 / 20000\n",
      "gradient norm: 0.06027332117082551, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 4938 / 20000\n",
      "gradient norm: 0.018919926820672117, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 4939 / 20000\n",
      "gradient norm: 0.08362467217375524, minimum ratio: 2.46578947368421\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 4940 / 20000\n",
      "gradient norm: 0.10285726760048419, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 4941 / 20000\n",
      "gradient norm: 0.10529062105342746, minimum ratio: 2.5078947368421054\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 4942 / 20000\n",
      "gradient norm: 0.06925815228896681, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 4943 / 20000\n",
      "gradient norm: 0.08003749794443138, minimum ratio: 2.4868421052631575\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 4944 / 20000\n",
      "gradient norm: 0.04203825257718563, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 4945 / 20000\n",
      "gradient norm: 0.0771983373851981, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 4946 / 20000\n",
      "gradient norm: 0.07856790401274338, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 4947 / 20000\n",
      "gradient norm: 0.03138418107118923, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 4948 / 20000\n",
      "gradient norm: 0.05825373108382337, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 4949 / 20000\n",
      "gradient norm: 0.08230166567955166, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 4950 / 20000\n",
      "gradient norm: 0.05014019852387719, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 4951 / 20000\n",
      "gradient norm: 0.05572956724790856, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 4952 / 20000\n",
      "gradient norm: 0.046681726118549705, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 4953 / 20000\n",
      "gradient norm: 0.06090088221390033, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 4954 / 20000\n",
      "gradient norm: 0.04323641676455736, minimum ratio: 2.492105263157895\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 4955 / 20000\n",
      "gradient norm: 0.07440561492694542, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 4956 / 20000\n",
      "gradient norm: 0.04504903688211925, minimum ratio: 2.505263157894737\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 4957 / 20000\n",
      "gradient norm: 0.08746708481339738, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00552\n",
      "epoch 4958 / 20000\n",
      "gradient norm: 0.1332329666474834, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 4959 / 20000\n",
      "gradient norm: 0.04928343731444329, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 4960 / 20000\n",
      "gradient norm: 0.05705766720348038, minimum ratio: 2.5078947368421054\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 4961 / 20000\n",
      "gradient norm: 0.07316743367118761, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 4962 / 20000\n",
      "gradient norm: 0.10242124478099868, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00555\n",
      "epoch 4963 / 20000\n",
      "gradient norm: 0.04455552765284665, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 4964 / 20000\n",
      "gradient norm: 0.08544487139442936, minimum ratio: 2.5105263157894737\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00552\n",
      "epoch 4965 / 20000\n",
      "gradient norm: 0.05214032417279668, minimum ratio: 2.494736842105263\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00555\n",
      "epoch 4966 / 20000\n",
      "gradient norm: 0.06522184633649886, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 4967 / 20000\n",
      "gradient norm: 0.08979018367244862, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 4968 / 20000\n",
      "gradient norm: 0.11153140384703875, minimum ratio: 2.492105263157895\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00552\n",
      "epoch 4969 / 20000\n",
      "gradient norm: 0.02715390975936316, minimum ratio: 2.489473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 4970 / 20000\n",
      "gradient norm: 0.07496748058474623, minimum ratio: 2.515789473684211\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00555\n",
      "epoch 4971 / 20000\n",
      "gradient norm: 0.07553693759837188, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 4972 / 20000\n",
      "gradient norm: 0.12042394687887281, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 4973 / 20000\n",
      "gradient norm: 0.04399750943412073, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 4974 / 20000\n",
      "gradient norm: 0.037794878633576445, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 4975 / 20000\n",
      "gradient norm: 0.101957194856368, minimum ratio: 2.4815789473684213\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 4976 / 20000\n",
      "gradient norm: 0.03578068826755043, minimum ratio: 2.5078947368421054\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 4977 / 20000\n",
      "gradient norm: 0.059867643256438896, minimum ratio: 2.4868421052631575\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 4978 / 20000\n",
      "gradient norm: 0.09571055084234104, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00554\n",
      "epoch 4979 / 20000\n",
      "gradient norm: 0.1025091121555306, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 4980 / 20000\n",
      "gradient norm: 0.06355598998561618, minimum ratio: 2.4684210526315784\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 4981 / 20000\n",
      "gradient norm: 0.061840619338909164, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 4982 / 20000\n",
      "gradient norm: 0.09809945289453026, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 4983 / 20000\n",
      "gradient norm: 0.03586207280022791, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 4984 / 20000\n",
      "gradient norm: 0.10514628881355748, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 4985 / 20000\n",
      "gradient norm: 0.08885716320946813, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 4986 / 20000\n",
      "gradient norm: 0.09719423321075737, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 4987 / 20000\n",
      "gradient norm: 0.0594526325003244, minimum ratio: 2.4868421052631575\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 4988 / 20000\n",
      "gradient norm: 0.05363475962076336, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 4989 / 20000\n",
      "gradient norm: 0.05649323551915586, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 4990 / 20000\n",
      "gradient norm: 0.023192343513073865, minimum ratio: 2.4894736842105267\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 4991 / 20000\n",
      "gradient norm: 0.09713808901142329, minimum ratio: 2.494736842105263\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 4992 / 20000\n",
      "gradient norm: 0.026724178678705357, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00553\n",
      "epoch 4993 / 20000\n",
      "gradient norm: 0.03953919094055891, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 4994 / 20000\n",
      "gradient norm: 0.09027334256097674, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 4995 / 20000\n",
      "gradient norm: 0.07405867602210492, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 4996 / 20000\n",
      "gradient norm: 0.0994518450461328, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 4997 / 20000\n",
      "gradient norm: 0.06104043999221176, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 4998 / 20000\n",
      "gradient norm: 0.08008053590310737, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 4999 / 20000\n",
      "gradient norm: 0.08691384422127157, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 5000 / 20000\n",
      "gradient norm: 0.10871145720011555, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00556\n",
      "epoch 5001 / 20000\n",
      "gradient norm: 0.058016684124595486, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 5002 / 20000\n",
      "gradient norm: 0.055790134152630344, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 5003 / 20000\n",
      "gradient norm: 0.06332574508269317, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 5004 / 20000\n",
      "gradient norm: 0.04776735475752503, minimum ratio: 2.494736842105263\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 5005 / 20000\n",
      "gradient norm: 0.10864460427546874, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 5006 / 20000\n",
      "gradient norm: 0.035300814313814044, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 5007 / 20000\n",
      "gradient norm: 0.053678145399317145, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00554\n",
      "epoch 5008 / 20000\n",
      "gradient norm: 0.05386507589719258, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 5009 / 20000\n",
      "gradient norm: 0.04321930740843527, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 5010 / 20000\n",
      "gradient norm: 0.048602281138300896, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 5011 / 20000\n",
      "gradient norm: 0.039398082823026925, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 5012 / 20000\n",
      "gradient norm: 0.07343292341101915, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 5013 / 20000\n",
      "gradient norm: 0.09506990434601903, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 5014 / 20000\n",
      "gradient norm: 0.09026575571624562, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 5015 / 20000\n",
      "gradient norm: 0.03932543011615053, minimum ratio: 2.507894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 5016 / 20000\n",
      "gradient norm: 0.11766176181845367, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 5017 / 20000\n",
      "gradient norm: 0.0476870463025989, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 5018 / 20000\n",
      "gradient norm: 0.04484430747106671, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00554\n",
      "epoch 5019 / 20000\n",
      "gradient norm: 0.04208797315368429, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 5020 / 20000\n",
      "gradient norm: 0.056507197266910225, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 5021 / 20000\n",
      "gradient norm: 0.040665722626727074, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 5022 / 20000\n",
      "gradient norm: 0.05810396876768209, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 5023 / 20000\n",
      "gradient norm: 0.1219915027031675, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 5024 / 20000\n",
      "gradient norm: 0.03504717821488157, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 5025 / 20000\n",
      "gradient norm: 0.09087323793210089, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 5026 / 20000\n",
      "gradient norm: 0.058187417744193226, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00552\n",
      "epoch 5027 / 20000\n",
      "gradient norm: 0.04056847869651392, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 5028 / 20000\n",
      "gradient norm: 0.026745801471406594, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 5029 / 20000\n",
      "gradient norm: 0.05093083065003157, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 5030 / 20000\n",
      "gradient norm: 0.05654767245869152, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 5031 / 20000\n",
      "gradient norm: 0.11087108519859612, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00555\n",
      "epoch 5032 / 20000\n",
      "gradient norm: 0.05955309761338867, minimum ratio: 2.518421052631579\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 5033 / 20000\n",
      "gradient norm: 0.06967695479397662, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00552\n",
      "epoch 5034 / 20000\n",
      "gradient norm: 0.06386947026476264, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 5035 / 20000\n",
      "gradient norm: 0.08068509300937876, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 5036 / 20000\n",
      "gradient norm: 0.14143317058915272, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00552\n",
      "epoch 5037 / 20000\n",
      "gradient norm: 0.0699094888404943, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 5038 / 20000\n",
      "gradient norm: 0.05742054968141019, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 5039 / 20000\n",
      "gradient norm: 0.047062930796528235, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 5040 / 20000\n",
      "gradient norm: 0.08209179673576728, minimum ratio: 2.4736842105263155\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 5041 / 20000\n",
      "gradient norm: 0.06452601251658052, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 5042 / 20000\n",
      "gradient norm: 0.025176192913932027, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 5043 / 20000\n",
      "gradient norm: 0.052675114129669964, minimum ratio: 2.4894736842105267\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 5044 / 20000\n",
      "gradient norm: 0.04619487846503034, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 5045 / 20000\n",
      "gradient norm: 0.0468828683369793, minimum ratio: 2.494736842105263\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 5046 / 20000\n",
      "gradient norm: 0.04747171685448848, minimum ratio: 2.494736842105263\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 5047 / 20000\n",
      "gradient norm: 0.07155578187666833, minimum ratio: 2.4815789473684213\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00552\n",
      "epoch 5048 / 20000\n",
      "gradient norm: 0.06848942098440602, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00552\n",
      "epoch 5049 / 20000\n",
      "gradient norm: 0.026737548119854182, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 5050 / 20000\n",
      "gradient norm: 0.03559702599886805, minimum ratio: 2.4868421052631584\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 5051 / 20000\n",
      "gradient norm: 0.08268061559647322, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00552\n",
      "epoch 5052 / 20000\n",
      "gradient norm: 0.057195921370293945, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 5053 / 20000\n",
      "gradient norm: 0.06653424221440218, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 5054 / 20000\n",
      "gradient norm: 0.060980114445555955, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 5055 / 20000\n",
      "gradient norm: 0.08436753530986607, minimum ratio: 2.4842105263157896\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00552\n",
      "epoch 5056 / 20000\n",
      "gradient norm: 0.08513388730352744, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00555\n",
      "epoch 5057 / 20000\n",
      "gradient norm: 0.048502968973480165, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 5058 / 20000\n",
      "gradient norm: 0.05495019955560565, minimum ratio: 2.510526315789474\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00552\n",
      "epoch 5059 / 20000\n",
      "gradient norm: 0.043193761943257414, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 5060 / 20000\n",
      "gradient norm: 0.04808755582780577, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00554\n",
      "epoch 5061 / 20000\n",
      "gradient norm: 0.0321992719109403, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 5062 / 20000\n",
      "gradient norm: 0.09537860375712626, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 5063 / 20000\n",
      "gradient norm: 0.03820054093375802, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 5064 / 20000\n",
      "gradient norm: 0.045741567737422884, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 5065 / 20000\n",
      "gradient norm: 0.07062251429306343, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 5066 / 20000\n",
      "gradient norm: 0.04170403452008031, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 5067 / 20000\n",
      "gradient norm: 0.06678162168827839, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 5068 / 20000\n",
      "gradient norm: 0.08099397900514305, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 5069 / 20000\n",
      "gradient norm: 0.06830459303455427, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 5070 / 20000\n",
      "gradient norm: 0.07790571037912741, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 5071 / 20000\n",
      "gradient norm: 0.025414604926481843, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 5072 / 20000\n",
      "gradient norm: 0.09657898766454309, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00553\n",
      "epoch 5073 / 20000\n",
      "gradient norm: 0.08200755337020382, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 5074 / 20000\n",
      "gradient norm: 0.06459431420080364, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 5075 / 20000\n",
      "gradient norm: 0.05980000615818426, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 5076 / 20000\n",
      "gradient norm: 0.08182417671196163, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 5077 / 20000\n",
      "gradient norm: 0.10119919863063842, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00552\n",
      "epoch 5078 / 20000\n",
      "gradient norm: 0.03318822360597551, minimum ratio: 2.4842105263157896\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 5079 / 20000\n",
      "gradient norm: 0.05983352102339268, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 5080 / 20000\n",
      "gradient norm: 0.08130165480542928, minimum ratio: 2.507894736842105\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 5081 / 20000\n",
      "gradient norm: 0.11185287008993328, minimum ratio: 2.4842105263157896\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 5082 / 20000\n",
      "gradient norm: 0.026437897176947445, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 5083 / 20000\n",
      "gradient norm: 0.10728392581222579, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00552\n",
      "epoch 5084 / 20000\n",
      "gradient norm: 0.10256878024665639, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00557\n",
      "epoch 5085 / 20000\n",
      "gradient norm: 0.06141616922104731, minimum ratio: 2.489473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 5086 / 20000\n",
      "gradient norm: 0.06534343521343544, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 5087 / 20000\n",
      "gradient norm: 0.05446631749509834, minimum ratio: 2.492105263157895\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 5088 / 20000\n",
      "gradient norm: 0.10304781596641988, minimum ratio: 2.5078947368421054\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00553\n",
      "epoch 5089 / 20000\n",
      "gradient norm: 0.07855949236545712, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 5090 / 20000\n",
      "gradient norm: 0.03541916534595657, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 5091 / 20000\n",
      "gradient norm: 0.05216780806949828, minimum ratio: 2.465789473684211\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 5092 / 20000\n",
      "gradient norm: 0.0571880450588651, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 5093 / 20000\n",
      "gradient norm: 0.07935694931074977, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 5094 / 20000\n",
      "gradient norm: 0.019924824897316284, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 5095 / 20000\n",
      "gradient norm: 0.07092850090702996, minimum ratio: 2.494736842105263\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00553\n",
      "epoch 5096 / 20000\n",
      "gradient norm: 0.07328147895168513, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 5097 / 20000\n",
      "gradient norm: 0.0646840360132046, minimum ratio: 2.436842105263158\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 5098 / 20000\n",
      "gradient norm: 0.05967718979809433, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 5099 / 20000\n",
      "gradient norm: 0.047718266694573686, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 5100 / 20000\n",
      "gradient norm: 0.08391223679063842, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 5101 / 20000\n",
      "gradient norm: 0.037805967760505155, minimum ratio: 2.492105263157895\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 5102 / 20000\n",
      "gradient norm: 0.04637050529709086, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00552\n",
      "epoch 5103 / 20000\n",
      "gradient norm: 0.06831487972522154, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 5104 / 20000\n",
      "gradient norm: 0.0670399967348203, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 5105 / 20000\n",
      "gradient norm: 0.04330684180604294, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 5106 / 20000\n",
      "gradient norm: 0.06485468352911994, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 5107 / 20000\n",
      "gradient norm: 0.06475025869440287, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00554\n",
      "epoch 5108 / 20000\n",
      "gradient norm: 0.06409098260337487, minimum ratio: 2.4842105263157896\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 5109 / 20000\n",
      "gradient norm: 0.06611279299249873, minimum ratio: 2.4842105263157896\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00552\n",
      "epoch 5110 / 20000\n",
      "gradient norm: 0.05240507228882052, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 5111 / 20000\n",
      "gradient norm: 0.07839240663452074, minimum ratio: 2.492105263157895\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00555\n",
      "epoch 5112 / 20000\n",
      "gradient norm: 0.05374423650209792, minimum ratio: 2.460526315789474\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00552\n",
      "epoch 5113 / 20000\n",
      "gradient norm: 0.0915312405268196, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 5114 / 20000\n",
      "gradient norm: 0.04400872008409351, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 5115 / 20000\n",
      "gradient norm: 0.10249681503046304, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 5116 / 20000\n",
      "gradient norm: 0.0623993688786868, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 5117 / 20000\n",
      "gradient norm: 0.08543629662017338, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00552\n",
      "epoch 5118 / 20000\n",
      "gradient norm: 0.11900649557355791, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 5119 / 20000\n",
      "gradient norm: 0.05128897898248397, minimum ratio: 2.4894736842105267\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 5120 / 20000\n",
      "gradient norm: 0.11324976594187319, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00552\n",
      "epoch 5121 / 20000\n",
      "gradient norm: 0.03938570577884093, minimum ratio: 2.5105263157894737\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00554\n",
      "epoch 5122 / 20000\n",
      "gradient norm: 0.08456450316589326, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 5123 / 20000\n",
      "gradient norm: 0.05574523704126477, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 5124 / 20000\n",
      "gradient norm: 0.10068058856995776, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 5125 / 20000\n",
      "gradient norm: 0.035865672849467956, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 5126 / 20000\n",
      "gradient norm: 0.03292218627757393, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 5127 / 20000\n",
      "gradient norm: 0.062289447378134355, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00552\n",
      "epoch 5128 / 20000\n",
      "gradient norm: 0.10427433188306168, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 5129 / 20000\n",
      "gradient norm: 0.0496674512833124, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00552\n",
      "epoch 5130 / 20000\n",
      "gradient norm: 0.053154222150624264, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 5131 / 20000\n",
      "gradient norm: 0.03064509655814618, minimum ratio: 2.4894736842105267\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 5132 / 20000\n",
      "gradient norm: 0.040543599432567134, minimum ratio: 2.5078947368421054\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 5133 / 20000\n",
      "gradient norm: 0.05080742390418891, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 5134 / 20000\n",
      "gradient norm: 0.11500547511968762, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 5135 / 20000\n",
      "gradient norm: 0.0919128597015515, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 5136 / 20000\n",
      "gradient norm: 0.1381818067166023, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 5137 / 20000\n",
      "gradient norm: 0.04820822998590302, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 5138 / 20000\n",
      "gradient norm: 0.05367123690666631, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 5139 / 20000\n",
      "gradient norm: 0.07135474818642251, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 5140 / 20000\n",
      "gradient norm: 0.06892850644362625, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 5141 / 20000\n",
      "gradient norm: 0.13857841596473008, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00554\n",
      "epoch 5142 / 20000\n",
      "gradient norm: 0.03822007392591331, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 5143 / 20000\n",
      "gradient norm: 0.11709382943809032, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 5144 / 20000\n",
      "gradient norm: 0.06011674925684929, minimum ratio: 2.494736842105263\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 5145 / 20000\n",
      "gradient norm: 0.08745436448953114, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 5146 / 20000\n",
      "gradient norm: 0.0523537805856904, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 5147 / 20000\n",
      "gradient norm: 0.02893751164083369, minimum ratio: 2.494736842105263\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 5148 / 20000\n",
      "gradient norm: 0.09161927917739376, minimum ratio: 2.4736842105263155\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 5149 / 20000\n",
      "gradient norm: 0.08162608514248859, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 5150 / 20000\n",
      "gradient norm: 0.07095507747726515, minimum ratio: 2.492105263157895\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 5151 / 20000\n",
      "gradient norm: 0.011195140366908163, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 5152 / 20000\n",
      "gradient norm: 0.09828763664700091, minimum ratio: 2.46578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 5153 / 20000\n",
      "gradient norm: 0.06286037794779986, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 5154 / 20000\n",
      "gradient norm: 0.038090047135483474, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 5155 / 20000\n",
      "gradient norm: 0.057769234001170844, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 5156 / 20000\n",
      "gradient norm: 0.11329445449518971, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 5157 / 20000\n",
      "gradient norm: 0.08253721398068592, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00552\n",
      "epoch 5158 / 20000\n",
      "gradient norm: 0.07779440534068272, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00555\n",
      "epoch 5159 / 20000\n",
      "gradient norm: 0.089920814614743, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00552\n",
      "epoch 5160 / 20000\n",
      "gradient norm: 0.09471075050532818, minimum ratio: 2.492105263157895\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 5161 / 20000\n",
      "gradient norm: 0.07044483479694463, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 5162 / 20000\n",
      "gradient norm: 0.07242799596861005, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00555\n",
      "epoch 5163 / 20000\n",
      "gradient norm: 0.08443374029593542, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 5164 / 20000\n",
      "gradient norm: 0.08933016855735332, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00552\n",
      "epoch 5165 / 20000\n",
      "gradient norm: 0.07298157241893932, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 5166 / 20000\n",
      "gradient norm: 0.04578889691038057, minimum ratio: 2.513157894736842\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 5167 / 20000\n",
      "gradient norm: 0.10430627618916333, minimum ratio: 2.4868421052631575\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00552\n",
      "epoch 5168 / 20000\n",
      "gradient norm: 0.07570458676491398, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 5169 / 20000\n",
      "gradient norm: 0.07192936586216092, minimum ratio: 2.492105263157895\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 5170 / 20000\n",
      "gradient norm: 0.07540074951248243, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 5171 / 20000\n",
      "gradient norm: 0.021546051022596657, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 5172 / 20000\n",
      "gradient norm: 0.040812401377479546, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 5173 / 20000\n",
      "gradient norm: 0.013499454435077496, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 5174 / 20000\n",
      "gradient norm: 0.07869239595675026, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 5175 / 20000\n",
      "gradient norm: 0.05827576317824423, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 5176 / 20000\n",
      "gradient norm: 0.11651159590110183, minimum ratio: 2.505263157894737\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 5177 / 20000\n",
      "gradient norm: 0.06805209704907611, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 5178 / 20000\n",
      "gradient norm: 0.06739927921444178, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 5179 / 20000\n",
      "gradient norm: 0.04897826933301985, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 5180 / 20000\n",
      "gradient norm: 0.04968985531013459, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 5181 / 20000\n",
      "gradient norm: 0.06682877608545823, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 5182 / 20000\n",
      "gradient norm: 0.03846645590965636, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 5183 / 20000\n",
      "gradient norm: 0.06373608722788049, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 5184 / 20000\n",
      "gradient norm: 0.056740631407592446, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 5185 / 20000\n",
      "gradient norm: 0.09117327159037814, minimum ratio: 2.4894736842105267\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 5186 / 20000\n",
      "gradient norm: 0.05845829242025502, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 5187 / 20000\n",
      "gradient norm: 0.0946011684864061, minimum ratio: 2.4894736842105267\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00553\n",
      "epoch 5188 / 20000\n",
      "gradient norm: 0.11821942136157304, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 5189 / 20000\n",
      "gradient norm: 0.0666452837176621, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 5190 / 20000\n",
      "gradient norm: 0.043434769148007035, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 5191 / 20000\n",
      "gradient norm: 0.08308769902214408, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 5192 / 20000\n",
      "gradient norm: 0.06661241200345103, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 5193 / 20000\n",
      "gradient norm: 0.09697649837471545, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 5194 / 20000\n",
      "gradient norm: 0.08160839832271449, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 5195 / 20000\n",
      "gradient norm: 0.11722345370799303, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00556\n",
      "epoch 5196 / 20000\n",
      "gradient norm: 0.10582293814513832, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00551\n",
      "epoch 5197 / 20000\n",
      "gradient norm: 0.08478846470825374, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 5198 / 20000\n",
      "gradient norm: 0.06663264625240117, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00554\n",
      "epoch 5199 / 20000\n",
      "gradient norm: 0.07048571559425909, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00554\n",
      "epoch 5200 / 20000\n",
      "gradient norm: 0.08484159596264362, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 5201 / 20000\n",
      "gradient norm: 0.07609354535816237, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 5202 / 20000\n",
      "gradient norm: 0.08473912719637156, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 5203 / 20000\n",
      "gradient norm: 0.0445071961148642, minimum ratio: 2.4868421052631584\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 5204 / 20000\n",
      "gradient norm: 0.058839053846895695, minimum ratio: 2.4631578947368427\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 5205 / 20000\n",
      "gradient norm: 0.03098082727228757, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 5206 / 20000\n",
      "gradient norm: 0.08840927021810785, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 5207 / 20000\n",
      "gradient norm: 0.04606901545776054, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 5208 / 20000\n",
      "gradient norm: 0.08638951528701, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 5209 / 20000\n",
      "gradient norm: 0.1429340853355825, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00556\n",
      "epoch 5210 / 20000\n",
      "gradient norm: 0.09462188562611118, minimum ratio: 2.4736842105263155\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00552\n",
      "epoch 5211 / 20000\n",
      "gradient norm: 0.10867142304778099, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 5212 / 20000\n",
      "gradient norm: 0.07701357780024409, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 5213 / 20000\n",
      "gradient norm: 0.05358123447513208, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 5214 / 20000\n",
      "gradient norm: 0.061015893501462415, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 5215 / 20000\n",
      "gradient norm: 0.07206090987892821, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00552\n",
      "epoch 5216 / 20000\n",
      "gradient norm: 0.09014655961073004, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 5217 / 20000\n",
      "gradient norm: 0.06698931922437623, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 5218 / 20000\n",
      "gradient norm: 0.04396495339460671, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 5219 / 20000\n",
      "gradient norm: 0.07064451870974153, minimum ratio: 2.4842105263157896\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 5220 / 20000\n",
      "gradient norm: 0.024267398286610842, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 5221 / 20000\n",
      "gradient norm: 0.05664646450895816, minimum ratio: 2.494736842105263\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 5222 / 20000\n",
      "gradient norm: 0.07647933129919693, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 5223 / 20000\n",
      "gradient norm: 0.04855275619775057, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 5224 / 20000\n",
      "gradient norm: 0.03566868993220851, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 5225 / 20000\n",
      "gradient norm: 0.039419863547664136, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 5226 / 20000\n",
      "gradient norm: 0.048152979667065665, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 5227 / 20000\n",
      "gradient norm: 0.09941032901406288, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 5228 / 20000\n",
      "gradient norm: 0.10622713534394279, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 5229 / 20000\n",
      "gradient norm: 0.1162276758113876, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 5230 / 20000\n",
      "gradient norm: 0.08120261086151004, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 5231 / 20000\n",
      "gradient norm: 0.05995272003929131, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 5232 / 20000\n",
      "gradient norm: 0.06821913458406925, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 5233 / 20000\n",
      "gradient norm: 0.08764795842580497, minimum ratio: 2.4815789473684213\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00552\n",
      "epoch 5234 / 20000\n",
      "gradient norm: 0.06639155867742375, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 5235 / 20000\n",
      "gradient norm: 0.07337253156583756, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00552\n",
      "epoch 5236 / 20000\n",
      "gradient norm: 0.10234483814565465, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00551\n",
      "epoch 5237 / 20000\n",
      "gradient norm: 0.05865851417183876, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 5238 / 20000\n",
      "gradient norm: 0.08613267497275956, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 5239 / 20000\n",
      "gradient norm: 0.0798166340100579, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 5240 / 20000\n",
      "gradient norm: 0.030221054737921804, minimum ratio: 2.5105263157894737\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 5241 / 20000\n",
      "gradient norm: 0.09999032685300335, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 5242 / 20000\n",
      "gradient norm: 0.10196082331822254, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00556\n",
      "epoch 5243 / 20000\n",
      "gradient norm: 0.15165092411916703, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00551\n",
      "epoch 5244 / 20000\n",
      "gradient norm: 0.07143054704647511, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00552\n",
      "epoch 5245 / 20000\n",
      "gradient norm: 0.07982749864459038, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 5246 / 20000\n",
      "gradient norm: 0.06310462112014648, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 5247 / 20000\n",
      "gradient norm: 0.07232703367481008, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 5248 / 20000\n",
      "gradient norm: 0.06825245311483741, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00553\n",
      "epoch 5249 / 20000\n",
      "gradient norm: 0.09541027166415006, minimum ratio: 2.5078947368421054\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 5250 / 20000\n",
      "gradient norm: 0.08268784219399095, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 5251 / 20000\n",
      "gradient norm: 0.047126614023, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 5252 / 20000\n",
      "gradient norm: 0.08228445838904008, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 5253 / 20000\n",
      "gradient norm: 0.08441165427211672, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00552\n",
      "epoch 5254 / 20000\n",
      "gradient norm: 0.027252316591329873, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 5255 / 20000\n",
      "gradient norm: 0.047316107113147154, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 5256 / 20000\n",
      "gradient norm: 0.09884420060552657, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 5257 / 20000\n",
      "gradient norm: 0.06434849217475858, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 5258 / 20000\n",
      "gradient norm: 0.06284552253782749, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 5259 / 20000\n",
      "gradient norm: 0.20490422169677913, minimum ratio: 2.5105263157894733\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00555\n",
      "epoch 5260 / 20000\n",
      "gradient norm: 0.03795482375426218, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 5261 / 20000\n",
      "gradient norm: 0.11656507145380601, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00551\n",
      "epoch 5262 / 20000\n",
      "gradient norm: 0.08024988713441417, minimum ratio: 2.5131578947368425\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00556\n",
      "epoch 5263 / 20000\n",
      "gradient norm: 0.09984247293323278, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 5264 / 20000\n",
      "gradient norm: 0.05844989191973582, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 5265 / 20000\n",
      "gradient norm: 0.06972941241110675, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 5266 / 20000\n",
      "gradient norm: 0.15538974199444056, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00552\n",
      "epoch 5267 / 20000\n",
      "gradient norm: 0.0453157601878047, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 5268 / 20000\n",
      "gradient norm: 0.09714041685219854, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 5269 / 20000\n",
      "gradient norm: 0.03631827712524682, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 5270 / 20000\n",
      "gradient norm: 0.0756894655060023, minimum ratio: 2.507894736842105\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 5271 / 20000\n",
      "gradient norm: 0.03861592685279902, minimum ratio: 2.5105263157894737\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 5272 / 20000\n",
      "gradient norm: 0.04610783691168763, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 5273 / 20000\n",
      "gradient norm: 0.05670341744553298, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 5274 / 20000\n",
      "gradient norm: 0.07644540621549822, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 5275 / 20000\n",
      "gradient norm: 0.06589247728697956, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 5276 / 20000\n",
      "gradient norm: 0.07459266636578832, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 5277 / 20000\n",
      "gradient norm: 0.09610990877263248, minimum ratio: 2.4894736842105267\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 5278 / 20000\n",
      "gradient norm: 0.06764569858205505, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 5279 / 20000\n",
      "gradient norm: 0.07690322588314302, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 5280 / 20000\n",
      "gradient norm: 0.06927780882688239, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00552\n",
      "epoch 5281 / 20000\n",
      "gradient norm: 0.02759946782316547, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 5282 / 20000\n",
      "gradient norm: 0.07332226174185053, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 5283 / 20000\n",
      "gradient norm: 0.06656365207163617, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 5284 / 20000\n",
      "gradient norm: 0.05110637008328922, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 5285 / 20000\n",
      "gradient norm: 0.06389205122832209, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 5286 / 20000\n",
      "gradient norm: 0.0345740675838897, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 5287 / 20000\n",
      "gradient norm: 0.0559390107227955, minimum ratio: 2.526315789473684\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 5288 / 20000\n",
      "gradient norm: 0.04163218516623601, minimum ratio: 2.492105263157895\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 5289 / 20000\n",
      "gradient norm: 0.0622850656582159, minimum ratio: 2.46578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 5290 / 20000\n",
      "gradient norm: 0.035220146644860506, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 5291 / 20000\n",
      "gradient norm: 0.07494168085395359, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 5292 / 20000\n",
      "gradient norm: 0.04499743440828752, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 5293 / 20000\n",
      "gradient norm: 0.0653340459393803, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00552\n",
      "epoch 5294 / 20000\n",
      "gradient norm: 0.030267261841800064, minimum ratio: 2.492105263157895\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 5295 / 20000\n",
      "gradient norm: 0.08680660696700215, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 5296 / 20000\n",
      "gradient norm: 0.05729025600885507, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 5297 / 20000\n",
      "gradient norm: 0.07338343665469438, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 5298 / 20000\n",
      "gradient norm: 0.05155032913899049, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 5299 / 20000\n",
      "gradient norm: 0.07654855318833143, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 5300 / 20000\n",
      "gradient norm: 0.04762566235149279, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 5301 / 20000\n",
      "gradient norm: 0.056099070119671524, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 5302 / 20000\n",
      "gradient norm: 0.07130931437131949, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 5303 / 20000\n",
      "gradient norm: 0.043784051842521876, minimum ratio: 2.5131578947368425\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 5304 / 20000\n",
      "gradient norm: 0.054995481797959656, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 5305 / 20000\n",
      "gradient norm: 0.03930383702390827, minimum ratio: 2.489473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 5306 / 20000\n",
      "gradient norm: 0.05069799331249669, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 5307 / 20000\n",
      "gradient norm: 0.05034392743255012, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 5308 / 20000\n",
      "gradient norm: 0.027808906510472298, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 5309 / 20000\n",
      "gradient norm: 0.03713451909425203, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 5310 / 20000\n",
      "gradient norm: 0.0403688504738966, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 5311 / 20000\n",
      "gradient norm: 0.02514100332700764, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 5312 / 20000\n",
      "gradient norm: 0.0666211700590793, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 5313 / 20000\n",
      "gradient norm: 0.029418742487905547, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 5314 / 20000\n",
      "gradient norm: 0.07160556712187827, minimum ratio: 2.5105263157894737\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 5315 / 20000\n",
      "gradient norm: 0.02503791288472712, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 5316 / 20000\n",
      "gradient norm: 0.040150410757632926, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 5317 / 20000\n",
      "gradient norm: 0.035127284776535816, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 5318 / 20000\n",
      "gradient norm: 0.08489038713742048, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 5319 / 20000\n",
      "gradient norm: 0.1327794787939638, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 5320 / 20000\n",
      "gradient norm: 0.05551044933963567, minimum ratio: 2.505263157894737\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 5321 / 20000\n",
      "gradient norm: 0.055249736171390396, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 5322 / 20000\n",
      "gradient norm: 0.11206290213158354, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00552\n",
      "epoch 5323 / 20000\n",
      "gradient norm: 0.049496401741635054, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00554\n",
      "epoch 5324 / 20000\n",
      "gradient norm: 0.1470344525296241, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 5325 / 20000\n",
      "gradient norm: 0.08263819088460878, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 5326 / 20000\n",
      "gradient norm: 0.08748728156206198, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00552\n",
      "epoch 5327 / 20000\n",
      "gradient norm: 0.03071293991524726, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 5328 / 20000\n",
      "gradient norm: 0.06866165343672037, minimum ratio: 2.492105263157895\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00554\n",
      "epoch 5329 / 20000\n",
      "gradient norm: 0.07949293969431892, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 5330 / 20000\n",
      "gradient norm: 0.08858778822468594, minimum ratio: 2.505263157894737\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 5331 / 20000\n",
      "gradient norm: 0.07025718118529767, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 5332 / 20000\n",
      "gradient norm: 0.028455276711611077, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 5333 / 20000\n",
      "gradient norm: 0.1010188142536208, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 5334 / 20000\n",
      "gradient norm: 0.03226847483892925, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 5335 / 20000\n",
      "gradient norm: 0.04047287526191212, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 5336 / 20000\n",
      "gradient norm: 0.06305369417532347, minimum ratio: 2.5078947368421054\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 5337 / 20000\n",
      "gradient norm: 0.09659928071778268, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 5338 / 20000\n",
      "gradient norm: 0.07833934912923723, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 5339 / 20000\n",
      "gradient norm: 0.05735460063442588, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 5340 / 20000\n",
      "gradient norm: 0.03525127594184596, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 5341 / 20000\n",
      "gradient norm: 0.06744539819192141, minimum ratio: 2.515789473684211\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 5342 / 20000\n",
      "gradient norm: 0.07029756081465166, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 5343 / 20000\n",
      "gradient norm: 0.11306449346011505, minimum ratio: 2.505263157894737\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00552\n",
      "epoch 5344 / 20000\n",
      "gradient norm: 0.06713819515425712, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 5345 / 20000\n",
      "gradient norm: 0.12157865875633433, minimum ratio: 2.4815789473684213\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 5346 / 20000\n",
      "gradient norm: 0.03861245795269497, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 5347 / 20000\n",
      "gradient norm: 0.07052999426377937, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 5348 / 20000\n",
      "gradient norm: 0.06632776453625411, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00554\n",
      "epoch 5349 / 20000\n",
      "gradient norm: 0.0743628857890144, minimum ratio: 2.460526315789474\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 5350 / 20000\n",
      "gradient norm: 0.0660982865083497, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 5351 / 20000\n",
      "gradient norm: 0.07547897705808282, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 5352 / 20000\n",
      "gradient norm: 0.05325065096258186, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 5353 / 20000\n",
      "gradient norm: 0.06815521116368473, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00552\n",
      "epoch 5354 / 20000\n",
      "gradient norm: 0.04250467216479592, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 5355 / 20000\n",
      "gradient norm: 0.07045737688895315, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 5356 / 20000\n",
      "gradient norm: 0.11504736391361803, minimum ratio: 2.5078947368421054\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 5357 / 20000\n",
      "gradient norm: 0.092828186287079, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 5358 / 20000\n",
      "gradient norm: 0.08595254796091467, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 5359 / 20000\n",
      "gradient norm: 0.10521710989996791, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 5360 / 20000\n",
      "gradient norm: 0.06634260827559046, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 5361 / 20000\n",
      "gradient norm: 0.09358596318634227, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 5362 / 20000\n",
      "gradient norm: 0.041553784103598446, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 5363 / 20000\n",
      "gradient norm: 0.06355036814056803, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 5364 / 20000\n",
      "gradient norm: 0.05942039175715763, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 5365 / 20000\n",
      "gradient norm: 0.09192190633621067, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 5366 / 20000\n",
      "gradient norm: 0.052981304994318634, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 5367 / 20000\n",
      "gradient norm: 0.03156948395917425, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 5368 / 20000\n",
      "gradient norm: 0.11329769960138947, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 5369 / 20000\n",
      "gradient norm: 0.04467533857678063, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 5370 / 20000\n",
      "gradient norm: 0.08005891140783206, minimum ratio: 2.4894736842105267\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 5371 / 20000\n",
      "gradient norm: 0.053290145413484424, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 5372 / 20000\n",
      "gradient norm: 0.036736819602083415, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 5373 / 20000\n",
      "gradient norm: 0.08992503682384267, minimum ratio: 2.492105263157895\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 5374 / 20000\n",
      "gradient norm: 0.04858029243769124, minimum ratio: 2.518421052631579\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 5375 / 20000\n",
      "gradient norm: 0.043960518174571916, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 5376 / 20000\n",
      "gradient norm: 0.05198984235175885, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 5377 / 20000\n",
      "gradient norm: 0.04152464459184557, minimum ratio: 2.492105263157895\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 5378 / 20000\n",
      "gradient norm: 0.05867372918874025, minimum ratio: 2.489473684210526\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 5379 / 20000\n",
      "gradient norm: 0.0822355528944172, minimum ratio: 2.489473684210526\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 5380 / 20000\n",
      "gradient norm: 0.12094942096155137, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 5381 / 20000\n",
      "gradient norm: 0.08707402943400666, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 5382 / 20000\n",
      "gradient norm: 0.06207957479637116, minimum ratio: 2.494736842105263\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 5383 / 20000\n",
      "gradient norm: 0.03973021692945622, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 5384 / 20000\n",
      "gradient norm: 0.10927898302907124, minimum ratio: 2.4868421052631575\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 5385 / 20000\n",
      "gradient norm: 0.03436448660795577, minimum ratio: 2.507894736842105\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 5386 / 20000\n",
      "gradient norm: 0.07118964294204488, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 5387 / 20000\n",
      "gradient norm: 0.07791795324010309, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 5388 / 20000\n",
      "gradient norm: 0.08411127259023488, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00551\n",
      "epoch 5389 / 20000\n",
      "gradient norm: 0.048760400706669316, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 5390 / 20000\n",
      "gradient norm: 0.05511899554403499, minimum ratio: 2.492105263157895\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 5391 / 20000\n",
      "gradient norm: 0.029882536779041402, minimum ratio: 2.505263157894737\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 5392 / 20000\n",
      "gradient norm: 0.101033023907803, minimum ratio: 2.5105263157894733\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 5393 / 20000\n",
      "gradient norm: 0.049288388108834624, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 5394 / 20000\n",
      "gradient norm: 0.03916548077540938, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 5395 / 20000\n",
      "gradient norm: 0.044572300277650356, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 5396 / 20000\n",
      "gradient norm: 0.05808328662533313, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 5397 / 20000\n",
      "gradient norm: 0.13972763321362436, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 5398 / 20000\n",
      "gradient norm: 0.07804258295800537, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 5399 / 20000\n",
      "gradient norm: 0.07190434547374025, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 5400 / 20000\n",
      "gradient norm: 0.08368778353906237, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00552\n",
      "epoch 5401 / 20000\n",
      "gradient norm: 0.041687835415359586, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 5402 / 20000\n",
      "gradient norm: 0.10541059615206905, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 5403 / 20000\n",
      "gradient norm: 0.042422797065228224, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 5404 / 20000\n",
      "gradient norm: 0.06800674565602094, minimum ratio: 2.4842105263157896\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 5405 / 20000\n",
      "gradient norm: 0.09256119397468865, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 5406 / 20000\n",
      "gradient norm: 0.08176155237015337, minimum ratio: 2.5236842105263158\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 5407 / 20000\n",
      "gradient norm: 0.0580987156718038, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 5408 / 20000\n",
      "gradient norm: 0.06575365175376646, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 5409 / 20000\n",
      "gradient norm: 0.07804859447060153, minimum ratio: 2.5105263157894737\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 5410 / 20000\n",
      "gradient norm: 0.056178446277044713, minimum ratio: 2.5078947368421054\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 5411 / 20000\n",
      "gradient norm: 0.05899499004590325, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 5412 / 20000\n",
      "gradient norm: 0.11379218401270919, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 5413 / 20000\n",
      "gradient norm: 0.06589198752772063, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 5414 / 20000\n",
      "gradient norm: 0.03807902996777557, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 5415 / 20000\n",
      "gradient norm: 0.06070663276477717, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 5416 / 20000\n",
      "gradient norm: 0.05105847245431505, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 5417 / 20000\n",
      "gradient norm: 0.08159858081489801, minimum ratio: 2.5105263157894737\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 5418 / 20000\n",
      "gradient norm: 0.097439139848575, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 5419 / 20000\n",
      "gradient norm: 0.09490983895375393, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 5420 / 20000\n",
      "gradient norm: 0.06647708042874001, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 5421 / 20000\n",
      "gradient norm: 0.04992548635345884, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 5422 / 20000\n",
      "gradient norm: 0.050411238975357264, minimum ratio: 2.494736842105263\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 5423 / 20000\n",
      "gradient norm: 0.0490417392575182, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 5424 / 20000\n",
      "gradient norm: 0.0515178948699031, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 5425 / 20000\n",
      "gradient norm: 0.029963706387206912, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 5426 / 20000\n",
      "gradient norm: 0.09505547262961045, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 5427 / 20000\n",
      "gradient norm: 0.0327261136189918, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 5428 / 20000\n",
      "gradient norm: 0.049924295337405056, minimum ratio: 2.4842105263157896\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 5429 / 20000\n",
      "gradient norm: 0.08535988192306831, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 5430 / 20000\n",
      "gradient norm: 0.0612656170851551, minimum ratio: 2.5131578947368425\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 5431 / 20000\n",
      "gradient norm: 0.11913974827621132, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00551\n",
      "epoch 5432 / 20000\n",
      "gradient norm: 0.032376927469158545, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00554\n",
      "epoch 5433 / 20000\n",
      "gradient norm: 0.06396818975917995, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 5434 / 20000\n",
      "gradient norm: 0.04776053869863972, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 5435 / 20000\n",
      "gradient norm: 0.09428009972907603, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 5436 / 20000\n",
      "gradient norm: 0.09758828149642795, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 5437 / 20000\n",
      "gradient norm: 0.06132705201162025, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 5438 / 20000\n",
      "gradient norm: 0.04538266296731308, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 5439 / 20000\n",
      "gradient norm: 0.030321277139591984, minimum ratio: 2.5105263157894737\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 5440 / 20000\n",
      "gradient norm: 0.07493349211290479, minimum ratio: 2.4842105263157896\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 5441 / 20000\n",
      "gradient norm: 0.06102032100898214, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 5442 / 20000\n",
      "gradient norm: 0.03771895219688304, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 5443 / 20000\n",
      "gradient norm: 0.0383389035705477, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 5444 / 20000\n",
      "gradient norm: 0.10103478177916259, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 5445 / 20000\n",
      "gradient norm: 0.06157676188740879, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 5446 / 20000\n",
      "gradient norm: 0.08948522625723854, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 5447 / 20000\n",
      "gradient norm: 0.07857699180021882, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 5448 / 20000\n",
      "gradient norm: 0.08221881254576147, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 5449 / 20000\n",
      "gradient norm: 0.07093169441213831, minimum ratio: 2.4868421052631575\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 5450 / 20000\n",
      "gradient norm: 0.11708252504467964, minimum ratio: 2.4842105263157896\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 5451 / 20000\n",
      "gradient norm: 0.054429802898084745, minimum ratio: 2.4842105263157896\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 5452 / 20000\n",
      "gradient norm: 0.07300762890372425, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 5453 / 20000\n",
      "gradient norm: 0.05810829409165308, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 5454 / 20000\n",
      "gradient norm: 0.02709851048712153, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 5455 / 20000\n",
      "gradient norm: 0.045128753990866244, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 5456 / 20000\n",
      "gradient norm: 0.12026431813137606, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00551\n",
      "epoch 5457 / 20000\n",
      "gradient norm: 0.05746736697619781, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 5458 / 20000\n",
      "gradient norm: 0.12139701459091157, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00555\n",
      "epoch 5459 / 20000\n",
      "gradient norm: 0.10979291459079832, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00551\n",
      "epoch 5460 / 20000\n",
      "gradient norm: 0.061303984650294296, minimum ratio: 2.492105263157895\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 5461 / 20000\n",
      "gradient norm: 0.07230150306713767, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00554\n",
      "epoch 5462 / 20000\n",
      "gradient norm: 0.09919761138735339, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 5463 / 20000\n",
      "gradient norm: 0.03427420786465518, minimum ratio: 2.5078947368421054\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 5464 / 20000\n",
      "gradient norm: 0.08170683012576774, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 5465 / 20000\n",
      "gradient norm: 0.07154738754616119, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00556\n",
      "epoch 5466 / 20000\n",
      "gradient norm: 0.05381723202299327, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 5467 / 20000\n",
      "gradient norm: 0.0684679712576326, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 5468 / 20000\n",
      "gradient norm: 0.1098797646118328, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 5469 / 20000\n",
      "gradient norm: 0.10942658488056622, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 5470 / 20000\n",
      "gradient norm: 0.07290361524792388, minimum ratio: 2.4842105263157896\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 5471 / 20000\n",
      "gradient norm: 0.03769459681643639, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 5472 / 20000\n",
      "gradient norm: 0.029803965429891832, minimum ratio: 2.5105263157894737\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 5473 / 20000\n",
      "gradient norm: 0.05914388137171045, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 5474 / 20000\n",
      "gradient norm: 0.0314763521309942, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 5475 / 20000\n",
      "gradient norm: 0.048500700751901604, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 5476 / 20000\n",
      "gradient norm: 0.11262378317769617, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 5477 / 20000\n",
      "gradient norm: 0.032318666082574055, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 5478 / 20000\n",
      "gradient norm: 0.04453499551163986, minimum ratio: 2.4868421052631575\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 5479 / 20000\n",
      "gradient norm: 0.07780839066253975, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 5480 / 20000\n",
      "gradient norm: 0.06635023700073361, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 5481 / 20000\n",
      "gradient norm: 0.09274300746619701, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 5482 / 20000\n",
      "gradient norm: 0.08217697394866263, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00554\n",
      "epoch 5483 / 20000\n",
      "gradient norm: 0.05095283922855742, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 5484 / 20000\n",
      "gradient norm: 0.08515285613248125, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 5485 / 20000\n",
      "gradient norm: 0.03721439067157917, minimum ratio: 2.5105263157894737\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 5486 / 20000\n",
      "gradient norm: 0.09438135044183582, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 5487 / 20000\n",
      "gradient norm: 0.10133670305367559, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 5488 / 20000\n",
      "gradient norm: 0.05913152830908075, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 5489 / 20000\n",
      "gradient norm: 0.06906075443839654, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 5490 / 20000\n",
      "gradient norm: 0.06656244488840457, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 5491 / 20000\n",
      "gradient norm: 0.08450379950227216, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 5492 / 20000\n",
      "gradient norm: 0.07593427752726711, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 5493 / 20000\n",
      "gradient norm: 0.06250751344487071, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 5494 / 20000\n",
      "gradient norm: 0.05087729566730559, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 5495 / 20000\n",
      "gradient norm: 0.05707257834728807, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 5496 / 20000\n",
      "gradient norm: 0.052883564843796194, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 5497 / 20000\n",
      "gradient norm: 0.07987599016632885, minimum ratio: 2.4842105263157896\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 5498 / 20000\n",
      "gradient norm: 0.07484030211344361, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 5499 / 20000\n",
      "gradient norm: 0.06794066418660805, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 5500 / 20000\n",
      "gradient norm: 0.06471555816824548, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 5501 / 20000\n",
      "gradient norm: 0.07714664377272129, minimum ratio: 2.507894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 5502 / 20000\n",
      "gradient norm: 0.06549972569337115, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 5503 / 20000\n",
      "gradient norm: 0.1017275622143643, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 5504 / 20000\n",
      "gradient norm: 0.07987872208468616, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 5505 / 20000\n",
      "gradient norm: 0.06788849717122503, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 5506 / 20000\n",
      "gradient norm: 0.04452056423178874, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 5507 / 20000\n",
      "gradient norm: 0.06232731704949401, minimum ratio: 2.4815789473684213\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 5508 / 20000\n",
      "gradient norm: 0.10510679203434847, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 5509 / 20000\n",
      "gradient norm: 0.03460740024456754, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 5510 / 20000\n",
      "gradient norm: 0.095428483618889, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00551\n",
      "epoch 5511 / 20000\n",
      "gradient norm: 0.03994029472232796, minimum ratio: 2.492105263157895\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00554\n",
      "epoch 5512 / 20000\n",
      "gradient norm: 0.07800674682948738, minimum ratio: 2.5210526315789474\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00552\n",
      "epoch 5513 / 20000\n",
      "gradient norm: 0.07411142735509202, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 5514 / 20000\n",
      "gradient norm: 0.053080668541952036, minimum ratio: 2.4973684210526312\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 5515 / 20000\n",
      "gradient norm: 0.09462668251944706, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 5516 / 20000\n",
      "gradient norm: 0.06207748572342098, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 5517 / 20000\n",
      "gradient norm: 0.07958405429963022, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 5518 / 20000\n",
      "gradient norm: 0.09571121603948995, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 5519 / 20000\n",
      "gradient norm: 0.04856286849826574, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 5520 / 20000\n",
      "gradient norm: 0.05763971438864246, minimum ratio: 2.507894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 5521 / 20000\n",
      "gradient norm: 0.11708928539883345, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00551\n",
      "epoch 5522 / 20000\n",
      "gradient norm: 0.11150398722384125, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 5523 / 20000\n",
      "gradient norm: 0.07984358235262334, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 5524 / 20000\n",
      "gradient norm: 0.08513042866252363, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 5525 / 20000\n",
      "gradient norm: 0.0509868721710518, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 5526 / 20000\n",
      "gradient norm: 0.11224775842856616, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 5527 / 20000\n",
      "gradient norm: 0.0502876828686567, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00555\n",
      "epoch 5528 / 20000\n",
      "gradient norm: 0.07347318949177861, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 5529 / 20000\n",
      "gradient norm: 0.04181431944016367, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 5530 / 20000\n",
      "gradient norm: 0.048508889973163605, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 5531 / 20000\n",
      "gradient norm: 0.04412021950702183, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00554\n",
      "epoch 5532 / 20000\n",
      "gradient norm: 0.06564567779423669, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 5533 / 20000\n",
      "gradient norm: 0.06746581441257149, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 5534 / 20000\n",
      "gradient norm: 0.05021872097859159, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 5535 / 20000\n",
      "gradient norm: 0.09424401208525524, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 5536 / 20000\n",
      "gradient norm: 0.06397624569945037, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 5537 / 20000\n",
      "gradient norm: 0.0973444450792158, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 5538 / 20000\n",
      "gradient norm: 0.04175362177193165, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 5539 / 20000\n",
      "gradient norm: 0.08529825927689672, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 5540 / 20000\n",
      "gradient norm: 0.04183651544735767, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 5541 / 20000\n",
      "gradient norm: 0.09678859263658524, minimum ratio: 2.528947368421053\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 5542 / 20000\n",
      "gradient norm: 0.03841491119237617, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 5543 / 20000\n",
      "gradient norm: 0.10078444692771882, minimum ratio: 2.507894736842105\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 5544 / 20000\n",
      "gradient norm: 0.0902200740238186, minimum ratio: 2.518421052631579\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00555\n",
      "epoch 5545 / 20000\n",
      "gradient norm: 0.058944736316334456, minimum ratio: 2.5078947368421054\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 5546 / 20000\n",
      "gradient norm: 0.08078259287867695, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 5547 / 20000\n",
      "gradient norm: 0.06970780761912465, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 5548 / 20000\n",
      "gradient norm: 0.05761673563392833, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 5549 / 20000\n",
      "gradient norm: 0.02287935833010124, minimum ratio: 2.513157894736842\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 5550 / 20000\n",
      "gradient norm: 0.056369578203884885, minimum ratio: 2.4842105263157896\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 5551 / 20000\n",
      "gradient norm: 0.06697960861492902, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 5552 / 20000\n",
      "gradient norm: 0.050348566175671294, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 5553 / 20000\n",
      "gradient norm: 0.0752201291907113, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 5554 / 20000\n",
      "gradient norm: 0.03820973925758153, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 5555 / 20000\n",
      "gradient norm: 0.03378434250771534, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 5556 / 20000\n",
      "gradient norm: 0.0542296702042222, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 5557 / 20000\n",
      "gradient norm: 0.06275587997515686, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 5558 / 20000\n",
      "gradient norm: 0.050679261272307485, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 5559 / 20000\n",
      "gradient norm: 0.0664797163917683, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 5560 / 20000\n",
      "gradient norm: 0.09941114881075919, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00551\n",
      "epoch 5561 / 20000\n",
      "gradient norm: 0.04640491714235395, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 5562 / 20000\n",
      "gradient norm: 0.07238548871828243, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 5563 / 20000\n",
      "gradient norm: 0.09905623039230704, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 5564 / 20000\n",
      "gradient norm: 0.0977692358137574, minimum ratio: 2.4842105263157896\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 5565 / 20000\n",
      "gradient norm: 0.0862273775273934, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 5566 / 20000\n",
      "gradient norm: 0.08361844572937116, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00551\n",
      "epoch 5567 / 20000\n",
      "gradient norm: 0.07150803512195125, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 5568 / 20000\n",
      "gradient norm: 0.08821959234774113, minimum ratio: 2.5105263157894737\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 5569 / 20000\n",
      "gradient norm: 0.046323388611199334, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 5570 / 20000\n",
      "gradient norm: 0.07416807100526057, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 5571 / 20000\n",
      "gradient norm: 0.06220845177449519, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 5572 / 20000\n",
      "gradient norm: 0.07011849613627419, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00551\n",
      "epoch 5573 / 20000\n",
      "gradient norm: 0.051256375227239914, minimum ratio: 2.492105263157895\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 5574 / 20000\n",
      "gradient norm: 0.043418884044513106, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 5575 / 20000\n",
      "gradient norm: 0.05809996783500537, minimum ratio: 2.5315789473684207\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 5576 / 20000\n",
      "gradient norm: 0.03356848807015922, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 5577 / 20000\n",
      "gradient norm: 0.07550289196660742, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 5578 / 20000\n",
      "gradient norm: 0.033040729438653216, minimum ratio: 2.4842105263157896\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 5579 / 20000\n",
      "gradient norm: 0.07780563121195883, minimum ratio: 2.5105263157894733\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 5580 / 20000\n",
      "gradient norm: 0.08295326569350436, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 5581 / 20000\n",
      "gradient norm: 0.12119162789895199, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 5582 / 20000\n",
      "gradient norm: 0.03804838049109094, minimum ratio: 2.5131578947368425\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 5583 / 20000\n",
      "gradient norm: 0.11545576644130051, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 5584 / 20000\n",
      "gradient norm: 0.07557410511071794, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00554\n",
      "epoch 5585 / 20000\n",
      "gradient norm: 0.051388686639256775, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 5586 / 20000\n",
      "gradient norm: 0.043623397301416844, minimum ratio: 2.4868421052631575\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 5587 / 20000\n",
      "gradient norm: 0.057720762968529016, minimum ratio: 2.507894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 5588 / 20000\n",
      "gradient norm: 0.05036419295356609, minimum ratio: 2.494736842105263\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 5589 / 20000\n",
      "gradient norm: 0.07609314056753647, minimum ratio: 2.4736842105263155\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 5590 / 20000\n",
      "gradient norm: 0.09385928348638117, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 5591 / 20000\n",
      "gradient norm: 0.040799655398586765, minimum ratio: 2.526315789473684\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 5592 / 20000\n",
      "gradient norm: 0.03418757845793152, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 5593 / 20000\n",
      "gradient norm: 0.09838411735836416, minimum ratio: 2.4684210526315784\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 5594 / 20000\n",
      "gradient norm: 0.08552523900289088, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 5595 / 20000\n",
      "gradient norm: 0.09140226247836836, minimum ratio: 2.507894736842105\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 5596 / 20000\n",
      "gradient norm: 0.042062926950166, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 5597 / 20000\n",
      "gradient norm: 0.07028864789754152, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 5598 / 20000\n",
      "gradient norm: 0.052645871008280665, minimum ratio: 2.5105263157894737\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 5599 / 20000\n",
      "gradient norm: 0.0327352543536108, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 5600 / 20000\n",
      "gradient norm: 0.07332201267126948, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 5601 / 20000\n",
      "gradient norm: 0.03933006445004139, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 5602 / 20000\n",
      "gradient norm: 0.04667849588440731, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 5603 / 20000\n",
      "gradient norm: 0.061538521462352946, minimum ratio: 2.513157894736842\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00553\n",
      "epoch 5604 / 20000\n",
      "gradient norm: 0.05164597413386218, minimum ratio: 2.507894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 5605 / 20000\n",
      "gradient norm: 0.01652073250443209, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 5606 / 20000\n",
      "gradient norm: 0.043942777905613184, minimum ratio: 2.5105263157894737\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 5607 / 20000\n",
      "gradient norm: 0.03420633945643203, minimum ratio: 2.507894736842105\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 5608 / 20000\n",
      "gradient norm: 0.05027119384612888, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 5609 / 20000\n",
      "gradient norm: 0.12533661632915027, minimum ratio: 2.4868421052631575\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00551\n",
      "epoch 5610 / 20000\n",
      "gradient norm: 0.09512635061400943, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00554\n",
      "epoch 5611 / 20000\n",
      "gradient norm: 0.14365168032236397, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 5612 / 20000\n",
      "gradient norm: 0.05424643820151687, minimum ratio: 2.4868421052631575\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 5613 / 20000\n",
      "gradient norm: 0.07613450312055647, minimum ratio: 2.4868421052631575\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00552\n",
      "epoch 5614 / 20000\n",
      "gradient norm: 0.03544681103085168, minimum ratio: 2.4868421052631575\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 5615 / 20000\n",
      "gradient norm: 0.033120068634161726, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 5616 / 20000\n",
      "gradient norm: 0.11057222809176892, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 5617 / 20000\n",
      "gradient norm: 0.04878568276762962, minimum ratio: 2.46578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 5618 / 20000\n",
      "gradient norm: 0.06379588501295075, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 5619 / 20000\n",
      "gradient norm: 0.03874184569576755, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 5620 / 20000\n",
      "gradient norm: 0.10719845991116017, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 5621 / 20000\n",
      "gradient norm: 0.060640226292889565, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 5622 / 20000\n",
      "gradient norm: 0.05996012908872217, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 5623 / 20000\n",
      "gradient norm: 0.04792172403540462, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 5624 / 20000\n",
      "gradient norm: 0.044126970577053726, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 5625 / 20000\n",
      "gradient norm: 0.058425692724995315, minimum ratio: 2.505263157894737\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00554\n",
      "epoch 5626 / 20000\n",
      "gradient norm: 0.054152198950760067, minimum ratio: 2.5105263157894737\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 5627 / 20000\n",
      "gradient norm: 0.09197415603557602, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 5628 / 20000\n",
      "gradient norm: 0.06962625437881798, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 5629 / 20000\n",
      "gradient norm: 0.10145641111012083, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 5630 / 20000\n",
      "gradient norm: 0.10338895308086649, minimum ratio: 2.5105263157894737\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 5631 / 20000\n",
      "gradient norm: 0.056612843880429864, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 5632 / 20000\n",
      "gradient norm: 0.061518607632024214, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 5633 / 20000\n",
      "gradient norm: 0.06836497253971174, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 5634 / 20000\n",
      "gradient norm: 0.11840565031161532, minimum ratio: 2.46578947368421\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 5635 / 20000\n",
      "gradient norm: 0.0674687108839862, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 5636 / 20000\n",
      "gradient norm: 0.05932588322320953, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 5637 / 20000\n",
      "gradient norm: 0.07301074510905892, minimum ratio: 2.5105263157894737\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 5638 / 20000\n",
      "gradient norm: 0.05146376293851063, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 5639 / 20000\n",
      "gradient norm: 0.08303828132920898, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 5640 / 20000\n",
      "gradient norm: 0.061575713101774454, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 5641 / 20000\n",
      "gradient norm: 0.10520434111822397, minimum ratio: 2.492105263157895\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 5642 / 20000\n",
      "gradient norm: 0.07524979414301924, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 5643 / 20000\n",
      "gradient norm: 0.060956868081120774, minimum ratio: 2.4868421052631575\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 5644 / 20000\n",
      "gradient norm: 0.06324841495370492, minimum ratio: 2.4894736842105267\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 5645 / 20000\n",
      "gradient norm: 0.07094916127971373, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 5646 / 20000\n",
      "gradient norm: 0.08128598053008318, minimum ratio: 2.5289473684210524\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 5647 / 20000\n",
      "gradient norm: 0.05752379586920142, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 5648 / 20000\n",
      "gradient norm: 0.058189817500533536, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 5649 / 20000\n",
      "gradient norm: 0.036651236907346174, minimum ratio: 2.492105263157895\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 5650 / 20000\n",
      "gradient norm: 0.09732025035191327, minimum ratio: 2.5157894736842104\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 5651 / 20000\n",
      "gradient norm: 0.05623134443885647, minimum ratio: 2.4894736842105267\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 5652 / 20000\n",
      "gradient norm: 0.09289431577781215, minimum ratio: 2.465789473684211\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 5653 / 20000\n",
      "gradient norm: 0.03401776810642332, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 5654 / 20000\n",
      "gradient norm: 0.04489979374920949, minimum ratio: 2.4868421052631584\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 5655 / 20000\n",
      "gradient norm: 0.029489676802768372, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 5656 / 20000\n",
      "gradient norm: 0.05936607765761437, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 5657 / 20000\n",
      "gradient norm: 0.02909147084574215, minimum ratio: 2.4842105263157896\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 5658 / 20000\n",
      "gradient norm: 0.03733403608202934, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 5659 / 20000\n",
      "gradient norm: 0.09490792118594982, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 5660 / 20000\n",
      "gradient norm: 0.03815702337305993, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 5661 / 20000\n",
      "gradient norm: 0.037893892149440944, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 5662 / 20000\n",
      "gradient norm: 0.040387909873970784, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 5663 / 20000\n",
      "gradient norm: 0.056422859663143754, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 5664 / 20000\n",
      "gradient norm: 0.04866059619234875, minimum ratio: 2.4868421052631584\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 5665 / 20000\n",
      "gradient norm: 0.07360752631211653, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 5666 / 20000\n",
      "gradient norm: 0.09690674941521138, minimum ratio: 2.4894736842105267\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 5667 / 20000\n",
      "gradient norm: 0.0685681271716021, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00554\n",
      "epoch 5668 / 20000\n",
      "gradient norm: 0.04663580434862524, minimum ratio: 2.4842105263157896\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 5669 / 20000\n",
      "gradient norm: 0.07808325372752734, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 5670 / 20000\n",
      "gradient norm: 0.09228125656954944, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 5671 / 20000\n",
      "gradient norm: 0.0676372988964431, minimum ratio: 2.526315789473684\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 5672 / 20000\n",
      "gradient norm: 0.02669249943573959, minimum ratio: 2.5184210526315787\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 5673 / 20000\n",
      "gradient norm: 0.09169080798164941, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 5674 / 20000\n",
      "gradient norm: 0.11377723939949647, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 5675 / 20000\n",
      "gradient norm: 0.09182603866793215, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 5676 / 20000\n",
      "gradient norm: 0.03600227352580987, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 5677 / 20000\n",
      "gradient norm: 0.06487065425608307, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 5678 / 20000\n",
      "gradient norm: 0.04507583181839436, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 5679 / 20000\n",
      "gradient norm: 0.05781064316397533, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00554\n",
      "epoch 5680 / 20000\n",
      "gradient norm: 0.05455023063404951, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 5681 / 20000\n",
      "gradient norm: 0.06268761804676615, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 5682 / 20000\n",
      "gradient norm: 0.06632308760890737, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00555\n",
      "epoch 5683 / 20000\n",
      "gradient norm: 0.06145959993591532, minimum ratio: 2.5157894736842104\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 5684 / 20000\n",
      "gradient norm: 0.09586440911516547, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00551\n",
      "epoch 5685 / 20000\n",
      "gradient norm: 0.05715351217077114, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 5686 / 20000\n",
      "gradient norm: 0.07514927315060049, minimum ratio: 2.494736842105263\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 5687 / 20000\n",
      "gradient norm: 0.05550385774404276, minimum ratio: 2.4894736842105267\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 5688 / 20000\n",
      "gradient norm: 0.044345795206027105, minimum ratio: 2.489473684210526\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 5689 / 20000\n",
      "gradient norm: 0.12552947900258005, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 5690 / 20000\n",
      "gradient norm: 0.08602204988710582, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 5691 / 20000\n",
      "gradient norm: 0.054844224359840155, minimum ratio: 2.507894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 5692 / 20000\n",
      "gradient norm: 0.049214673752430826, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 5693 / 20000\n",
      "gradient norm: 0.0833758779335767, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 5694 / 20000\n",
      "gradient norm: 0.10479523346293718, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 5695 / 20000\n",
      "gradient norm: 0.14095159980934113, minimum ratio: 2.518421052631579\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 5696 / 20000\n",
      "gradient norm: 0.05274308352090884, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 5697 / 20000\n",
      "gradient norm: 0.1062631409149617, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 5698 / 20000\n",
      "gradient norm: 0.08956773951649666, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00551\n",
      "epoch 5699 / 20000\n",
      "gradient norm: 0.08660465083085, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 5700 / 20000\n",
      "gradient norm: 0.11158069153316319, minimum ratio: 2.4842105263157896\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00555\n",
      "epoch 5701 / 20000\n",
      "gradient norm: 0.11269988771528006, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00551\n",
      "epoch 5702 / 20000\n",
      "gradient norm: 0.11665774160064757, minimum ratio: 2.4868421052631575\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 5703 / 20000\n",
      "gradient norm: 0.06742402695817873, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 5704 / 20000\n",
      "gradient norm: 0.06790315901162103, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 5705 / 20000\n",
      "gradient norm: 0.06127323320833966, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 5706 / 20000\n",
      "gradient norm: 0.12513093661982566, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 5707 / 20000\n",
      "gradient norm: 0.06659851805306971, minimum ratio: 2.492105263157895\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 5708 / 20000\n",
      "gradient norm: 0.0516874630266102, minimum ratio: 2.492105263157895\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 5709 / 20000\n",
      "gradient norm: 0.073427060211543, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 5710 / 20000\n",
      "gradient norm: 0.05107525034691207, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 5711 / 20000\n",
      "gradient norm: 0.06780347542371601, minimum ratio: 2.489473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 5712 / 20000\n",
      "gradient norm: 0.04556007945211604, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 5713 / 20000\n",
      "gradient norm: 0.04257266751665156, minimum ratio: 2.5210526315789474\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 5714 / 20000\n",
      "gradient norm: 0.07561504546902142, minimum ratio: 2.492105263157895\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 5715 / 20000\n",
      "gradient norm: 0.059401600155979395, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 5716 / 20000\n",
      "gradient norm: 0.05805133363173809, minimum ratio: 2.4842105263157896\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 5717 / 20000\n",
      "gradient norm: 0.062404454773059115, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 5718 / 20000\n",
      "gradient norm: 0.06079602922545746, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 5719 / 20000\n",
      "gradient norm: 0.06646404557977803, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 5720 / 20000\n",
      "gradient norm: 0.058731162804178894, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 5721 / 20000\n",
      "gradient norm: 0.020947453420376405, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 5722 / 20000\n",
      "gradient norm: 0.12713267392246053, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00551\n",
      "epoch 5723 / 20000\n",
      "gradient norm: 0.06329135107807815, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00554\n",
      "epoch 5724 / 20000\n",
      "gradient norm: 0.07481449449551292, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 5725 / 20000\n",
      "gradient norm: 0.09294179396238178, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 5726 / 20000\n",
      "gradient norm: 0.0602608139597578, minimum ratio: 2.5236842105263158\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 5727 / 20000\n",
      "gradient norm: 0.09444763930514455, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 5728 / 20000\n",
      "gradient norm: 0.07653793680947274, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 5729 / 20000\n",
      "gradient norm: 0.05434845907439012, minimum ratio: 2.4868421052631575\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 5730 / 20000\n",
      "gradient norm: 0.061019941087579355, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 5731 / 20000\n",
      "gradient norm: 0.05715640162816271, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 5732 / 20000\n",
      "gradient norm: 0.06385625788243487, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 5733 / 20000\n",
      "gradient norm: 0.1050167744688224, minimum ratio: 2.4842105263157896\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 5734 / 20000\n",
      "gradient norm: 0.07638372833025642, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 5735 / 20000\n",
      "gradient norm: 0.12691804906353354, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 5736 / 20000\n",
      "gradient norm: 0.07118789186642971, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 5737 / 20000\n",
      "gradient norm: 0.10268319875467569, minimum ratio: 2.5078947368421054\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 5738 / 20000\n",
      "gradient norm: 0.01613540609832853, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 5739 / 20000\n",
      "gradient norm: 0.04466415836941451, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00551\n",
      "epoch 5740 / 20000\n",
      "gradient norm: 0.08771478093694896, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 5741 / 20000\n",
      "gradient norm: 0.035404818889219314, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 5742 / 20000\n",
      "gradient norm: 0.07043755226186477, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 5743 / 20000\n",
      "gradient norm: 0.0731606368208304, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 5744 / 20000\n",
      "gradient norm: 0.048195151961408556, minimum ratio: 2.526315789473684\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 5745 / 20000\n",
      "gradient norm: 0.056623876094818115, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 5746 / 20000\n",
      "gradient norm: 0.05576512395055033, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 5747 / 20000\n",
      "gradient norm: 0.04669957986334339, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 5748 / 20000\n",
      "gradient norm: 0.043785819987533614, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 5749 / 20000\n",
      "gradient norm: 0.06326690450077876, minimum ratio: 2.526315789473684\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 5750 / 20000\n",
      "gradient norm: 0.029472225040080957, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 5751 / 20000\n",
      "gradient norm: 0.057282340712845325, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 5752 / 20000\n",
      "gradient norm: 0.08369720241171308, minimum ratio: 2.5078947368421054\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 5753 / 20000\n",
      "gradient norm: 0.09165306383511052, minimum ratio: 2.507894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 5754 / 20000\n",
      "gradient norm: 0.04390027266344987, minimum ratio: 2.489473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 5755 / 20000\n",
      "gradient norm: 0.05790107112261467, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 5756 / 20000\n",
      "gradient norm: 0.03753281835815869, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 5757 / 20000\n",
      "gradient norm: 0.07312430639285594, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 5758 / 20000\n",
      "gradient norm: 0.04999169115035329, minimum ratio: 2.492105263157895\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 5759 / 20000\n",
      "gradient norm: 0.06604878016514704, minimum ratio: 2.5184210526315787\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 5760 / 20000\n",
      "gradient norm: 0.024683438891770493, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 5761 / 20000\n",
      "gradient norm: 0.11105363431852311, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 5762 / 20000\n",
      "gradient norm: 0.04844427082571201, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 5763 / 20000\n",
      "gradient norm: 0.0727453278232133, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 5764 / 20000\n",
      "gradient norm: 0.0575464050489245, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 5765 / 20000\n",
      "gradient norm: 0.035649808327434584, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 5766 / 20000\n",
      "gradient norm: 0.08727931702742353, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 5767 / 20000\n",
      "gradient norm: 0.05149993527447805, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 5768 / 20000\n",
      "gradient norm: 0.09480721404543146, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 5769 / 20000\n",
      "gradient norm: 0.019095087533059996, minimum ratio: 2.4894736842105267\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 5770 / 20000\n",
      "gradient norm: 0.10927020653616637, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 5771 / 20000\n",
      "gradient norm: 0.08361362211871892, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 5772 / 20000\n",
      "gradient norm: 0.07884348928928375, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00551\n",
      "epoch 5773 / 20000\n",
      "gradient norm: 0.06650267928489484, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 5774 / 20000\n",
      "gradient norm: 0.04292972930124961, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 5775 / 20000\n",
      "gradient norm: 0.09765899970079772, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 5776 / 20000\n",
      "gradient norm: 0.09839278715662658, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 5777 / 20000\n",
      "gradient norm: 0.0571216638199985, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 5778 / 20000\n",
      "gradient norm: 0.07213283330202103, minimum ratio: 2.465789473684211\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 5779 / 20000\n",
      "gradient norm: 0.04984615201829001, minimum ratio: 2.505263157894737\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 5780 / 20000\n",
      "gradient norm: 0.04335195533349179, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 5781 / 20000\n",
      "gradient norm: 0.08772113604936749, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 5782 / 20000\n",
      "gradient norm: 0.03354305971879512, minimum ratio: 2.494736842105263\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 5783 / 20000\n",
      "gradient norm: 0.03054384284041589, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 5784 / 20000\n",
      "gradient norm: 0.05143187058274634, minimum ratio: 2.4842105263157896\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 5785 / 20000\n",
      "gradient norm: 0.07103974127676338, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 5786 / 20000\n",
      "gradient norm: 0.09503531455993652, minimum ratio: 2.492105263157895\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 5787 / 20000\n",
      "gradient norm: 0.028102010022848845, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00551\n",
      "epoch 5788 / 20000\n",
      "gradient norm: 0.07450092310318723, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 5789 / 20000\n",
      "gradient norm: 0.056007855164352804, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 5790 / 20000\n",
      "gradient norm: 0.09946289280196652, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00555\n",
      "epoch 5791 / 20000\n",
      "gradient norm: 0.08136126515455544, minimum ratio: 2.4894736842105267\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00551\n",
      "epoch 5792 / 20000\n",
      "gradient norm: 0.09203140380850527, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 5793 / 20000\n",
      "gradient norm: 0.043879770702915266, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 5794 / 20000\n",
      "gradient norm: 0.044278927671257406, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 5795 / 20000\n",
      "gradient norm: 0.03009235253557563, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 5796 / 20000\n",
      "gradient norm: 0.06041457146056928, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 5797 / 20000\n",
      "gradient norm: 0.09687452239450067, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00554\n",
      "epoch 5798 / 20000\n",
      "gradient norm: 0.0648214036191348, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 5799 / 20000\n",
      "gradient norm: 0.07774601585697383, minimum ratio: 2.4868421052631584\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 5800 / 20000\n",
      "gradient norm: 0.04369275792851113, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 5801 / 20000\n",
      "gradient norm: 0.040444041645969264, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 5802 / 20000\n",
      "gradient norm: 0.07189824930537725, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 5803 / 20000\n",
      "gradient norm: 0.061995257157832384, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 5804 / 20000\n",
      "gradient norm: 0.06221434794133529, minimum ratio: 2.4736842105263155\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 5805 / 20000\n",
      "gradient norm: 0.047345424827653915, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 5806 / 20000\n",
      "gradient norm: 0.07916413430211833, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 5807 / 20000\n",
      "gradient norm: 0.04426036952645518, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 5808 / 20000\n",
      "gradient norm: 0.09935959475114942, minimum ratio: 2.494736842105263\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00551\n",
      "epoch 5809 / 20000\n",
      "gradient norm: 0.06716889774543233, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 5810 / 20000\n",
      "gradient norm: 0.07979912450537086, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 5811 / 20000\n",
      "gradient norm: 0.01848353914829204, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 5812 / 20000\n",
      "gradient norm: 0.06467078640707768, minimum ratio: 2.507894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 5813 / 20000\n",
      "gradient norm: 0.08816540065163281, minimum ratio: 2.492105263157895\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 5814 / 20000\n",
      "gradient norm: 0.024391749102505855, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 5815 / 20000\n",
      "gradient norm: 0.032228704207227565, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 5816 / 20000\n",
      "gradient norm: 0.03726406781061087, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 5817 / 20000\n",
      "gradient norm: 0.06917525012977421, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 5818 / 20000\n",
      "gradient norm: 0.0662119320986676, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 5819 / 20000\n",
      "gradient norm: 0.04555669457477052, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 5820 / 20000\n",
      "gradient norm: 0.0662306658050511, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 5821 / 20000\n",
      "gradient norm: 0.10606793779879808, minimum ratio: 2.4842105263157896\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 5822 / 20000\n",
      "gradient norm: 0.08965484803775325, minimum ratio: 2.5263157894736845\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 5823 / 20000\n",
      "gradient norm: 0.07361058914102614, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 5824 / 20000\n",
      "gradient norm: 0.067902899638284, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 5825 / 20000\n",
      "gradient norm: 0.04590974160237238, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 5826 / 20000\n",
      "gradient norm: 0.07480189902707934, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00553\n",
      "epoch 5827 / 20000\n",
      "gradient norm: 0.09441789682023227, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 5828 / 20000\n",
      "gradient norm: 0.041238029501982965, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 5829 / 20000\n",
      "gradient norm: 0.020602039439836517, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 5830 / 20000\n",
      "gradient norm: 0.03428637044271454, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 5831 / 20000\n",
      "gradient norm: 0.04829553564923117, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 5832 / 20000\n",
      "gradient norm: 0.07916467377799563, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 5833 / 20000\n",
      "gradient norm: 0.08583009743597358, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 5834 / 20000\n",
      "gradient norm: 0.055829923250712454, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00554\n",
      "epoch 5835 / 20000\n",
      "gradient norm: 0.08276961144292727, minimum ratio: 2.5157894736842104\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 5836 / 20000\n",
      "gradient norm: 0.021882364482735284, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 5837 / 20000\n",
      "gradient norm: 0.02925954869715497, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 5838 / 20000\n",
      "gradient norm: 0.05199351845658384, minimum ratio: 2.5131578947368425\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 5839 / 20000\n",
      "gradient norm: 0.09946503711398691, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 5840 / 20000\n",
      "gradient norm: 0.05364807516161818, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00553\n",
      "epoch 5841 / 20000\n",
      "gradient norm: 0.10219170880736783, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 5842 / 20000\n",
      "gradient norm: 0.08750672696623951, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 5843 / 20000\n",
      "gradient norm: 0.07666359771974385, minimum ratio: 2.513157894736842\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 5844 / 20000\n",
      "gradient norm: 0.07212339725811034, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 5845 / 20000\n",
      "gradient norm: 0.050597401830600575, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 5846 / 20000\n",
      "gradient norm: 0.06427703611552715, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 5847 / 20000\n",
      "gradient norm: 0.0510587640455924, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 5848 / 20000\n",
      "gradient norm: 0.09485508521902375, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 5849 / 20000\n",
      "gradient norm: 0.03383117543125991, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 5850 / 20000\n",
      "gradient norm: 0.035219439581851475, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 5851 / 20000\n",
      "gradient norm: 0.07680360422818922, minimum ratio: 2.4868421052631575\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 5852 / 20000\n",
      "gradient norm: 0.04651883240148891, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 5853 / 20000\n",
      "gradient norm: 0.050262545089935884, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 5854 / 20000\n",
      "gradient norm: 0.02345490075822454, minimum ratio: 2.5105263157894737\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 5855 / 20000\n",
      "gradient norm: 0.049123341421363875, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 5856 / 20000\n",
      "gradient norm: 0.07345688919303939, minimum ratio: 2.5078947368421054\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 5857 / 20000\n",
      "gradient norm: 0.08949408479384147, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 5858 / 20000\n",
      "gradient norm: 0.10968474514083937, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 5859 / 20000\n",
      "gradient norm: 0.11965929524740204, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 5860 / 20000\n",
      "gradient norm: 0.06988478830317035, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 5861 / 20000\n",
      "gradient norm: 0.07710458411020227, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 5862 / 20000\n",
      "gradient norm: 0.07593927491689101, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 5863 / 20000\n",
      "gradient norm: 0.08623130015621427, minimum ratio: 2.5105263157894733\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 5864 / 20000\n",
      "gradient norm: 0.06675867800367996, minimum ratio: 2.494736842105263\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 5865 / 20000\n",
      "gradient norm: 0.038373255665646866, minimum ratio: 2.4868421052631575\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 5866 / 20000\n",
      "gradient norm: 0.03868110373150557, minimum ratio: 2.460526315789474\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 5867 / 20000\n",
      "gradient norm: 0.03010132335475646, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 5868 / 20000\n",
      "gradient norm: 0.04032521696353797, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 5869 / 20000\n",
      "gradient norm: 0.06806158262770623, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 5870 / 20000\n",
      "gradient norm: 0.032668194980942644, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 5871 / 20000\n",
      "gradient norm: 0.05685693718260154, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 5872 / 20000\n",
      "gradient norm: 0.08304606942692772, minimum ratio: 2.460526315789474\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 5873 / 20000\n",
      "gradient norm: 0.07494761489215307, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 5874 / 20000\n",
      "gradient norm: 0.07415207487065345, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 5875 / 20000\n",
      "gradient norm: 0.07089444127632305, minimum ratio: 2.460526315789474\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 5876 / 20000\n",
      "gradient norm: 0.10881422332022339, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00551\n",
      "epoch 5877 / 20000\n",
      "gradient norm: 0.08857536286814138, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00556\n",
      "epoch 5878 / 20000\n",
      "gradient norm: 0.06364780920557678, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 5879 / 20000\n",
      "gradient norm: 0.06757866049883887, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 5880 / 20000\n",
      "gradient norm: 0.061829660553485155, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 5881 / 20000\n",
      "gradient norm: 0.07328732835594565, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 5882 / 20000\n",
      "gradient norm: 0.056527921406086534, minimum ratio: 2.5105263157894737\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 5883 / 20000\n",
      "gradient norm: 0.08299857599195093, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 5884 / 20000\n",
      "gradient norm: 0.062179216562071815, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00554\n",
      "epoch 5885 / 20000\n",
      "gradient norm: 0.030275539749709424, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 5886 / 20000\n",
      "gradient norm: 0.15351452946197242, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 5887 / 20000\n",
      "gradient norm: 0.025994549738243222, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00554\n",
      "epoch 5888 / 20000\n",
      "gradient norm: 0.059628137038089335, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 5889 / 20000\n",
      "gradient norm: 0.1298806379782036, minimum ratio: 2.4894736842105267\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 5890 / 20000\n",
      "gradient norm: 0.10393214350915514, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 5891 / 20000\n",
      "gradient norm: 0.06946524820523337, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 5892 / 20000\n",
      "gradient norm: 0.09626650891732424, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 5893 / 20000\n",
      "gradient norm: 0.1271503748721443, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 5894 / 20000\n",
      "gradient norm: 0.13176815980114043, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 5895 / 20000\n",
      "gradient norm: 0.07569683901965618, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 5896 / 20000\n",
      "gradient norm: 0.06404679454863071, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 5897 / 20000\n",
      "gradient norm: 0.04678527670330368, minimum ratio: 2.4842105263157896\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00554\n",
      "epoch 5898 / 20000\n",
      "gradient norm: 0.0561366586771328, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 5899 / 20000\n",
      "gradient norm: 0.055757362104486674, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 5900 / 20000\n",
      "gradient norm: 0.016225866056629457, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 5901 / 20000\n",
      "gradient norm: 0.08818395651178434, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 5902 / 20000\n",
      "gradient norm: 0.12184303463436663, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00551\n",
      "epoch 5903 / 20000\n",
      "gradient norm: 0.0794383694883436, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 5904 / 20000\n",
      "gradient norm: 0.15310445637442172, minimum ratio: 2.4894736842105267\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00556\n",
      "epoch 5905 / 20000\n",
      "gradient norm: 0.09202483849367127, minimum ratio: 2.4499999999999997\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 5906 / 20000\n",
      "gradient norm: 0.11212429485749453, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 5907 / 20000\n",
      "gradient norm: 0.04752689157612622, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 5908 / 20000\n",
      "gradient norm: 0.04774606514547486, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 5909 / 20000\n",
      "gradient norm: 0.07899163232650608, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 5910 / 20000\n",
      "gradient norm: 0.06869946554070339, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 5911 / 20000\n",
      "gradient norm: 0.06456868894019863, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 5912 / 20000\n",
      "gradient norm: 0.0359836999559775, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 5913 / 20000\n",
      "gradient norm: 0.06215211716335034, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00552\n",
      "epoch 5914 / 20000\n",
      "gradient norm: 0.03561311075463891, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 5915 / 20000\n",
      "gradient norm: 0.02721473455312662, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 5916 / 20000\n",
      "gradient norm: 0.071427502844017, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 5917 / 20000\n",
      "gradient norm: 0.03584372537443414, minimum ratio: 2.5078947368421054\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 5918 / 20000\n",
      "gradient norm: 0.06446000235155225, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 5919 / 20000\n",
      "gradient norm: 0.03712849220028147, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 5920 / 20000\n",
      "gradient norm: 0.05361103094764985, minimum ratio: 2.505263157894737\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 5921 / 20000\n",
      "gradient norm: 0.08744196017505601, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 5922 / 20000\n",
      "gradient norm: 0.09974978736136109, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 5923 / 20000\n",
      "gradient norm: 0.028010461130179465, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 5924 / 20000\n",
      "gradient norm: 0.11898735712748021, minimum ratio: 2.4973684210526312\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 5925 / 20000\n",
      "gradient norm: 0.07152568992751185, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00554\n",
      "epoch 5926 / 20000\n",
      "gradient norm: 0.06471268882160075, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 5927 / 20000\n",
      "gradient norm: 0.0978474544826895, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 5928 / 20000\n",
      "gradient norm: 0.0850969890889246, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 5929 / 20000\n",
      "gradient norm: 0.08488400161149912, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 5930 / 20000\n",
      "gradient norm: 0.08508535544387996, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 5931 / 20000\n",
      "gradient norm: 0.08419894831604324, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 5932 / 20000\n",
      "gradient norm: 0.10354943454149179, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 5933 / 20000\n",
      "gradient norm: 0.04683684662450105, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 5934 / 20000\n",
      "gradient norm: 0.13222424313426018, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 5935 / 20000\n",
      "gradient norm: 0.01714088312110107, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 5936 / 20000\n",
      "gradient norm: 0.06003224913729355, minimum ratio: 2.4868421052631575\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 5937 / 20000\n",
      "gradient norm: 0.03026650172250811, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 5938 / 20000\n",
      "gradient norm: 0.0263831389893312, minimum ratio: 2.5157894736842104\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 5939 / 20000\n",
      "gradient norm: 0.0619275362114422, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 5940 / 20000\n",
      "gradient norm: 0.07305357384029776, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 5941 / 20000\n",
      "gradient norm: 0.054476059041917324, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 5942 / 20000\n",
      "gradient norm: 0.05469473160337657, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 5943 / 20000\n",
      "gradient norm: 0.06962979682430159, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 5944 / 20000\n",
      "gradient norm: 0.035441355081275105, minimum ratio: 2.489473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 5945 / 20000\n",
      "gradient norm: 0.039857978001236916, minimum ratio: 2.5105263157894737\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 5946 / 20000\n",
      "gradient norm: 0.10225260793231428, minimum ratio: 2.5289473684210524\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 5947 / 20000\n",
      "gradient norm: 0.04572179257229436, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 5948 / 20000\n",
      "gradient norm: 0.06749452470103279, minimum ratio: 2.507894736842105\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 5949 / 20000\n",
      "gradient norm: 0.05030480623827316, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 5950 / 20000\n",
      "gradient norm: 0.06480362490401603, minimum ratio: 2.494736842105263\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 5951 / 20000\n",
      "gradient norm: 0.047974262037314475, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 5952 / 20000\n",
      "gradient norm: 0.08070091268746182, minimum ratio: 2.507894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 5953 / 20000\n",
      "gradient norm: 0.09047800675034523, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 5954 / 20000\n",
      "gradient norm: 0.059790664628962986, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 5955 / 20000\n",
      "gradient norm: 0.056219035817775875, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 5956 / 20000\n",
      "gradient norm: 0.06658375874394551, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 5957 / 20000\n",
      "gradient norm: 0.07864996569696814, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 5958 / 20000\n",
      "gradient norm: 0.10362949763657525, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 5959 / 20000\n",
      "gradient norm: 0.045666394056752324, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 5960 / 20000\n",
      "gradient norm: 0.10573309974279255, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 5961 / 20000\n",
      "gradient norm: 0.1048672974575311, minimum ratio: 2.5236842105263158\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 5962 / 20000\n",
      "gradient norm: 0.04266096948413178, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 5963 / 20000\n",
      "gradient norm: 0.08450833725510165, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 5964 / 20000\n",
      "gradient norm: 0.06128640568931587, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 5965 / 20000\n",
      "gradient norm: 0.07797304767882451, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 5966 / 20000\n",
      "gradient norm: 0.07289894767745864, minimum ratio: 2.4894736842105267\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 5967 / 20000\n",
      "gradient norm: 0.03583596838871017, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 5968 / 20000\n",
      "gradient norm: 0.042777981179824565, minimum ratio: 2.4868421052631575\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 5969 / 20000\n",
      "gradient norm: 0.04340505678555928, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 5970 / 20000\n",
      "gradient norm: 0.07143822222133167, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 5971 / 20000\n",
      "gradient norm: 0.03891997117898427, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 5972 / 20000\n",
      "gradient norm: 0.07422428263816983, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 5973 / 20000\n",
      "gradient norm: 0.0492377374030184, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00565\n",
      "\tval loss: 0.00552\n",
      "epoch 5974 / 20000\n",
      "gradient norm: 0.17012003692798316, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00551\n",
      "epoch 5975 / 20000\n",
      "gradient norm: 0.04307806849828921, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00555\n",
      "epoch 5976 / 20000\n",
      "gradient norm: 0.08611731312703341, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 5977 / 20000\n",
      "gradient norm: 0.04940570771577768, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 5978 / 20000\n",
      "gradient norm: 0.0947752445936203, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 5979 / 20000\n",
      "gradient norm: 0.04449429179658182, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00555\n",
      "epoch 5980 / 20000\n",
      "gradient norm: 0.10694775986485183, minimum ratio: 2.5184210526315787\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 5981 / 20000\n",
      "gradient norm: 0.05290263710776344, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 5982 / 20000\n",
      "gradient norm: 0.08225029427558184, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 5983 / 20000\n",
      "gradient norm: 0.07426469237543643, minimum ratio: 2.518421052631579\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 5984 / 20000\n",
      "gradient norm: 0.058752368204295635, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 5985 / 20000\n",
      "gradient norm: 0.09911273705074564, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 5986 / 20000\n",
      "gradient norm: 0.05254548287484795, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00551\n",
      "epoch 5987 / 20000\n",
      "gradient norm: 0.02572129924374167, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 5988 / 20000\n",
      "gradient norm: 0.05718944006366655, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 5989 / 20000\n",
      "gradient norm: 0.05624112699297257, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 5990 / 20000\n",
      "gradient norm: 0.05200060660718009, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 5991 / 20000\n",
      "gradient norm: 0.10612434198264964, minimum ratio: 2.4842105263157896\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 5992 / 20000\n",
      "gradient norm: 0.0876989116659388, minimum ratio: 2.492105263157895\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 5993 / 20000\n",
      "gradient norm: 0.10171316587366164, minimum ratio: 2.489473684210526\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 5994 / 20000\n",
      "gradient norm: 0.13782325750798918, minimum ratio: 2.4842105263157896\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 5995 / 20000\n",
      "gradient norm: 0.1192516164155677, minimum ratio: 2.4894736842105267\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 5996 / 20000\n",
      "gradient norm: 0.02225417514273431, minimum ratio: 2.4842105263157896\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 5997 / 20000\n",
      "gradient norm: 0.07713594019878656, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 5998 / 20000\n",
      "gradient norm: 0.04598937195260078, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 5999 / 20000\n",
      "gradient norm: 0.09421538363676518, minimum ratio: 2.489473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 6000 / 20000\n",
      "gradient norm: 0.047594453615602106, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 6001 / 20000\n",
      "gradient norm: 0.08389059768524021, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 6002 / 20000\n",
      "gradient norm: 0.1266188840381801, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 6003 / 20000\n",
      "gradient norm: 0.08108191809151322, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 6004 / 20000\n",
      "gradient norm: 0.05318204342620447, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 6005 / 20000\n",
      "gradient norm: 0.07794397900579497, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 6006 / 20000\n",
      "gradient norm: 0.09491115162381902, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 6007 / 20000\n",
      "gradient norm: 0.0643290267616976, minimum ratio: 2.492105263157895\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 6008 / 20000\n",
      "gradient norm: 0.1078080921433866, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 6009 / 20000\n",
      "gradient norm: 0.10854465764714405, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00555\n",
      "epoch 6010 / 20000\n",
      "gradient norm: 0.09536482678959146, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6011 / 20000\n",
      "gradient norm: 0.06081077069393359, minimum ratio: 2.492105263157895\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 6012 / 20000\n",
      "gradient norm: 0.03319755975098815, minimum ratio: 2.518421052631579\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 6013 / 20000\n",
      "gradient norm: 0.05454600614029914, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00553\n",
      "epoch 6014 / 20000\n",
      "gradient norm: 0.08057945978362113, minimum ratio: 2.4868421052631575\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 6015 / 20000\n",
      "gradient norm: 0.07335020080790855, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 6016 / 20000\n",
      "gradient norm: 0.033861873438581824, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 6017 / 20000\n",
      "gradient norm: 0.029750542555120774, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6018 / 20000\n",
      "gradient norm: 0.09002503653755412, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 6019 / 20000\n",
      "gradient norm: 0.047096656751818955, minimum ratio: 2.5210526315789474\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 6020 / 20000\n",
      "gradient norm: 0.05566380498930812, minimum ratio: 2.4842105263157896\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 6021 / 20000\n",
      "gradient norm: 0.09845825808588415, minimum ratio: 2.5236842105263158\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 6022 / 20000\n",
      "gradient norm: 0.07770405139308423, minimum ratio: 2.5157894736842104\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00551\n",
      "epoch 6023 / 20000\n",
      "gradient norm: 0.08495670510455966, minimum ratio: 2.478947368421053\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 6024 / 20000\n",
      "gradient norm: 0.0804336293367669, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6025 / 20000\n",
      "gradient norm: 0.0353085240785731, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 6026 / 20000\n",
      "gradient norm: 0.09620549023384228, minimum ratio: 2.4842105263157896\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6027 / 20000\n",
      "gradient norm: 0.06388761551352218, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 6028 / 20000\n",
      "gradient norm: 0.042084366839844733, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6029 / 20000\n",
      "gradient norm: 0.044806676523876376, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6030 / 20000\n",
      "gradient norm: 0.10564084886573255, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 6031 / 20000\n",
      "gradient norm: 0.05073748290305957, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 6032 / 20000\n",
      "gradient norm: 0.07474258117144927, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6033 / 20000\n",
      "gradient norm: 0.0776732255180832, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 6034 / 20000\n",
      "gradient norm: 0.08127637405414134, minimum ratio: 2.5157894736842104\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 6035 / 20000\n",
      "gradient norm: 0.02522171614691615, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6036 / 20000\n",
      "gradient norm: 0.05563489947235212, minimum ratio: 2.4973684210526312\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00554\n",
      "epoch 6037 / 20000\n",
      "gradient norm: 0.06928082508966327, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 6038 / 20000\n",
      "gradient norm: 0.0902798562310636, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 6039 / 20000\n",
      "gradient norm: 0.029568614656454884, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 6040 / 20000\n",
      "gradient norm: 0.05808530596550554, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 6041 / 20000\n",
      "gradient norm: 0.03496392420493066, minimum ratio: 2.5105263157894737\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 6042 / 20000\n",
      "gradient norm: 0.10907381284050643, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 6043 / 20000\n",
      "gradient norm: 0.05050109513103962, minimum ratio: 2.5210526315789474\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 6044 / 20000\n",
      "gradient norm: 0.0863976888358593, minimum ratio: 2.5105263157894733\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00555\n",
      "epoch 6045 / 20000\n",
      "gradient norm: 0.06660832927445881, minimum ratio: 2.5184210526315787\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 6046 / 20000\n",
      "gradient norm: 0.06197730387793854, minimum ratio: 2.492105263157895\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 6047 / 20000\n",
      "gradient norm: 0.03216564925969578, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00554\n",
      "epoch 6048 / 20000\n",
      "gradient norm: 0.042965694272425026, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 6049 / 20000\n",
      "gradient norm: 0.0905006984830834, minimum ratio: 2.4815789473684213\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 6050 / 20000\n",
      "gradient norm: 0.07835752196842805, minimum ratio: 2.492105263157895\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 6051 / 20000\n",
      "gradient norm: 0.06197062024148181, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6052 / 20000\n",
      "gradient norm: 0.04135143320308998, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 6053 / 20000\n",
      "gradient norm: 0.07152842910727486, minimum ratio: 2.5078947368421054\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 6054 / 20000\n",
      "gradient norm: 0.07782951259287074, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 6055 / 20000\n",
      "gradient norm: 0.10619277323712595, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 6056 / 20000\n",
      "gradient norm: 0.07749607705045491, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 6057 / 20000\n",
      "gradient norm: 0.07046454027295113, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 6058 / 20000\n",
      "gradient norm: 0.08046329987701029, minimum ratio: 2.507894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 6059 / 20000\n",
      "gradient norm: 0.12513678963296115, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 6060 / 20000\n",
      "gradient norm: 0.06027822365285829, minimum ratio: 2.5105263157894737\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00554\n",
      "epoch 6061 / 20000\n",
      "gradient norm: 0.08192963525652885, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 6062 / 20000\n",
      "gradient norm: 0.11276861483929679, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 6063 / 20000\n",
      "gradient norm: 0.09339733619708568, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6064 / 20000\n",
      "gradient norm: 0.0769843301968649, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 6065 / 20000\n",
      "gradient norm: 0.08897187979891896, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 6066 / 20000\n",
      "gradient norm: 0.052352351282024756, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00551\n",
      "epoch 6067 / 20000\n",
      "gradient norm: 0.04685247811721638, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6068 / 20000\n",
      "gradient norm: 0.05374286917503923, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6069 / 20000\n",
      "gradient norm: 0.05013585517008323, minimum ratio: 2.4868421052631575\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 6070 / 20000\n",
      "gradient norm: 0.019993439622339793, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 6071 / 20000\n",
      "gradient norm: 0.03717038605827838, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 6072 / 20000\n",
      "gradient norm: 0.08553356683114544, minimum ratio: 2.505263157894737\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 6073 / 20000\n",
      "gradient norm: 0.03315902128815651, minimum ratio: 2.4868421052631584\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00554\n",
      "epoch 6074 / 20000\n",
      "gradient norm: 0.04187239398015663, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6075 / 20000\n",
      "gradient norm: 0.048591556180326734, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 6076 / 20000\n",
      "gradient norm: 0.038842846697662026, minimum ratio: 2.4736842105263155\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 6077 / 20000\n",
      "gradient norm: 0.040176285488996655, minimum ratio: 2.4868421052631575\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6078 / 20000\n",
      "gradient norm: 0.06100316750234924, minimum ratio: 2.5078947368421054\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 6079 / 20000\n",
      "gradient norm: 0.11064330191584304, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 6080 / 20000\n",
      "gradient norm: 0.054572002351051196, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 6081 / 20000\n",
      "gradient norm: 0.1157810635631904, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 6082 / 20000\n",
      "gradient norm: 0.061225710684084333, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6083 / 20000\n",
      "gradient norm: 0.07393836037954316, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 6084 / 20000\n",
      "gradient norm: 0.032334717572666705, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 6085 / 20000\n",
      "gradient norm: 0.09466134512331337, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 6086 / 20000\n",
      "gradient norm: 0.0979668760264758, minimum ratio: 2.5210526315789474\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00555\n",
      "epoch 6087 / 20000\n",
      "gradient norm: 0.061647245776839554, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6088 / 20000\n",
      "gradient norm: 0.061270562116988, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 6089 / 20000\n",
      "gradient norm: 0.10687794885598123, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 6090 / 20000\n",
      "gradient norm: 0.04915619918028824, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6091 / 20000\n",
      "gradient norm: 0.06586072675418109, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 6092 / 20000\n",
      "gradient norm: 0.08551428618375212, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 6093 / 20000\n",
      "gradient norm: 0.04442890905193053, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 6094 / 20000\n",
      "gradient norm: 0.08807061158586293, minimum ratio: 2.5105263157894737\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 6095 / 20000\n",
      "gradient norm: 0.03920691859093495, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 6096 / 20000\n",
      "gradient norm: 0.06833833985729143, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 6097 / 20000\n",
      "gradient norm: 0.05862351818359457, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 6098 / 20000\n",
      "gradient norm: 0.1063098309095949, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 6099 / 20000\n",
      "gradient norm: 0.08379340230021626, minimum ratio: 2.4868421052631575\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 6100 / 20000\n",
      "gradient norm: 0.08859975927043706, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 6101 / 20000\n",
      "gradient norm: 0.057439945347141474, minimum ratio: 2.5105263157894733\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6102 / 20000\n",
      "gradient norm: 0.04911852671648376, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00554\n",
      "epoch 6103 / 20000\n",
      "gradient norm: 0.07833966775797307, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6104 / 20000\n",
      "gradient norm: 0.11911778891226277, minimum ratio: 2.515789473684211\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 6105 / 20000\n",
      "gradient norm: 0.028902004210976884, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 6106 / 20000\n",
      "gradient norm: 0.07227958226576447, minimum ratio: 2.507894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 6107 / 20000\n",
      "gradient norm: 0.027972104580840096, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6108 / 20000\n",
      "gradient norm: 0.11874703480862081, minimum ratio: 2.494736842105263\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 6109 / 20000\n",
      "gradient norm: 0.034356786956777796, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 6110 / 20000\n",
      "gradient norm: 0.10120026674121618, minimum ratio: 2.5131578947368416\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00555\n",
      "epoch 6111 / 20000\n",
      "gradient norm: 0.06760920549277216, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 6112 / 20000\n",
      "gradient norm: 0.08228294865693897, minimum ratio: 2.4868421052631575\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6113 / 20000\n",
      "gradient norm: 0.13228041271213442, minimum ratio: 2.5105263157894737\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 6114 / 20000\n",
      "gradient norm: 0.08785808767424896, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00552\n",
      "epoch 6115 / 20000\n",
      "gradient norm: 0.0377080382022541, minimum ratio: 2.4842105263157896\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 6116 / 20000\n",
      "gradient norm: 0.11264471744652838, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6117 / 20000\n",
      "gradient norm: 0.059111055117682554, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 6118 / 20000\n",
      "gradient norm: 0.06013747910037637, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 6119 / 20000\n",
      "gradient norm: 0.03146517364803003, minimum ratio: 2.507894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 6120 / 20000\n",
      "gradient norm: 0.044755411392543465, minimum ratio: 2.5105263157894733\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 6121 / 20000\n",
      "gradient norm: 0.06242303448379971, minimum ratio: 2.51578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 6122 / 20000\n",
      "gradient norm: 0.03684141839039512, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6123 / 20000\n",
      "gradient norm: 0.06416591798188165, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6124 / 20000\n",
      "gradient norm: 0.054177113343030214, minimum ratio: 2.507894736842105\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 6125 / 20000\n",
      "gradient norm: 0.08577109914040193, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 6126 / 20000\n",
      "gradient norm: 0.025633582590671722, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6127 / 20000\n",
      "gradient norm: 0.046273088111774996, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 6128 / 20000\n",
      "gradient norm: 0.027530981355084805, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 6129 / 20000\n",
      "gradient norm: 0.07248020422412083, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 6130 / 20000\n",
      "gradient norm: 0.059395659976871684, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 6131 / 20000\n",
      "gradient norm: 0.04853198883938603, minimum ratio: 2.513157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 6132 / 20000\n",
      "gradient norm: 0.046800683965557255, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6133 / 20000\n",
      "gradient norm: 0.05941243740380742, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6134 / 20000\n",
      "gradient norm: 0.052248124789912254, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 6135 / 20000\n",
      "gradient norm: 0.055663304796325974, minimum ratio: 2.5236842105263158\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 6136 / 20000\n",
      "gradient norm: 0.03405771047982853, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 6137 / 20000\n",
      "gradient norm: 0.04127660508675035, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 6138 / 20000\n",
      "gradient norm: 0.09294445987325162, minimum ratio: 2.4842105263157896\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6139 / 20000\n",
      "gradient norm: 0.07149936963105574, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 6140 / 20000\n",
      "gradient norm: 0.051677320821909234, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6141 / 20000\n",
      "gradient norm: 0.10514256556052715, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 6142 / 20000\n",
      "gradient norm: 0.05370486376341432, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 6143 / 20000\n",
      "gradient norm: 0.09863832755945623, minimum ratio: 2.4842105263157896\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 6144 / 20000\n",
      "gradient norm: 0.051459654700011015, minimum ratio: 2.4894736842105267\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 6145 / 20000\n",
      "gradient norm: 0.123890278453473, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6146 / 20000\n",
      "gradient norm: 0.055038200720446184, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 6147 / 20000\n",
      "gradient norm: 0.056370340716966894, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 6148 / 20000\n",
      "gradient norm: 0.05007849756657379, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6149 / 20000\n",
      "gradient norm: 0.038723538658814505, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 6150 / 20000\n",
      "gradient norm: 0.026027257728856057, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 6151 / 20000\n",
      "gradient norm: 0.08887953858356923, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 6152 / 20000\n",
      "gradient norm: 0.09962723718490452, minimum ratio: 2.4894736842105267\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 6153 / 20000\n",
      "gradient norm: 0.026978074412909336, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 6154 / 20000\n",
      "gradient norm: 0.048004362848587334, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 6155 / 20000\n",
      "gradient norm: 0.06812408921541646, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6156 / 20000\n",
      "gradient norm: 0.03831025068939198, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 6157 / 20000\n",
      "gradient norm: 0.10533673560712487, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 6158 / 20000\n",
      "gradient norm: 0.12772740941727534, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 6159 / 20000\n",
      "gradient norm: 0.0650752286601346, minimum ratio: 2.4868421052631575\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 6160 / 20000\n",
      "gradient norm: 0.05389300885144621, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 6161 / 20000\n",
      "gradient norm: 0.059617765771690756, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6162 / 20000\n",
      "gradient norm: 0.09267173043917865, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 6163 / 20000\n",
      "gradient norm: 0.06184450988075696, minimum ratio: 2.4736842105263155\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 6164 / 20000\n",
      "gradient norm: 0.057868183648679405, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00554\n",
      "epoch 6165 / 20000\n",
      "gradient norm: 0.01723879207565915, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 6166 / 20000\n",
      "gradient norm: 0.10515554796438664, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 6167 / 20000\n",
      "gradient norm: 0.06829636893235147, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6168 / 20000\n",
      "gradient norm: 0.05887105845613405, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00554\n",
      "epoch 6169 / 20000\n",
      "gradient norm: 0.11301244772039354, minimum ratio: 2.513157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 6170 / 20000\n",
      "gradient norm: 0.051418071452644654, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 6171 / 20000\n",
      "gradient norm: 0.06142235758306924, minimum ratio: 2.494736842105263\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 6172 / 20000\n",
      "gradient norm: 0.0561538394940726, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6173 / 20000\n",
      "gradient norm: 0.09549463822622783, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 6174 / 20000\n",
      "gradient norm: 0.11782604648033157, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 6175 / 20000\n",
      "gradient norm: 0.05244344398670364, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 6176 / 20000\n",
      "gradient norm: 0.09779487841296941, minimum ratio: 2.5105263157894737\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 6177 / 20000\n",
      "gradient norm: 0.06653256551362574, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 6178 / 20000\n",
      "gradient norm: 0.08713411580538377, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 6179 / 20000\n",
      "gradient norm: 0.07822708890307695, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6180 / 20000\n",
      "gradient norm: 0.08998775406507775, minimum ratio: 2.492105263157895\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00551\n",
      "epoch 6181 / 20000\n",
      "gradient norm: 0.02206269378075376, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 6182 / 20000\n",
      "gradient norm: 0.15829395106993616, minimum ratio: 2.4736842105263155\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00556\n",
      "epoch 6183 / 20000\n",
      "gradient norm: 0.07734513861942105, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00551\n",
      "epoch 6184 / 20000\n",
      "gradient norm: 0.08349930244730785, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 6185 / 20000\n",
      "gradient norm: 0.07696265896083787, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 6186 / 20000\n",
      "gradient norm: 0.04916962259449065, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 6187 / 20000\n",
      "gradient norm: 0.08757294621318579, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 6188 / 20000\n",
      "gradient norm: 0.08886043401435018, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 6189 / 20000\n",
      "gradient norm: 0.047852322401013225, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 6190 / 20000\n",
      "gradient norm: 0.05158825885155238, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 6191 / 20000\n",
      "gradient norm: 0.05491154399351217, minimum ratio: 2.4868421052631575\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 6192 / 20000\n",
      "gradient norm: 0.06723685935139656, minimum ratio: 2.4842105263157896\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6193 / 20000\n",
      "gradient norm: 0.031647286501538474, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6194 / 20000\n",
      "gradient norm: 0.0898452993715182, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 6195 / 20000\n",
      "gradient norm: 0.08609195722965524, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 6196 / 20000\n",
      "gradient norm: 0.07397707080235705, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 6197 / 20000\n",
      "gradient norm: 0.03172061391524039, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 6198 / 20000\n",
      "gradient norm: 0.07085706604993902, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 6199 / 20000\n",
      "gradient norm: 0.09364327043294907, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6200 / 20000\n",
      "gradient norm: 0.08593009348260239, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 6201 / 20000\n",
      "gradient norm: 0.1036816673586145, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 6202 / 20000\n",
      "gradient norm: 0.06790307760820724, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6203 / 20000\n",
      "gradient norm: 0.12326424708589911, minimum ratio: 2.46578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6204 / 20000\n",
      "gradient norm: 0.04268422917812131, minimum ratio: 2.494736842105263\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6205 / 20000\n",
      "gradient norm: 0.10555742616998032, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6206 / 20000\n",
      "gradient norm: 0.04033048401470296, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 6207 / 20000\n",
      "gradient norm: 0.032780393346911296, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 6208 / 20000\n",
      "gradient norm: 0.08029399829683825, minimum ratio: 2.489473684210526\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 6209 / 20000\n",
      "gradient norm: 0.05084854568121955, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 6210 / 20000\n",
      "gradient norm: 0.02339898496575188, minimum ratio: 2.507894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 6211 / 20000\n",
      "gradient norm: 0.07383122522151098, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6212 / 20000\n",
      "gradient norm: 0.027076318743638694, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 6213 / 20000\n",
      "gradient norm: 0.05995595426065847, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 6214 / 20000\n",
      "gradient norm: 0.08928196545457467, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6215 / 20000\n",
      "gradient norm: 0.06062263308558613, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 6216 / 20000\n",
      "gradient norm: 0.04371977486880496, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6217 / 20000\n",
      "gradient norm: 0.0610753924556775, minimum ratio: 2.492105263157895\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6218 / 20000\n",
      "gradient norm: 0.06967544334474951, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6219 / 20000\n",
      "gradient norm: 0.07202893393696286, minimum ratio: 2.4868421052631575\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6220 / 20000\n",
      "gradient norm: 0.05753438879037276, minimum ratio: 2.4842105263157896\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 6221 / 20000\n",
      "gradient norm: 0.03516560931893764, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6222 / 20000\n",
      "gradient norm: 0.061252488259924576, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 6223 / 20000\n",
      "gradient norm: 0.06062441653921269, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 6224 / 20000\n",
      "gradient norm: 0.1167231451254338, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 6225 / 20000\n",
      "gradient norm: 0.028449573521356797, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 6226 / 20000\n",
      "gradient norm: 0.0706835959572345, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 6227 / 20000\n",
      "gradient norm: 0.06593834668456111, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 6228 / 20000\n",
      "gradient norm: 0.1107298587448895, minimum ratio: 2.492105263157895\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 6229 / 20000\n",
      "gradient norm: 0.06136469557532109, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 6230 / 20000\n",
      "gradient norm: 0.04009409560239874, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6231 / 20000\n",
      "gradient norm: 0.10492373240413144, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6232 / 20000\n",
      "gradient norm: 0.0589926119428128, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 6233 / 20000\n",
      "gradient norm: 0.047042400372447446, minimum ratio: 2.513157894736842\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 6234 / 20000\n",
      "gradient norm: 0.07350263267289847, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 6235 / 20000\n",
      "gradient norm: 0.08411605918081477, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 6236 / 20000\n",
      "gradient norm: 0.04382650801562704, minimum ratio: 2.494736842105263\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 6237 / 20000\n",
      "gradient norm: 0.03563614218728617, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 6238 / 20000\n",
      "gradient norm: 0.08195949659420876, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 6239 / 20000\n",
      "gradient norm: 0.08663381938822567, minimum ratio: 2.4894736842105267\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 6240 / 20000\n",
      "gradient norm: 0.058546742162434384, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6241 / 20000\n",
      "gradient norm: 0.10524482699111104, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 6242 / 20000\n",
      "gradient norm: 0.05597789020976052, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 6243 / 20000\n",
      "gradient norm: 0.07265484824893065, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 6244 / 20000\n",
      "gradient norm: 0.06440359484986402, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 6245 / 20000\n",
      "gradient norm: 0.06729181183618493, minimum ratio: 2.4894736842105267\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 6246 / 20000\n",
      "gradient norm: 0.07481484208256006, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 6247 / 20000\n",
      "gradient norm: 0.06009346101200208, minimum ratio: 2.4842105263157896\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 6248 / 20000\n",
      "gradient norm: 0.06881685432745144, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6249 / 20000\n",
      "gradient norm: 0.08546060556545854, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 6250 / 20000\n",
      "gradient norm: 0.037144708359846845, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 6251 / 20000\n",
      "gradient norm: 0.08548893209081143, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 6252 / 20000\n",
      "gradient norm: 0.09094181912951171, minimum ratio: 2.4736842105263155\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 6253 / 20000\n",
      "gradient norm: 0.0947818955173716, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 6254 / 20000\n",
      "gradient norm: 0.06357814453076571, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 6255 / 20000\n",
      "gradient norm: 0.05696202829130925, minimum ratio: 2.4894736842105267\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 6256 / 20000\n",
      "gradient norm: 0.08934969484107569, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00555\n",
      "epoch 6257 / 20000\n",
      "gradient norm: 0.09762541070813313, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 6258 / 20000\n",
      "gradient norm: 0.04181744718516711, minimum ratio: 2.507894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6259 / 20000\n",
      "gradient norm: 0.03845474330591969, minimum ratio: 2.492105263157895\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6260 / 20000\n",
      "gradient norm: 0.03979175115819089, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 6261 / 20000\n",
      "gradient norm: 0.13683796033728868, minimum ratio: 2.489473684210526\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 6262 / 20000\n",
      "gradient norm: 0.0526107320911251, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 6263 / 20000\n",
      "gradient norm: 0.06907266008784063, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 6264 / 20000\n",
      "gradient norm: 0.13688006694428623, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00555\n",
      "epoch 6265 / 20000\n",
      "gradient norm: 0.11435798287857324, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00565\n",
      "\tval loss: 0.00552\n",
      "epoch 6266 / 20000\n",
      "gradient norm: 0.1266229711472988, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 6267 / 20000\n",
      "gradient norm: 0.09289062255993485, minimum ratio: 2.507894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 6268 / 20000\n",
      "gradient norm: 0.058768143178895116, minimum ratio: 2.4894736842105267\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 6269 / 20000\n",
      "gradient norm: 0.0738490068615647, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 6270 / 20000\n",
      "gradient norm: 0.07606000278610736, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 6271 / 20000\n",
      "gradient norm: 0.04351010630489327, minimum ratio: 2.5105263157894737\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 6272 / 20000\n",
      "gradient norm: 0.05570424618781544, minimum ratio: 2.5105263157894737\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 6273 / 20000\n",
      "gradient norm: 0.056965970929013565, minimum ratio: 2.518421052631579\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6274 / 20000\n",
      "gradient norm: 0.09698008513078094, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6275 / 20000\n",
      "gradient norm: 0.12553195271175355, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 6276 / 20000\n",
      "gradient norm: 0.07650838895642664, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00551\n",
      "epoch 6277 / 20000\n",
      "gradient norm: 0.10090048349229619, minimum ratio: 2.460526315789474\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 6278 / 20000\n",
      "gradient norm: 0.05476018771878444, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6279 / 20000\n",
      "gradient norm: 0.08633464123704471, minimum ratio: 2.5078947368421054\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 6280 / 20000\n",
      "gradient norm: 0.08573346410412341, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6281 / 20000\n",
      "gradient norm: 0.04870471986941993, minimum ratio: 2.492105263157895\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 6282 / 20000\n",
      "gradient norm: 0.0328969023830723, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6283 / 20000\n",
      "gradient norm: 0.07971872226335108, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 6284 / 20000\n",
      "gradient norm: 0.06036771016079001, minimum ratio: 2.4842105263157896\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 6285 / 20000\n",
      "gradient norm: 0.04993658361490816, minimum ratio: 2.5105263157894733\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 6286 / 20000\n",
      "gradient norm: 0.05424573872005567, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 6287 / 20000\n",
      "gradient norm: 0.04434778698487207, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6288 / 20000\n",
      "gradient norm: 0.060677701330860145, minimum ratio: 2.515789473684211\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 6289 / 20000\n",
      "gradient norm: 0.06052946750423871, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00565\n",
      "\tval loss: 0.00551\n",
      "epoch 6290 / 20000\n",
      "gradient norm: 0.08843326399801299, minimum ratio: 2.4842105263157896\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 6291 / 20000\n",
      "gradient norm: 0.09404990845359862, minimum ratio: 2.5105263157894737\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 6292 / 20000\n",
      "gradient norm: 0.07463646132964641, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00554\n",
      "epoch 6293 / 20000\n",
      "gradient norm: 0.12094859567878302, minimum ratio: 2.4973684210526312\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 6294 / 20000\n",
      "gradient norm: 0.06240998941939324, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 6295 / 20000\n",
      "gradient norm: 0.03046657007507747, minimum ratio: 2.4868421052631575\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 6296 / 20000\n",
      "gradient norm: 0.0506909750693012, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 6297 / 20000\n",
      "gradient norm: 0.03266093891579658, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00552\n",
      "epoch 6298 / 20000\n",
      "gradient norm: 0.10279625095427036, minimum ratio: 2.494736842105263\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 6299 / 20000\n",
      "gradient norm: 0.05548293184256181, minimum ratio: 2.4868421052631575\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 6300 / 20000\n",
      "gradient norm: 0.1065755031304434, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 6301 / 20000\n",
      "gradient norm: 0.05873839871492237, minimum ratio: 2.5131578947368425\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 6302 / 20000\n",
      "gradient norm: 0.07071640877984464, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6303 / 20000\n",
      "gradient norm: 0.0555931942362804, minimum ratio: 2.5105263157894733\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 6304 / 20000\n",
      "gradient norm: 0.049054558272473514, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6305 / 20000\n",
      "gradient norm: 0.11045351281063631, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 6306 / 20000\n",
      "gradient norm: 0.08630972256651148, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00553\n",
      "epoch 6307 / 20000\n",
      "gradient norm: 0.07338211560272612, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00553\n",
      "epoch 6308 / 20000\n",
      "gradient norm: 0.06045853783143684, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 6309 / 20000\n",
      "gradient norm: 0.07710079694516025, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00553\n",
      "epoch 6310 / 20000\n",
      "gradient norm: 0.17060951283201575, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 6311 / 20000\n",
      "gradient norm: 0.10744468739721924, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00551\n",
      "epoch 6312 / 20000\n",
      "gradient norm: 0.09584960242500529, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 6313 / 20000\n",
      "gradient norm: 0.07560751622077078, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 6314 / 20000\n",
      "gradient norm: 0.04806667604134418, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6315 / 20000\n",
      "gradient norm: 0.10148173838388175, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 6316 / 20000\n",
      "gradient norm: 0.049879202037118375, minimum ratio: 2.5105263157894737\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 6317 / 20000\n",
      "gradient norm: 0.05988913931651041, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 6318 / 20000\n",
      "gradient norm: 0.11295328254345804, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 6319 / 20000\n",
      "gradient norm: 0.05367243905493524, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 6320 / 20000\n",
      "gradient norm: 0.08814716234337538, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6321 / 20000\n",
      "gradient norm: 0.06308299652300775, minimum ratio: 2.492105263157895\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 6322 / 20000\n",
      "gradient norm: 0.019009658048162237, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 6323 / 20000\n",
      "gradient norm: 0.04329613017034717, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 6324 / 20000\n",
      "gradient norm: 0.06265866273315623, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6325 / 20000\n",
      "gradient norm: 0.0473862787039252, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 6326 / 20000\n",
      "gradient norm: 0.07046598952729255, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6327 / 20000\n",
      "gradient norm: 0.0908417190075852, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 6328 / 20000\n",
      "gradient norm: 0.038044613917008974, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 6329 / 20000\n",
      "gradient norm: 0.06126769265392795, minimum ratio: 2.4868421052631575\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6330 / 20000\n",
      "gradient norm: 0.12993222894147038, minimum ratio: 2.492105263157895\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 6331 / 20000\n",
      "gradient norm: 0.04311078062164597, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 6332 / 20000\n",
      "gradient norm: 0.0788365340558812, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 6333 / 20000\n",
      "gradient norm: 0.044555494489031844, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6334 / 20000\n",
      "gradient norm: 0.06426797428866848, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 6335 / 20000\n",
      "gradient norm: 0.0817905455478467, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 6336 / 20000\n",
      "gradient norm: 0.06267999560805038, minimum ratio: 2.4842105263157896\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 6337 / 20000\n",
      "gradient norm: 0.036283011722844094, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 6338 / 20000\n",
      "gradient norm: 0.10028160357614979, minimum ratio: 2.492105263157895\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 6339 / 20000\n",
      "gradient norm: 0.12340582790784538, minimum ratio: 2.4868421052631575\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 6340 / 20000\n",
      "gradient norm: 0.06611801136750728, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 6341 / 20000\n",
      "gradient norm: 0.04987799050286412, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 6342 / 20000\n",
      "gradient norm: 0.10543988761492074, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6343 / 20000\n",
      "gradient norm: 0.02956542260653805, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 6344 / 20000\n",
      "gradient norm: 0.0784559368621558, minimum ratio: 2.4868421052631575\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6345 / 20000\n",
      "gradient norm: 0.05331034667324275, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 6346 / 20000\n",
      "gradient norm: 0.0679931792546995, minimum ratio: 2.4894736842105267\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 6347 / 20000\n",
      "gradient norm: 0.09655168815515935, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 6348 / 20000\n",
      "gradient norm: 0.03990710408288578, minimum ratio: 2.492105263157895\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6349 / 20000\n",
      "gradient norm: 0.10608760896138847, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 6350 / 20000\n",
      "gradient norm: 0.052031210012501106, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 6351 / 20000\n",
      "gradient norm: 0.10427113715559244, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 6352 / 20000\n",
      "gradient norm: 0.09665654000127688, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00555\n",
      "epoch 6353 / 20000\n",
      "gradient norm: 0.07503937953151762, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 6354 / 20000\n",
      "gradient norm: 0.06511648267041892, minimum ratio: 2.465789473684211\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 6355 / 20000\n",
      "gradient norm: 0.05510338518070057, minimum ratio: 2.4868421052631575\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 6356 / 20000\n",
      "gradient norm: 0.07194403023459017, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00554\n",
      "epoch 6357 / 20000\n",
      "gradient norm: 0.05480621356400661, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6358 / 20000\n",
      "gradient norm: 0.06201405415777117, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 6359 / 20000\n",
      "gradient norm: 0.05381763685727492, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 6360 / 20000\n",
      "gradient norm: 0.03838856994480011, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00553\n",
      "epoch 6361 / 20000\n",
      "gradient norm: 0.026256969285896048, minimum ratio: 2.4868421052631575\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6362 / 20000\n",
      "gradient norm: 0.08469025138765574, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 6363 / 20000\n",
      "gradient norm: 0.07412805058993399, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6364 / 20000\n",
      "gradient norm: 0.10262179613346234, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00551\n",
      "epoch 6365 / 20000\n",
      "gradient norm: 0.05577568046282977, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 6366 / 20000\n",
      "gradient norm: 0.08115481794811785, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 6367 / 20000\n",
      "gradient norm: 0.07061924342997372, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 6368 / 20000\n",
      "gradient norm: 0.12382542330306023, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 6369 / 20000\n",
      "gradient norm: 0.13839615415781736, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00555\n",
      "epoch 6370 / 20000\n",
      "gradient norm: 0.0504136206000112, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6371 / 20000\n",
      "gradient norm: 0.08205832471139729, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 6372 / 20000\n",
      "gradient norm: 0.052101102148299105, minimum ratio: 2.5105263157894737\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 6373 / 20000\n",
      "gradient norm: 0.10151609894819558, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6374 / 20000\n",
      "gradient norm: 0.037768269787193276, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 6375 / 20000\n",
      "gradient norm: 0.06744134274777025, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 6376 / 20000\n",
      "gradient norm: 0.06246604351326823, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00554\n",
      "epoch 6377 / 20000\n",
      "gradient norm: 0.07327260618330911, minimum ratio: 2.492105263157895\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 6378 / 20000\n",
      "gradient norm: 0.03725420474074781, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6379 / 20000\n",
      "gradient norm: 0.043488881638040766, minimum ratio: 2.4868421052631575\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 6380 / 20000\n",
      "gradient norm: 0.02484481083229184, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6381 / 20000\n",
      "gradient norm: 0.09394420456374064, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 6382 / 20000\n",
      "gradient norm: 0.02857616474648239, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 6383 / 20000\n",
      "gradient norm: 0.08871929941233248, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 6384 / 20000\n",
      "gradient norm: 0.055746999438269995, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00551\n",
      "epoch 6385 / 20000\n",
      "gradient norm: 0.0647252582712099, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 6386 / 20000\n",
      "gradient norm: 0.061259993381099775, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 6387 / 20000\n",
      "gradient norm: 0.07289621150994208, minimum ratio: 2.507894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 6388 / 20000\n",
      "gradient norm: 0.04441051825415343, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 6389 / 20000\n",
      "gradient norm: 0.051688883191673085, minimum ratio: 2.492105263157895\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 6390 / 20000\n",
      "gradient norm: 0.11292406031861901, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 6391 / 20000\n",
      "gradient norm: 0.08102103404235095, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 6392 / 20000\n",
      "gradient norm: 0.03544022796268109, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 6393 / 20000\n",
      "gradient norm: 0.07909035321790725, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6394 / 20000\n",
      "gradient norm: 0.06338485988089815, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 6395 / 20000\n",
      "gradient norm: 0.046087797556538135, minimum ratio: 2.4868421052631575\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 6396 / 20000\n",
      "gradient norm: 0.02687953453278169, minimum ratio: 2.5210526315789474\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 6397 / 20000\n",
      "gradient norm: 0.07853087497642264, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6398 / 20000\n",
      "gradient norm: 0.04202579613047419, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 6399 / 20000\n",
      "gradient norm: 0.10056537167110946, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 6400 / 20000\n",
      "gradient norm: 0.1071351352147758, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00553\n",
      "epoch 6401 / 20000\n",
      "gradient norm: 0.13277087511960417, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 6402 / 20000\n",
      "gradient norm: 0.07797561842016876, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 6403 / 20000\n",
      "gradient norm: 0.0739764227764681, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 6404 / 20000\n",
      "gradient norm: 0.10248912457609549, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00555\n",
      "epoch 6405 / 20000\n",
      "gradient norm: 0.06725416594417766, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 6406 / 20000\n",
      "gradient norm: 0.09630760143045336, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00551\n",
      "epoch 6407 / 20000\n",
      "gradient norm: 0.11281018395675346, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 6408 / 20000\n",
      "gradient norm: 0.058056983980350196, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 6409 / 20000\n",
      "gradient norm: 0.0970929876784794, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 6410 / 20000\n",
      "gradient norm: 0.08013003339874558, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 6411 / 20000\n",
      "gradient norm: 0.10073500347789377, minimum ratio: 2.465789473684211\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00551\n",
      "epoch 6412 / 20000\n",
      "gradient norm: 0.06726057612104341, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 6413 / 20000\n",
      "gradient norm: 0.05243451471324079, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 6414 / 20000\n",
      "gradient norm: 0.0472484600613825, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 6415 / 20000\n",
      "gradient norm: 0.11215042386902496, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6416 / 20000\n",
      "gradient norm: 0.05218296934617683, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 6417 / 20000\n",
      "gradient norm: 0.05596456390048843, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 6418 / 20000\n",
      "gradient norm: 0.05798722751205787, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6419 / 20000\n",
      "gradient norm: 0.06455785926664248, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6420 / 20000\n",
      "gradient norm: 0.10467503103427589, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 6421 / 20000\n",
      "gradient norm: 0.05558444178313948, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 6422 / 20000\n",
      "gradient norm: 0.08030278398655355, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 6423 / 20000\n",
      "gradient norm: 0.16405932628549635, minimum ratio: 2.465789473684211\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00556\n",
      "epoch 6424 / 20000\n",
      "gradient norm: 0.0318209178512916, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 6425 / 20000\n",
      "gradient norm: 0.05692317176726647, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 6426 / 20000\n",
      "gradient norm: 0.05378921137889847, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 6427 / 20000\n",
      "gradient norm: 0.027181453857338056, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 6428 / 20000\n",
      "gradient norm: 0.05011296443990432, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6429 / 20000\n",
      "gradient norm: 0.10603626084048301, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00551\n",
      "epoch 6430 / 20000\n",
      "gradient norm: 0.06868019097601064, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 6431 / 20000\n",
      "gradient norm: 0.11858816049061716, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 6432 / 20000\n",
      "gradient norm: 0.11901467619463801, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 6433 / 20000\n",
      "gradient norm: 0.04476469561632257, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 6434 / 20000\n",
      "gradient norm: 0.07755546708358452, minimum ratio: 2.46578947368421\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 6435 / 20000\n",
      "gradient norm: 0.08736238483106717, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 6436 / 20000\n",
      "gradient norm: 0.10332525457488373, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6437 / 20000\n",
      "gradient norm: 0.09522280696546659, minimum ratio: 2.4868421052631575\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 6438 / 20000\n",
      "gradient norm: 0.03401798651611898, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 6439 / 20000\n",
      "gradient norm: 0.049295024859020486, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 6440 / 20000\n",
      "gradient norm: 0.08441152202431113, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 6441 / 20000\n",
      "gradient norm: 0.09003632079111412, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 6442 / 20000\n",
      "gradient norm: 0.08429797145072371, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 6443 / 20000\n",
      "gradient norm: 0.08902824873803183, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00555\n",
      "epoch 6444 / 20000\n",
      "gradient norm: 0.0536687379644718, minimum ratio: 2.518421052631579\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 6445 / 20000\n",
      "gradient norm: 0.07989463699050248, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 6446 / 20000\n",
      "gradient norm: 0.05127225269097835, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 6447 / 20000\n",
      "gradient norm: 0.1054634100291878, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 6448 / 20000\n",
      "gradient norm: 0.028692403036984615, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 6449 / 20000\n",
      "gradient norm: 0.07448298303643242, minimum ratio: 2.4868421052631575\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 6450 / 20000\n",
      "gradient norm: 0.05172856114222668, minimum ratio: 2.492105263157895\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00554\n",
      "epoch 6451 / 20000\n",
      "gradient norm: 0.08582840093004052, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6452 / 20000\n",
      "gradient norm: 0.049381384276784956, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6453 / 20000\n",
      "gradient norm: 0.13247705351386685, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 6454 / 20000\n",
      "gradient norm: 0.07881743116740836, minimum ratio: 2.5105263157894733\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 6455 / 20000\n",
      "gradient norm: 0.08657204144401476, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 6456 / 20000\n",
      "gradient norm: 0.03468758726376109, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6457 / 20000\n",
      "gradient norm: 0.10606614639982581, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 6458 / 20000\n",
      "gradient norm: 0.05114338602288626, minimum ratio: 2.5078947368421054\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 6459 / 20000\n",
      "gradient norm: 0.0708535275189206, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 6460 / 20000\n",
      "gradient norm: 0.02887132464093156, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6461 / 20000\n",
      "gradient norm: 0.04836509839515202, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 6462 / 20000\n",
      "gradient norm: 0.029842617019312456, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 6463 / 20000\n",
      "gradient norm: 0.09199921583058313, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6464 / 20000\n",
      "gradient norm: 0.05412311905820388, minimum ratio: 2.4842105263157896\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6465 / 20000\n",
      "gradient norm: 0.09686734690330923, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 6466 / 20000\n",
      "gradient norm: 0.06474094756413251, minimum ratio: 2.5078947368421054\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 6467 / 20000\n",
      "gradient norm: 0.09782245085807517, minimum ratio: 2.5105263157894737\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 6468 / 20000\n",
      "gradient norm: 0.11497037846129388, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 6469 / 20000\n",
      "gradient norm: 0.04518093148362823, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6470 / 20000\n",
      "gradient norm: 0.0554052465595305, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 6471 / 20000\n",
      "gradient norm: 0.12027839187067002, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 6472 / 20000\n",
      "gradient norm: 0.04907072614878416, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 6473 / 20000\n",
      "gradient norm: 0.054637173539958894, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 6474 / 20000\n",
      "gradient norm: 0.037332124571548775, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6475 / 20000\n",
      "gradient norm: 0.04362312146986369, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00553\n",
      "epoch 6476 / 20000\n",
      "gradient norm: 0.04946229360939469, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6477 / 20000\n",
      "gradient norm: 0.06244994237204082, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 6478 / 20000\n",
      "gradient norm: 0.051581830834038556, minimum ratio: 2.4842105263157896\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 6479 / 20000\n",
      "gradient norm: 0.061238773312652484, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 6480 / 20000\n",
      "gradient norm: 0.08522279339376837, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6481 / 20000\n",
      "gradient norm: 0.0482470152201131, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 6482 / 20000\n",
      "gradient norm: 0.06120480098252301, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6483 / 20000\n",
      "gradient norm: 0.03423331378144212, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6484 / 20000\n",
      "gradient norm: 0.013750120167969726, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6485 / 20000\n",
      "gradient norm: 0.034627052082214504, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 6486 / 20000\n",
      "gradient norm: 0.0683260282385163, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6487 / 20000\n",
      "gradient norm: 0.06930308087612502, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 6488 / 20000\n",
      "gradient norm: 0.09909627435263246, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 6489 / 20000\n",
      "gradient norm: 0.06721701766946353, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 6490 / 20000\n",
      "gradient norm: 0.0975907975807786, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 6491 / 20000\n",
      "gradient norm: 0.06333548069233075, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 6492 / 20000\n",
      "gradient norm: 0.05773027194663882, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 6493 / 20000\n",
      "gradient norm: 0.055197670895722695, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 6494 / 20000\n",
      "gradient norm: 0.06226846262870822, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 6495 / 20000\n",
      "gradient norm: 0.030496546998620033, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6496 / 20000\n",
      "gradient norm: 0.040271442936500534, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 6497 / 20000\n",
      "gradient norm: 0.06722786114551127, minimum ratio: 2.5105263157894737\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 6498 / 20000\n",
      "gradient norm: 0.047390921448823065, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 6499 / 20000\n",
      "gradient norm: 0.03355447665671818, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 6500 / 20000\n",
      "gradient norm: 0.027450267618405633, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 6501 / 20000\n",
      "gradient norm: 0.11422774102538824, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 6502 / 20000\n",
      "gradient norm: 0.07679827630636282, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6503 / 20000\n",
      "gradient norm: 0.08728325075935572, minimum ratio: 2.4842105263157896\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 6504 / 20000\n",
      "gradient norm: 0.0888557316357037, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 6505 / 20000\n",
      "gradient norm: 0.06983547852723859, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 6506 / 20000\n",
      "gradient norm: 0.07963620044756681, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 6507 / 20000\n",
      "gradient norm: 0.027469215987366624, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 6508 / 20000\n",
      "gradient norm: 0.06142281644861214, minimum ratio: 2.492105263157895\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00551\n",
      "epoch 6509 / 20000\n",
      "gradient norm: 0.07833782443776727, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6510 / 20000\n",
      "gradient norm: 0.0359702413843479, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 6511 / 20000\n",
      "gradient norm: 0.09562562394421548, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00552\n",
      "epoch 6512 / 20000\n",
      "gradient norm: 0.052835709298960865, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 6513 / 20000\n",
      "gradient norm: 0.0834153086761944, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6514 / 20000\n",
      "gradient norm: 0.07166167028481141, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00555\n",
      "epoch 6515 / 20000\n",
      "gradient norm: 0.0750055368989706, minimum ratio: 2.494736842105263\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6516 / 20000\n",
      "gradient norm: 0.14245191041845828, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.00573\n",
      "\tval loss: 0.00551\n",
      "epoch 6517 / 20000\n",
      "gradient norm: 0.108462892298121, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00555\n",
      "epoch 6518 / 20000\n",
      "gradient norm: 0.07921327505027875, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 6519 / 20000\n",
      "gradient norm: 0.024191377800889313, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 6520 / 20000\n",
      "gradient norm: 0.06669603864429519, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 6521 / 20000\n",
      "gradient norm: 0.07538539415691048, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 6522 / 20000\n",
      "gradient norm: 0.05923977808561176, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 6523 / 20000\n",
      "gradient norm: 0.08125224418472499, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6524 / 20000\n",
      "gradient norm: 0.08477301831590012, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 6525 / 20000\n",
      "gradient norm: 0.07363482646178454, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 6526 / 20000\n",
      "gradient norm: 0.07289527636021376, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 6527 / 20000\n",
      "gradient norm: 0.035162112792022526, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 6528 / 20000\n",
      "gradient norm: 0.04677948844619095, minimum ratio: 2.5289473684210524\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 6529 / 20000\n",
      "gradient norm: 0.0631680813676212, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 6530 / 20000\n",
      "gradient norm: 0.05863736674655229, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 6531 / 20000\n",
      "gradient norm: 0.10416942567098886, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 6532 / 20000\n",
      "gradient norm: 0.08431518520228565, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 6533 / 20000\n",
      "gradient norm: 0.12011729425285012, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 6534 / 20000\n",
      "gradient norm: 0.058819804806262255, minimum ratio: 2.492105263157895\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00554\n",
      "epoch 6535 / 20000\n",
      "gradient norm: 0.0910354521474801, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00553\n",
      "epoch 6536 / 20000\n",
      "gradient norm: 0.04084530638647266, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 6537 / 20000\n",
      "gradient norm: 0.06377648629131727, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 6538 / 20000\n",
      "gradient norm: 0.09330994251649827, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00554\n",
      "epoch 6539 / 20000\n",
      "gradient norm: 0.0995549886720255, minimum ratio: 2.4868421052631575\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 6540 / 20000\n",
      "gradient norm: 0.0923660967964679, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 6541 / 20000\n",
      "gradient norm: 0.05622083295020275, minimum ratio: 2.489473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 6542 / 20000\n",
      "gradient norm: 0.026789117109728977, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 6543 / 20000\n",
      "gradient norm: 0.0976661927998066, minimum ratio: 2.4868421052631575\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 6544 / 20000\n",
      "gradient norm: 0.07336063135880977, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 6545 / 20000\n",
      "gradient norm: 0.0838425022084266, minimum ratio: 2.4868421052631575\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 6546 / 20000\n",
      "gradient norm: 0.06754844967508689, minimum ratio: 2.494736842105263\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00555\n",
      "epoch 6547 / 20000\n",
      "gradient norm: 0.0642861059459392, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 6548 / 20000\n",
      "gradient norm: 0.06259390180639457, minimum ratio: 2.4868421052631575\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 6549 / 20000\n",
      "gradient norm: 0.07381164049729705, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6550 / 20000\n",
      "gradient norm: 0.10553506325231865, minimum ratio: 2.4842105263157896\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00554\n",
      "epoch 6551 / 20000\n",
      "gradient norm: 0.08256676251767203, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 6552 / 20000\n",
      "gradient norm: 0.07607933529652655, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 6553 / 20000\n",
      "gradient norm: 0.14035690011223778, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00556\n",
      "epoch 6554 / 20000\n",
      "gradient norm: 0.04306911095045507, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 6555 / 20000\n",
      "gradient norm: 0.08886219037231058, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00551\n",
      "epoch 6556 / 20000\n",
      "gradient norm: 0.043711703416192904, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 6557 / 20000\n",
      "gradient norm: 0.07119674963178113, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 6558 / 20000\n",
      "gradient norm: 0.03404436792334309, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 6559 / 20000\n",
      "gradient norm: 0.05905255620018579, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 6560 / 20000\n",
      "gradient norm: 0.09430921729654074, minimum ratio: 2.4842105263157896\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6561 / 20000\n",
      "gradient norm: 0.07954124300158583, minimum ratio: 2.492105263157895\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00555\n",
      "epoch 6562 / 20000\n",
      "gradient norm: 0.054211799390031956, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6563 / 20000\n",
      "gradient norm: 0.15620839898474514, minimum ratio: 2.4736842105263155\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00551\n",
      "epoch 6564 / 20000\n",
      "gradient norm: 0.06678319344064221, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00555\n",
      "epoch 6565 / 20000\n",
      "gradient norm: 0.08327164029469714, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 6566 / 20000\n",
      "gradient norm: 0.048586903809336945, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 6567 / 20000\n",
      "gradient norm: 0.08412791404407471, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6568 / 20000\n",
      "gradient norm: 0.042381933773867786, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 6569 / 20000\n",
      "gradient norm: 0.05295106256380677, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 6570 / 20000\n",
      "gradient norm: 0.03923266369383782, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 6571 / 20000\n",
      "gradient norm: 0.04220358049497008, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 6572 / 20000\n",
      "gradient norm: 0.05428063769068103, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6573 / 20000\n",
      "gradient norm: 0.07088927860604599, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6574 / 20000\n",
      "gradient norm: 0.04548085085116327, minimum ratio: 2.4868421052631575\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 6575 / 20000\n",
      "gradient norm: 0.10337154334411025, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 6576 / 20000\n",
      "gradient norm: 0.05372078395157587, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6577 / 20000\n",
      "gradient norm: 0.04289006601902656, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 6578 / 20000\n",
      "gradient norm: 0.04854370848624967, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6579 / 20000\n",
      "gradient norm: 0.057139397016726434, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 6580 / 20000\n",
      "gradient norm: 0.07181499135913327, minimum ratio: 2.4894736842105267\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 6581 / 20000\n",
      "gradient norm: 0.031622968905139714, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 6582 / 20000\n",
      "gradient norm: 0.04178862230037339, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 6583 / 20000\n",
      "gradient norm: 0.1199881330539938, minimum ratio: 2.4815789473684213\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6584 / 20000\n",
      "gradient norm: 0.13339632749557495, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00551\n",
      "epoch 6585 / 20000\n",
      "gradient norm: 0.049733867519535124, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00554\n",
      "epoch 6586 / 20000\n",
      "gradient norm: 0.10309628414688632, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 6587 / 20000\n",
      "gradient norm: 0.06990453277830966, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 6588 / 20000\n",
      "gradient norm: 0.07531351543730125, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 6589 / 20000\n",
      "gradient norm: 0.04698629246558994, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 6590 / 20000\n",
      "gradient norm: 0.05450671468861401, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 6591 / 20000\n",
      "gradient norm: 0.06939852295909077, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 6592 / 20000\n",
      "gradient norm: 0.06842583871912211, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6593 / 20000\n",
      "gradient norm: 0.08036623941734433, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 6594 / 20000\n",
      "gradient norm: 0.032028545829234645, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 6595 / 20000\n",
      "gradient norm: 0.10621662915218621, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 6596 / 20000\n",
      "gradient norm: 0.0555166908307001, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00553\n",
      "epoch 6597 / 20000\n",
      "gradient norm: 0.08594615722540766, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 6598 / 20000\n",
      "gradient norm: 0.04643528611632064, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 6599 / 20000\n",
      "gradient norm: 0.10831460182089359, minimum ratio: 2.492105263157895\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 6600 / 20000\n",
      "gradient norm: 0.08206857810728252, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 6601 / 20000\n",
      "gradient norm: 0.03964068414643407, minimum ratio: 2.515789473684211\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 6602 / 20000\n",
      "gradient norm: 0.043227002053754404, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6603 / 20000\n",
      "gradient norm: 0.059199298164458014, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 6604 / 20000\n",
      "gradient norm: 0.04629559101886116, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 6605 / 20000\n",
      "gradient norm: 0.05983160514733754, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 6606 / 20000\n",
      "gradient norm: 0.07549542363994988, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 6607 / 20000\n",
      "gradient norm: 0.08538358459918527, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 6608 / 20000\n",
      "gradient norm: 0.0944510803965386, minimum ratio: 2.4736842105263155\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 6609 / 20000\n",
      "gradient norm: 0.04515932410140522, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 6610 / 20000\n",
      "gradient norm: 0.07033509184839204, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6611 / 20000\n",
      "gradient norm: 0.07966539316112176, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 6612 / 20000\n",
      "gradient norm: 0.07613596360897645, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6613 / 20000\n",
      "gradient norm: 0.11031928460579365, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 6614 / 20000\n",
      "gradient norm: 0.06785210219823057, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 6615 / 20000\n",
      "gradient norm: 0.10662253713235259, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 6616 / 20000\n",
      "gradient norm: 0.044934681500308216, minimum ratio: 2.4842105263157896\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6617 / 20000\n",
      "gradient norm: 0.09247797803254798, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 6618 / 20000\n",
      "gradient norm: 0.09756288502831012, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 6619 / 20000\n",
      "gradient norm: 0.042646658403100446, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6620 / 20000\n",
      "gradient norm: 0.054035987122915685, minimum ratio: 2.507894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 6621 / 20000\n",
      "gradient norm: 0.051607552100904286, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 6622 / 20000\n",
      "gradient norm: 0.10071057081222534, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 6623 / 20000\n",
      "gradient norm: 0.14126038062386215, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 6624 / 20000\n",
      "gradient norm: 0.12302726734196767, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6625 / 20000\n",
      "gradient norm: 0.03565895860083401, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 6626 / 20000\n",
      "gradient norm: 0.051658419135492295, minimum ratio: 2.46578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 6627 / 20000\n",
      "gradient norm: 0.0730624807474669, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6628 / 20000\n",
      "gradient norm: 0.057539485991583206, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6629 / 20000\n",
      "gradient norm: 0.08072958252159879, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 6630 / 20000\n",
      "gradient norm: 0.0577713176026009, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 6631 / 20000\n",
      "gradient norm: 0.07369633135385811, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6632 / 20000\n",
      "gradient norm: 0.052792190905165626, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 6633 / 20000\n",
      "gradient norm: 0.06801162764895707, minimum ratio: 2.492105263157895\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 6634 / 20000\n",
      "gradient norm: 0.08101657626684755, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00554\n",
      "epoch 6635 / 20000\n",
      "gradient norm: 0.036583519220585003, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 6636 / 20000\n",
      "gradient norm: 0.06685080530587584, minimum ratio: 2.46578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 6637 / 20000\n",
      "gradient norm: 0.12368751637404785, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6638 / 20000\n",
      "gradient norm: 0.06591794471023604, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 6639 / 20000\n",
      "gradient norm: 0.10393790138186887, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6640 / 20000\n",
      "gradient norm: 0.054748143986216746, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 6641 / 20000\n",
      "gradient norm: 0.05664186805370264, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 6642 / 20000\n",
      "gradient norm: 0.05160404052003287, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 6643 / 20000\n",
      "gradient norm: 0.051909075991716236, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6644 / 20000\n",
      "gradient norm: 0.07687723310664296, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 6645 / 20000\n",
      "gradient norm: 0.0942921310197562, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 6646 / 20000\n",
      "gradient norm: 0.04266097788058687, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6647 / 20000\n",
      "gradient norm: 0.04036373883718625, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 6648 / 20000\n",
      "gradient norm: 0.06460508616873994, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 6649 / 20000\n",
      "gradient norm: 0.06608926993794739, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 6650 / 20000\n",
      "gradient norm: 0.035542764177080244, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6651 / 20000\n",
      "gradient norm: 0.08030707883881405, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 6652 / 20000\n",
      "gradient norm: 0.07269144838210195, minimum ratio: 2.4842105263157896\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 6653 / 20000\n",
      "gradient norm: 0.08087831793818623, minimum ratio: 2.492105263157895\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 6654 / 20000\n",
      "gradient norm: 0.07249611569568515, minimum ratio: 2.46578947368421\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00554\n",
      "epoch 6655 / 20000\n",
      "gradient norm: 0.04819748579757288, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6656 / 20000\n",
      "gradient norm: 0.11106013553217053, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 6657 / 20000\n",
      "gradient norm: 0.05923298845300451, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 6658 / 20000\n",
      "gradient norm: 0.05399277759715915, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 6659 / 20000\n",
      "gradient norm: 0.06476240640040487, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6660 / 20000\n",
      "gradient norm: 0.04348254745127633, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 6661 / 20000\n",
      "gradient norm: 0.09788574661070015, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 6662 / 20000\n",
      "gradient norm: 0.08278313756454736, minimum ratio: 2.492105263157895\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 6663 / 20000\n",
      "gradient norm: 0.11029384151333943, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 6664 / 20000\n",
      "gradient norm: 0.10883929522242397, minimum ratio: 2.492105263157895\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 6665 / 20000\n",
      "gradient norm: 0.04820746922632679, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 6666 / 20000\n",
      "gradient norm: 0.02943176320695784, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 6667 / 20000\n",
      "gradient norm: 0.05644882938941009, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6668 / 20000\n",
      "gradient norm: 0.04798793961526826, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 6669 / 20000\n",
      "gradient norm: 0.06105501763522625, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 6670 / 20000\n",
      "gradient norm: 0.04268842446617782, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 6671 / 20000\n",
      "gradient norm: 0.03597083741624374, minimum ratio: 2.4868421052631575\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 6672 / 20000\n",
      "gradient norm: 0.08965859560703393, minimum ratio: 2.492105263157895\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 6673 / 20000\n",
      "gradient norm: 0.016353144237655215, minimum ratio: 2.465789473684211\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 6674 / 20000\n",
      "gradient norm: 0.08761130622588098, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6675 / 20000\n",
      "gradient norm: 0.05050620558904484, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6676 / 20000\n",
      "gradient norm: 0.017714634996082168, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 6677 / 20000\n",
      "gradient norm: 0.07450553379021585, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6678 / 20000\n",
      "gradient norm: 0.04897831485141069, minimum ratio: 2.4868421052631575\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 6679 / 20000\n",
      "gradient norm: 0.032768559496616945, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 6680 / 20000\n",
      "gradient norm: 0.04047917060961481, minimum ratio: 2.452631578947368\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6681 / 20000\n",
      "gradient norm: 0.06875720922835171, minimum ratio: 2.4894736842105267\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6682 / 20000\n",
      "gradient norm: 0.04080173047987046, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 6683 / 20000\n",
      "gradient norm: 0.059768776165583404, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6684 / 20000\n",
      "gradient norm: 0.08679023784497986, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6685 / 20000\n",
      "gradient norm: 0.11380909651052207, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 6686 / 20000\n",
      "gradient norm: 0.059951126837404445, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 6687 / 20000\n",
      "gradient norm: 0.05166259579709731, minimum ratio: 2.46578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6688 / 20000\n",
      "gradient norm: 0.07871601323131472, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 6689 / 20000\n",
      "gradient norm: 0.07497979688923806, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 6690 / 20000\n",
      "gradient norm: 0.05697441677330062, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 6691 / 20000\n",
      "gradient norm: 0.02484833452035673, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 6692 / 20000\n",
      "gradient norm: 0.08140862599248067, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 6693 / 20000\n",
      "gradient norm: 0.03480341377144214, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6694 / 20000\n",
      "gradient norm: 0.14259972341824323, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 6695 / 20000\n",
      "gradient norm: 0.031071213859831914, minimum ratio: 2.4868421052631575\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 6696 / 20000\n",
      "gradient norm: 0.07109795202268288, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 6697 / 20000\n",
      "gradient norm: 0.036643854255089536, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 6698 / 20000\n",
      "gradient norm: 0.08455837480141781, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 6699 / 20000\n",
      "gradient norm: 0.05539747379225446, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 6700 / 20000\n",
      "gradient norm: 0.0717970211408101, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 6701 / 20000\n",
      "gradient norm: 0.030194050719728693, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6702 / 20000\n",
      "gradient norm: 0.10812374611850828, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 6703 / 20000\n",
      "gradient norm: 0.0893399179331027, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 6704 / 20000\n",
      "gradient norm: 0.07773575361352414, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 6705 / 20000\n",
      "gradient norm: 0.07835863291984424, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 6706 / 20000\n",
      "gradient norm: 0.11809166986495256, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 6707 / 20000\n",
      "gradient norm: 0.07479602377861738, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 6708 / 20000\n",
      "gradient norm: 0.042531056446023285, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6709 / 20000\n",
      "gradient norm: 0.028587429638719186, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6710 / 20000\n",
      "gradient norm: 0.058359113056212664, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6711 / 20000\n",
      "gradient norm: 0.05388752329599811, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 6712 / 20000\n",
      "gradient norm: 0.06263947506158729, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 6713 / 20000\n",
      "gradient norm: 0.026663518248824403, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 6714 / 20000\n",
      "gradient norm: 0.04272804586798884, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 6715 / 20000\n",
      "gradient norm: 0.059531228747800924, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 6716 / 20000\n",
      "gradient norm: 0.10429294512141496, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 6717 / 20000\n",
      "gradient norm: 0.07327364181401208, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 6718 / 20000\n",
      "gradient norm: 0.047350335895316675, minimum ratio: 2.46578947368421\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 6719 / 20000\n",
      "gradient norm: 0.07739321450935677, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00554\n",
      "epoch 6720 / 20000\n",
      "gradient norm: 0.103235601214692, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 6721 / 20000\n",
      "gradient norm: 0.16997650847770274, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00551\n",
      "epoch 6722 / 20000\n",
      "gradient norm: 0.04446516666212119, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00555\n",
      "epoch 6723 / 20000\n",
      "gradient norm: 0.0918187744973693, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 6724 / 20000\n",
      "gradient norm: 0.07562910474371165, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 6725 / 20000\n",
      "gradient norm: 0.08231170766521245, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00551\n",
      "epoch 6726 / 20000\n",
      "gradient norm: 0.10033371561439708, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00556\n",
      "epoch 6727 / 20000\n",
      "gradient norm: 0.06406812003115192, minimum ratio: 2.507894736842105\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 6728 / 20000\n",
      "gradient norm: 0.11677367950323969, minimum ratio: 2.492105263157895\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00551\n",
      "epoch 6729 / 20000\n",
      "gradient norm: 0.0644112901063636, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 6730 / 20000\n",
      "gradient norm: 0.10539405408781022, minimum ratio: 2.492105263157895\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00556\n",
      "epoch 6731 / 20000\n",
      "gradient norm: 0.05217452679062262, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 6732 / 20000\n",
      "gradient norm: 0.11804733640747145, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 6733 / 20000\n",
      "gradient norm: 0.04095867319847457, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 6734 / 20000\n",
      "gradient norm: 0.09922602481674403, minimum ratio: 2.46578947368421\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00555\n",
      "epoch 6735 / 20000\n",
      "gradient norm: 0.06409491592785344, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 6736 / 20000\n",
      "gradient norm: 0.08119603322120383, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 6737 / 20000\n",
      "gradient norm: 0.044807601370848715, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 6738 / 20000\n",
      "gradient norm: 0.0660941339447163, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 6739 / 20000\n",
      "gradient norm: 0.05331211053999141, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 6740 / 20000\n",
      "gradient norm: 0.08519539813278243, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 6741 / 20000\n",
      "gradient norm: 0.09894623735453933, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 6742 / 20000\n",
      "gradient norm: 0.06823417911073193, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 6743 / 20000\n",
      "gradient norm: 0.061737364885630086, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6744 / 20000\n",
      "gradient norm: 0.09071115648839623, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 6745 / 20000\n",
      "gradient norm: 0.07009941409341991, minimum ratio: 2.4868421052631575\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 6746 / 20000\n",
      "gradient norm: 0.047597091703210026, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 6747 / 20000\n",
      "gradient norm: 0.03622650442412123, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 6748 / 20000\n",
      "gradient norm: 0.04274876230920199, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 6749 / 20000\n",
      "gradient norm: 0.07106074725743383, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6750 / 20000\n",
      "gradient norm: 0.12746902089565992, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 6751 / 20000\n",
      "gradient norm: 0.05912085945601575, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 6752 / 20000\n",
      "gradient norm: 0.0812035069684498, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6753 / 20000\n",
      "gradient norm: 0.0340469321818091, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00553\n",
      "epoch 6754 / 20000\n",
      "gradient norm: 0.05248343235871289, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 6755 / 20000\n",
      "gradient norm: 0.020624552362278337, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6756 / 20000\n",
      "gradient norm: 0.05684911370917689, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6757 / 20000\n",
      "gradient norm: 0.0444563320488669, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 6758 / 20000\n",
      "gradient norm: 0.1176440198905766, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 6759 / 20000\n",
      "gradient norm: 0.03889777761651203, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 6760 / 20000\n",
      "gradient norm: 0.06265234260354191, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 6761 / 20000\n",
      "gradient norm: 0.04467087591183372, minimum ratio: 2.465789473684211\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 6762 / 20000\n",
      "gradient norm: 0.08337268093600869, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 6763 / 20000\n",
      "gradient norm: 0.03151841924409382, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6764 / 20000\n",
      "gradient norm: 0.05472942761844024, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 6765 / 20000\n",
      "gradient norm: 0.07027506234589964, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6766 / 20000\n",
      "gradient norm: 0.040289082447998226, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 6767 / 20000\n",
      "gradient norm: 0.055318655679002404, minimum ratio: 2.492105263157895\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 6768 / 20000\n",
      "gradient norm: 0.08674638520460576, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 6769 / 20000\n",
      "gradient norm: 0.059240093862172216, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 6770 / 20000\n",
      "gradient norm: 0.08013915631454438, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 6771 / 20000\n",
      "gradient norm: 0.06791479836101644, minimum ratio: 2.4842105263157896\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 6772 / 20000\n",
      "gradient norm: 0.07111550588160753, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 6773 / 20000\n",
      "gradient norm: 0.06458358524832875, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 6774 / 20000\n",
      "gradient norm: 0.09126378851942718, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 6775 / 20000\n",
      "gradient norm: 0.10886128584388644, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 6776 / 20000\n",
      "gradient norm: 0.03417164567508735, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00554\n",
      "epoch 6777 / 20000\n",
      "gradient norm: 0.08854830905329436, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 6778 / 20000\n",
      "gradient norm: 0.025649313669418916, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 6779 / 20000\n",
      "gradient norm: 0.09137993663898669, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 6780 / 20000\n",
      "gradient norm: 0.06093886465532705, minimum ratio: 2.4894736842105267\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00555\n",
      "epoch 6781 / 20000\n",
      "gradient norm: 0.10605850559659302, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 6782 / 20000\n",
      "gradient norm: 0.07278555951779708, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6783 / 20000\n",
      "gradient norm: 0.05903630063403398, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 6784 / 20000\n",
      "gradient norm: 0.02281023316027131, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6785 / 20000\n",
      "gradient norm: 0.041328095365315676, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 6786 / 20000\n",
      "gradient norm: 0.048066637536976486, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 6787 / 20000\n",
      "gradient norm: 0.04352980339899659, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 6788 / 20000\n",
      "gradient norm: 0.08319826275692321, minimum ratio: 2.4842105263157896\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6789 / 20000\n",
      "gradient norm: 0.09724845725577325, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 6790 / 20000\n",
      "gradient norm: 0.09656264097429812, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 6791 / 20000\n",
      "gradient norm: 0.06906443438492715, minimum ratio: 2.4842105263157896\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 6792 / 20000\n",
      "gradient norm: 0.03280617038399214, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 6793 / 20000\n",
      "gradient norm: 0.07332647910516243, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6794 / 20000\n",
      "gradient norm: 0.0969889183761552, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 6795 / 20000\n",
      "gradient norm: 0.12229059508536011, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00551\n",
      "epoch 6796 / 20000\n",
      "gradient norm: 0.0593238893779926, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 6797 / 20000\n",
      "gradient norm: 0.044959486098377965, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 6798 / 20000\n",
      "gradient norm: 0.048747421766165644, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 6799 / 20000\n",
      "gradient norm: 0.06645419611595571, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 6800 / 20000\n",
      "gradient norm: 0.07652239850722253, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 6801 / 20000\n",
      "gradient norm: 0.10990135883912444, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 6802 / 20000\n",
      "gradient norm: 0.07920257706427947, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 6803 / 20000\n",
      "gradient norm: 0.08363512821961194, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 6804 / 20000\n",
      "gradient norm: 0.04075731954071671, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6805 / 20000\n",
      "gradient norm: 0.05179303651675582, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 6806 / 20000\n",
      "gradient norm: 0.11009415134321898, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 6807 / 20000\n",
      "gradient norm: 0.11475289985537529, minimum ratio: 2.492105263157895\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 6808 / 20000\n",
      "gradient norm: 0.11491367337293923, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 6809 / 20000\n",
      "gradient norm: 0.058461539272684604, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 6810 / 20000\n",
      "gradient norm: 0.060433594160713255, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6811 / 20000\n",
      "gradient norm: 0.05373189831152558, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 6812 / 20000\n",
      "gradient norm: 0.07963479062891565, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6813 / 20000\n",
      "gradient norm: 0.09900786558864638, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 6814 / 20000\n",
      "gradient norm: 0.07227300922386348, minimum ratio: 2.4894736842105267\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 6815 / 20000\n",
      "gradient norm: 0.04636965211830102, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6816 / 20000\n",
      "gradient norm: 0.07804473876603879, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 6817 / 20000\n",
      "gradient norm: 0.043347972285118885, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 6818 / 20000\n",
      "gradient norm: 0.08409344224492088, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 6819 / 20000\n",
      "gradient norm: 0.05763631402805913, minimum ratio: 2.492105263157895\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 6820 / 20000\n",
      "gradient norm: 0.05468726722756401, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 6821 / 20000\n",
      "gradient norm: 0.018899343282100745, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 6822 / 20000\n",
      "gradient norm: 0.03361532400595024, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6823 / 20000\n",
      "gradient norm: 0.07874983496731147, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 6824 / 20000\n",
      "gradient norm: 0.04612468395498581, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6825 / 20000\n",
      "gradient norm: 0.050241483229910955, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 6826 / 20000\n",
      "gradient norm: 0.051263900961203035, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 6827 / 20000\n",
      "gradient norm: 0.04268855947884731, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 6828 / 20000\n",
      "gradient norm: 0.07285403294008574, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 6829 / 20000\n",
      "gradient norm: 0.07344715515500866, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 6830 / 20000\n",
      "gradient norm: 0.060747009396436624, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 6831 / 20000\n",
      "gradient norm: 0.09395282120385673, minimum ratio: 2.4842105263157896\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 6832 / 20000\n",
      "gradient norm: 0.07691616838565096, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 6833 / 20000\n",
      "gradient norm: 0.06850492249941453, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 6834 / 20000\n",
      "gradient norm: 0.051922826358349994, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 6835 / 20000\n",
      "gradient norm: 0.07251651934348047, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 6836 / 20000\n",
      "gradient norm: 0.08720754156820476, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 6837 / 20000\n",
      "gradient norm: 0.09614339063409716, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 6838 / 20000\n",
      "gradient norm: 0.03245809602958616, minimum ratio: 2.489473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6839 / 20000\n",
      "gradient norm: 0.0835911322501488, minimum ratio: 2.46578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6840 / 20000\n",
      "gradient norm: 0.030538835504557937, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 6841 / 20000\n",
      "gradient norm: 0.03135935867612716, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 6842 / 20000\n",
      "gradient norm: 0.033887201512698084, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 6843 / 20000\n",
      "gradient norm: 0.06672142894240096, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6844 / 20000\n",
      "gradient norm: 0.035284644429339096, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 6845 / 20000\n",
      "gradient norm: 0.049006801717041526, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6846 / 20000\n",
      "gradient norm: 0.05550404227687977, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6847 / 20000\n",
      "gradient norm: 0.04527994591626339, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 6848 / 20000\n",
      "gradient norm: 0.038459684408735484, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 6849 / 20000\n",
      "gradient norm: 0.04175060096895322, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 6850 / 20000\n",
      "gradient norm: 0.02197176741901785, minimum ratio: 2.4868421052631584\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00551\n",
      "epoch 6851 / 20000\n",
      "gradient norm: 0.022484265587991104, minimum ratio: 2.4842105263157896\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 6852 / 20000\n",
      "gradient norm: 0.04402456746174721, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6853 / 20000\n",
      "gradient norm: 0.02336136631492991, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 6854 / 20000\n",
      "gradient norm: 0.039319199189776555, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 6855 / 20000\n",
      "gradient norm: 0.05758957640500739, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 6856 / 20000\n",
      "gradient norm: 0.0806965313386172, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 6857 / 20000\n",
      "gradient norm: 0.03344657039269805, minimum ratio: 2.492105263157895\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 6858 / 20000\n",
      "gradient norm: 0.10775937052676454, minimum ratio: 2.4868421052631575\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 6859 / 20000\n",
      "gradient norm: 0.07258266813005321, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 6860 / 20000\n",
      "gradient norm: 0.06196536176139489, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6861 / 20000\n",
      "gradient norm: 0.10351066559087485, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6862 / 20000\n",
      "gradient norm: 0.06771642697276548, minimum ratio: 2.4868421052631584\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 6863 / 20000\n",
      "gradient norm: 0.10347906389506534, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 6864 / 20000\n",
      "gradient norm: 0.062110177328577265, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 6865 / 20000\n",
      "gradient norm: 0.02831852511735633, minimum ratio: 2.460526315789474\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6866 / 20000\n",
      "gradient norm: 0.09619365818798542, minimum ratio: 2.492105263157895\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 6867 / 20000\n",
      "gradient norm: 0.039739387488225475, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 6868 / 20000\n",
      "gradient norm: 0.08713216509204358, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 6869 / 20000\n",
      "gradient norm: 0.042342909349827096, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 6870 / 20000\n",
      "gradient norm: 0.0773865373339504, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6871 / 20000\n",
      "gradient norm: 0.05244591733207926, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6872 / 20000\n",
      "gradient norm: 0.08735250739846379, minimum ratio: 2.46578947368421\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 6873 / 20000\n",
      "gradient norm: 0.09128156860242598, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 6874 / 20000\n",
      "gradient norm: 0.032887336012208834, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 6875 / 20000\n",
      "gradient norm: 0.12122826126869768, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00551\n",
      "epoch 6876 / 20000\n",
      "gradient norm: 0.059066699497634545, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 6877 / 20000\n",
      "gradient norm: 0.0680737204675097, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 6878 / 20000\n",
      "gradient norm: 0.04078455292619765, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 6879 / 20000\n",
      "gradient norm: 0.049829079216578975, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6880 / 20000\n",
      "gradient norm: 0.08163252519443631, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 6881 / 20000\n",
      "gradient norm: 0.0386959683673922, minimum ratio: 2.4868421052631575\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 6882 / 20000\n",
      "gradient norm: 0.04429494685609825, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 6883 / 20000\n",
      "gradient norm: 0.09573415160411969, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6884 / 20000\n",
      "gradient norm: 0.10790529189398512, minimum ratio: 2.460526315789474\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 6885 / 20000\n",
      "gradient norm: 0.04283272530301474, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00551\n",
      "epoch 6886 / 20000\n",
      "gradient norm: 0.02949987530882936, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6887 / 20000\n",
      "gradient norm: 0.07717157708248124, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 6888 / 20000\n",
      "gradient norm: 0.039673741499427706, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 6889 / 20000\n",
      "gradient norm: 0.06048938207095489, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 6890 / 20000\n",
      "gradient norm: 0.07303262571804225, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 6891 / 20000\n",
      "gradient norm: 0.05206249619368464, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 6892 / 20000\n",
      "gradient norm: 0.04565225215628743, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6893 / 20000\n",
      "gradient norm: 0.0600318580691237, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 6894 / 20000\n",
      "gradient norm: 0.040985740459291264, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00553\n",
      "epoch 6895 / 20000\n",
      "gradient norm: 0.06676293021882884, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 6896 / 20000\n",
      "gradient norm: 0.06100160055211745, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 6897 / 20000\n",
      "gradient norm: 0.03682287098490633, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6898 / 20000\n",
      "gradient norm: 0.04508013512895559, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6899 / 20000\n",
      "gradient norm: 0.04269717380520888, minimum ratio: 2.4894736842105267\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 6900 / 20000\n",
      "gradient norm: 0.08224118751240894, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 6901 / 20000\n",
      "gradient norm: 0.08072093670489267, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 6902 / 20000\n",
      "gradient norm: 0.09317780821584165, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 6903 / 20000\n",
      "gradient norm: 0.07768284407211468, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6904 / 20000\n",
      "gradient norm: 0.037185903172940016, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6905 / 20000\n",
      "gradient norm: 0.04527511235937709, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 6906 / 20000\n",
      "gradient norm: 0.12801074469462037, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00551\n",
      "epoch 6907 / 20000\n",
      "gradient norm: 0.052634114370448515, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 6908 / 20000\n",
      "gradient norm: 0.08407649537548423, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 6909 / 20000\n",
      "gradient norm: 0.0677403049194254, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6910 / 20000\n",
      "gradient norm: 0.04179107284289785, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6911 / 20000\n",
      "gradient norm: 0.03227448259713128, minimum ratio: 2.4868421052631584\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 6912 / 20000\n",
      "gradient norm: 0.06149453038233332, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6913 / 20000\n",
      "gradient norm: 0.03620509593747556, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 6914 / 20000\n",
      "gradient norm: 0.0717956954613328, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6915 / 20000\n",
      "gradient norm: 0.0933955199434422, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 6916 / 20000\n",
      "gradient norm: 0.025795246263442095, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 6917 / 20000\n",
      "gradient norm: 0.08830411717644893, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 6918 / 20000\n",
      "gradient norm: 0.053853147619520314, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 6919 / 20000\n",
      "gradient norm: 0.05129540665075183, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6920 / 20000\n",
      "gradient norm: 0.03179052499763202, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 6921 / 20000\n",
      "gradient norm: 0.06722269009333104, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6922 / 20000\n",
      "gradient norm: 0.022947843026486225, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 6923 / 20000\n",
      "gradient norm: 0.03077376434157486, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 6924 / 20000\n",
      "gradient norm: 0.07728743553161621, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6925 / 20000\n",
      "gradient norm: 0.05284641176695004, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 6926 / 20000\n",
      "gradient norm: 0.08256567741045728, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 6927 / 20000\n",
      "gradient norm: 0.05126867553917691, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6928 / 20000\n",
      "gradient norm: 0.0898972797440365, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6929 / 20000\n",
      "gradient norm: 0.03296330445300555, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6930 / 20000\n",
      "gradient norm: 0.04442046434269287, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 6931 / 20000\n",
      "gradient norm: 0.037456393940374255, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 6932 / 20000\n",
      "gradient norm: 0.08177676086779684, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 6933 / 20000\n",
      "gradient norm: 0.05809948209207505, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 6934 / 20000\n",
      "gradient norm: 0.06404192029731348, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 6935 / 20000\n",
      "gradient norm: 0.07638652168679982, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 6936 / 20000\n",
      "gradient norm: 0.04001463373424485, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 6937 / 20000\n",
      "gradient norm: 0.03890073180082254, minimum ratio: 2.4447368421052635\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 6938 / 20000\n",
      "gradient norm: 0.09759797700098716, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 6939 / 20000\n",
      "gradient norm: 0.08104591252049431, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 6940 / 20000\n",
      "gradient norm: 0.051957976014818996, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 6941 / 20000\n",
      "gradient norm: 0.04500838468084112, minimum ratio: 2.46578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6942 / 20000\n",
      "gradient norm: 0.033591536281164736, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 6943 / 20000\n",
      "gradient norm: 0.03136805057874881, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 6944 / 20000\n",
      "gradient norm: 0.03888560144696385, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 6945 / 20000\n",
      "gradient norm: 0.04362771438900381, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 6946 / 20000\n",
      "gradient norm: 0.08839283508132212, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 6947 / 20000\n",
      "gradient norm: 0.0363742861954961, minimum ratio: 2.465789473684211\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 6948 / 20000\n",
      "gradient norm: 0.07086720134248026, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 6949 / 20000\n",
      "gradient norm: 0.04733278162893839, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 6950 / 20000\n",
      "gradient norm: 0.0773486863472499, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 6951 / 20000\n",
      "gradient norm: 0.13026296312455088, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00554\n",
      "epoch 6952 / 20000\n",
      "gradient norm: 0.05237009850679897, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6953 / 20000\n",
      "gradient norm: 0.10725398175418377, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 6954 / 20000\n",
      "gradient norm: 0.09068944631144404, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 6955 / 20000\n",
      "gradient norm: 0.06784893391886726, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 6956 / 20000\n",
      "gradient norm: 0.07413029053714126, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 6957 / 20000\n",
      "gradient norm: 0.07899403589544818, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 6958 / 20000\n",
      "gradient norm: 0.08311333961319178, minimum ratio: 2.4394736842105265\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 6959 / 20000\n",
      "gradient norm: 0.05465547923813574, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 6960 / 20000\n",
      "gradient norm: 0.06328595790546387, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 6961 / 20000\n",
      "gradient norm: 0.10347518464550376, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 6962 / 20000\n",
      "gradient norm: 0.06643613462802023, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 6963 / 20000\n",
      "gradient norm: 0.0350089815328829, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 6964 / 20000\n",
      "gradient norm: 0.07734777935547754, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 6965 / 20000\n",
      "gradient norm: 0.06942296175111551, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6966 / 20000\n",
      "gradient norm: 0.07846087944926694, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6967 / 20000\n",
      "gradient norm: 0.1001771503360942, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 6968 / 20000\n",
      "gradient norm: 0.0880111682927236, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 6969 / 20000\n",
      "gradient norm: 0.05765515274833888, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 6970 / 20000\n",
      "gradient norm: 0.07933278410928324, minimum ratio: 2.4684210526315784\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 6971 / 20000\n",
      "gradient norm: 0.07768733928969596, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6972 / 20000\n",
      "gradient norm: 0.058346622783574276, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6973 / 20000\n",
      "gradient norm: 0.04455622694513295, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 6974 / 20000\n",
      "gradient norm: 0.05687443329952657, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 6975 / 20000\n",
      "gradient norm: 0.0983028965711128, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 6976 / 20000\n",
      "gradient norm: 0.045986672965227626, minimum ratio: 2.492105263157895\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 6977 / 20000\n",
      "gradient norm: 0.029617965599754825, minimum ratio: 2.465789473684211\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 6978 / 20000\n",
      "gradient norm: 0.02053648018045351, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 6979 / 20000\n",
      "gradient norm: 0.0290544573799707, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 6980 / 20000\n",
      "gradient norm: 0.07252078820602037, minimum ratio: 2.507894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6981 / 20000\n",
      "gradient norm: 0.06253186811227351, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6982 / 20000\n",
      "gradient norm: 0.032083128491649404, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 6983 / 20000\n",
      "gradient norm: 0.043745122966356575, minimum ratio: 2.4842105263157896\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 6984 / 20000\n",
      "gradient norm: 0.09076319995801896, minimum ratio: 2.4842105263157896\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6985 / 20000\n",
      "gradient norm: 0.06863265055289958, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 6986 / 20000\n",
      "gradient norm: 0.06183932820567861, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 6987 / 20000\n",
      "gradient norm: 0.06295823663822375, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 6988 / 20000\n",
      "gradient norm: 0.0523312250879826, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6989 / 20000\n",
      "gradient norm: 0.08970102776947897, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 6990 / 20000\n",
      "gradient norm: 0.06327516019518953, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 6991 / 20000\n",
      "gradient norm: 0.06862365402048454, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 6992 / 20000\n",
      "gradient norm: 0.07029694668017328, minimum ratio: 2.460526315789474\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 6993 / 20000\n",
      "gradient norm: 0.05204209155635908, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 6994 / 20000\n",
      "gradient norm: 0.0770271016517654, minimum ratio: 2.4894736842105267\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6995 / 20000\n",
      "gradient norm: 0.054787050758022815, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 6996 / 20000\n",
      "gradient norm: 0.08389876806177199, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 6997 / 20000\n",
      "gradient norm: 0.10181221019593067, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 6998 / 20000\n",
      "gradient norm: 0.06418431847123429, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 6999 / 20000\n",
      "gradient norm: 0.08148221360170282, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 7000 / 20000\n",
      "gradient norm: 0.041258724755607545, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 7001 / 20000\n",
      "gradient norm: 0.03849897050531581, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 7002 / 20000\n",
      "gradient norm: 0.06382109198602848, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 7003 / 20000\n",
      "gradient norm: 0.09196422272361815, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 7004 / 20000\n",
      "gradient norm: 0.032155152526684105, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 7005 / 20000\n",
      "gradient norm: 0.04272564430721104, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 7006 / 20000\n",
      "gradient norm: 0.06114936480298638, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 7007 / 20000\n",
      "gradient norm: 0.08032487821765244, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00551\n",
      "epoch 7008 / 20000\n",
      "gradient norm: 0.061242313764523715, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 7009 / 20000\n",
      "gradient norm: 0.10969539894722402, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 7010 / 20000\n",
      "gradient norm: 0.06596668483689427, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00551\n",
      "epoch 7011 / 20000\n",
      "gradient norm: 0.07055412768386304, minimum ratio: 2.4894736842105267\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 7012 / 20000\n",
      "gradient norm: 0.03924007806926966, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 7013 / 20000\n",
      "gradient norm: 0.08324508194345981, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 7014 / 20000\n",
      "gradient norm: 0.0426273996126838, minimum ratio: 2.492105263157895\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 7015 / 20000\n",
      "gradient norm: 0.056471042771590874, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 7016 / 20000\n",
      "gradient norm: 0.05146547997719608, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 7017 / 20000\n",
      "gradient norm: 0.041992808517534286, minimum ratio: 2.4842105263157896\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 7018 / 20000\n",
      "gradient norm: 0.08568963789730333, minimum ratio: 2.460526315789474\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 7019 / 20000\n",
      "gradient norm: 0.03301319867023267, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 7020 / 20000\n",
      "gradient norm: 0.057110892405034974, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 7021 / 20000\n",
      "gradient norm: 0.11015145102282986, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00551\n",
      "epoch 7022 / 20000\n",
      "gradient norm: 0.04281819492462091, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 7023 / 20000\n",
      "gradient norm: 0.05480428440205287, minimum ratio: 2.4499999999999997\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 7024 / 20000\n",
      "gradient norm: 0.07969869475346059, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 7025 / 20000\n",
      "gradient norm: 0.06315619393717498, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 7026 / 20000\n",
      "gradient norm: 0.027531509549589828, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 7027 / 20000\n",
      "gradient norm: 0.03139060374815017, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 7028 / 20000\n",
      "gradient norm: 0.07122051576152444, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 7029 / 20000\n",
      "gradient norm: 0.019552280587959103, minimum ratio: 2.460526315789474\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 7030 / 20000\n",
      "gradient norm: 0.059735065849963576, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 7031 / 20000\n",
      "gradient norm: 0.02516371535602957, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 7032 / 20000\n",
      "gradient norm: 0.07346559455618262, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 7033 / 20000\n",
      "gradient norm: 0.06322711025131866, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 7034 / 20000\n",
      "gradient norm: 0.050520141841843724, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 7035 / 20000\n",
      "gradient norm: 0.06452355363580864, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 7036 / 20000\n",
      "gradient norm: 0.03971468535019085, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 7037 / 20000\n",
      "gradient norm: 0.05137100111460313, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 7038 / 20000\n",
      "gradient norm: 0.07341886102221906, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 7039 / 20000\n",
      "gradient norm: 0.10546525046811439, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00554\n",
      "epoch 7040 / 20000\n",
      "gradient norm: 0.09199886629357934, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 7041 / 20000\n",
      "gradient norm: 0.03394075218238868, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 7042 / 20000\n",
      "gradient norm: 0.06996164412703365, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 7043 / 20000\n",
      "gradient norm: 0.11117184476461262, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 7044 / 20000\n",
      "gradient norm: 0.046486800973070785, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 7045 / 20000\n",
      "gradient norm: 0.08660061669070274, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 7046 / 20000\n",
      "gradient norm: 0.05643680569482967, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 7047 / 20000\n",
      "gradient norm: 0.07592515047872439, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 7048 / 20000\n",
      "gradient norm: 0.043534139811526984, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 7049 / 20000\n",
      "gradient norm: 0.04358889866853133, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 7050 / 20000\n",
      "gradient norm: 0.06273386144312099, minimum ratio: 2.4842105263157896\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00552\n",
      "epoch 7051 / 20000\n",
      "gradient norm: 0.057696296280482784, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 7052 / 20000\n",
      "gradient norm: 0.05374545993981883, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 7053 / 20000\n",
      "gradient norm: 0.0732031927909702, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 7054 / 20000\n",
      "gradient norm: 0.044450660585425794, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 7055 / 20000\n",
      "gradient norm: 0.06021660176338628, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 7056 / 20000\n",
      "gradient norm: 0.08022859779885039, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 7057 / 20000\n",
      "gradient norm: 0.05179885710822418, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 7058 / 20000\n",
      "gradient norm: 0.06725428969366476, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00553\n",
      "epoch 7059 / 20000\n",
      "gradient norm: 0.031499456337769516, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 7060 / 20000\n",
      "gradient norm: 0.08499643905088305, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 7061 / 20000\n",
      "gradient norm: 0.052999005041783676, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 7062 / 20000\n",
      "gradient norm: 0.05676122140721418, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 7063 / 20000\n",
      "gradient norm: 0.05936237412970513, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 7064 / 20000\n",
      "gradient norm: 0.05800643708789721, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 7065 / 20000\n",
      "gradient norm: 0.028533037548186257, minimum ratio: 2.4736842105263155\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 7066 / 20000\n",
      "gradient norm: 0.05288430873770267, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 7067 / 20000\n",
      "gradient norm: 0.07910308090504259, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00551\n",
      "epoch 7068 / 20000\n",
      "gradient norm: 0.05240094102919102, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 7069 / 20000\n",
      "gradient norm: 0.06498895605909638, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 7070 / 20000\n",
      "gradient norm: 0.09847533141146414, minimum ratio: 2.460526315789474\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 7071 / 20000\n",
      "gradient norm: 0.080807413905859, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 7072 / 20000\n",
      "gradient norm: 0.06298071648052428, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 7073 / 20000\n",
      "gradient norm: 0.1388942071935162, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 7074 / 20000\n",
      "gradient norm: 0.04945486891665496, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 7075 / 20000\n",
      "gradient norm: 0.035205162392230704, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 7076 / 20000\n",
      "gradient norm: 0.039501058199675754, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 7077 / 20000\n",
      "gradient norm: 0.061907623952720314, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 7078 / 20000\n",
      "gradient norm: 0.062487018236424774, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00553\n",
      "epoch 7079 / 20000\n",
      "gradient norm: 0.03195256582694128, minimum ratio: 2.4684210526315784\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 7080 / 20000\n",
      "gradient norm: 0.032304958847817034, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 7081 / 20000\n",
      "gradient norm: 0.08677950885612518, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 7082 / 20000\n",
      "gradient norm: 0.10891026858007535, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00551\n",
      "epoch 7083 / 20000\n",
      "gradient norm: 0.05696600831288379, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 7084 / 20000\n",
      "gradient norm: 0.07385348051320761, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 7085 / 20000\n",
      "gradient norm: 0.05878316564485431, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00565\n",
      "\tval loss: 0.00551\n",
      "epoch 7086 / 20000\n",
      "gradient norm: 0.0810834135627374, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 7087 / 20000\n",
      "gradient norm: 0.05850125628057867, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 7088 / 20000\n",
      "gradient norm: 0.054821788042318076, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 7089 / 20000\n",
      "gradient norm: 0.03269826227915473, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 7090 / 20000\n",
      "gradient norm: 0.0741532959509641, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 7091 / 20000\n",
      "gradient norm: 0.05767892184667289, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 7092 / 20000\n",
      "gradient norm: 0.044269696925766766, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 7093 / 20000\n",
      "gradient norm: 0.06641001912066713, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 7094 / 20000\n",
      "gradient norm: 0.021039742583525367, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 7095 / 20000\n",
      "gradient norm: 0.09614445362240076, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 7096 / 20000\n",
      "gradient norm: 0.08149374945787713, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 7097 / 20000\n",
      "gradient norm: 0.06543675981083652, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 7098 / 20000\n",
      "gradient norm: 0.07984725828282535, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 7099 / 20000\n",
      "gradient norm: 0.05492457782384008, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 7100 / 20000\n",
      "gradient norm: 0.03540960932878079, minimum ratio: 2.4684210526315784\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 7101 / 20000\n",
      "gradient norm: 0.048690099371015094, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 7102 / 20000\n",
      "gradient norm: 0.0788304788293317, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 7103 / 20000\n",
      "gradient norm: 0.054614267544820905, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 7104 / 20000\n",
      "gradient norm: 0.0530166942771757, minimum ratio: 2.465789473684211\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 7105 / 20000\n",
      "gradient norm: 0.06098914978792891, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 7106 / 20000\n",
      "gradient norm: 0.052703951951116323, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 7107 / 20000\n",
      "gradient norm: 0.07638227185816504, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 7108 / 20000\n",
      "gradient norm: 0.033624692892772146, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 7109 / 20000\n",
      "gradient norm: 0.06936574337305501, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 7110 / 20000\n",
      "gradient norm: 0.07634385352139361, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 7111 / 20000\n",
      "gradient norm: 0.06943604825937655, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 7112 / 20000\n",
      "gradient norm: 0.0844521535327658, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 7113 / 20000\n",
      "gradient norm: 0.07643025845754892, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 7114 / 20000\n",
      "gradient norm: 0.04729821963701397, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 7115 / 20000\n",
      "gradient norm: 0.06607620886643417, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 7116 / 20000\n",
      "gradient norm: 0.054856982722412795, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 7117 / 20000\n",
      "gradient norm: 0.014601979208237026, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 7118 / 20000\n",
      "gradient norm: 0.04155285638989881, minimum ratio: 2.46578947368421\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 7119 / 20000\n",
      "gradient norm: 0.06613503821427003, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 7120 / 20000\n",
      "gradient norm: 0.07142072237911634, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 7121 / 20000\n",
      "gradient norm: 0.069804076658329, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 7122 / 20000\n",
      "gradient norm: 0.06287237428477965, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 7123 / 20000\n",
      "gradient norm: 0.04038710365421139, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 7124 / 20000\n",
      "gradient norm: 0.10073376377113163, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 7125 / 20000\n",
      "gradient norm: 0.08894754500943236, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 7126 / 20000\n",
      "gradient norm: 0.1219365187571384, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 7127 / 20000\n",
      "gradient norm: 0.1016896078363061, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 7128 / 20000\n",
      "gradient norm: 0.06318201593239792, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 7129 / 20000\n",
      "gradient norm: 0.10286533343605697, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 7130 / 20000\n",
      "gradient norm: 0.0956255323253572, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 7131 / 20000\n",
      "gradient norm: 0.11078927252674475, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00551\n",
      "epoch 7132 / 20000\n",
      "gradient norm: 0.03379155392758548, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 7133 / 20000\n",
      "gradient norm: 0.06504103157203645, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 7134 / 20000\n",
      "gradient norm: 0.06620052055222914, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 7135 / 20000\n",
      "gradient norm: 0.08637332613579929, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 7136 / 20000\n",
      "gradient norm: 0.0638349765795283, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 7137 / 20000\n",
      "gradient norm: 0.08795470278710127, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 7138 / 20000\n",
      "gradient norm: 0.07492253102827817, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 7139 / 20000\n",
      "gradient norm: 0.054912728257477283, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 7140 / 20000\n",
      "gradient norm: 0.06051838475832483, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 7141 / 20000\n",
      "gradient norm: 0.11455790291074663, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 7142 / 20000\n",
      "gradient norm: 0.055385920306434855, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 7143 / 20000\n",
      "gradient norm: 0.06132841747603379, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 7144 / 20000\n",
      "gradient norm: 0.050537543080281466, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 7145 / 20000\n",
      "gradient norm: 0.057310852978844196, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 7146 / 20000\n",
      "gradient norm: 0.046398417580348905, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 7147 / 20000\n",
      "gradient norm: 0.08208763557195198, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 7148 / 20000\n",
      "gradient norm: 0.07383638230385259, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 7149 / 20000\n",
      "gradient norm: 0.0584772235743003, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 7150 / 20000\n",
      "gradient norm: 0.041167266870616004, minimum ratio: 2.492105263157895\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 7151 / 20000\n",
      "gradient norm: 0.04152802568569314, minimum ratio: 2.492105263157895\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 7152 / 20000\n",
      "gradient norm: 0.04274925569188781, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 7153 / 20000\n",
      "gradient norm: 0.07611836143769324, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 7154 / 20000\n",
      "gradient norm: 0.06986123375827447, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 7155 / 20000\n",
      "gradient norm: 0.10085651755798608, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 7156 / 20000\n",
      "gradient norm: 0.0849119683552999, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 7157 / 20000\n",
      "gradient norm: 0.048768328852020204, minimum ratio: 2.4815789473684213\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 7158 / 20000\n",
      "gradient norm: 0.053999733994714916, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 7159 / 20000\n",
      "gradient norm: 0.02681917406152934, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 7160 / 20000\n",
      "gradient norm: 0.030452817634795792, minimum ratio: 2.4842105263157896\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 7161 / 20000\n",
      "gradient norm: 0.07554777615587227, minimum ratio: 2.46578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 7162 / 20000\n",
      "gradient norm: 0.07368214635062031, minimum ratio: 2.4894736842105267\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 7163 / 20000\n",
      "gradient norm: 0.07375705539016053, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 7164 / 20000\n",
      "gradient norm: 0.034724574667052366, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 7165 / 20000\n",
      "gradient norm: 0.037342167721362785, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 7166 / 20000\n",
      "gradient norm: 0.05323984014103189, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 7167 / 20000\n",
      "gradient norm: 0.06600958568742499, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 7168 / 20000\n",
      "gradient norm: 0.04011783542227931, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 7169 / 20000\n",
      "gradient norm: 0.05394321502535604, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 7170 / 20000\n",
      "gradient norm: 0.07809051172807813, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 7171 / 20000\n",
      "gradient norm: 0.05015775910578668, minimum ratio: 2.4868421052631575\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 7172 / 20000\n",
      "gradient norm: 0.08076461695600301, minimum ratio: 2.4842105263157896\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 7173 / 20000\n",
      "gradient norm: 0.09437389462254941, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 7174 / 20000\n",
      "gradient norm: 0.06671051314333454, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 7175 / 20000\n",
      "gradient norm: 0.0692707880953094, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 7176 / 20000\n",
      "gradient norm: 0.09938049183983821, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 7177 / 20000\n",
      "gradient norm: 0.09911291545722634, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 7178 / 20000\n",
      "gradient norm: 0.10517992114182562, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 7179 / 20000\n",
      "gradient norm: 0.08864572618040256, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00551\n",
      "epoch 7180 / 20000\n",
      "gradient norm: 0.07459963124711066, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 7181 / 20000\n",
      "gradient norm: 0.10461229251814075, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00555\n",
      "epoch 7182 / 20000\n",
      "gradient norm: 0.06237745442194864, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00551\n",
      "epoch 7183 / 20000\n",
      "gradient norm: 0.04657089110696688, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 7184 / 20000\n",
      "gradient norm: 0.05929942525108345, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 7185 / 20000\n",
      "gradient norm: 0.08553845511050895, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 7186 / 20000\n",
      "gradient norm: 0.028057946037733927, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 7187 / 20000\n",
      "gradient norm: 0.08659506967524067, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00551\n",
      "epoch 7188 / 20000\n",
      "gradient norm: 0.07385591027559713, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 7189 / 20000\n",
      "gradient norm: 0.07662173203425482, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 7190 / 20000\n",
      "gradient norm: 0.08533959049964324, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 7191 / 20000\n",
      "gradient norm: 0.06126461876556277, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 7192 / 20000\n",
      "gradient norm: 0.07552140770712867, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 7193 / 20000\n",
      "gradient norm: 0.06339408148778602, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 7194 / 20000\n",
      "gradient norm: 0.06874113826779649, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00565\n",
      "\tval loss: 0.00551\n",
      "epoch 7195 / 20000\n",
      "gradient norm: 0.06452027813065797, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 7196 / 20000\n",
      "gradient norm: 0.09379009145777673, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 7197 / 20000\n",
      "gradient norm: 0.10266403248533607, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00554\n",
      "epoch 7198 / 20000\n",
      "gradient norm: 0.05068289578775875, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 7199 / 20000\n",
      "gradient norm: 0.05660723912296817, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 7200 / 20000\n",
      "gradient norm: 0.028499960211775033, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 7201 / 20000\n",
      "gradient norm: 0.031001445167930797, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 7202 / 20000\n",
      "gradient norm: 0.11883309076074511, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 7203 / 20000\n",
      "gradient norm: 0.06560787034686655, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 7204 / 20000\n",
      "gradient norm: 0.05698026262689382, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 7205 / 20000\n",
      "gradient norm: 0.0627351822622586, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 7206 / 20000\n",
      "gradient norm: 0.04428314417600632, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 7207 / 20000\n",
      "gradient norm: 0.03950111746962648, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 7208 / 20000\n",
      "gradient norm: 0.1325279938755557, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 7209 / 20000\n",
      "gradient norm: 0.10189945995807648, minimum ratio: 2.4868421052631575\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 7210 / 20000\n",
      "gradient norm: 0.04904473279020749, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 7211 / 20000\n",
      "gradient norm: 0.06031207228079438, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 7212 / 20000\n",
      "gradient norm: 0.11819268914405257, minimum ratio: 2.46578947368421\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 7213 / 20000\n",
      "gradient norm: 0.0442088600830175, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 7214 / 20000\n",
      "gradient norm: 0.08905631059315056, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 7215 / 20000\n",
      "gradient norm: 0.0746392723522149, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 7216 / 20000\n",
      "gradient norm: 0.052779988560359925, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 7217 / 20000\n",
      "gradient norm: 0.07959135237615556, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 7218 / 20000\n",
      "gradient norm: 0.07043191255070269, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 7219 / 20000\n",
      "gradient norm: 0.046611051133368164, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 7220 / 20000\n",
      "gradient norm: 0.07989345345413312, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 7221 / 20000\n",
      "gradient norm: 0.03555750151281245, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 7222 / 20000\n",
      "gradient norm: 0.03996098166680895, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 7223 / 20000\n",
      "gradient norm: 0.07929394545499235, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 7224 / 20000\n",
      "gradient norm: 0.04765188728924841, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 7225 / 20000\n",
      "gradient norm: 0.07647113926941529, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 7226 / 20000\n",
      "gradient norm: 0.054829332199005876, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 7227 / 20000\n",
      "gradient norm: 0.03469668191974051, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 7228 / 20000\n",
      "gradient norm: 0.05646696832263842, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 7229 / 20000\n",
      "gradient norm: 0.050031586943077855, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 7230 / 20000\n",
      "gradient norm: 0.03157927161009866, minimum ratio: 2.460526315789474\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 7231 / 20000\n",
      "gradient norm: 0.07644110138062388, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 7232 / 20000\n",
      "gradient norm: 0.021694818860851228, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 7233 / 20000\n",
      "gradient norm: 0.06802791837253608, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 7234 / 20000\n",
      "gradient norm: 0.056282173725776374, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 7235 / 20000\n",
      "gradient norm: 0.06658425004570745, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 7236 / 20000\n",
      "gradient norm: 0.060257011879002675, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 7237 / 20000\n",
      "gradient norm: 0.0476427783141844, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 7238 / 20000\n",
      "gradient norm: 0.07290263002505526, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 7239 / 20000\n",
      "gradient norm: 0.06900897779269144, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00554\n",
      "epoch 7240 / 20000\n",
      "gradient norm: 0.11653024784754962, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 7241 / 20000\n",
      "gradient norm: 0.0701246063108556, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 7242 / 20000\n",
      "gradient norm: 0.03595060756197199, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 7243 / 20000\n",
      "gradient norm: 0.13698018656577915, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00552\n",
      "epoch 7244 / 20000\n",
      "gradient norm: 0.037466011475771666, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 7245 / 20000\n",
      "gradient norm: 0.041650819446658716, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 7246 / 20000\n",
      "gradient norm: 0.09514202701393515, minimum ratio: 2.4631578947368427\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00551\n",
      "epoch 7247 / 20000\n",
      "gradient norm: 0.06151286856038496, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 7248 / 20000\n",
      "gradient norm: 0.07680216411245055, minimum ratio: 2.4894736842105267\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 7249 / 20000\n",
      "gradient norm: 0.06488750770222396, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 7250 / 20000\n",
      "gradient norm: 0.06187678111018613, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 7251 / 20000\n",
      "gradient norm: 0.06693774415180087, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00553\n",
      "epoch 7252 / 20000\n",
      "gradient norm: 0.07210656616371125, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 7253 / 20000\n",
      "gradient norm: 0.07399700614041649, minimum ratio: 2.4868421052631584\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 7254 / 20000\n",
      "gradient norm: 0.041668440971989185, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 7255 / 20000\n",
      "gradient norm: 0.04856598668266088, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 7256 / 20000\n",
      "gradient norm: 0.0784076001145877, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 7257 / 20000\n",
      "gradient norm: 0.04811554998741485, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 7258 / 20000\n",
      "gradient norm: 0.1118038140120916, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 7259 / 20000\n",
      "gradient norm: 0.12787218973971903, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 7260 / 20000\n",
      "gradient norm: 0.03273034069570713, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 7261 / 20000\n",
      "gradient norm: 0.0529772081063129, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 7262 / 20000\n",
      "gradient norm: 0.13266724516870454, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 7263 / 20000\n",
      "gradient norm: 0.08718943715211935, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 7264 / 20000\n",
      "gradient norm: 0.07912026302074082, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 7265 / 20000\n",
      "gradient norm: 0.05284477639361285, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 7266 / 20000\n",
      "gradient norm: 0.06671103148255497, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00554\n",
      "epoch 7267 / 20000\n",
      "gradient norm: 0.07059943210333586, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 7268 / 20000\n",
      "gradient norm: 0.043162657209904864, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 7269 / 20000\n",
      "gradient norm: 0.07712616038043052, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 7270 / 20000\n",
      "gradient norm: 0.09109553493908606, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 7271 / 20000\n",
      "gradient norm: 0.071899538859725, minimum ratio: 2.4736842105263155\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 7272 / 20000\n",
      "gradient norm: 0.046993555064545944, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 7273 / 20000\n",
      "gradient norm: 0.0613626129925251, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 7274 / 20000\n",
      "gradient norm: 0.08451856800820678, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 7275 / 20000\n",
      "gradient norm: 0.048472785056219436, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 7276 / 20000\n",
      "gradient norm: 0.08034212872735225, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 7277 / 20000\n",
      "gradient norm: 0.04062416168926575, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 7278 / 20000\n",
      "gradient norm: 0.0658447066671215, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 7279 / 20000\n",
      "gradient norm: 0.06214356503915042, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 7280 / 20000\n",
      "gradient norm: 0.07161351770628244, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 7281 / 20000\n",
      "gradient norm: 0.07737760862801224, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 7282 / 20000\n",
      "gradient norm: 0.06267538305837661, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 7283 / 20000\n",
      "gradient norm: 0.03845554613508284, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 7284 / 20000\n",
      "gradient norm: 0.04991741509002168, minimum ratio: 2.4578947368421056\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 7285 / 20000\n",
      "gradient norm: 0.025092212134040892, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 7286 / 20000\n",
      "gradient norm: 0.0741378175735008, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 7287 / 20000\n",
      "gradient norm: 0.07235699286684394, minimum ratio: 2.492105263157895\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 7288 / 20000\n",
      "gradient norm: 0.039833753573475406, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 7289 / 20000\n",
      "gradient norm: 0.10723000566940755, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 7290 / 20000\n",
      "gradient norm: 0.07994079636409879, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 7291 / 20000\n",
      "gradient norm: 0.07007617628551088, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 7292 / 20000\n",
      "gradient norm: 0.07708810246549547, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 7293 / 20000\n",
      "gradient norm: 0.09433919488219544, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 7294 / 20000\n",
      "gradient norm: 0.1095058495993726, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00551\n",
      "epoch 7295 / 20000\n",
      "gradient norm: 0.05183627588849049, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 7296 / 20000\n",
      "gradient norm: 0.09890343714505434, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00553\n",
      "epoch 7297 / 20000\n",
      "gradient norm: 0.05322778924164595, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 7298 / 20000\n",
      "gradient norm: 0.046119665494188666, minimum ratio: 2.4894736842105267\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 7299 / 20000\n",
      "gradient norm: 0.07619020974379964, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 7300 / 20000\n",
      "gradient norm: 0.06301746572717093, minimum ratio: 2.4842105263157896\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 7301 / 20000\n",
      "gradient norm: 0.052738557307748124, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 7302 / 20000\n",
      "gradient norm: 0.05566912051290274, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 7303 / 20000\n",
      "gradient norm: 0.0696212927432498, minimum ratio: 2.4736842105263155\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 7304 / 20000\n",
      "gradient norm: 0.06438685662578791, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00553\n",
      "epoch 7305 / 20000\n",
      "gradient norm: 0.0990942869684659, minimum ratio: 2.4842105263157896\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 7306 / 20000\n",
      "gradient norm: 0.10555438615847379, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 7307 / 20000\n",
      "gradient norm: 0.07809198222821578, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 7308 / 20000\n",
      "gradient norm: 0.07421823320328258, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 7309 / 20000\n",
      "gradient norm: 0.11615559516940266, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00553\n",
      "epoch 7310 / 20000\n",
      "gradient norm: 0.05677770121837966, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 7311 / 20000\n",
      "gradient norm: 0.038752909167669713, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 7312 / 20000\n",
      "gradient norm: 0.03621574450517073, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 7313 / 20000\n",
      "gradient norm: 0.030875977434334345, minimum ratio: 2.4842105263157896\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 7314 / 20000\n",
      "gradient norm: 0.04794391214818461, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 7315 / 20000\n",
      "gradient norm: 0.05191660515265539, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 7316 / 20000\n",
      "gradient norm: 0.03347545313590672, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 7317 / 20000\n",
      "gradient norm: 0.042890935379546136, minimum ratio: 2.489473684210526\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 7318 / 20000\n",
      "gradient norm: 0.08142653753748164, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 7319 / 20000\n",
      "gradient norm: 0.05768342487863265, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 7320 / 20000\n",
      "gradient norm: 0.07872541307006031, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 7321 / 20000\n",
      "gradient norm: 0.02887410658877343, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 7322 / 20000\n",
      "gradient norm: 0.04648628376889974, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 7323 / 20000\n",
      "gradient norm: 0.08320989494677633, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 7324 / 20000\n",
      "gradient norm: 0.06897676341759507, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 7325 / 20000\n",
      "gradient norm: 0.044617106883379165, minimum ratio: 2.4842105263157896\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 7326 / 20000\n",
      "gradient norm: 0.09021313267294317, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 7327 / 20000\n",
      "gradient norm: 0.05449852830497548, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 7328 / 20000\n",
      "gradient norm: 0.1501202571671456, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 7329 / 20000\n",
      "gradient norm: 0.06170836304954719, minimum ratio: 2.494736842105263\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 7330 / 20000\n",
      "gradient norm: 0.08132176200160757, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 7331 / 20000\n",
      "gradient norm: 0.0339481103583239, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 7332 / 20000\n",
      "gradient norm: 0.09470664465334266, minimum ratio: 2.4842105263157896\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 7333 / 20000\n",
      "gradient norm: 0.06297075317706913, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 7334 / 20000\n",
      "gradient norm: 0.07184376424993388, minimum ratio: 2.492105263157895\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 7335 / 20000\n",
      "gradient norm: 0.12833578407298774, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 7336 / 20000\n",
      "gradient norm: 0.07724267253070138, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 7337 / 20000\n",
      "gradient norm: 0.1250029318034649, minimum ratio: 2.4842105263157896\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 7338 / 20000\n",
      "gradient norm: 0.047354599490063265, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 7339 / 20000\n",
      "gradient norm: 0.09434603530098684, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 7340 / 20000\n",
      "gradient norm: 0.07898316747741774, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 7341 / 20000\n",
      "gradient norm: 0.04642384042381309, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 7342 / 20000\n",
      "gradient norm: 0.07437942147953436, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 7343 / 20000\n",
      "gradient norm: 0.03991010785102844, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00551\n",
      "epoch 7344 / 20000\n",
      "gradient norm: 0.08702060644282028, minimum ratio: 2.4894736842105267\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 7345 / 20000\n",
      "gradient norm: 0.062086018559057266, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 7346 / 20000\n",
      "gradient norm: 0.05520719208288938, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 7347 / 20000\n",
      "gradient norm: 0.0502752289903583, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00551\n",
      "epoch 7348 / 20000\n",
      "gradient norm: 0.0654683643952012, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 7349 / 20000\n",
      "gradient norm: 0.03033372286881786, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 7350 / 20000\n",
      "gradient norm: 0.0552815769915469, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 7351 / 20000\n",
      "gradient norm: 0.040538335240853485, minimum ratio: 2.4842105263157896\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 7352 / 20000\n",
      "gradient norm: 0.04357476293807849, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 7353 / 20000\n",
      "gradient norm: 0.08772872213739902, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 7354 / 20000\n",
      "gradient norm: 0.0765129917563172, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00551\n",
      "epoch 7355 / 20000\n",
      "gradient norm: 0.0529781874793116, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 7356 / 20000\n",
      "gradient norm: 0.08019537216750905, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 7357 / 20000\n",
      "gradient norm: 0.07201819459442049, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 7358 / 20000\n",
      "gradient norm: 0.059462878678459674, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 7359 / 20000\n",
      "gradient norm: 0.06850125757046044, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 7360 / 20000\n",
      "gradient norm: 0.07045492317411117, minimum ratio: 2.5078947368421054\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00554\n",
      "epoch 7361 / 20000\n",
      "gradient norm: 0.04700817965203896, minimum ratio: 2.4894736842105267\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 7362 / 20000\n",
      "gradient norm: 0.0730987768038176, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 7363 / 20000\n",
      "gradient norm: 0.050613118772162125, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 7364 / 20000\n",
      "gradient norm: 0.022143485984997824, minimum ratio: 2.4868421052631575\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 7365 / 20000\n",
      "gradient norm: 0.09647310641594231, minimum ratio: 2.4842105263157896\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 7366 / 20000\n",
      "gradient norm: 0.06291041726944968, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 7367 / 20000\n",
      "gradient norm: 0.04125929978908971, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00565\n",
      "\tval loss: 0.00552\n",
      "epoch 7368 / 20000\n",
      "gradient norm: 0.04657922699698247, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 7369 / 20000\n",
      "gradient norm: 0.031843864322581794, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 7370 / 20000\n",
      "gradient norm: 0.0348921213299036, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 7371 / 20000\n",
      "gradient norm: 0.06070699915289879, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 7372 / 20000\n",
      "gradient norm: 0.020890501022222452, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 7373 / 20000\n",
      "gradient norm: 0.057592127413954586, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 7374 / 20000\n",
      "gradient norm: 0.08167302282527089, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 7375 / 20000\n",
      "gradient norm: 0.06965722749009728, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 7376 / 20000\n",
      "gradient norm: 0.044111760798841715, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 7377 / 20000\n",
      "gradient norm: 0.06953198264818639, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 7378 / 20000\n",
      "gradient norm: 0.012049368502630387, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 7379 / 20000\n",
      "gradient norm: 0.0814528227201663, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 7380 / 20000\n",
      "gradient norm: 0.051410065265372396, minimum ratio: 2.489473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 7381 / 20000\n",
      "gradient norm: 0.0805271873541642, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 7382 / 20000\n",
      "gradient norm: 0.025614376689190976, minimum ratio: 2.4842105263157896\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 7383 / 20000\n",
      "gradient norm: 0.04654444640618749, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 7384 / 20000\n",
      "gradient norm: 0.03491016841144301, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 7385 / 20000\n",
      "gradient norm: 0.12100556422956288, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 7386 / 20000\n",
      "gradient norm: 0.07628904149169102, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 7387 / 20000\n",
      "gradient norm: 0.06171309400815517, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 7388 / 20000\n",
      "gradient norm: 0.03160651210055221, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 7389 / 20000\n",
      "gradient norm: 0.054802279963041656, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 7390 / 20000\n",
      "gradient norm: 0.06342348965699784, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 7391 / 20000\n",
      "gradient norm: 0.044242659816518426, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 7392 / 20000\n",
      "gradient norm: 0.08022061828523874, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 7393 / 20000\n",
      "gradient norm: 0.0487562699127011, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 7394 / 20000\n",
      "gradient norm: 0.03280291164992377, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 7395 / 20000\n",
      "gradient norm: 0.049603256236878224, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 7396 / 20000\n",
      "gradient norm: 0.021800014408654533, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 7397 / 20000\n",
      "gradient norm: 0.09065065067261457, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 7398 / 20000\n",
      "gradient norm: 0.07997324620373547, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 7399 / 20000\n",
      "gradient norm: 0.054754011100158095, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 7400 / 20000\n",
      "gradient norm: 0.08391767487046309, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 7401 / 20000\n",
      "gradient norm: 0.06148773181485012, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 7402 / 20000\n",
      "gradient norm: 0.050732685573166236, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00552\n",
      "epoch 7403 / 20000\n",
      "gradient norm: 0.09151564561761916, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00555\n",
      "epoch 7404 / 20000\n",
      "gradient norm: 0.12008417677134275, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 7405 / 20000\n",
      "gradient norm: 0.10147819895064458, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 7406 / 20000\n",
      "gradient norm: 0.03604303440079093, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 7407 / 20000\n",
      "gradient norm: 0.02384575523319654, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 7408 / 20000\n",
      "gradient norm: 0.08852356381248683, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 7409 / 20000\n",
      "gradient norm: 0.04086903092684224, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 7410 / 20000\n",
      "gradient norm: 0.03743221305194311, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 7411 / 20000\n",
      "gradient norm: 0.05131290829740465, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 7412 / 20000\n",
      "gradient norm: 0.09278775518760085, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 7413 / 20000\n",
      "gradient norm: 0.038244915631366894, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 7414 / 20000\n",
      "gradient norm: 0.031169766501989216, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 7415 / 20000\n",
      "gradient norm: 0.0829999657580629, minimum ratio: 2.494736842105263\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 7416 / 20000\n",
      "gradient norm: 0.037482173123862594, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 7417 / 20000\n",
      "gradient norm: 0.05283246049657464, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 7418 / 20000\n",
      "gradient norm: 0.0720752732740948, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 7419 / 20000\n",
      "gradient norm: 0.04018107141018845, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 7420 / 20000\n",
      "gradient norm: 0.058804351778235286, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 7421 / 20000\n",
      "gradient norm: 0.07479304843582213, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 7422 / 20000\n",
      "gradient norm: 0.07669443867052905, minimum ratio: 2.492105263157895\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 7423 / 20000\n",
      "gradient norm: 0.04683940138784237, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 7424 / 20000\n",
      "gradient norm: 0.041826504457276314, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 7425 / 20000\n",
      "gradient norm: 0.08662682678550482, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 7426 / 20000\n",
      "gradient norm: 0.1056268106913194, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 7427 / 20000\n",
      "gradient norm: 0.06065715610748157, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 7428 / 20000\n",
      "gradient norm: 0.03595686057815328, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 7429 / 20000\n",
      "gradient norm: 0.10387761774472892, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00551\n",
      "epoch 7430 / 20000\n",
      "gradient norm: 0.12737585580907762, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 7431 / 20000\n",
      "gradient norm: 0.03302319173235446, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00551\n",
      "epoch 7432 / 20000\n",
      "gradient norm: 0.09052783017978072, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 7433 / 20000\n",
      "gradient norm: 0.06693651084788144, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 7434 / 20000\n",
      "gradient norm: 0.07358001836109906, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 7435 / 20000\n",
      "gradient norm: 0.07408768660388887, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 7436 / 20000\n",
      "gradient norm: 0.06029955719714053, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 7437 / 20000\n",
      "gradient norm: 0.08871622553851921, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 7438 / 20000\n",
      "gradient norm: 0.061403366780723445, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00554\n",
      "epoch 7439 / 20000\n",
      "gradient norm: 0.03587601838808041, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 7440 / 20000\n",
      "gradient norm: 0.0818199283676222, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 7441 / 20000\n",
      "gradient norm: 0.04216237175569404, minimum ratio: 2.436842105263158\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 7442 / 20000\n",
      "gradient norm: 0.051277399878017604, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 7443 / 20000\n",
      "gradient norm: 0.059068976319395006, minimum ratio: 2.4868421052631575\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 7444 / 20000\n",
      "gradient norm: 0.06455787288723513, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 7445 / 20000\n",
      "gradient norm: 0.055510197329567745, minimum ratio: 2.460526315789474\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00553\n",
      "epoch 7446 / 20000\n",
      "gradient norm: 0.09404959378298372, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 7447 / 20000\n",
      "gradient norm: 0.058357311179861426, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 7448 / 20000\n",
      "gradient norm: 0.07178971555549651, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 7449 / 20000\n",
      "gradient norm: 0.059566904747043736, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 7450 / 20000\n",
      "gradient norm: 0.07527343620313331, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 7451 / 20000\n",
      "gradient norm: 0.06127608614042401, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 7452 / 20000\n",
      "gradient norm: 0.08409778471104801, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 7453 / 20000\n",
      "gradient norm: 0.07513508765259758, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 7454 / 20000\n",
      "gradient norm: 0.05499653427978046, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 7455 / 20000\n",
      "gradient norm: 0.05608739622402936, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 7456 / 20000\n",
      "gradient norm: 0.07333709020167589, minimum ratio: 2.465789473684211\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00554\n",
      "epoch 7457 / 20000\n",
      "gradient norm: 0.07726828903832939, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 7458 / 20000\n",
      "gradient norm: 0.08126361411996186, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 7459 / 20000\n",
      "gradient norm: 0.07879943225998431, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 7460 / 20000\n",
      "gradient norm: 0.07720355447963811, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 7461 / 20000\n",
      "gradient norm: 0.05767920828657225, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 7462 / 20000\n",
      "gradient norm: 0.0735718755167909, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 7463 / 20000\n",
      "gradient norm: 0.08183378202375025, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 7464 / 20000\n",
      "gradient norm: 0.0590992653160356, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 7465 / 20000\n",
      "gradient norm: 0.0916367377503775, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 7466 / 20000\n",
      "gradient norm: 0.05861717276275158, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 7467 / 20000\n",
      "gradient norm: 0.07791237393394113, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 7468 / 20000\n",
      "gradient norm: 0.06942160447943024, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 7469 / 20000\n",
      "gradient norm: 0.04164177633356303, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 7470 / 20000\n",
      "gradient norm: 0.07291126225027256, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00554\n",
      "epoch 7471 / 20000\n",
      "gradient norm: 0.04379625695582945, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 7472 / 20000\n",
      "gradient norm: 0.05619864599430002, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 7473 / 20000\n",
      "gradient norm: 0.05624309930135496, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00553\n",
      "epoch 7474 / 20000\n",
      "gradient norm: 0.04289489384973422, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 7475 / 20000\n",
      "gradient norm: 0.09357823443133384, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 7476 / 20000\n",
      "gradient norm: 0.08748617098899558, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 7477 / 20000\n",
      "gradient norm: 0.13840134046040475, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 7478 / 20000\n",
      "gradient norm: 0.062291346956044436, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 7479 / 20000\n",
      "gradient norm: 0.12597462791018188, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 7480 / 20000\n",
      "gradient norm: 0.09799027489498258, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00554\n",
      "epoch 7481 / 20000\n",
      "gradient norm: 0.11164025589823723, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00555\n",
      "epoch 7482 / 20000\n",
      "gradient norm: 0.15561752551002428, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00573\n",
      "\tval loss: 0.00551\n",
      "epoch 7483 / 20000\n",
      "gradient norm: 0.04894065426196903, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 7484 / 20000\n",
      "gradient norm: 0.09584426367655396, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00555\n",
      "epoch 7485 / 20000\n",
      "gradient norm: 0.06578913779230788, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 7486 / 20000\n",
      "gradient norm: 0.11722083180211484, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 7487 / 20000\n",
      "gradient norm: 0.11079028650419787, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 7488 / 20000\n",
      "gradient norm: 0.0836944094626233, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 7489 / 20000\n",
      "gradient norm: 0.08777879824629053, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00551\n",
      "epoch 7490 / 20000\n",
      "gradient norm: 0.08194262359756976, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 7491 / 20000\n",
      "gradient norm: 0.10888409236213192, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 7492 / 20000\n",
      "gradient norm: 0.09704966051504016, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00551\n",
      "epoch 7493 / 20000\n",
      "gradient norm: 0.05963643120776396, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 7494 / 20000\n",
      "gradient norm: 0.12855360622052103, minimum ratio: 2.460526315789474\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00555\n",
      "epoch 7495 / 20000\n",
      "gradient norm: 0.07490911800414324, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 7496 / 20000\n",
      "gradient norm: 0.05248239608772565, minimum ratio: 2.4894736842105267\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 7497 / 20000\n",
      "gradient norm: 0.05673265480436385, minimum ratio: 2.4736842105263155\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 7498 / 20000\n",
      "gradient norm: 0.04066508886171505, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 7499 / 20000\n",
      "gradient norm: 0.042606497096130624, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 7500 / 20000\n",
      "gradient norm: 0.037992372846929356, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 7501 / 20000\n",
      "gradient norm: 0.07262312271632254, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 7502 / 20000\n",
      "gradient norm: 0.08073074859566987, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 7503 / 20000\n",
      "gradient norm: 0.022178870072821155, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 7504 / 20000\n",
      "gradient norm: 0.03316896718752105, minimum ratio: 2.4421052631578943\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 7505 / 20000\n",
      "gradient norm: 0.03489833709318191, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 7506 / 20000\n",
      "gradient norm: 0.057741147524211556, minimum ratio: 2.460526315789474\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 7507 / 20000\n",
      "gradient norm: 0.03901074215536937, minimum ratio: 2.46578947368421\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 7508 / 20000\n",
      "gradient norm: 0.03809376921162766, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 7509 / 20000\n",
      "gradient norm: 0.039936339446285274, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 7510 / 20000\n",
      "gradient norm: 0.057029030736885034, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00553\n",
      "epoch 7511 / 20000\n",
      "gradient norm: 0.042794046632479876, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 7512 / 20000\n",
      "gradient norm: 0.08956982410745695, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 7513 / 20000\n",
      "gradient norm: 0.04055888269795105, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 7514 / 20000\n",
      "gradient norm: 0.0758115075295791, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 7515 / 20000\n",
      "gradient norm: 0.08453422006277833, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 7516 / 20000\n",
      "gradient norm: 0.0818672320456244, minimum ratio: 2.46578947368421\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 7517 / 20000\n",
      "gradient norm: 0.08956521359505132, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 7518 / 20000\n",
      "gradient norm: 0.11878501099999994, minimum ratio: 2.423684210526316\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 7519 / 20000\n",
      "gradient norm: 0.09037562637240626, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 7520 / 20000\n",
      "gradient norm: 0.06814428057987243, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 7521 / 20000\n",
      "gradient norm: 0.07531592744635418, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 7522 / 20000\n",
      "gradient norm: 0.07251518941484392, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00554\n",
      "epoch 7523 / 20000\n",
      "gradient norm: 0.05005687853554264, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 7524 / 20000\n",
      "gradient norm: 0.05070641124621034, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 7525 / 20000\n",
      "gradient norm: 0.0663284269394353, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 7526 / 20000\n",
      "gradient norm: 0.06186502627679147, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 7527 / 20000\n",
      "gradient norm: 0.09617339435499161, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 7528 / 20000\n",
      "gradient norm: 0.07013274522614665, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 7529 / 20000\n",
      "gradient norm: 0.08547859551617876, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00552\n",
      "epoch 7530 / 20000\n",
      "gradient norm: 0.09239418915240094, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 7531 / 20000\n",
      "gradient norm: 0.10978918964974582, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 7532 / 20000\n",
      "gradient norm: 0.11537336290348321, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 7533 / 20000\n",
      "gradient norm: 0.05898313972284086, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 7534 / 20000\n",
      "gradient norm: 0.04286282113753259, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 7535 / 20000\n",
      "gradient norm: 0.02727898771991022, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 7536 / 20000\n",
      "gradient norm: 0.04772517328092363, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 7537 / 20000\n",
      "gradient norm: 0.053112550638616085, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 7538 / 20000\n",
      "gradient norm: 0.07800146203953773, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 7539 / 20000\n",
      "gradient norm: 0.050647209922317415, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 7540 / 20000\n",
      "gradient norm: 0.05438129795220448, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 7541 / 20000\n",
      "gradient norm: 0.046408422909735236, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 7542 / 20000\n",
      "gradient norm: 0.044497050606878474, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 7543 / 20000\n",
      "gradient norm: 0.14473656855989248, minimum ratio: 2.465789473684211\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00551\n",
      "epoch 7544 / 20000\n",
      "gradient norm: 0.029601521280710585, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00553\n",
      "epoch 7545 / 20000\n",
      "gradient norm: 0.06407659559044987, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 7546 / 20000\n",
      "gradient norm: 0.029420285223750398, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 7547 / 20000\n",
      "gradient norm: 0.06730544765014201, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 7548 / 20000\n",
      "gradient norm: 0.0600341553799808, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 7549 / 20000\n",
      "gradient norm: 0.05102971075393725, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 7550 / 20000\n",
      "gradient norm: 0.07596786669455469, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 7551 / 20000\n",
      "gradient norm: 0.05857948903576471, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 7552 / 20000\n",
      "gradient norm: 0.05065148291760124, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 7553 / 20000\n",
      "gradient norm: 0.11697031173389405, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 7554 / 20000\n",
      "gradient norm: 0.07202108216006309, minimum ratio: 2.4815789473684213\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 7555 / 20000\n",
      "gradient norm: 0.0866958973929286, minimum ratio: 2.46578947368421\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 7556 / 20000\n",
      "gradient norm: 0.09803396416828036, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00555\n",
      "epoch 7557 / 20000\n",
      "gradient norm: 0.058430375589523464, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 7558 / 20000\n",
      "gradient norm: 0.0941617006319575, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 7559 / 20000\n",
      "gradient norm: 0.06534893193747848, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 7560 / 20000\n",
      "gradient norm: 0.0695496806583833, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 7561 / 20000\n",
      "gradient norm: 0.04299728821206372, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 7562 / 20000\n",
      "gradient norm: 0.08876645506825298, minimum ratio: 2.46578947368421\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 7563 / 20000\n",
      "gradient norm: 0.0702851798851043, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 7564 / 20000\n",
      "gradient norm: 0.08395253849448636, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 7565 / 20000\n",
      "gradient norm: 0.06117854034528136, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 7566 / 20000\n",
      "gradient norm: 0.05422500088752713, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00551\n",
      "epoch 7567 / 20000\n",
      "gradient norm: 0.07768125728762243, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 7568 / 20000\n",
      "gradient norm: 0.08320763011579402, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 7569 / 20000\n",
      "gradient norm: 0.10873508750228211, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 7570 / 20000\n",
      "gradient norm: 0.0517790351586882, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 7571 / 20000\n",
      "gradient norm: 0.0386245418631006, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 7572 / 20000\n",
      "gradient norm: 0.045875354524469, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 7573 / 20000\n",
      "gradient norm: 0.03504964936291799, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 7574 / 20000\n",
      "gradient norm: 0.08974591747391969, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 7575 / 20000\n",
      "gradient norm: 0.04983469922444783, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 7576 / 20000\n",
      "gradient norm: 0.08263077959418297, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 7577 / 20000\n",
      "gradient norm: 0.05733296406106092, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 7578 / 20000\n",
      "gradient norm: 0.05486490245675668, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 7579 / 20000\n",
      "gradient norm: 0.08888232958270237, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 7580 / 20000\n",
      "gradient norm: 0.08968069334514439, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 7581 / 20000\n",
      "gradient norm: 0.07113871519686654, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 7582 / 20000\n",
      "gradient norm: 0.06543925646110438, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 7583 / 20000\n",
      "gradient norm: 0.09060711949132383, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 7584 / 20000\n",
      "gradient norm: 0.10459524870384485, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 7585 / 20000\n",
      "gradient norm: 0.05332918278872967, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 7586 / 20000\n",
      "gradient norm: 0.025988977547967806, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 7587 / 20000\n",
      "gradient norm: 0.11311432963702828, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 7588 / 20000\n",
      "gradient norm: 0.07084695750381798, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 7589 / 20000\n",
      "gradient norm: 0.12062817200785503, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 7590 / 20000\n",
      "gradient norm: 0.07981960293545853, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 7591 / 20000\n",
      "gradient norm: 0.06688714621122926, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 7592 / 20000\n",
      "gradient norm: 0.13046988239511847, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 7593 / 20000\n",
      "gradient norm: 0.07078922603977844, minimum ratio: 2.4447368421052635\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 7594 / 20000\n",
      "gradient norm: 0.041778559068916366, minimum ratio: 2.465789473684211\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 7595 / 20000\n",
      "gradient norm: 0.05946122566820122, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 7596 / 20000\n",
      "gradient norm: 0.042361467581940815, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 7597 / 20000\n",
      "gradient norm: 0.0562677861598786, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 7598 / 20000\n",
      "gradient norm: 0.029078093779389746, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 7599 / 20000\n",
      "gradient norm: 0.05219208955168142, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 7600 / 20000\n",
      "gradient norm: 0.10076227795798331, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 7601 / 20000\n",
      "gradient norm: 0.047708825615700334, minimum ratio: 2.4842105263157896\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 7602 / 20000\n",
      "gradient norm: 0.08894050298840739, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 7603 / 20000\n",
      "gradient norm: 0.07241945741407108, minimum ratio: 2.4578947368421056\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 7604 / 20000\n",
      "gradient norm: 0.02049932276713662, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 7605 / 20000\n",
      "gradient norm: 0.058706840383820236, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 7606 / 20000\n",
      "gradient norm: 0.047848829824943095, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 7607 / 20000\n",
      "gradient norm: 0.044188885629409924, minimum ratio: 2.4499999999999997\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 7608 / 20000\n",
      "gradient norm: 0.036286772025050595, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 7609 / 20000\n",
      "gradient norm: 0.07893932718434371, minimum ratio: 2.4631578947368427\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 7610 / 20000\n",
      "gradient norm: 0.04642400398734026, minimum ratio: 2.465789473684211\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 7611 / 20000\n",
      "gradient norm: 0.11160534725058824, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 7612 / 20000\n",
      "gradient norm: 0.07948076393222436, minimum ratio: 2.4499999999999997\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 7613 / 20000\n",
      "gradient norm: 0.06758600263856351, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 7614 / 20000\n",
      "gradient norm: 0.0474080195708666, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 7615 / 20000\n",
      "gradient norm: 0.07666070549748838, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 7616 / 20000\n",
      "gradient norm: 0.045617443043738604, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 7617 / 20000\n",
      "gradient norm: 0.11934403283521533, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 7618 / 20000\n",
      "gradient norm: 0.04889953657402657, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 7619 / 20000\n",
      "gradient norm: 0.0799752582097426, minimum ratio: 2.4842105263157896\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 7620 / 20000\n",
      "gradient norm: 0.02473726074094884, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 7621 / 20000\n",
      "gradient norm: 0.06985723243269604, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 7622 / 20000\n",
      "gradient norm: 0.04855341138318181, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 7623 / 20000\n",
      "gradient norm: 0.031324342198786326, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 7624 / 20000\n",
      "gradient norm: 0.019544875278370455, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 7625 / 20000\n",
      "gradient norm: 0.07466970013774699, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 7626 / 20000\n",
      "gradient norm: 0.08844099308771547, minimum ratio: 2.4842105263157896\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 7627 / 20000\n",
      "gradient norm: 0.0610194740438601, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 7628 / 20000\n",
      "gradient norm: 0.12042231718078256, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00553\n",
      "epoch 7629 / 20000\n",
      "gradient norm: 0.036192304687574506, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 7630 / 20000\n",
      "gradient norm: 0.1423017786582932, minimum ratio: 2.4421052631578943\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 7631 / 20000\n",
      "gradient norm: 0.04654627537820488, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00555\n",
      "epoch 7632 / 20000\n",
      "gradient norm: 0.09143635502550751, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00553\n",
      "epoch 7633 / 20000\n",
      "gradient norm: 0.07786352722905576, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 7634 / 20000\n",
      "gradient norm: 0.061701960337813944, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 7635 / 20000\n",
      "gradient norm: 0.06508281256537884, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00555\n",
      "epoch 7636 / 20000\n",
      "gradient norm: 0.10207514034118503, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 7637 / 20000\n",
      "gradient norm: 0.1006916721817106, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 7638 / 20000\n",
      "gradient norm: 0.051087474334053695, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 7639 / 20000\n",
      "gradient norm: 0.1077974271029234, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00556\n",
      "epoch 7640 / 20000\n",
      "gradient norm: 0.049408729770220816, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 7641 / 20000\n",
      "gradient norm: 0.08264634932857007, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 7642 / 20000\n",
      "gradient norm: 0.11431857472052798, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 7643 / 20000\n",
      "gradient norm: 0.06275033616111614, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 7644 / 20000\n",
      "gradient norm: 0.026512815587921068, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 7645 / 20000\n",
      "gradient norm: 0.10093896515900269, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 7646 / 20000\n",
      "gradient norm: 0.07015593865071423, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 7647 / 20000\n",
      "gradient norm: 0.0717233718605712, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 7648 / 20000\n",
      "gradient norm: 0.05388712939748075, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 7649 / 20000\n",
      "gradient norm: 0.12470148666761816, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 7650 / 20000\n",
      "gradient norm: 0.039013954839902, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 7651 / 20000\n",
      "gradient norm: 0.06594047445105389, minimum ratio: 2.460526315789474\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 7652 / 20000\n",
      "gradient norm: 0.06502890534466133, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 7653 / 20000\n",
      "gradient norm: 0.131712106638588, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 7654 / 20000\n",
      "gradient norm: 0.08496558264596388, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 7655 / 20000\n",
      "gradient norm: 0.05998655816074461, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 7656 / 20000\n",
      "gradient norm: 0.08460871374700218, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00554\n",
      "epoch 7657 / 20000\n",
      "gradient norm: 0.06197201675968245, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 7658 / 20000\n",
      "gradient norm: 0.12879368802532554, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 7659 / 20000\n",
      "gradient norm: 0.06048867478966713, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00554\n",
      "epoch 7660 / 20000\n",
      "gradient norm: 0.07595409595523961, minimum ratio: 2.4842105263157896\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 7661 / 20000\n",
      "gradient norm: 0.07799897016957402, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00551\n",
      "epoch 7662 / 20000\n",
      "gradient norm: 0.06945204759540502, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 7663 / 20000\n",
      "gradient norm: 0.10483965091407299, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 7664 / 20000\n",
      "gradient norm: 0.038921282830415294, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 7665 / 20000\n",
      "gradient norm: 0.047329115368484054, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 7666 / 20000\n",
      "gradient norm: 0.03350790587137453, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 7667 / 20000\n",
      "gradient norm: 0.031463748644455336, minimum ratio: 2.4578947368421056\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 7668 / 20000\n",
      "gradient norm: 0.08102153544314206, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 7669 / 20000\n",
      "gradient norm: 0.07951369701186195, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 7670 / 20000\n",
      "gradient norm: 0.11631573986960575, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 7671 / 20000\n",
      "gradient norm: 0.05058106529759243, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 7672 / 20000\n",
      "gradient norm: 0.0881210298393853, minimum ratio: 2.460526315789474\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 7673 / 20000\n",
      "gradient norm: 0.06228277843911201, minimum ratio: 2.465789473684211\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 7674 / 20000\n",
      "gradient norm: 0.06769913039170206, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 7675 / 20000\n",
      "gradient norm: 0.06528062466531992, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 7676 / 20000\n",
      "gradient norm: 0.10580680740531534, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 7677 / 20000\n",
      "gradient norm: 0.06652021608897485, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 7678 / 20000\n",
      "gradient norm: 0.08694328989076894, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 7679 / 20000\n",
      "gradient norm: 0.06003273237729445, minimum ratio: 2.4868421052631575\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 7680 / 20000\n",
      "gradient norm: 0.07667490345193073, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 7681 / 20000\n",
      "gradient norm: 0.06593507478828542, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00551\n",
      "epoch 7682 / 20000\n",
      "gradient norm: 0.030598437937442213, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 7683 / 20000\n",
      "gradient norm: 0.04471762431785464, minimum ratio: 2.460526315789474\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 7684 / 20000\n",
      "gradient norm: 0.042042486340506, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 7685 / 20000\n",
      "gradient norm: 0.045395618391921744, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 7686 / 20000\n",
      "gradient norm: 0.05564055347349495, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 7687 / 20000\n",
      "gradient norm: 0.07870167406508699, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 7688 / 20000\n",
      "gradient norm: 0.0605429939168971, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 7689 / 20000\n",
      "gradient norm: 0.028005353029584512, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 7690 / 20000\n",
      "gradient norm: 0.030159529036609456, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 7691 / 20000\n",
      "gradient norm: 0.049346122599672526, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 7692 / 20000\n",
      "gradient norm: 0.08004201319999993, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 7693 / 20000\n",
      "gradient norm: 0.05413089206558652, minimum ratio: 2.4684210526315784\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 7694 / 20000\n",
      "gradient norm: 0.10039207764202729, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 7695 / 20000\n",
      "gradient norm: 0.04952586180297658, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 7696 / 20000\n",
      "gradient norm: 0.07524800853570923, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 7697 / 20000\n",
      "gradient norm: 0.05325922419433482, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 7698 / 20000\n",
      "gradient norm: 0.04714599656290375, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 7699 / 20000\n",
      "gradient norm: 0.05854337982600555, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 7700 / 20000\n",
      "gradient norm: 0.04367868759436533, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 7701 / 20000\n",
      "gradient norm: 0.12213090070872568, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 7702 / 20000\n",
      "gradient norm: 0.07309088471811265, minimum ratio: 2.4736842105263155\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 7703 / 20000\n",
      "gradient norm: 0.10720073344418779, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00552\n",
      "epoch 7704 / 20000\n",
      "gradient norm: 0.09601482434663922, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 7705 / 20000\n",
      "gradient norm: 0.04015700209129136, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 7706 / 20000\n",
      "gradient norm: 0.0513994584325701, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 7707 / 20000\n",
      "gradient norm: 0.059819439746206626, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 7708 / 20000\n",
      "gradient norm: 0.03126897703623399, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 7709 / 20000\n",
      "gradient norm: 0.01990829611895606, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 7710 / 20000\n",
      "gradient norm: 0.04766603623284027, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 7711 / 20000\n",
      "gradient norm: 0.06870122952386737, minimum ratio: 2.494736842105263\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 7712 / 20000\n",
      "gradient norm: 0.09235610786709003, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 7713 / 20000\n",
      "gradient norm: 0.031194104522000998, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 7714 / 20000\n",
      "gradient norm: 0.06627412175294012, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 7715 / 20000\n",
      "gradient norm: 0.03266143909422681, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 7716 / 20000\n",
      "gradient norm: 0.10283624031580985, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 7717 / 20000\n",
      "gradient norm: 0.06450830912217498, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 7718 / 20000\n",
      "gradient norm: 0.0695200200425461, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 7719 / 20000\n",
      "gradient norm: 0.0920102015370503, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 7720 / 20000\n",
      "gradient norm: 0.07352785940747708, minimum ratio: 2.4447368421052635\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 7721 / 20000\n",
      "gradient norm: 0.06223049940308556, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 7722 / 20000\n",
      "gradient norm: 0.03181072624283843, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 7723 / 20000\n",
      "gradient norm: 0.08861512620933354, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 7724 / 20000\n",
      "gradient norm: 0.0607475524302572, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 7725 / 20000\n",
      "gradient norm: 0.043903671321459115, minimum ratio: 2.465789473684211\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 7726 / 20000\n",
      "gradient norm: 0.04765344297629781, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 7727 / 20000\n",
      "gradient norm: 0.08058988588163629, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 7728 / 20000\n",
      "gradient norm: 0.047930094617186114, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 7729 / 20000\n",
      "gradient norm: 0.066467954631662, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 7730 / 20000\n",
      "gradient norm: 0.08861790364608169, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 7731 / 20000\n",
      "gradient norm: 0.06499965937109664, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 7732 / 20000\n",
      "gradient norm: 0.03515747663914226, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 7733 / 20000\n",
      "gradient norm: 0.061142940423451364, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 7734 / 20000\n",
      "gradient norm: 0.09390451724175364, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 7735 / 20000\n",
      "gradient norm: 0.062446551863104105, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 7736 / 20000\n",
      "gradient norm: 0.06058054041932337, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00552\n",
      "epoch 7737 / 20000\n",
      "gradient norm: 0.10120741039281711, minimum ratio: 2.4421052631578943\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 7738 / 20000\n",
      "gradient norm: 0.024994667721330188, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 7739 / 20000\n",
      "gradient norm: 0.12414664431707934, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 7740 / 20000\n",
      "gradient norm: 0.10579786379821599, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 7741 / 20000\n",
      "gradient norm: 0.095342606829945, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 7742 / 20000\n",
      "gradient norm: 0.06249169574584812, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00554\n",
      "epoch 7743 / 20000\n",
      "gradient norm: 0.11374942224938422, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 7744 / 20000\n",
      "gradient norm: 0.07750333065632731, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 7745 / 20000\n",
      "gradient norm: 0.036440490279346704, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 7746 / 20000\n",
      "gradient norm: 0.048339269851567224, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 7747 / 20000\n",
      "gradient norm: 0.060326900507789105, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 7748 / 20000\n",
      "gradient norm: 0.03098988125566393, minimum ratio: 2.460526315789474\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 7749 / 20000\n",
      "gradient norm: 0.052634983891039155, minimum ratio: 2.465789473684211\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 7750 / 20000\n",
      "gradient norm: 0.048955946642308845, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 7751 / 20000\n",
      "gradient norm: 0.023629051662283018, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 7752 / 20000\n",
      "gradient norm: 0.06106513398117386, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 7753 / 20000\n",
      "gradient norm: 0.04576247918885201, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 7754 / 20000\n",
      "gradient norm: 0.05860882415436208, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 7755 / 20000\n",
      "gradient norm: 0.049094728485215455, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 7756 / 20000\n",
      "gradient norm: 0.03059294902777765, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 7757 / 20000\n",
      "gradient norm: 0.054064475843915716, minimum ratio: 2.492105263157895\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 7758 / 20000\n",
      "gradient norm: 0.09257070545572788, minimum ratio: 2.4447368421052635\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 7759 / 20000\n",
      "gradient norm: 0.03570704101002775, minimum ratio: 2.465789473684211\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 7760 / 20000\n",
      "gradient norm: 0.06325645113975042, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 7761 / 20000\n",
      "gradient norm: 0.02896708217303967, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 7762 / 20000\n",
      "gradient norm: 0.1260587174911052, minimum ratio: 2.46578947368421\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 7763 / 20000\n",
      "gradient norm: 0.113872010842897, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 7764 / 20000\n",
      "gradient norm: 0.06617909151827917, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 7765 / 20000\n",
      "gradient norm: 0.030177961351000704, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 7766 / 20000\n",
      "gradient norm: 0.0629922445223201, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 7767 / 20000\n",
      "gradient norm: 0.04183633916545659, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 7768 / 20000\n",
      "gradient norm: 0.019574859805288725, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 7769 / 20000\n",
      "gradient norm: 0.04328015327337198, minimum ratio: 2.4394736842105265\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 7770 / 20000\n",
      "gradient norm: 0.04212279793864582, minimum ratio: 2.4842105263157896\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 7771 / 20000\n",
      "gradient norm: 0.07537171995500103, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 7772 / 20000\n",
      "gradient norm: 0.05737061286345124, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00553\n",
      "epoch 7773 / 20000\n",
      "gradient norm: 0.05100912507623434, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 7774 / 20000\n",
      "gradient norm: 0.04011160146910697, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 7775 / 20000\n",
      "gradient norm: 0.041896589973475784, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 7776 / 20000\n",
      "gradient norm: 0.0626391431724187, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 7777 / 20000\n",
      "gradient norm: 0.08309762162389234, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00552\n",
      "epoch 7778 / 20000\n",
      "gradient norm: 0.04806785291293636, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 7779 / 20000\n",
      "gradient norm: 0.06817750766640529, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 7780 / 20000\n",
      "gradient norm: 0.09221793740289286, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 7781 / 20000\n",
      "gradient norm: 0.0693633608170785, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 7782 / 20000\n",
      "gradient norm: 0.07007650274317712, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 7783 / 20000\n",
      "gradient norm: 0.08482263068435714, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 7784 / 20000\n",
      "gradient norm: 0.052123488421784714, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 7785 / 20000\n",
      "gradient norm: 0.08458253974094987, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 7786 / 20000\n",
      "gradient norm: 0.0902326685609296, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 7787 / 20000\n",
      "gradient norm: 0.06330908822201309, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 7788 / 20000\n",
      "gradient norm: 0.04713496322801802, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 7789 / 20000\n",
      "gradient norm: 0.06774552364367992, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 7790 / 20000\n",
      "gradient norm: 0.09871731838211417, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 7791 / 20000\n",
      "gradient norm: 0.05798593023791909, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 7792 / 20000\n",
      "gradient norm: 0.04276660020695999, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00552\n",
      "epoch 7793 / 20000\n",
      "gradient norm: 0.06568410852923989, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 7794 / 20000\n",
      "gradient norm: 0.0521404487953987, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 7795 / 20000\n",
      "gradient norm: 0.07306587276980281, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 7796 / 20000\n",
      "gradient norm: 0.02662186583620496, minimum ratio: 2.460526315789474\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 7797 / 20000\n",
      "gradient norm: 0.101819560630247, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 7798 / 20000\n",
      "gradient norm: 0.11822800134541467, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 7799 / 20000\n",
      "gradient norm: 0.05062806967180222, minimum ratio: 2.492105263157895\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00552\n",
      "epoch 7800 / 20000\n",
      "gradient norm: 0.09491369663737714, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 7801 / 20000\n",
      "gradient norm: 0.06578992313006893, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 7802 / 20000\n",
      "gradient norm: 0.053324755805078894, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 7803 / 20000\n",
      "gradient norm: 0.04728941910434514, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 7804 / 20000\n",
      "gradient norm: 0.03900906798662618, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 7805 / 20000\n",
      "gradient norm: 0.07761538660270162, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 7806 / 20000\n",
      "gradient norm: 0.0646760422096122, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 7807 / 20000\n",
      "gradient norm: 0.04951069538947195, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 7808 / 20000\n",
      "gradient norm: 0.09623363357968628, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 7809 / 20000\n",
      "gradient norm: 0.07128661131719127, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 7810 / 20000\n",
      "gradient norm: 0.07876221684273332, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 7811 / 20000\n",
      "gradient norm: 0.08745220169657841, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 7812 / 20000\n",
      "gradient norm: 0.0303641140635591, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 7813 / 20000\n",
      "gradient norm: 0.09071459926781245, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 7814 / 20000\n",
      "gradient norm: 0.08835735495085828, minimum ratio: 2.46578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 7815 / 20000\n",
      "gradient norm: 0.03391067692427896, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 7816 / 20000\n",
      "gradient norm: 0.0957999782403931, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 7817 / 20000\n",
      "gradient norm: 0.08335620310390368, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 7818 / 20000\n",
      "gradient norm: 0.13907703512813896, minimum ratio: 2.4868421052631575\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 7819 / 20000\n",
      "gradient norm: 0.05984505242668092, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 7820 / 20000\n",
      "gradient norm: 0.058983499446185306, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 7821 / 20000\n",
      "gradient norm: 0.10513590445043519, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 7822 / 20000\n",
      "gradient norm: 0.07343825703719631, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 7823 / 20000\n",
      "gradient norm: 0.08138919464545324, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 7824 / 20000\n",
      "gradient norm: 0.054824367514811456, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 7825 / 20000\n",
      "gradient norm: 0.08099315242725424, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 7826 / 20000\n",
      "gradient norm: 0.07105134066659957, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 7827 / 20000\n",
      "gradient norm: 0.09105014486704022, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 7828 / 20000\n",
      "gradient norm: 0.04167245625285432, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 7829 / 20000\n",
      "gradient norm: 0.08733108517481014, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 7830 / 20000\n",
      "gradient norm: 0.04946075056795962, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 7831 / 20000\n",
      "gradient norm: 0.06565935455728322, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 7832 / 20000\n",
      "gradient norm: 0.056322433694731444, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 7833 / 20000\n",
      "gradient norm: 0.05979856077465229, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 7834 / 20000\n",
      "gradient norm: 0.08018224069382995, minimum ratio: 2.4842105263157896\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 7835 / 20000\n",
      "gradient norm: 0.06297735532280058, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 7836 / 20000\n",
      "gradient norm: 0.06948057399131358, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 7837 / 20000\n",
      "gradient norm: 0.04986177809769288, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 7838 / 20000\n",
      "gradient norm: 0.0123900615144521, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00551\n",
      "epoch 7839 / 20000\n",
      "gradient norm: 0.06311383738648146, minimum ratio: 2.489473684210526\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 7840 / 20000\n",
      "gradient norm: 0.051648283610120416, minimum ratio: 2.4894736842105267\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 7841 / 20000\n",
      "gradient norm: 0.09709558158647269, minimum ratio: 2.46578947368421\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 7842 / 20000\n",
      "gradient norm: 0.08127809769939631, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00551\n",
      "epoch 7843 / 20000\n",
      "gradient norm: 0.08706951398926321, minimum ratio: 2.4815789473684213\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 7844 / 20000\n",
      "gradient norm: 0.056060583563521504, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 7845 / 20000\n",
      "gradient norm: 0.06278759724227712, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 7846 / 20000\n",
      "gradient norm: 0.053683455917052925, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 7847 / 20000\n",
      "gradient norm: 0.09416853246511891, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 7848 / 20000\n",
      "gradient norm: 0.11305371526395902, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00551\n",
      "epoch 7849 / 20000\n",
      "gradient norm: 0.05007131354068406, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 7850 / 20000\n",
      "gradient norm: 0.12436045811045915, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 7851 / 20000\n",
      "gradient norm: 0.03559663306805305, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 7852 / 20000\n",
      "gradient norm: 0.0923093871679157, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 7853 / 20000\n",
      "gradient norm: 0.07957320322748274, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 7854 / 20000\n",
      "gradient norm: 0.04047200971399434, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 7855 / 20000\n",
      "gradient norm: 0.0718632954522036, minimum ratio: 2.4499999999999997\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 7856 / 20000\n",
      "gradient norm: 0.07273411689675413, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 7857 / 20000\n",
      "gradient norm: 0.05840983899543062, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 7858 / 20000\n",
      "gradient norm: 0.046430632879491895, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 7859 / 20000\n",
      "gradient norm: 0.06217503285733983, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 7860 / 20000\n",
      "gradient norm: 0.032033712952397764, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 7861 / 20000\n",
      "gradient norm: 0.04682341520674527, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 7862 / 20000\n",
      "gradient norm: 0.022253908828133717, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 7863 / 20000\n",
      "gradient norm: 0.08871354395523667, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 7864 / 20000\n",
      "gradient norm: 0.04884763875452336, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 7865 / 20000\n",
      "gradient norm: 0.06533819185278844, minimum ratio: 2.4736842105263155\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 7866 / 20000\n",
      "gradient norm: 0.09479548461968079, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 7867 / 20000\n",
      "gradient norm: 0.07616546849021688, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 7868 / 20000\n",
      "gradient norm: 0.0497893720457796, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 7869 / 20000\n",
      "gradient norm: 0.0718773401749786, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 7870 / 20000\n",
      "gradient norm: 0.046678088285261765, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 7871 / 20000\n",
      "gradient norm: 0.061903497989987954, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00551\n",
      "epoch 7872 / 20000\n",
      "gradient norm: 0.07193009206093848, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 7873 / 20000\n",
      "gradient norm: 0.08598187583265826, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 7874 / 20000\n",
      "gradient norm: 0.07725787203526124, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 7875 / 20000\n",
      "gradient norm: 0.08410999405896291, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 7876 / 20000\n",
      "gradient norm: 0.048447146866237745, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 7877 / 20000\n",
      "gradient norm: 0.04910497338278219, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 7878 / 20000\n",
      "gradient norm: 0.04693515054532327, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00551\n",
      "epoch 7879 / 20000\n",
      "gradient norm: 0.09502075234195217, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 7880 / 20000\n",
      "gradient norm: 0.04304914176464081, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 7881 / 20000\n",
      "gradient norm: 0.05848348294966854, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 7882 / 20000\n",
      "gradient norm: 0.08121092413784936, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 7883 / 20000\n",
      "gradient norm: 0.040399051023996435, minimum ratio: 2.4815789473684213\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 7884 / 20000\n",
      "gradient norm: 0.049815573962405324, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 7885 / 20000\n",
      "gradient norm: 0.026039778866106644, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 7886 / 20000\n",
      "gradient norm: 0.08380282972939312, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 7887 / 20000\n",
      "gradient norm: 0.047385592974023893, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 7888 / 20000\n",
      "gradient norm: 0.05462845985312015, minimum ratio: 2.46578947368421\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 7889 / 20000\n",
      "gradient norm: 0.07515725411940366, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 7890 / 20000\n",
      "gradient norm: 0.07475059886928648, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 7891 / 20000\n",
      "gradient norm: 0.06522591403336264, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00552\n",
      "epoch 7892 / 20000\n",
      "gradient norm: 0.04107668297365308, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 7893 / 20000\n",
      "gradient norm: 0.05823065301592578, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 7894 / 20000\n",
      "gradient norm: 0.05039539613062516, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 7895 / 20000\n",
      "gradient norm: 0.0858163425582461, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 7896 / 20000\n",
      "gradient norm: 0.09386897628428414, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 7897 / 20000\n",
      "gradient norm: 0.0667278695909772, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 7898 / 20000\n",
      "gradient norm: 0.07326229507452808, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 7899 / 20000\n",
      "gradient norm: 0.0826676414872054, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 7900 / 20000\n",
      "gradient norm: 0.043652854539686814, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 7901 / 20000\n",
      "gradient norm: 0.05202714930055663, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 7902 / 20000\n",
      "gradient norm: 0.050124812114518136, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00551\n",
      "epoch 7903 / 20000\n",
      "gradient norm: 0.09548555703077, minimum ratio: 2.46578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 7904 / 20000\n",
      "gradient norm: 0.07047836948186159, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 7905 / 20000\n",
      "gradient norm: 0.08763533388264477, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 7906 / 20000\n",
      "gradient norm: 0.08149453878286295, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 7907 / 20000\n",
      "gradient norm: 0.05009487828647252, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 7908 / 20000\n",
      "gradient norm: 0.07374814213835634, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 7909 / 20000\n",
      "gradient norm: 0.10804291849490255, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 7910 / 20000\n",
      "gradient norm: 0.08235183198121376, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 7911 / 20000\n",
      "gradient norm: 0.036427798186196014, minimum ratio: 2.46578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 7912 / 20000\n",
      "gradient norm: 0.09424806211609393, minimum ratio: 2.465789473684211\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 7913 / 20000\n",
      "gradient norm: 0.07210472656879574, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 7914 / 20000\n",
      "gradient norm: 0.07606478733941913, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 7915 / 20000\n",
      "gradient norm: 0.08026938833063468, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 7916 / 20000\n",
      "gradient norm: 0.05641974578611553, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 7917 / 20000\n",
      "gradient norm: 0.09356302744708955, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 7918 / 20000\n",
      "gradient norm: 0.05642313283169642, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 7919 / 20000\n",
      "gradient norm: 0.074556746694725, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 7920 / 20000\n",
      "gradient norm: 0.06085755804087967, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 7921 / 20000\n",
      "gradient norm: 0.04536052451294381, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 7922 / 20000\n",
      "gradient norm: 0.08861394628183916, minimum ratio: 2.465789473684211\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 7923 / 20000\n",
      "gradient norm: 0.05274004410603084, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 7924 / 20000\n",
      "gradient norm: 0.04579768673283979, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 7925 / 20000\n",
      "gradient norm: 0.022334794979542494, minimum ratio: 2.4894736842105267\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 7926 / 20000\n",
      "gradient norm: 0.06300699498387985, minimum ratio: 2.4815789473684213\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 7927 / 20000\n",
      "gradient norm: 0.0759583639446646, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 7928 / 20000\n",
      "gradient norm: 0.10392013809178025, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 7929 / 20000\n",
      "gradient norm: 0.1227553723147139, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 7930 / 20000\n",
      "gradient norm: 0.07098055677488446, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 7931 / 20000\n",
      "gradient norm: 0.05786291154799983, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 7932 / 20000\n",
      "gradient norm: 0.0796851587947458, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 7933 / 20000\n",
      "gradient norm: 0.05856656297692098, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 7934 / 20000\n",
      "gradient norm: 0.06163670677051414, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 7935 / 20000\n",
      "gradient norm: 0.04338888538768515, minimum ratio: 2.4815789473684213\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 7936 / 20000\n",
      "gradient norm: 0.09572252578800544, minimum ratio: 2.4736842105263155\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 7937 / 20000\n",
      "gradient norm: 0.14133644622052088, minimum ratio: 2.46578947368421\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00551\n",
      "epoch 7938 / 20000\n",
      "gradient norm: 0.09034003660781309, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00555\n",
      "epoch 7939 / 20000\n",
      "gradient norm: 0.08731061383150518, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 7940 / 20000\n",
      "gradient norm: 0.07520395411120262, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 7941 / 20000\n",
      "gradient norm: 0.05870750968460925, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 7942 / 20000\n",
      "gradient norm: 0.04896759119583294, minimum ratio: 2.4447368421052635\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 7943 / 20000\n",
      "gradient norm: 0.09136422595474869, minimum ratio: 2.492105263157894\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 7944 / 20000\n",
      "gradient norm: 0.052807507396209985, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 7945 / 20000\n",
      "gradient norm: 0.06082925639930181, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 7946 / 20000\n",
      "gradient norm: 0.06417698989389464, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 7947 / 20000\n",
      "gradient norm: 0.0599224588368088, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 7948 / 20000\n",
      "gradient norm: 0.05801891317241825, minimum ratio: 2.4842105263157896\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 7949 / 20000\n",
      "gradient norm: 0.049540042906301096, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 7950 / 20000\n",
      "gradient norm: 0.035743444139370695, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 7951 / 20000\n",
      "gradient norm: 0.10438817297108471, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 7952 / 20000\n",
      "gradient norm: 0.05952670032274909, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00555\n",
      "epoch 7953 / 20000\n",
      "gradient norm: 0.058509714144747704, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 7954 / 20000\n",
      "gradient norm: 0.04859745316207409, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 7955 / 20000\n",
      "gradient norm: 0.029454705378157087, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 7956 / 20000\n",
      "gradient norm: 0.08364669175352901, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 7957 / 20000\n",
      "gradient norm: 0.060805239801993594, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 7958 / 20000\n",
      "gradient norm: 0.06044855181244202, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 7959 / 20000\n",
      "gradient norm: 0.07818694692105055, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 7960 / 20000\n",
      "gradient norm: 0.06802338268607855, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 7961 / 20000\n",
      "gradient norm: 0.10079180565662682, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 7962 / 20000\n",
      "gradient norm: 0.07651920814532787, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 7963 / 20000\n",
      "gradient norm: 0.043688968900823966, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 7964 / 20000\n",
      "gradient norm: 0.07486710150260478, minimum ratio: 2.492105263157895\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 7965 / 20000\n",
      "gradient norm: 0.08165252330945805, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 7966 / 20000\n",
      "gradient norm: 0.04059778794180602, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 7967 / 20000\n",
      "gradient norm: 0.07306481199339032, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 7968 / 20000\n",
      "gradient norm: 0.07587461860384792, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 7969 / 20000\n",
      "gradient norm: 0.05485635361401364, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 7970 / 20000\n",
      "gradient norm: 0.04537476290715858, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 7971 / 20000\n",
      "gradient norm: 0.04840767763380427, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 7972 / 20000\n",
      "gradient norm: 0.11496109864674509, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 7973 / 20000\n",
      "gradient norm: 0.09218815956410253, minimum ratio: 2.4868421052631575\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 7974 / 20000\n",
      "gradient norm: 0.05944169289432466, minimum ratio: 2.4842105263157896\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 7975 / 20000\n",
      "gradient norm: 0.10456661868374795, minimum ratio: 2.4868421052631575\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 7976 / 20000\n",
      "gradient norm: 0.06598708935780451, minimum ratio: 2.4578947368421056\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 7977 / 20000\n",
      "gradient norm: 0.07977038901299238, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 7978 / 20000\n",
      "gradient norm: 0.07484486332396045, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00555\n",
      "epoch 7979 / 20000\n",
      "gradient norm: 0.05873236060142517, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 7980 / 20000\n",
      "gradient norm: 0.09156193304806948, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 7981 / 20000\n",
      "gradient norm: 0.07705502363387495, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 7982 / 20000\n",
      "gradient norm: 0.08572364808060229, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00554\n",
      "epoch 7983 / 20000\n",
      "gradient norm: 0.06237635953584686, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 7984 / 20000\n",
      "gradient norm: 0.09286986285587773, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00551\n",
      "epoch 7985 / 20000\n",
      "gradient norm: 0.04303435853216797, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00555\n",
      "epoch 7986 / 20000\n",
      "gradient norm: 0.09008872671984136, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 7987 / 20000\n",
      "gradient norm: 0.05387793271802366, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 7988 / 20000\n",
      "gradient norm: 0.07784737733891234, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 7989 / 20000\n",
      "gradient norm: 0.058362589799799025, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00554\n",
      "epoch 7990 / 20000\n",
      "gradient norm: 0.04624137579230592, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 7991 / 20000\n",
      "gradient norm: 0.057468066341243684, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 7992 / 20000\n",
      "gradient norm: 0.08077461482025683, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 7993 / 20000\n",
      "gradient norm: 0.04873777856118977, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 7994 / 20000\n",
      "gradient norm: 0.07450992241501808, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 7995 / 20000\n",
      "gradient norm: 0.04720086662564427, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 7996 / 20000\n",
      "gradient norm: 0.04629311361350119, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 7997 / 20000\n",
      "gradient norm: 0.0797859996673651, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 7998 / 20000\n",
      "gradient norm: 0.029871194623410702, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 7999 / 20000\n",
      "gradient norm: 0.06871940186829306, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 8000 / 20000\n",
      "gradient norm: 0.08815320720896125, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8001 / 20000\n",
      "gradient norm: 0.03961537350551225, minimum ratio: 2.492105263157895\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 8002 / 20000\n",
      "gradient norm: 0.050148659909609705, minimum ratio: 2.492105263157895\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 8003 / 20000\n",
      "gradient norm: 0.05977638181866496, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 8004 / 20000\n",
      "gradient norm: 0.11729498981731012, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 8005 / 20000\n",
      "gradient norm: 0.08025203738361597, minimum ratio: 2.4842105263157896\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 8006 / 20000\n",
      "gradient norm: 0.07819782715523615, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 8007 / 20000\n",
      "gradient norm: 0.1197366988635622, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8008 / 20000\n",
      "gradient norm: 0.08323050028411672, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 8009 / 20000\n",
      "gradient norm: 0.051574020442785695, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 8010 / 20000\n",
      "gradient norm: 0.13125576492166147, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 8011 / 20000\n",
      "gradient norm: 0.06513595808064565, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 8012 / 20000\n",
      "gradient norm: 0.027243768476182595, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8013 / 20000\n",
      "gradient norm: 0.07566189899807796, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8014 / 20000\n",
      "gradient norm: 0.05975085942191072, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 8015 / 20000\n",
      "gradient norm: 0.09339451330015436, minimum ratio: 2.492105263157895\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8016 / 20000\n",
      "gradient norm: 0.10363148839678615, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00555\n",
      "epoch 8017 / 20000\n",
      "gradient norm: 0.03795931956847198, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 8018 / 20000\n",
      "gradient norm: 0.08023382985265926, minimum ratio: 2.492105263157895\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 8019 / 20000\n",
      "gradient norm: 0.057759520277613774, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 8020 / 20000\n",
      "gradient norm: 0.06977344275219366, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 8021 / 20000\n",
      "gradient norm: 0.07370609766803682, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 8022 / 20000\n",
      "gradient norm: 0.07790129998466, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 8023 / 20000\n",
      "gradient norm: 0.1056947220931761, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 8024 / 20000\n",
      "gradient norm: 0.04042452840076294, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 8025 / 20000\n",
      "gradient norm: 0.14444303372874856, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 8026 / 20000\n",
      "gradient norm: 0.0550957819505129, minimum ratio: 2.46578947368421\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 8027 / 20000\n",
      "gradient norm: 0.07178058952558786, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8028 / 20000\n",
      "gradient norm: 0.027569614352614735, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8029 / 20000\n",
      "gradient norm: 0.07726874545915052, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8030 / 20000\n",
      "gradient norm: 0.011188014112121891, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8031 / 20000\n",
      "gradient norm: 0.04215249326080084, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 8032 / 20000\n",
      "gradient norm: 0.08021206932608038, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 8033 / 20000\n",
      "gradient norm: 0.05156872846418992, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8034 / 20000\n",
      "gradient norm: 0.12635725736618042, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 8035 / 20000\n",
      "gradient norm: 0.12089493498206139, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00551\n",
      "epoch 8036 / 20000\n",
      "gradient norm: 0.05686060560401529, minimum ratio: 2.4815789473684213\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8037 / 20000\n",
      "gradient norm: 0.04673938514315523, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00553\n",
      "epoch 8038 / 20000\n",
      "gradient norm: 0.07672626443672925, minimum ratio: 2.4815789473684213\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00552\n",
      "epoch 8039 / 20000\n",
      "gradient norm: 0.04925606001052074, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 8040 / 20000\n",
      "gradient norm: 0.03316192091733683, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 8041 / 20000\n",
      "gradient norm: 0.06629654101561755, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 8042 / 20000\n",
      "gradient norm: 0.08715424325782806, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 8043 / 20000\n",
      "gradient norm: 0.07233392627676949, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 8044 / 20000\n",
      "gradient norm: 0.07613879794371314, minimum ratio: 2.46578947368421\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 8045 / 20000\n",
      "gradient norm: 0.10081566794542596, minimum ratio: 2.4868421052631575\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 8046 / 20000\n",
      "gradient norm: 0.05086085060611367, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00551\n",
      "epoch 8047 / 20000\n",
      "gradient norm: 0.06984680122695863, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 8048 / 20000\n",
      "gradient norm: 0.05118239833973348, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 8049 / 20000\n",
      "gradient norm: 0.07847557155764662, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8050 / 20000\n",
      "gradient norm: 0.07663473137654364, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 8051 / 20000\n",
      "gradient norm: 0.04848564226995222, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 8052 / 20000\n",
      "gradient norm: 0.029759345576167107, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8053 / 20000\n",
      "gradient norm: 0.05078938973019831, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 8054 / 20000\n",
      "gradient norm: 0.03574316511367215, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 8055 / 20000\n",
      "gradient norm: 0.11547683086246252, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 8056 / 20000\n",
      "gradient norm: 0.0818824652233161, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 8057 / 20000\n",
      "gradient norm: 0.04204379633301869, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 8058 / 20000\n",
      "gradient norm: 0.08972682850435376, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8059 / 20000\n",
      "gradient norm: 0.05229041015263647, minimum ratio: 2.4868421052631575\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8060 / 20000\n",
      "gradient norm: 0.018390444274700712, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 8061 / 20000\n",
      "gradient norm: 0.08112436986993998, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8062 / 20000\n",
      "gradient norm: 0.04788561078021303, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 8063 / 20000\n",
      "gradient norm: 0.03279717519762926, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8064 / 20000\n",
      "gradient norm: 0.05468562833266333, minimum ratio: 2.4736842105263155\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 8065 / 20000\n",
      "gradient norm: 0.10763315408257768, minimum ratio: 2.4842105263157896\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 8066 / 20000\n",
      "gradient norm: 0.07960087215178646, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8067 / 20000\n",
      "gradient norm: 0.06770789589791093, minimum ratio: 2.4842105263157896\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8068 / 20000\n",
      "gradient norm: 0.05040548462420702, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 8069 / 20000\n",
      "gradient norm: 0.06961170141585171, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8070 / 20000\n",
      "gradient norm: 0.07013035845011473, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 8071 / 20000\n",
      "gradient norm: 0.0476693402742967, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 8072 / 20000\n",
      "gradient norm: 0.04140731377992779, minimum ratio: 2.4868421052631575\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8073 / 20000\n",
      "gradient norm: 0.05373317049816251, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 8074 / 20000\n",
      "gradient norm: 0.036745454439369496, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8075 / 20000\n",
      "gradient norm: 0.07175389339681715, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 8076 / 20000\n",
      "gradient norm: 0.09682537388289347, minimum ratio: 2.4842105263157896\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 8077 / 20000\n",
      "gradient norm: 0.09178689896361902, minimum ratio: 2.489473684210526\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 8078 / 20000\n",
      "gradient norm: 0.05231700820149854, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 8079 / 20000\n",
      "gradient norm: 0.06626559898722917, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8080 / 20000\n",
      "gradient norm: 0.07907083071768284, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 8081 / 20000\n",
      "gradient norm: 0.07724671578034759, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 8082 / 20000\n",
      "gradient norm: 0.09341986748040654, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 8083 / 20000\n",
      "gradient norm: 0.13047272543190047, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 8084 / 20000\n",
      "gradient norm: 0.06342384332674555, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 8085 / 20000\n",
      "gradient norm: 0.05067772831534967, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 8086 / 20000\n",
      "gradient norm: 0.028044156948453747, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8087 / 20000\n",
      "gradient norm: 0.05073734396137297, minimum ratio: 2.4894736842105267\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8088 / 20000\n",
      "gradient norm: 0.07532646121399011, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8089 / 20000\n",
      "gradient norm: 0.05176392931025475, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8090 / 20000\n",
      "gradient norm: 0.04666769571485929, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8091 / 20000\n",
      "gradient norm: 0.037109158365637995, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 8092 / 20000\n",
      "gradient norm: 0.08816720673348755, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 8093 / 20000\n",
      "gradient norm: 0.07982690149219707, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 8094 / 20000\n",
      "gradient norm: 0.04520819551544264, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8095 / 20000\n",
      "gradient norm: 0.05937151500256732, minimum ratio: 2.492105263157895\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 8096 / 20000\n",
      "gradient norm: 0.04092123369628098, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 8097 / 20000\n",
      "gradient norm: 0.07394110133463982, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8098 / 20000\n",
      "gradient norm: 0.061877664527855814, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 8099 / 20000\n",
      "gradient norm: 0.09739301929948851, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 8100 / 20000\n",
      "gradient norm: 0.037857221730519086, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8101 / 20000\n",
      "gradient norm: 0.0366842845978681, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8102 / 20000\n",
      "gradient norm: 0.03620245691854507, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8103 / 20000\n",
      "gradient norm: 0.036331507879367564, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 8104 / 20000\n",
      "gradient norm: 0.05485408290405758, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 8105 / 20000\n",
      "gradient norm: 0.0686904297908768, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8106 / 20000\n",
      "gradient norm: 0.056777078949380666, minimum ratio: 2.489473684210526\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 8107 / 20000\n",
      "gradient norm: 0.09133911051321775, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 8108 / 20000\n",
      "gradient norm: 0.057602339395089075, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 8109 / 20000\n",
      "gradient norm: 0.05022353513049893, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 8110 / 20000\n",
      "gradient norm: 0.058897585317026824, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 8111 / 20000\n",
      "gradient norm: 0.06966862821718678, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 8112 / 20000\n",
      "gradient norm: 0.039572534937178716, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 8113 / 20000\n",
      "gradient norm: 0.06641086176387034, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 8114 / 20000\n",
      "gradient norm: 0.13862678501755, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 8115 / 20000\n",
      "gradient norm: 0.07247693632962182, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 8116 / 20000\n",
      "gradient norm: 0.07158720021834597, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8117 / 20000\n",
      "gradient norm: 0.10159853560617194, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 8118 / 20000\n",
      "gradient norm: 0.04258164085331373, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 8119 / 20000\n",
      "gradient norm: 0.06505817429751914, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8120 / 20000\n",
      "gradient norm: 0.08107381855370477, minimum ratio: 2.4868421052631575\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 8121 / 20000\n",
      "gradient norm: 0.08897436026018113, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8122 / 20000\n",
      "gradient norm: 0.030211968754883856, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8123 / 20000\n",
      "gradient norm: 0.028101952804718167, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8124 / 20000\n",
      "gradient norm: 0.07854587014298886, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8125 / 20000\n",
      "gradient norm: 0.07930756245332304, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 8126 / 20000\n",
      "gradient norm: 0.03644140239339322, minimum ratio: 2.46578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8127 / 20000\n",
      "gradient norm: 0.06299742293776944, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 8128 / 20000\n",
      "gradient norm: 0.07158349675592035, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 8129 / 20000\n",
      "gradient norm: 0.01906101823260542, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 8130 / 20000\n",
      "gradient norm: 0.11897229962050915, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8131 / 20000\n",
      "gradient norm: 0.04133420638390817, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 8132 / 20000\n",
      "gradient norm: 0.028770496799552348, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 8133 / 20000\n",
      "gradient norm: 0.03238306914863642, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 8134 / 20000\n",
      "gradient norm: 0.01485736103495583, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8135 / 20000\n",
      "gradient norm: 0.10105110914446414, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 8136 / 20000\n",
      "gradient norm: 0.06795098465227056, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 8137 / 20000\n",
      "gradient norm: 0.09320403204765171, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8138 / 20000\n",
      "gradient norm: 0.06815400197956478, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8139 / 20000\n",
      "gradient norm: 0.06318446563091129, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 8140 / 20000\n",
      "gradient norm: 0.07706450263503939, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 8141 / 20000\n",
      "gradient norm: 0.07349437638185918, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8142 / 20000\n",
      "gradient norm: 0.03636848185851704, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8143 / 20000\n",
      "gradient norm: 0.10190860799048096, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 8144 / 20000\n",
      "gradient norm: 0.09281842352356762, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8145 / 20000\n",
      "gradient norm: 0.08195189491380006, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00555\n",
      "epoch 8146 / 20000\n",
      "gradient norm: 0.1172485495917499, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 8147 / 20000\n",
      "gradient norm: 0.07461030792910606, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 8148 / 20000\n",
      "gradient norm: 0.07282521724118851, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 8149 / 20000\n",
      "gradient norm: 0.05262115961522795, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 8150 / 20000\n",
      "gradient norm: 0.03804645519994665, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8151 / 20000\n",
      "gradient norm: 0.04495950089767575, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 8152 / 20000\n",
      "gradient norm: 0.06504133035195991, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 8153 / 20000\n",
      "gradient norm: 0.027998656034469604, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8154 / 20000\n",
      "gradient norm: 0.057693984563229606, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 8155 / 20000\n",
      "gradient norm: 0.0602051371242851, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 8156 / 20000\n",
      "gradient norm: 0.09500450911582448, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 8157 / 20000\n",
      "gradient norm: 0.08355650247540325, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00552\n",
      "epoch 8158 / 20000\n",
      "gradient norm: 0.061357288592262194, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 8159 / 20000\n",
      "gradient norm: 0.0868359963351395, minimum ratio: 2.507894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 8160 / 20000\n",
      "gradient norm: 0.06775092062889598, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 8161 / 20000\n",
      "gradient norm: 0.048963536450173706, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8162 / 20000\n",
      "gradient norm: 0.04314468636584934, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8163 / 20000\n",
      "gradient norm: 0.053351975919213146, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 8164 / 20000\n",
      "gradient norm: 0.07818413130007684, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8165 / 20000\n",
      "gradient norm: 0.043594808637863025, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 8166 / 20000\n",
      "gradient norm: 0.03493199485819787, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 8167 / 20000\n",
      "gradient norm: 0.026700879345298745, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 8168 / 20000\n",
      "gradient norm: 0.0545541812753072, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8169 / 20000\n",
      "gradient norm: 0.05270796085096663, minimum ratio: 2.4736842105263155\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8170 / 20000\n",
      "gradient norm: 0.04460600661695935, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 8171 / 20000\n",
      "gradient norm: 0.03980669871089049, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 8172 / 20000\n",
      "gradient norm: 0.04528691837913357, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8173 / 20000\n",
      "gradient norm: 0.07058047380996868, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 8174 / 20000\n",
      "gradient norm: 0.04646137246163562, minimum ratio: 2.494736842105263\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 8175 / 20000\n",
      "gradient norm: 0.018777467936160974, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8176 / 20000\n",
      "gradient norm: 0.046943907625973225, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 8177 / 20000\n",
      "gradient norm: 0.07986792011070065, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 8178 / 20000\n",
      "gradient norm: 0.04502626467728987, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 8179 / 20000\n",
      "gradient norm: 0.06242879998171702, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 8180 / 20000\n",
      "gradient norm: 0.03803017194150016, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 8181 / 20000\n",
      "gradient norm: 0.040663829538971186, minimum ratio: 2.465789473684211\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 8182 / 20000\n",
      "gradient norm: 0.0719169091025833, minimum ratio: 2.4631578947368427\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 8183 / 20000\n",
      "gradient norm: 0.05969735042890534, minimum ratio: 2.4736842105263155\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8184 / 20000\n",
      "gradient norm: 0.04864140407880768, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 8185 / 20000\n",
      "gradient norm: 0.0600976143614389, minimum ratio: 2.460526315789474\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 8186 / 20000\n",
      "gradient norm: 0.048924901260761544, minimum ratio: 2.492105263157895\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 8187 / 20000\n",
      "gradient norm: 0.042358481674455106, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 8188 / 20000\n",
      "gradient norm: 0.07060199923580512, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 8189 / 20000\n",
      "gradient norm: 0.08302623120835051, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8190 / 20000\n",
      "gradient norm: 0.0522300997399725, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 8191 / 20000\n",
      "gradient norm: 0.0549237272789469, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8192 / 20000\n",
      "gradient norm: 0.07470638497034088, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 8193 / 20000\n",
      "gradient norm: 0.07405815942911431, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 8194 / 20000\n",
      "gradient norm: 0.061739534088701475, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8195 / 20000\n",
      "gradient norm: 0.042091927432920784, minimum ratio: 2.4868421052631575\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8196 / 20000\n",
      "gradient norm: 0.058759617095347494, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 8197 / 20000\n",
      "gradient norm: 0.03744027824723162, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8198 / 20000\n",
      "gradient norm: 0.07431479773367755, minimum ratio: 2.4815789473684213\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 8199 / 20000\n",
      "gradient norm: 0.07804340199800208, minimum ratio: 2.4842105263157896\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 8200 / 20000\n",
      "gradient norm: 0.06055771523097064, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 8201 / 20000\n",
      "gradient norm: 0.04754701354249846, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 8202 / 20000\n",
      "gradient norm: 0.06526073791246745, minimum ratio: 2.4394736842105265\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 8203 / 20000\n",
      "gradient norm: 0.07374885585159063, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8204 / 20000\n",
      "gradient norm: 0.0802063611918129, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 8205 / 20000\n",
      "gradient norm: 0.05362537218024954, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 8206 / 20000\n",
      "gradient norm: 0.09455181390512735, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 8207 / 20000\n",
      "gradient norm: 0.03983851979137398, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 8208 / 20000\n",
      "gradient norm: 0.05088892744970508, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 8209 / 20000\n",
      "gradient norm: 0.05703336972510442, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8210 / 20000\n",
      "gradient norm: 0.06304351799190044, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 8211 / 20000\n",
      "gradient norm: 0.04389546069432981, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8212 / 20000\n",
      "gradient norm: 0.04145732059259899, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8213 / 20000\n",
      "gradient norm: 0.11734135961160064, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00553\n",
      "epoch 8214 / 20000\n",
      "gradient norm: 0.05562657315749675, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 8215 / 20000\n",
      "gradient norm: 0.049351584049873054, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 8216 / 20000\n",
      "gradient norm: 0.0738574733841233, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 8217 / 20000\n",
      "gradient norm: 0.0955544461030513, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 8218 / 20000\n",
      "gradient norm: 0.05534620472462848, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 8219 / 20000\n",
      "gradient norm: 0.08490683021955192, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8220 / 20000\n",
      "gradient norm: 0.0336900947149843, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 8221 / 20000\n",
      "gradient norm: 0.08427241568278987, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 8222 / 20000\n",
      "gradient norm: 0.07635003776522353, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 8223 / 20000\n",
      "gradient norm: 0.06360711963498034, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 8224 / 20000\n",
      "gradient norm: 0.026384353011962958, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 8225 / 20000\n",
      "gradient norm: 0.09970407298533246, minimum ratio: 2.4842105263157896\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 8226 / 20000\n",
      "gradient norm: 0.11039450403768569, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00555\n",
      "epoch 8227 / 20000\n",
      "gradient norm: 0.08706928088213317, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 8228 / 20000\n",
      "gradient norm: 0.09888454398605973, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8229 / 20000\n",
      "gradient norm: 0.022702733771438943, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8230 / 20000\n",
      "gradient norm: 0.06785702414344996, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 8231 / 20000\n",
      "gradient norm: 0.061624170892173424, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 8232 / 20000\n",
      "gradient norm: 0.06147647951729596, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 8233 / 20000\n",
      "gradient norm: 0.06094122864305973, minimum ratio: 2.460526315789474\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8234 / 20000\n",
      "gradient norm: 0.021037342259660363, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 8235 / 20000\n",
      "gradient norm: 0.035574835594161414, minimum ratio: 2.4447368421052635\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8236 / 20000\n",
      "gradient norm: 0.03806289397471119, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 8237 / 20000\n",
      "gradient norm: 0.026407199693494476, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 8238 / 20000\n",
      "gradient norm: 0.038837055617477745, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 8239 / 20000\n",
      "gradient norm: 0.07894019363448024, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 8240 / 20000\n",
      "gradient norm: 0.09144380828365684, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00551\n",
      "epoch 8241 / 20000\n",
      "gradient norm: 0.08317516470560804, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 8242 / 20000\n",
      "gradient norm: 0.04946035347529687, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8243 / 20000\n",
      "gradient norm: 0.055291572061832994, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8244 / 20000\n",
      "gradient norm: 0.05122125466004945, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 8245 / 20000\n",
      "gradient norm: 0.11189827637281269, minimum ratio: 2.505263157894737\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 8246 / 20000\n",
      "gradient norm: 0.04821115860249847, minimum ratio: 2.4263157894736844\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 8247 / 20000\n",
      "gradient norm: 0.05934722977690399, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 8248 / 20000\n",
      "gradient norm: 0.06476002791896462, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8249 / 20000\n",
      "gradient norm: 0.043080042843939736, minimum ratio: 2.4447368421052635\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 8250 / 20000\n",
      "gradient norm: 0.10520816710777581, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 8251 / 20000\n",
      "gradient norm: 0.060964417178183794, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 8252 / 20000\n",
      "gradient norm: 0.020122506452025846, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 8253 / 20000\n",
      "gradient norm: 0.047573024639859796, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8254 / 20000\n",
      "gradient norm: 0.10930524292052723, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 8255 / 20000\n",
      "gradient norm: 0.10207327629905194, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00551\n",
      "epoch 8256 / 20000\n",
      "gradient norm: 0.05451964132953435, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00555\n",
      "epoch 8257 / 20000\n",
      "gradient norm: 0.09222999901976436, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00552\n",
      "epoch 8258 / 20000\n",
      "gradient norm: 0.058916974390740506, minimum ratio: 2.4499999999999997\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 8259 / 20000\n",
      "gradient norm: 0.03674649451568257, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 8260 / 20000\n",
      "gradient norm: 0.08443461614297121, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 8261 / 20000\n",
      "gradient norm: 0.12022410734789446, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 8262 / 20000\n",
      "gradient norm: 0.06168985314434394, minimum ratio: 2.4421052631578943\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 8263 / 20000\n",
      "gradient norm: 0.0575090426573297, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 8264 / 20000\n",
      "gradient norm: 0.04424923623446375, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8265 / 20000\n",
      "gradient norm: 0.09843968925997615, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 8266 / 20000\n",
      "gradient norm: 0.09818058169912547, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8267 / 20000\n",
      "gradient norm: 0.02973444911185652, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 8268 / 20000\n",
      "gradient norm: 0.0466227698198054, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 8269 / 20000\n",
      "gradient norm: 0.039340760791674256, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 8270 / 20000\n",
      "gradient norm: 0.062184824608266354, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 8271 / 20000\n",
      "gradient norm: 0.05749626527540386, minimum ratio: 2.460526315789474\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 8272 / 20000\n",
      "gradient norm: 0.08548374529345892, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 8273 / 20000\n",
      "gradient norm: 0.045963432086864486, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 8274 / 20000\n",
      "gradient norm: 0.07702597943716682, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 8275 / 20000\n",
      "gradient norm: 0.05728073065984063, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 8276 / 20000\n",
      "gradient norm: 0.054431771219242364, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 8277 / 20000\n",
      "gradient norm: 0.03273759897274431, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 8278 / 20000\n",
      "gradient norm: 0.09911644080420956, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 8279 / 20000\n",
      "gradient norm: 0.06949210544553353, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 8280 / 20000\n",
      "gradient norm: 0.0521039662999101, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 8281 / 20000\n",
      "gradient norm: 0.055752827145624906, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 8282 / 20000\n",
      "gradient norm: 0.07817846079706214, minimum ratio: 2.492105263157895\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 8283 / 20000\n",
      "gradient norm: 0.09832122549414635, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 8284 / 20000\n",
      "gradient norm: 0.052532549132592976, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 8285 / 20000\n",
      "gradient norm: 0.05326919007347897, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 8286 / 20000\n",
      "gradient norm: 0.05930183428426972, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 8287 / 20000\n",
      "gradient norm: 0.06334885765681975, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8288 / 20000\n",
      "gradient norm: 0.043569648114498705, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 8289 / 20000\n",
      "gradient norm: 0.0513595633674413, minimum ratio: 2.460526315789474\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 8290 / 20000\n",
      "gradient norm: 0.03525464213453233, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 8291 / 20000\n",
      "gradient norm: 0.07495034200837836, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 8292 / 20000\n",
      "gradient norm: 0.08466514687461313, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8293 / 20000\n",
      "gradient norm: 0.09823023958597332, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 8294 / 20000\n",
      "gradient norm: 0.05107933704130119, minimum ratio: 2.4815789473684213\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8295 / 20000\n",
      "gradient norm: 0.07183971378253773, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 8296 / 20000\n",
      "gradient norm: 0.10416187805822119, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8297 / 20000\n",
      "gradient norm: 0.05855705885915086, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00553\n",
      "epoch 8298 / 20000\n",
      "gradient norm: 0.07673226809129119, minimum ratio: 2.4736842105263155\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 8299 / 20000\n",
      "gradient norm: 0.11580448818858713, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00551\n",
      "epoch 8300 / 20000\n",
      "gradient norm: 0.08762376953382045, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00555\n",
      "epoch 8301 / 20000\n",
      "gradient norm: 0.04703027187497355, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8302 / 20000\n",
      "gradient norm: 0.05699009899399243, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 8303 / 20000\n",
      "gradient norm: 0.12079047644510865, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 8304 / 20000\n",
      "gradient norm: 0.07135544862831011, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 8305 / 20000\n",
      "gradient norm: 0.04539131802448537, minimum ratio: 2.4868421052631575\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 8306 / 20000\n",
      "gradient norm: 0.056728865165496245, minimum ratio: 2.4973684210526312\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 8307 / 20000\n",
      "gradient norm: 0.04655244457535446, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 8308 / 20000\n",
      "gradient norm: 0.041497962025459856, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8309 / 20000\n",
      "gradient norm: 0.030259642197052017, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 8310 / 20000\n",
      "gradient norm: 0.050480747973779216, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 8311 / 20000\n",
      "gradient norm: 0.07236512698000297, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 8312 / 20000\n",
      "gradient norm: 0.07855533587280661, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 8313 / 20000\n",
      "gradient norm: 0.1020316225476563, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 8314 / 20000\n",
      "gradient norm: 0.05622171575669199, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 8315 / 20000\n",
      "gradient norm: 0.03255622767028399, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 8316 / 20000\n",
      "gradient norm: 0.03407244832487777, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 8317 / 20000\n",
      "gradient norm: 0.0439786420611199, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 8318 / 20000\n",
      "gradient norm: 0.05161692824913189, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 8319 / 20000\n",
      "gradient norm: 0.047408575570443645, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8320 / 20000\n",
      "gradient norm: 0.023956104851095006, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 8321 / 20000\n",
      "gradient norm: 0.05921199102886021, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8322 / 20000\n",
      "gradient norm: 0.10191842372296378, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 8323 / 20000\n",
      "gradient norm: 0.08699774503475055, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 8324 / 20000\n",
      "gradient norm: 0.0847315396531485, minimum ratio: 2.4394736842105265\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 8325 / 20000\n",
      "gradient norm: 0.06957618362503126, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8326 / 20000\n",
      "gradient norm: 0.05612324390676804, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 8327 / 20000\n",
      "gradient norm: 0.10122949781361967, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 8328 / 20000\n",
      "gradient norm: 0.025675658500404097, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 8329 / 20000\n",
      "gradient norm: 0.03051963049801998, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 8330 / 20000\n",
      "gradient norm: 0.07596778444712982, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 8331 / 20000\n",
      "gradient norm: 0.0614493495086208, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 8332 / 20000\n",
      "gradient norm: 0.06486694581690244, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 8333 / 20000\n",
      "gradient norm: 0.07722985453438014, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 8334 / 20000\n",
      "gradient norm: 0.04794875666266307, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 8335 / 20000\n",
      "gradient norm: 0.05313643848057836, minimum ratio: 2.492105263157895\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8336 / 20000\n",
      "gradient norm: 0.0358746165438788, minimum ratio: 2.460526315789474\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 8337 / 20000\n",
      "gradient norm: 0.02723415198852308, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 8338 / 20000\n",
      "gradient norm: 0.03164977040432859, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 8339 / 20000\n",
      "gradient norm: 0.06396088946348755, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 8340 / 20000\n",
      "gradient norm: 0.07154360150161665, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 8341 / 20000\n",
      "gradient norm: 0.045189751079306006, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 8342 / 20000\n",
      "gradient norm: 0.06741241513373097, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8343 / 20000\n",
      "gradient norm: 0.024734553502639756, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 8344 / 20000\n",
      "gradient norm: 0.05394663318293169, minimum ratio: 2.46578947368421\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 8345 / 20000\n",
      "gradient norm: 0.08224375289864838, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8346 / 20000\n",
      "gradient norm: 0.06592947850003839, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 8347 / 20000\n",
      "gradient norm: 0.03695063744089566, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 8348 / 20000\n",
      "gradient norm: 0.06724929698975757, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8349 / 20000\n",
      "gradient norm: 0.07495398743776605, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8350 / 20000\n",
      "gradient norm: 0.03790815663523972, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 8351 / 20000\n",
      "gradient norm: 0.04831815813668072, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8352 / 20000\n",
      "gradient norm: 0.05660215762327425, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8353 / 20000\n",
      "gradient norm: 0.060084332595579326, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 8354 / 20000\n",
      "gradient norm: 0.037217145145405084, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8355 / 20000\n",
      "gradient norm: 0.049219375767279416, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8356 / 20000\n",
      "gradient norm: 0.0959470962989144, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 8357 / 20000\n",
      "gradient norm: 0.053337834775447845, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00551\n",
      "epoch 8358 / 20000\n",
      "gradient norm: 0.07821167586371303, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 8359 / 20000\n",
      "gradient norm: 0.08825909229926765, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 8360 / 20000\n",
      "gradient norm: 0.07268402335466817, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 8361 / 20000\n",
      "gradient norm: 0.0879350493196398, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 8362 / 20000\n",
      "gradient norm: 0.08573865587823093, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 8363 / 20000\n",
      "gradient norm: 0.05078025985858403, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 8364 / 20000\n",
      "gradient norm: 0.021266187737637665, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 8365 / 20000\n",
      "gradient norm: 0.08023263557697646, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 8366 / 20000\n",
      "gradient norm: 0.06669369211886078, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 8367 / 20000\n",
      "gradient norm: 0.04849509440828115, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 8368 / 20000\n",
      "gradient norm: 0.1490912005538121, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 8369 / 20000\n",
      "gradient norm: 0.05775051360251382, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 8370 / 20000\n",
      "gradient norm: 0.04480735189281404, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 8371 / 20000\n",
      "gradient norm: 0.10042747145052999, minimum ratio: 2.46578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00555\n",
      "epoch 8372 / 20000\n",
      "gradient norm: 0.03982198744779453, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 8373 / 20000\n",
      "gradient norm: 0.06737080807215534, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 8374 / 20000\n",
      "gradient norm: 0.07312060068943538, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 8375 / 20000\n",
      "gradient norm: 0.05883141004596837, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 8376 / 20000\n",
      "gradient norm: 0.06411717087030411, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 8377 / 20000\n",
      "gradient norm: 0.056904317607404664, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 8378 / 20000\n",
      "gradient norm: 0.06714679280412383, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8379 / 20000\n",
      "gradient norm: 0.05225488269934431, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 8380 / 20000\n",
      "gradient norm: 0.0667845498828683, minimum ratio: 2.46578947368421\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00551\n",
      "epoch 8381 / 20000\n",
      "gradient norm: 0.0482213239884004, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8382 / 20000\n",
      "gradient norm: 0.05465437669772655, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8383 / 20000\n",
      "gradient norm: 0.09612708783242851, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 8384 / 20000\n",
      "gradient norm: 0.03055730741471052, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8385 / 20000\n",
      "gradient norm: 0.08727109548635781, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 8386 / 20000\n",
      "gradient norm: 0.06611184391658753, minimum ratio: 2.452631578947368\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8387 / 20000\n",
      "gradient norm: 0.050488719483837485, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 8388 / 20000\n",
      "gradient norm: 0.0710277380712796, minimum ratio: 2.4447368421052635\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 8389 / 20000\n",
      "gradient norm: 0.066267544956645, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 8390 / 20000\n",
      "gradient norm: 0.09541154599719448, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 8391 / 20000\n",
      "gradient norm: 0.11351634562015533, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 8392 / 20000\n",
      "gradient norm: 0.06260175202623941, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 8393 / 20000\n",
      "gradient norm: 0.14944849512539804, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 8394 / 20000\n",
      "gradient norm: 0.08847552072256804, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00557\n",
      "epoch 8395 / 20000\n",
      "gradient norm: 0.06062078422110062, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 8396 / 20000\n",
      "gradient norm: 0.06545395945431665, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 8397 / 20000\n",
      "gradient norm: 0.057278046384453773, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 8398 / 20000\n",
      "gradient norm: 0.11104664526646957, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 8399 / 20000\n",
      "gradient norm: 0.1102708134567365, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00551\n",
      "epoch 8400 / 20000\n",
      "gradient norm: 0.09164431458339095, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 8401 / 20000\n",
      "gradient norm: 0.060987459262833, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 8402 / 20000\n",
      "gradient norm: 0.04933488252572715, minimum ratio: 2.4578947368421056\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 8403 / 20000\n",
      "gradient norm: 0.05225491980672814, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 8404 / 20000\n",
      "gradient norm: 0.08723001752514392, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8405 / 20000\n",
      "gradient norm: 0.1009373243432492, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 8406 / 20000\n",
      "gradient norm: 0.06010048318421468, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00552\n",
      "epoch 8407 / 20000\n",
      "gradient norm: 0.04679416859289631, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00565\n",
      "\tval loss: 0.00551\n",
      "epoch 8408 / 20000\n",
      "gradient norm: 0.06371747376397252, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 8409 / 20000\n",
      "gradient norm: 0.06357644370291382, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 8410 / 20000\n",
      "gradient norm: 0.05660665402683662, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 8411 / 20000\n",
      "gradient norm: 0.06150262133451179, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 8412 / 20000\n",
      "gradient norm: 0.031370171054732054, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00553\n",
      "epoch 8413 / 20000\n",
      "gradient norm: 0.10241453093476593, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 8414 / 20000\n",
      "gradient norm: 0.03860905289184302, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8415 / 20000\n",
      "gradient norm: 0.10787472629453987, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 8416 / 20000\n",
      "gradient norm: 0.10802028779289685, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 8417 / 20000\n",
      "gradient norm: 0.062145996213075705, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 8418 / 20000\n",
      "gradient norm: 0.07434508771984838, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8419 / 20000\n",
      "gradient norm: 0.0369065182749182, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 8420 / 20000\n",
      "gradient norm: 0.031991159536119085, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 8421 / 20000\n",
      "gradient norm: 0.06297563714906573, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 8422 / 20000\n",
      "gradient norm: 0.09733570949174464, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 8423 / 20000\n",
      "gradient norm: 0.11743837327230722, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00551\n",
      "epoch 8424 / 20000\n",
      "gradient norm: 0.033042528229998425, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00554\n",
      "epoch 8425 / 20000\n",
      "gradient norm: 0.09529383399058133, minimum ratio: 2.4815789473684213\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 8426 / 20000\n",
      "gradient norm: 0.05351347988471389, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 8427 / 20000\n",
      "gradient norm: 0.08034274671808816, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 8428 / 20000\n",
      "gradient norm: 0.059619233186822385, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 8429 / 20000\n",
      "gradient norm: 0.09127751959022135, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 8430 / 20000\n",
      "gradient norm: 0.0373925952881109, minimum ratio: 2.460526315789474\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00551\n",
      "epoch 8431 / 20000\n",
      "gradient norm: 0.07459482835838571, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 8432 / 20000\n",
      "gradient norm: 0.01683754159603268, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 8433 / 20000\n",
      "gradient norm: 0.06691733250045218, minimum ratio: 2.46578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 8434 / 20000\n",
      "gradient norm: 0.07479887316003442, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 8435 / 20000\n",
      "gradient norm: 0.061948526970809326, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 8436 / 20000\n",
      "gradient norm: 0.08772534085437655, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 8437 / 20000\n",
      "gradient norm: 0.06734076712746173, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 8438 / 20000\n",
      "gradient norm: 0.061558962101116776, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 8439 / 20000\n",
      "gradient norm: 0.06069282121461583, minimum ratio: 2.46578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8440 / 20000\n",
      "gradient norm: 0.02811322182242293, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 8441 / 20000\n",
      "gradient norm: 0.04899737180676311, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8442 / 20000\n",
      "gradient norm: 0.038281947548966855, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 8443 / 20000\n",
      "gradient norm: 0.03915669288835488, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 8444 / 20000\n",
      "gradient norm: 0.07320388685911894, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 8445 / 20000\n",
      "gradient norm: 0.04046445841231616, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00553\n",
      "epoch 8446 / 20000\n",
      "gradient norm: 0.11643543798709288, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 8447 / 20000\n",
      "gradient norm: 0.04955616092775017, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 8448 / 20000\n",
      "gradient norm: 0.10234154399950057, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 8449 / 20000\n",
      "gradient norm: 0.06303364539053291, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 8450 / 20000\n",
      "gradient norm: 0.02670580302947201, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8451 / 20000\n",
      "gradient norm: 0.08518169797025621, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 8452 / 20000\n",
      "gradient norm: 0.032521534580155276, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 8453 / 20000\n",
      "gradient norm: 0.05886909319087863, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8454 / 20000\n",
      "gradient norm: 0.03233578765502898, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 8455 / 20000\n",
      "gradient norm: 0.10641558794304729, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 8456 / 20000\n",
      "gradient norm: 0.0544165100727696, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 8457 / 20000\n",
      "gradient norm: 0.07965714231249876, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 8458 / 20000\n",
      "gradient norm: 0.06420395892928354, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 8459 / 20000\n",
      "gradient norm: 0.06585672739311121, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 8460 / 20000\n",
      "gradient norm: 0.03943039249861613, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 8461 / 20000\n",
      "gradient norm: 0.08775917970342562, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00551\n",
      "epoch 8462 / 20000\n",
      "gradient norm: 0.03918964260810753, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 8463 / 20000\n",
      "gradient norm: 0.053336859826231375, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 8464 / 20000\n",
      "gradient norm: 0.0770338661968708, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 8465 / 20000\n",
      "gradient norm: 0.06515709750237875, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8466 / 20000\n",
      "gradient norm: 0.0673568727215752, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00554\n",
      "epoch 8467 / 20000\n",
      "gradient norm: 0.05359520763158798, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 8468 / 20000\n",
      "gradient norm: 0.07950423815054819, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 8469 / 20000\n",
      "gradient norm: 0.08107616927009076, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 8470 / 20000\n",
      "gradient norm: 0.05084651176002808, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 8471 / 20000\n",
      "gradient norm: 0.11264319985639304, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 8472 / 20000\n",
      "gradient norm: 0.052871395455440506, minimum ratio: 2.46578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 8473 / 20000\n",
      "gradient norm: 0.06376183748943731, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 8474 / 20000\n",
      "gradient norm: 0.03344912544707768, minimum ratio: 2.4631578947368427\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 8475 / 20000\n",
      "gradient norm: 0.06084119371371344, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 8476 / 20000\n",
      "gradient norm: 0.041628616221714765, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 8477 / 20000\n",
      "gradient norm: 0.0401783236884512, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8478 / 20000\n",
      "gradient norm: 0.09333568078000098, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8479 / 20000\n",
      "gradient norm: 0.057887061819201335, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8480 / 20000\n",
      "gradient norm: 0.07130197410151595, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 8481 / 20000\n",
      "gradient norm: 0.045782226050505415, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 8482 / 20000\n",
      "gradient norm: 0.08056035410845652, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 8483 / 20000\n",
      "gradient norm: 0.06041217196616344, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 8484 / 20000\n",
      "gradient norm: 0.05432376230601221, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 8485 / 20000\n",
      "gradient norm: 0.03194710143725388, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 8486 / 20000\n",
      "gradient norm: 0.054185759800020605, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 8487 / 20000\n",
      "gradient norm: 0.05945513732149266, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8488 / 20000\n",
      "gradient norm: 0.12494551402051002, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00553\n",
      "epoch 8489 / 20000\n",
      "gradient norm: 0.07139577530324459, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 8490 / 20000\n",
      "gradient norm: 0.1361656596636749, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 8491 / 20000\n",
      "gradient norm: 0.13422560587059706, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00556\n",
      "epoch 8492 / 20000\n",
      "gradient norm: 0.05850620748242363, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 8493 / 20000\n",
      "gradient norm: 0.07372995858895592, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 8494 / 20000\n",
      "gradient norm: 0.07971252233255655, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00555\n",
      "epoch 8495 / 20000\n",
      "gradient norm: 0.12197875906713307, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 8496 / 20000\n",
      "gradient norm: 0.04874709552677814, minimum ratio: 2.4447368421052627\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 8497 / 20000\n",
      "gradient norm: 0.060754575206374284, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 8498 / 20000\n",
      "gradient norm: 0.03864001386682503, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 8499 / 20000\n",
      "gradient norm: 0.048001397619373165, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 8500 / 20000\n",
      "gradient norm: 0.06695301097352058, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 8501 / 20000\n",
      "gradient norm: 0.03343589678115677, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 8502 / 20000\n",
      "gradient norm: 0.07119582546874881, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 8503 / 20000\n",
      "gradient norm: 0.07874467862711754, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 8504 / 20000\n",
      "gradient norm: 0.05615529470378533, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 8505 / 20000\n",
      "gradient norm: 0.03899519669357687, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 8506 / 20000\n",
      "gradient norm: 0.06512725708307698, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 8507 / 20000\n",
      "gradient norm: 0.03551100759068504, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 8508 / 20000\n",
      "gradient norm: 0.05452571960631758, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 8509 / 20000\n",
      "gradient norm: 0.0507911758904811, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8510 / 20000\n",
      "gradient norm: 0.04947569299838506, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 8511 / 20000\n",
      "gradient norm: 0.07839003772824071, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 8512 / 20000\n",
      "gradient norm: 0.03708068606283632, minimum ratio: 2.465789473684211\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 8513 / 20000\n",
      "gradient norm: 0.054237968812230974, minimum ratio: 2.46578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8514 / 20000\n",
      "gradient norm: 0.04237982805352658, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 8515 / 20000\n",
      "gradient norm: 0.05993060051696375, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 8516 / 20000\n",
      "gradient norm: 0.024614669964648783, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8517 / 20000\n",
      "gradient norm: 0.04591777978930622, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8518 / 20000\n",
      "gradient norm: 0.06756376320845447, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8519 / 20000\n",
      "gradient norm: 0.06478087767027318, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8520 / 20000\n",
      "gradient norm: 0.041470920987194404, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8521 / 20000\n",
      "gradient norm: 0.048477677832124755, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 8522 / 20000\n",
      "gradient norm: 0.08118517944240011, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 8523 / 20000\n",
      "gradient norm: 0.0877301057043951, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 8524 / 20000\n",
      "gradient norm: 0.09034335617616307, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 8525 / 20000\n",
      "gradient norm: 0.09494714729953557, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8526 / 20000\n",
      "gradient norm: 0.07269880087551428, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 8527 / 20000\n",
      "gradient norm: 0.04730812741036061, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 8528 / 20000\n",
      "gradient norm: 0.02192349404504057, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8529 / 20000\n",
      "gradient norm: 0.06476932851364836, minimum ratio: 2.460526315789474\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 8530 / 20000\n",
      "gradient norm: 0.08475118078058586, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 8531 / 20000\n",
      "gradient norm: 0.036640809616073966, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 8532 / 20000\n",
      "gradient norm: 0.03078279341571033, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 8533 / 20000\n",
      "gradient norm: 0.07237048505339772, minimum ratio: 2.4499999999999997\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 8534 / 20000\n",
      "gradient norm: 0.03936616793362191, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 8535 / 20000\n",
      "gradient norm: 0.05352936736017, minimum ratio: 2.460526315789474\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 8536 / 20000\n",
      "gradient norm: 0.08834592206403613, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 8537 / 20000\n",
      "gradient norm: 0.04679772010422312, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 8538 / 20000\n",
      "gradient norm: 0.039635396300582215, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 8539 / 20000\n",
      "gradient norm: 0.07634275210148189, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 8540 / 20000\n",
      "gradient norm: 0.039479151644627564, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 8541 / 20000\n",
      "gradient norm: 0.07299943047109991, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 8542 / 20000\n",
      "gradient norm: 0.048655999249604065, minimum ratio: 2.489473684210526\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00551\n",
      "epoch 8543 / 20000\n",
      "gradient norm: 0.11947113543283194, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 8544 / 20000\n",
      "gradient norm: 0.12632604059763253, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00556\n",
      "epoch 8545 / 20000\n",
      "gradient norm: 0.06078570504905656, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 8546 / 20000\n",
      "gradient norm: 0.04880360345123336, minimum ratio: 2.4499999999999997\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 8547 / 20000\n",
      "gradient norm: 0.061445340572390705, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8548 / 20000\n",
      "gradient norm: 0.04653174336999655, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 8549 / 20000\n",
      "gradient norm: 0.05261226563015953, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8550 / 20000\n",
      "gradient norm: 0.12062542128842324, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00551\n",
      "epoch 8551 / 20000\n",
      "gradient norm: 0.04895722019136883, minimum ratio: 2.4842105263157896\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 8552 / 20000\n",
      "gradient norm: 0.07805612945230678, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8553 / 20000\n",
      "gradient norm: 0.06994369509629905, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 8554 / 20000\n",
      "gradient norm: 0.06262112047988921, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 8555 / 20000\n",
      "gradient norm: 0.09329086448997259, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8556 / 20000\n",
      "gradient norm: 0.05101050465600565, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 8557 / 20000\n",
      "gradient norm: 0.06645015685353428, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 8558 / 20000\n",
      "gradient norm: 0.030580334074329585, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8559 / 20000\n",
      "gradient norm: 0.052885838034853805, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8560 / 20000\n",
      "gradient norm: 0.04302906934753992, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 8561 / 20000\n",
      "gradient norm: 0.036163546683383174, minimum ratio: 2.492105263157895\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 8562 / 20000\n",
      "gradient norm: 0.052053435385460034, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 8563 / 20000\n",
      "gradient norm: 0.0907173054292798, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 8564 / 20000\n",
      "gradient norm: 0.059152844827622175, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 8565 / 20000\n",
      "gradient norm: 0.07888977346010506, minimum ratio: 2.46578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8566 / 20000\n",
      "gradient norm: 0.04716391407418996, minimum ratio: 2.46578947368421\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 8567 / 20000\n",
      "gradient norm: 0.04940388991963118, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 8568 / 20000\n",
      "gradient norm: 0.045568990128231235, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 8569 / 20000\n",
      "gradient norm: 0.08853520447155461, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 8570 / 20000\n",
      "gradient norm: 0.08324763760901988, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 8571 / 20000\n",
      "gradient norm: 0.1130661501083523, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 8572 / 20000\n",
      "gradient norm: 0.04284663847647607, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8573 / 20000\n",
      "gradient norm: 0.08460255214595236, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 8574 / 20000\n",
      "gradient norm: 0.040967678010929376, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 8575 / 20000\n",
      "gradient norm: 0.02286459758761339, minimum ratio: 2.4394736842105265\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 8576 / 20000\n",
      "gradient norm: 0.0833397179376334, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 8577 / 20000\n",
      "gradient norm: 0.04925809665292036, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 8578 / 20000\n",
      "gradient norm: 0.05895426246570423, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 8579 / 20000\n",
      "gradient norm: 0.044929835392395034, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 8580 / 20000\n",
      "gradient norm: 0.08429419220192358, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 8581 / 20000\n",
      "gradient norm: 0.09306735347490758, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 8582 / 20000\n",
      "gradient norm: 0.10022214916534722, minimum ratio: 2.489473684210526\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 8583 / 20000\n",
      "gradient norm: 0.08888156327884644, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 8584 / 20000\n",
      "gradient norm: 0.05527453147806227, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 8585 / 20000\n",
      "gradient norm: 0.06275429838569835, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8586 / 20000\n",
      "gradient norm: 0.036215136089595035, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00553\n",
      "epoch 8587 / 20000\n",
      "gradient norm: 0.07891694118734449, minimum ratio: 2.492105263157895\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 8588 / 20000\n",
      "gradient norm: 0.04279724496882409, minimum ratio: 2.4815789473684213\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 8589 / 20000\n",
      "gradient norm: 0.07683685480151325, minimum ratio: 2.4868421052631575\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8590 / 20000\n",
      "gradient norm: 0.038968391716480255, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 8591 / 20000\n",
      "gradient norm: 0.11700461531290784, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8592 / 20000\n",
      "gradient norm: 0.05243032792350277, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 8593 / 20000\n",
      "gradient norm: 0.12176650296896696, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00551\n",
      "epoch 8594 / 20000\n",
      "gradient norm: 0.10627731517888606, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00556\n",
      "epoch 8595 / 20000\n",
      "gradient norm: 0.06402737187454477, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 8596 / 20000\n",
      "gradient norm: 0.0766362021677196, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00551\n",
      "epoch 8597 / 20000\n",
      "gradient norm: 0.05226540980220307, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 8598 / 20000\n",
      "gradient norm: 0.03811289579607546, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 8599 / 20000\n",
      "gradient norm: 0.0843430490931496, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 8600 / 20000\n",
      "gradient norm: 0.042576400039251894, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 8601 / 20000\n",
      "gradient norm: 0.0602841400395846, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8602 / 20000\n",
      "gradient norm: 0.060439972672611475, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 8603 / 20000\n",
      "gradient norm: 0.0557834833234665, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00551\n",
      "epoch 8604 / 20000\n",
      "gradient norm: 0.05662394338287413, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8605 / 20000\n",
      "gradient norm: 0.0677963892230764, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 8606 / 20000\n",
      "gradient norm: 0.07556681628921069, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 8607 / 20000\n",
      "gradient norm: 0.06646656588418409, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 8608 / 20000\n",
      "gradient norm: 0.08523901843000203, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 8609 / 20000\n",
      "gradient norm: 0.060318037372780964, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8610 / 20000\n",
      "gradient norm: 0.06992661120602861, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8611 / 20000\n",
      "gradient norm: 0.05784117872826755, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 8612 / 20000\n",
      "gradient norm: 0.04828697732591536, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00565\n",
      "\tval loss: 0.00552\n",
      "epoch 8613 / 20000\n",
      "gradient norm: 0.03647649451158941, minimum ratio: 2.4447368421052627\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 8614 / 20000\n",
      "gradient norm: 0.049235941653023474, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8615 / 20000\n",
      "gradient norm: 0.07399179937783629, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 8616 / 20000\n",
      "gradient norm: 0.12156262225471437, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 8617 / 20000\n",
      "gradient norm: 0.04891423124354333, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 8618 / 20000\n",
      "gradient norm: 0.051676202812814154, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 8619 / 20000\n",
      "gradient norm: 0.10753081896109506, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8620 / 20000\n",
      "gradient norm: 0.06980382307665423, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 8621 / 20000\n",
      "gradient norm: 0.07962995253910776, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 8622 / 20000\n",
      "gradient norm: 0.05659155279863626, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8623 / 20000\n",
      "gradient norm: 0.024062766147835646, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 8624 / 20000\n",
      "gradient norm: 0.054148655879544094, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 8625 / 20000\n",
      "gradient norm: 0.041811130417045206, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00553\n",
      "epoch 8626 / 20000\n",
      "gradient norm: 0.06709559200680815, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 8627 / 20000\n",
      "gradient norm: 0.05657760175381554, minimum ratio: 2.4842105263157896\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8628 / 20000\n",
      "gradient norm: 0.07641583881922998, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8629 / 20000\n",
      "gradient norm: 0.02943222800968215, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 8630 / 20000\n",
      "gradient norm: 0.04379559663357213, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 8631 / 20000\n",
      "gradient norm: 0.06294872454600409, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 8632 / 20000\n",
      "gradient norm: 0.11045722244307399, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 8633 / 20000\n",
      "gradient norm: 0.07242333953035995, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8634 / 20000\n",
      "gradient norm: 0.040708366490434855, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00551\n",
      "epoch 8635 / 20000\n",
      "gradient norm: 0.05829505578731187, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8636 / 20000\n",
      "gradient norm: 0.058856513336650096, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8637 / 20000\n",
      "gradient norm: 0.08802113775163889, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8638 / 20000\n",
      "gradient norm: 0.07442415269906633, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 8639 / 20000\n",
      "gradient norm: 0.03593748007551767, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8640 / 20000\n",
      "gradient norm: 0.05505010631168261, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 8641 / 20000\n",
      "gradient norm: 0.045744799776002765, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 8642 / 20000\n",
      "gradient norm: 0.08261619685799815, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00551\n",
      "epoch 8643 / 20000\n",
      "gradient norm: 0.05403051379835233, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 8644 / 20000\n",
      "gradient norm: 0.10502288735006005, minimum ratio: 2.513157894736842\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 8645 / 20000\n",
      "gradient norm: 0.04188662488013506, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00565\n",
      "\tval loss: 0.00551\n",
      "epoch 8646 / 20000\n",
      "gradient norm: 0.08112369262380525, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 8647 / 20000\n",
      "gradient norm: 0.06261649349471554, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 8648 / 20000\n",
      "gradient norm: 0.10837987088598311, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 8649 / 20000\n",
      "gradient norm: 0.09366544109070674, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 8650 / 20000\n",
      "gradient norm: 0.024708740951609798, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8651 / 20000\n",
      "gradient norm: 0.0470256304834038, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8652 / 20000\n",
      "gradient norm: 0.05255973746534437, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 8653 / 20000\n",
      "gradient norm: 0.031976955080608604, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 8654 / 20000\n",
      "gradient norm: 0.10520771436858922, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 8655 / 20000\n",
      "gradient norm: 0.03777594400889939, minimum ratio: 2.4868421052631575\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 8656 / 20000\n",
      "gradient norm: 0.04687143524643034, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 8657 / 20000\n",
      "gradient norm: 0.13465139619074762, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 8658 / 20000\n",
      "gradient norm: 0.1285884115495719, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00551\n",
      "epoch 8659 / 20000\n",
      "gradient norm: 0.06515850720461458, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 8660 / 20000\n",
      "gradient norm: 0.0859541680838447, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00555\n",
      "epoch 8661 / 20000\n",
      "gradient norm: 0.0645377535111038, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 8662 / 20000\n",
      "gradient norm: 0.055744952929671854, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 8663 / 20000\n",
      "gradient norm: 0.01162824894709047, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 8664 / 20000\n",
      "gradient norm: 0.06392449224949814, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 8665 / 20000\n",
      "gradient norm: 0.09197282081004232, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 8666 / 20000\n",
      "gradient norm: 0.05828174011548981, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8667 / 20000\n",
      "gradient norm: 0.061668525740969926, minimum ratio: 2.4842105263157896\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 8668 / 20000\n",
      "gradient norm: 0.0433722142042825, minimum ratio: 2.4842105263157896\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 8669 / 20000\n",
      "gradient norm: 0.030722746363608167, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8670 / 20000\n",
      "gradient norm: 0.05185431390418671, minimum ratio: 2.4842105263157896\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 8671 / 20000\n",
      "gradient norm: 0.053388608852401376, minimum ratio: 2.492105263157895\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 8672 / 20000\n",
      "gradient norm: 0.052430011390242726, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8673 / 20000\n",
      "gradient norm: 0.03911222916212864, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 8674 / 20000\n",
      "gradient norm: 0.08897064669872634, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 8675 / 20000\n",
      "gradient norm: 0.05393714673118666, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00551\n",
      "epoch 8676 / 20000\n",
      "gradient norm: 0.06487561913672835, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 8677 / 20000\n",
      "gradient norm: 0.04663128578977194, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8678 / 20000\n",
      "gradient norm: 0.08638963749399409, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 8679 / 20000\n",
      "gradient norm: 0.05520353348401841, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 8680 / 20000\n",
      "gradient norm: 0.06156894422019832, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8681 / 20000\n",
      "gradient norm: 0.06476611352991313, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00554\n",
      "epoch 8682 / 20000\n",
      "gradient norm: 0.10329988994635642, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8683 / 20000\n",
      "gradient norm: 0.08209500944940373, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 8684 / 20000\n",
      "gradient norm: 0.05089470188249834, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 8685 / 20000\n",
      "gradient norm: 0.083974733017385, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 8686 / 20000\n",
      "gradient norm: 0.06600777749554254, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 8687 / 20000\n",
      "gradient norm: 0.07636956940405071, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 8688 / 20000\n",
      "gradient norm: 0.054109695163788274, minimum ratio: 2.4842105263157896\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 8689 / 20000\n",
      "gradient norm: 0.05083070232649334, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 8690 / 20000\n",
      "gradient norm: 0.07367833951138891, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 8691 / 20000\n",
      "gradient norm: 0.032803659567434806, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 8692 / 20000\n",
      "gradient norm: 0.0927617842098698, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 8693 / 20000\n",
      "gradient norm: 0.09094766899943352, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 8694 / 20000\n",
      "gradient norm: 0.059794649787363596, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 8695 / 20000\n",
      "gradient norm: 0.03538708059932105, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8696 / 20000\n",
      "gradient norm: 0.05899884921382181, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 8697 / 20000\n",
      "gradient norm: 0.0872823300305754, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8698 / 20000\n",
      "gradient norm: 0.05825297484989278, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 8699 / 20000\n",
      "gradient norm: 0.044071917014662176, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 8700 / 20000\n",
      "gradient norm: 0.11745979174156673, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 8701 / 20000\n",
      "gradient norm: 0.09553088579559699, minimum ratio: 2.4499999999999997\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 8702 / 20000\n",
      "gradient norm: 0.07572025817353278, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 8703 / 20000\n",
      "gradient norm: 0.0742318591219373, minimum ratio: 2.4894736842105267\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 8704 / 20000\n",
      "gradient norm: 0.10390948702115566, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 8705 / 20000\n",
      "gradient norm: 0.1049248370109126, minimum ratio: 2.4394736842105265\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00555\n",
      "epoch 8706 / 20000\n",
      "gradient norm: 0.06939006818356575, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 8707 / 20000\n",
      "gradient norm: 0.08480376382067334, minimum ratio: 2.4842105263157896\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 8708 / 20000\n",
      "gradient norm: 0.057242256501922384, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00555\n",
      "epoch 8709 / 20000\n",
      "gradient norm: 0.08162708306917921, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 8710 / 20000\n",
      "gradient norm: 0.08444272656925023, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 8711 / 20000\n",
      "gradient norm: 0.0810234542877879, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 8712 / 20000\n",
      "gradient norm: 0.0644099127384834, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 8713 / 20000\n",
      "gradient norm: 0.08809075329918414, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 8714 / 20000\n",
      "gradient norm: 0.07756783731747419, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8715 / 20000\n",
      "gradient norm: 0.12262406630907208, minimum ratio: 2.4894736842105267\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 8716 / 20000\n",
      "gradient norm: 0.07777282549068332, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 8717 / 20000\n",
      "gradient norm: 0.05500862924964167, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8718 / 20000\n",
      "gradient norm: 0.04055993471411057, minimum ratio: 2.4868421052631584\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 8719 / 20000\n",
      "gradient norm: 0.018144163499528076, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8720 / 20000\n",
      "gradient norm: 0.042101727885892615, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 8721 / 20000\n",
      "gradient norm: 0.07241149662877433, minimum ratio: 2.4447368421052635\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 8722 / 20000\n",
      "gradient norm: 0.055118175863754004, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8723 / 20000\n",
      "gradient norm: 0.04997727370937355, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 8724 / 20000\n",
      "gradient norm: 0.047734616964589804, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 8725 / 20000\n",
      "gradient norm: 0.036555873346515, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8726 / 20000\n",
      "gradient norm: 0.07518429201445542, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 8727 / 20000\n",
      "gradient norm: 0.032841841282788664, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 8728 / 20000\n",
      "gradient norm: 0.037026900114142336, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 8729 / 20000\n",
      "gradient norm: 0.08519150468055159, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 8730 / 20000\n",
      "gradient norm: 0.08311326972034294, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 8731 / 20000\n",
      "gradient norm: 0.030161838214553427, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8732 / 20000\n",
      "gradient norm: 0.10899843792867614, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 8733 / 20000\n",
      "gradient norm: 0.03330318226653617, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 8734 / 20000\n",
      "gradient norm: 0.13343140698270872, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 8735 / 20000\n",
      "gradient norm: 0.07472137326840311, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 8736 / 20000\n",
      "gradient norm: 0.029351643592235632, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8737 / 20000\n",
      "gradient norm: 0.0539899593568407, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 8738 / 20000\n",
      "gradient norm: 0.0804902363452129, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00551\n",
      "epoch 8739 / 20000\n",
      "gradient norm: 0.049398730785469525, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 8740 / 20000\n",
      "gradient norm: 0.027912961930269375, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 8741 / 20000\n",
      "gradient norm: 0.06231056616525166, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8742 / 20000\n",
      "gradient norm: 0.06378710316494107, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 8743 / 20000\n",
      "gradient norm: 0.03751078341156244, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 8744 / 20000\n",
      "gradient norm: 0.061245188815519214, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 8745 / 20000\n",
      "gradient norm: 0.04416811282862909, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00551\n",
      "epoch 8746 / 20000\n",
      "gradient norm: 0.0895054392167367, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8747 / 20000\n",
      "gradient norm: 0.028809042742068414, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8748 / 20000\n",
      "gradient norm: 0.10320772824343294, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 8749 / 20000\n",
      "gradient norm: 0.1074760075789527, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 8750 / 20000\n",
      "gradient norm: 0.08440110104857013, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 8751 / 20000\n",
      "gradient norm: 0.0616343142464757, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 8752 / 20000\n",
      "gradient norm: 0.05820703855715692, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 8753 / 20000\n",
      "gradient norm: 0.08046362368622795, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 8754 / 20000\n",
      "gradient norm: 0.05494883155915886, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 8755 / 20000\n",
      "gradient norm: 0.03903549036476761, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00553\n",
      "epoch 8756 / 20000\n",
      "gradient norm: 0.06753743649460375, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 8757 / 20000\n",
      "gradient norm: 0.06490228424081579, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 8758 / 20000\n",
      "gradient norm: 0.09772327443351969, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00551\n",
      "epoch 8759 / 20000\n",
      "gradient norm: 0.05832064221613109, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00554\n",
      "epoch 8760 / 20000\n",
      "gradient norm: 0.08350751944817603, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 8761 / 20000\n",
      "gradient norm: 0.056521356251323596, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00551\n",
      "epoch 8762 / 20000\n",
      "gradient norm: 0.07610799366375431, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 8763 / 20000\n",
      "gradient norm: 0.09540346852736548, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00555\n",
      "epoch 8764 / 20000\n",
      "gradient norm: 0.060521437088027596, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8765 / 20000\n",
      "gradient norm: 0.08549573412165046, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 8766 / 20000\n",
      "gradient norm: 0.06345946356304921, minimum ratio: 2.465789473684211\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 8767 / 20000\n",
      "gradient norm: 0.07035562518285587, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 8768 / 20000\n",
      "gradient norm: 0.04988765434245579, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 8769 / 20000\n",
      "gradient norm: 0.07847029104596004, minimum ratio: 2.4499999999999997\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 8770 / 20000\n",
      "gradient norm: 0.051780580019112676, minimum ratio: 2.492105263157895\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 8771 / 20000\n",
      "gradient norm: 0.05344313840032555, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 8772 / 20000\n",
      "gradient norm: 0.03771745756966993, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 8773 / 20000\n",
      "gradient norm: 0.058915120229357854, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 8774 / 20000\n",
      "gradient norm: 0.1060225457767956, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 8775 / 20000\n",
      "gradient norm: 0.06808996040854254, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8776 / 20000\n",
      "gradient norm: 0.06113047426333651, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 8777 / 20000\n",
      "gradient norm: 0.11162317940033972, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8778 / 20000\n",
      "gradient norm: 0.07383120502345264, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 8779 / 20000\n",
      "gradient norm: 0.03732471936382353, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 8780 / 20000\n",
      "gradient norm: 0.07360714537207969, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 8781 / 20000\n",
      "gradient norm: 0.06477205164264888, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 8782 / 20000\n",
      "gradient norm: 0.11492774600628763, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 8783 / 20000\n",
      "gradient norm: 0.05176506150746718, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 8784 / 20000\n",
      "gradient norm: 0.05996374771348201, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 8785 / 20000\n",
      "gradient norm: 0.07240394986001775, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8786 / 20000\n",
      "gradient norm: 0.06405110820196569, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 8787 / 20000\n",
      "gradient norm: 0.03291654019267298, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 8788 / 20000\n",
      "gradient norm: 0.08277339229243807, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8789 / 20000\n",
      "gradient norm: 0.04063076796592213, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 8790 / 20000\n",
      "gradient norm: 0.03292783304641489, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8791 / 20000\n",
      "gradient norm: 0.05244739228510298, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 8792 / 20000\n",
      "gradient norm: 0.06464536831481382, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 8793 / 20000\n",
      "gradient norm: 0.04789758211700246, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8794 / 20000\n",
      "gradient norm: 0.045570602582301944, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 8795 / 20000\n",
      "gradient norm: 0.12874102778732777, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 8796 / 20000\n",
      "gradient norm: 0.05150950720417313, minimum ratio: 2.4842105263157896\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 8797 / 20000\n",
      "gradient norm: 0.0816547611320857, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 8798 / 20000\n",
      "gradient norm: 0.04441753891296685, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8799 / 20000\n",
      "gradient norm: 0.04934632161166519, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8800 / 20000\n",
      "gradient norm: 0.06296996836317703, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8801 / 20000\n",
      "gradient norm: 0.03122309362515807, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 8802 / 20000\n",
      "gradient norm: 0.04879645525943488, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 8803 / 20000\n",
      "gradient norm: 0.0709301115712151, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 8804 / 20000\n",
      "gradient norm: 0.041465160640655085, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8805 / 20000\n",
      "gradient norm: 0.08840499690268189, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 8806 / 20000\n",
      "gradient norm: 0.040786502533592284, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 8807 / 20000\n",
      "gradient norm: 0.05243417411111295, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 8808 / 20000\n",
      "gradient norm: 0.02136051855632104, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 8809 / 20000\n",
      "gradient norm: 0.06336921034380794, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 8810 / 20000\n",
      "gradient norm: 0.07456415047636256, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8811 / 20000\n",
      "gradient norm: 0.052800076809944585, minimum ratio: 2.492105263157895\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 8812 / 20000\n",
      "gradient norm: 0.051980883872602135, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8813 / 20000\n",
      "gradient norm: 0.05984506837558001, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 8814 / 20000\n",
      "gradient norm: 0.05526911118067801, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 8815 / 20000\n",
      "gradient norm: 0.06791472987970337, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 8816 / 20000\n",
      "gradient norm: 0.05008536210516468, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8817 / 20000\n",
      "gradient norm: 0.04896107918466441, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 8818 / 20000\n",
      "gradient norm: 0.05111202012631111, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 8819 / 20000\n",
      "gradient norm: 0.055261845351196826, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 8820 / 20000\n",
      "gradient norm: 0.03731825976865366, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 8821 / 20000\n",
      "gradient norm: 0.023049999799695797, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 8822 / 20000\n",
      "gradient norm: 0.05781411158386618, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8823 / 20000\n",
      "gradient norm: 0.057899180304957554, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 8824 / 20000\n",
      "gradient norm: 0.07836809556465596, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8825 / 20000\n",
      "gradient norm: 0.01721583669859683, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 8826 / 20000\n",
      "gradient norm: 0.0557906428584829, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8827 / 20000\n",
      "gradient norm: 0.06961171168950386, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8828 / 20000\n",
      "gradient norm: 0.07586146894027479, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 8829 / 20000\n",
      "gradient norm: 0.05098801531130448, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8830 / 20000\n",
      "gradient norm: 0.03822556373779662, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 8831 / 20000\n",
      "gradient norm: 0.07917073287535459, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 8832 / 20000\n",
      "gradient norm: 0.04366134041629266, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8833 / 20000\n",
      "gradient norm: 0.044083820044761524, minimum ratio: 2.4894736842105267\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 8834 / 20000\n",
      "gradient norm: 0.08760426149819978, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 8835 / 20000\n",
      "gradient norm: 0.05633715679869056, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 8836 / 20000\n",
      "gradient norm: 0.061166494589997455, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 8837 / 20000\n",
      "gradient norm: 0.049280008737696335, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 8838 / 20000\n",
      "gradient norm: 0.05970993856317364, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8839 / 20000\n",
      "gradient norm: 0.06389074987964705, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00551\n",
      "epoch 8840 / 20000\n",
      "gradient norm: 0.07145747443428263, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8841 / 20000\n",
      "gradient norm: 0.03319039451889694, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 8842 / 20000\n",
      "gradient norm: 0.06555209023645148, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 8843 / 20000\n",
      "gradient norm: 0.04000649813679047, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8844 / 20000\n",
      "gradient norm: 0.031454738666070625, minimum ratio: 2.4736842105263155\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8845 / 20000\n",
      "gradient norm: 0.07351891886355588, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 8846 / 20000\n",
      "gradient norm: 0.04802967846626416, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 8847 / 20000\n",
      "gradient norm: 0.05020641878945753, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 8848 / 20000\n",
      "gradient norm: 0.06268754621851258, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 8849 / 20000\n",
      "gradient norm: 0.07870630818069912, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 8850 / 20000\n",
      "gradient norm: 0.06811626824492123, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 8851 / 20000\n",
      "gradient norm: 0.11331321793841198, minimum ratio: 2.4868421052631575\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 8852 / 20000\n",
      "gradient norm: 0.07527127413777635, minimum ratio: 2.5026315789473688\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 8853 / 20000\n",
      "gradient norm: 0.07630672183586285, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 8854 / 20000\n",
      "gradient norm: 0.06253176291647833, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 8855 / 20000\n",
      "gradient norm: 0.04564662271877751, minimum ratio: 2.4736842105263155\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00552\n",
      "epoch 8856 / 20000\n",
      "gradient norm: 0.035482275270624086, minimum ratio: 2.4894736842105267\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 8857 / 20000\n",
      "gradient norm: 0.06387730105780065, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 8858 / 20000\n",
      "gradient norm: 0.05185108655132353, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 8859 / 20000\n",
      "gradient norm: 0.06627767119789496, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 8860 / 20000\n",
      "gradient norm: 0.047425749187823385, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 8861 / 20000\n",
      "gradient norm: 0.037747733178548515, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8862 / 20000\n",
      "gradient norm: 0.062347606872208416, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 8863 / 20000\n",
      "gradient norm: 0.09917898348066956, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 8864 / 20000\n",
      "gradient norm: 0.04555085761239752, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8865 / 20000\n",
      "gradient norm: 0.0670806559137418, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8866 / 20000\n",
      "gradient norm: 0.042446147883310914, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 8867 / 20000\n",
      "gradient norm: 0.10455519217066467, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 8868 / 20000\n",
      "gradient norm: 0.030796723018283956, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 8869 / 20000\n",
      "gradient norm: 0.0749167327885516, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8870 / 20000\n",
      "gradient norm: 0.07570187089731917, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 8871 / 20000\n",
      "gradient norm: 0.03711278279661201, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 8872 / 20000\n",
      "gradient norm: 0.0675530488952063, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 8873 / 20000\n",
      "gradient norm: 0.05977680685464293, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 8874 / 20000\n",
      "gradient norm: 0.028232131560798734, minimum ratio: 2.460526315789474\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8875 / 20000\n",
      "gradient norm: 0.030467323813354596, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 8876 / 20000\n",
      "gradient norm: 0.07236250440473668, minimum ratio: 2.460526315789474\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 8877 / 20000\n",
      "gradient norm: 0.07809073230600916, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 8878 / 20000\n",
      "gradient norm: 0.08405892876908183, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 8879 / 20000\n",
      "gradient norm: 0.10587519442196935, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 8880 / 20000\n",
      "gradient norm: 0.01435251652583247, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8881 / 20000\n",
      "gradient norm: 0.07651058475312311, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8882 / 20000\n",
      "gradient norm: 0.025126634660409763, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 8883 / 20000\n",
      "gradient norm: 0.0466781562572578, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8884 / 20000\n",
      "gradient norm: 0.017064987681806087, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 8885 / 20000\n",
      "gradient norm: 0.052606653567636386, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 8886 / 20000\n",
      "gradient norm: 0.037357671186327934, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 8887 / 20000\n",
      "gradient norm: 0.07495765647036023, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 8888 / 20000\n",
      "gradient norm: 0.03548995067831129, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 8889 / 20000\n",
      "gradient norm: 0.05632025224622339, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8890 / 20000\n",
      "gradient norm: 0.0464553578349296, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8891 / 20000\n",
      "gradient norm: 0.06678130722139031, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 8892 / 20000\n",
      "gradient norm: 0.04584234138019383, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 8893 / 20000\n",
      "gradient norm: 0.0714734784560278, minimum ratio: 2.4868421052631575\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 8894 / 20000\n",
      "gradient norm: 0.07083986315410584, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 8895 / 20000\n",
      "gradient norm: 0.07017563418776263, minimum ratio: 2.4578947368421056\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 8896 / 20000\n",
      "gradient norm: 0.03591922985651763, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 8897 / 20000\n",
      "gradient norm: 0.0775579412584193, minimum ratio: 2.489473684210526\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 8898 / 20000\n",
      "gradient norm: 0.09955358447041363, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 8899 / 20000\n",
      "gradient norm: 0.04091119355871342, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 8900 / 20000\n",
      "gradient norm: 0.0686162588535808, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 8901 / 20000\n",
      "gradient norm: 0.028943332144990563, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 8902 / 20000\n",
      "gradient norm: 0.05194538802606985, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 8903 / 20000\n",
      "gradient norm: 0.06470967951463535, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 8904 / 20000\n",
      "gradient norm: 0.08705846057273448, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 8905 / 20000\n",
      "gradient norm: 0.11640348448418081, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 8906 / 20000\n",
      "gradient norm: 0.05610631074523553, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 8907 / 20000\n",
      "gradient norm: 0.0843768164049834, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 8908 / 20000\n",
      "gradient norm: 0.0322042960615363, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 8909 / 20000\n",
      "gradient norm: 0.054030174826039, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 8910 / 20000\n",
      "gradient norm: 0.016707898685126565, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8911 / 20000\n",
      "gradient norm: 0.12596864509396255, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 8912 / 20000\n",
      "gradient norm: 0.06399626308120787, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 8913 / 20000\n",
      "gradient norm: 0.06592257859301753, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8914 / 20000\n",
      "gradient norm: 0.036495668449788354, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 8915 / 20000\n",
      "gradient norm: 0.07923143630614504, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 8916 / 20000\n",
      "gradient norm: 0.042530786551651545, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 8917 / 20000\n",
      "gradient norm: 0.05403450966696255, minimum ratio: 2.4736842105263155\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 8918 / 20000\n",
      "gradient norm: 0.04561657813610509, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8919 / 20000\n",
      "gradient norm: 0.042037151666590944, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 8920 / 20000\n",
      "gradient norm: 0.09108189500693697, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 8921 / 20000\n",
      "gradient norm: 0.050064974784618244, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 8922 / 20000\n",
      "gradient norm: 0.053574522738927044, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8923 / 20000\n",
      "gradient norm: 0.10931628057733178, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 8924 / 20000\n",
      "gradient norm: 0.05583130833110772, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00565\n",
      "\tval loss: 0.00552\n",
      "epoch 8925 / 20000\n",
      "gradient norm: 0.055836425512097776, minimum ratio: 2.4842105263157896\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00551\n",
      "epoch 8926 / 20000\n",
      "gradient norm: 0.08562847541179508, minimum ratio: 2.4499999999999997\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 8927 / 20000\n",
      "gradient norm: 0.05637384796864353, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 8928 / 20000\n",
      "gradient norm: 0.0393336815177463, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 8929 / 20000\n",
      "gradient norm: 0.06672973569948226, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00551\n",
      "epoch 8930 / 20000\n",
      "gradient norm: 0.07387151755392551, minimum ratio: 2.4868421052631575\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 8931 / 20000\n",
      "gradient norm: 0.05485980142839253, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 8932 / 20000\n",
      "gradient norm: 0.07493097557744477, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 8933 / 20000\n",
      "gradient norm: 0.0560235311058932, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 8934 / 20000\n",
      "gradient norm: 0.06315917585743591, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 8935 / 20000\n",
      "gradient norm: 0.05119612591806799, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 8936 / 20000\n",
      "gradient norm: 0.07080946586211212, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 8937 / 20000\n",
      "gradient norm: 0.05529649631353095, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8938 / 20000\n",
      "gradient norm: 0.06849633206729777, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 8939 / 20000\n",
      "gradient norm: 0.06412721169181168, minimum ratio: 2.460526315789474\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 8940 / 20000\n",
      "gradient norm: 0.12630175985395908, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 8941 / 20000\n",
      "gradient norm: 0.134645945741795, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8942 / 20000\n",
      "gradient norm: 0.09401814645389095, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00555\n",
      "epoch 8943 / 20000\n",
      "gradient norm: 0.11759466823423281, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00551\n",
      "epoch 8944 / 20000\n",
      "gradient norm: 0.08506355769350193, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 8945 / 20000\n",
      "gradient norm: 0.10298248950857669, minimum ratio: 2.460526315789474\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00555\n",
      "epoch 8946 / 20000\n",
      "gradient norm: 0.10443814276368357, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 8947 / 20000\n",
      "gradient norm: 0.05448877206072211, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 8948 / 20000\n",
      "gradient norm: 0.04755195492180064, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 8949 / 20000\n",
      "gradient norm: 0.02400039446365554, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 8950 / 20000\n",
      "gradient norm: 0.04060504358494654, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 8951 / 20000\n",
      "gradient norm: 0.0641682242276147, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 8952 / 20000\n",
      "gradient norm: 0.03610990650486201, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 8953 / 20000\n",
      "gradient norm: 0.07856760453432798, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00553\n",
      "epoch 8954 / 20000\n",
      "gradient norm: 0.04820261578424834, minimum ratio: 2.4499999999999997\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 8955 / 20000\n",
      "gradient norm: 0.04096381479757838, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 8956 / 20000\n",
      "gradient norm: 0.059258571884129196, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8957 / 20000\n",
      "gradient norm: 0.04621583072002977, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 8958 / 20000\n",
      "gradient norm: 0.02178960049059242, minimum ratio: 2.478947368421053\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 8959 / 20000\n",
      "gradient norm: 0.049008998001227155, minimum ratio: 2.4842105263157896\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 8960 / 20000\n",
      "gradient norm: 0.06705144653096795, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 8961 / 20000\n",
      "gradient norm: 0.06564024802355561, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8962 / 20000\n",
      "gradient norm: 0.05356090934947133, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 8963 / 20000\n",
      "gradient norm: 0.09843014762736857, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8964 / 20000\n",
      "gradient norm: 0.05415212988737039, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 8965 / 20000\n",
      "gradient norm: 0.1365634460526053, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00551\n",
      "epoch 8966 / 20000\n",
      "gradient norm: 0.09602733794599771, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 8967 / 20000\n",
      "gradient norm: 0.047133043815847486, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 8968 / 20000\n",
      "gradient norm: 0.10616355197271332, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 8969 / 20000\n",
      "gradient norm: 0.05543671156192431, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8970 / 20000\n",
      "gradient norm: 0.06844340544193983, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 8971 / 20000\n",
      "gradient norm: 0.04510799783747643, minimum ratio: 2.460526315789474\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 8972 / 20000\n",
      "gradient norm: 0.07987959269667044, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 8973 / 20000\n",
      "gradient norm: 0.055810939011280425, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 8974 / 20000\n",
      "gradient norm: 0.03400755624170415, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 8975 / 20000\n",
      "gradient norm: 0.07412084215320647, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 8976 / 20000\n",
      "gradient norm: 0.024089152604574338, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 8977 / 20000\n",
      "gradient norm: 0.09637829358689487, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 8978 / 20000\n",
      "gradient norm: 0.03896662384067895, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 8979 / 20000\n",
      "gradient norm: 0.04124711664917413, minimum ratio: 2.460526315789474\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 8980 / 20000\n",
      "gradient norm: 0.06507621346099768, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 8981 / 20000\n",
      "gradient norm: 0.12116963183507323, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 8982 / 20000\n",
      "gradient norm: 0.035524043763871305, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 8983 / 20000\n",
      "gradient norm: 0.05928468631464057, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 8984 / 20000\n",
      "gradient norm: 0.0380088075180538, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 8985 / 20000\n",
      "gradient norm: 0.05093131004832685, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8986 / 20000\n",
      "gradient norm: 0.0813697908888571, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 8987 / 20000\n",
      "gradient norm: 0.03071072543389164, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 8988 / 20000\n",
      "gradient norm: 0.03070353507064283, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8989 / 20000\n",
      "gradient norm: 0.053483182506170124, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 8990 / 20000\n",
      "gradient norm: 0.039225687098223716, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 8991 / 20000\n",
      "gradient norm: 0.027002108574379236, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 8992 / 20000\n",
      "gradient norm: 0.04747104842681438, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 8993 / 20000\n",
      "gradient norm: 0.11649293793016113, minimum ratio: 2.460526315789474\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 8994 / 20000\n",
      "gradient norm: 0.05215170746669173, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00553\n",
      "epoch 8995 / 20000\n",
      "gradient norm: 0.07683240994811058, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 8996 / 20000\n",
      "gradient norm: 0.09600713377585635, minimum ratio: 2.5105263157894737\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 8997 / 20000\n",
      "gradient norm: 0.09728318161796778, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 8998 / 20000\n",
      "gradient norm: 0.08090131811331958, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 8999 / 20000\n",
      "gradient norm: 0.04076101766258944, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 9000 / 20000\n",
      "gradient norm: 0.06762091105338186, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 9001 / 20000\n",
      "gradient norm: 0.0741776687791571, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 9002 / 20000\n",
      "gradient norm: 0.02145813290553633, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 9003 / 20000\n",
      "gradient norm: 0.02630529153975658, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 9004 / 20000\n",
      "gradient norm: 0.0531325115589425, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 9005 / 20000\n",
      "gradient norm: 0.06754568743053824, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 9006 / 20000\n",
      "gradient norm: 0.055504786665551364, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 9007 / 20000\n",
      "gradient norm: 0.07069512107409537, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 9008 / 20000\n",
      "gradient norm: 0.08318935160059482, minimum ratio: 2.4263157894736844\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 9009 / 20000\n",
      "gradient norm: 0.06300908367484226, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 9010 / 20000\n",
      "gradient norm: 0.09339703322621062, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 9011 / 20000\n",
      "gradient norm: 0.10814768145792186, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 9012 / 20000\n",
      "gradient norm: 0.08696134621277452, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00551\n",
      "epoch 9013 / 20000\n",
      "gradient norm: 0.0735658077755943, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 9014 / 20000\n",
      "gradient norm: 0.07920535793527961, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00555\n",
      "epoch 9015 / 20000\n",
      "gradient norm: 0.08628391183447093, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 9016 / 20000\n",
      "gradient norm: 0.03066593334369827, minimum ratio: 2.436842105263158\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 9017 / 20000\n",
      "gradient norm: 0.057587784773204476, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 9018 / 20000\n",
      "gradient norm: 0.03627736450289376, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 9019 / 20000\n",
      "gradient norm: 0.07941299441154115, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 9020 / 20000\n",
      "gradient norm: 0.10257570806425065, minimum ratio: 2.46578947368421\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 9021 / 20000\n",
      "gradient norm: 0.05229695333400741, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 9022 / 20000\n",
      "gradient norm: 0.10606119211297482, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 9023 / 20000\n",
      "gradient norm: 0.11796566075645387, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 9024 / 20000\n",
      "gradient norm: 0.07813480059849098, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 9025 / 20000\n",
      "gradient norm: 0.053107149491552263, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 9026 / 20000\n",
      "gradient norm: 0.07885872758924961, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 9027 / 20000\n",
      "gradient norm: 0.016589076549280435, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00551\n",
      "epoch 9028 / 20000\n",
      "gradient norm: 0.04352747873053886, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 9029 / 20000\n",
      "gradient norm: 0.0726554524153471, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 9030 / 20000\n",
      "gradient norm: 0.142838952713646, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00555\n",
      "epoch 9031 / 20000\n",
      "gradient norm: 0.07220811251318082, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 9032 / 20000\n",
      "gradient norm: 0.08169835398439318, minimum ratio: 2.4868421052631575\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 9033 / 20000\n",
      "gradient norm: 0.07712312118383124, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 9034 / 20000\n",
      "gradient norm: 0.065204463142436, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 9035 / 20000\n",
      "gradient norm: 0.08251578424824402, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 9036 / 20000\n",
      "gradient norm: 0.06446849516942166, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 9037 / 20000\n",
      "gradient norm: 0.05909987160703167, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 9038 / 20000\n",
      "gradient norm: 0.055268558382522315, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 9039 / 20000\n",
      "gradient norm: 0.024396585373324342, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 9040 / 20000\n",
      "gradient norm: 0.04820563997782301, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 9041 / 20000\n",
      "gradient norm: 0.059956948418403044, minimum ratio: 2.46578947368421\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 9042 / 20000\n",
      "gradient norm: 0.07088281842879951, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 9043 / 20000\n",
      "gradient norm: 0.07251024941797368, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 9044 / 20000\n",
      "gradient norm: 0.07759806793183088, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 9045 / 20000\n",
      "gradient norm: 0.104187171018566, minimum ratio: 2.4842105263157896\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 9046 / 20000\n",
      "gradient norm: 0.07456862350227311, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 9047 / 20000\n",
      "gradient norm: 0.055409232241800055, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 9048 / 20000\n",
      "gradient norm: 0.11659834848251194, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00551\n",
      "epoch 9049 / 20000\n",
      "gradient norm: 0.08703709891415201, minimum ratio: 2.452631578947368\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 9050 / 20000\n",
      "gradient norm: 0.03523735300404951, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 9051 / 20000\n",
      "gradient norm: 0.033748741196177434, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 9052 / 20000\n",
      "gradient norm: 0.08391702244989574, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 9053 / 20000\n",
      "gradient norm: 0.074629675844335, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 9054 / 20000\n",
      "gradient norm: 0.062311763293109834, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 9055 / 20000\n",
      "gradient norm: 0.044888241100125015, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 9056 / 20000\n",
      "gradient norm: 0.07417424349114299, minimum ratio: 2.460526315789474\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 9057 / 20000\n",
      "gradient norm: 0.0592509699636139, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 9058 / 20000\n",
      "gradient norm: 0.033056717191357166, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 9059 / 20000\n",
      "gradient norm: 0.05580737494165078, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 9060 / 20000\n",
      "gradient norm: 0.06121988472295925, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 9061 / 20000\n",
      "gradient norm: 0.04911675848416053, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 9062 / 20000\n",
      "gradient norm: 0.12018662039190531, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 9063 / 20000\n",
      "gradient norm: 0.10632863186765462, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 9064 / 20000\n",
      "gradient norm: 0.03613578685326502, minimum ratio: 2.452631578947368\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 9065 / 20000\n",
      "gradient norm: 0.09083335055038333, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 9066 / 20000\n",
      "gradient norm: 0.04487858500215225, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 9067 / 20000\n",
      "gradient norm: 0.026590404318994842, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 9068 / 20000\n",
      "gradient norm: 0.03822495846543461, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 9069 / 20000\n",
      "gradient norm: 0.04990447376621887, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 9070 / 20000\n",
      "gradient norm: 0.07746466022217646, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 9071 / 20000\n",
      "gradient norm: 0.06851762774749659, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 9072 / 20000\n",
      "gradient norm: 0.08678507391596213, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 9073 / 20000\n",
      "gradient norm: 0.07963821820158046, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 9074 / 20000\n",
      "gradient norm: 0.07994611095637083, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00554\n",
      "epoch 9075 / 20000\n",
      "gradient norm: 0.05486793621093966, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 9076 / 20000\n",
      "gradient norm: 0.11544703820254654, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 9077 / 20000\n",
      "gradient norm: 0.040796581422910094, minimum ratio: 2.465789473684211\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 9078 / 20000\n",
      "gradient norm: 0.04345668794121593, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 9079 / 20000\n",
      "gradient norm: 0.05856393475551158, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 9080 / 20000\n",
      "gradient norm: 0.12053001299500465, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 9081 / 20000\n",
      "gradient norm: 0.058619718882255256, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00551\n",
      "epoch 9082 / 20000\n",
      "gradient norm: 0.08426296862307936, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 9083 / 20000\n",
      "gradient norm: 0.06187226180918515, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 9084 / 20000\n",
      "gradient norm: 0.06958361156284809, minimum ratio: 2.492105263157895\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 9085 / 20000\n",
      "gradient norm: 0.09158844931516796, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 9086 / 20000\n",
      "gradient norm: 0.05471047729952261, minimum ratio: 2.4447368421052635\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 9087 / 20000\n",
      "gradient norm: 0.08006457950978074, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 9088 / 20000\n",
      "gradient norm: 0.05122503166785464, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00551\n",
      "epoch 9089 / 20000\n",
      "gradient norm: 0.10116853180807084, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 9090 / 20000\n",
      "gradient norm: 0.07285661782952957, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 9091 / 20000\n",
      "gradient norm: 0.08450864255428314, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 9092 / 20000\n",
      "gradient norm: 0.059470878448337317, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00551\n",
      "epoch 9093 / 20000\n",
      "gradient norm: 0.07512627250980586, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 9094 / 20000\n",
      "gradient norm: 0.0828753640234936, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00555\n",
      "epoch 9095 / 20000\n",
      "gradient norm: 0.04007711062877206, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 9096 / 20000\n",
      "gradient norm: 0.11117112741339952, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 9097 / 20000\n",
      "gradient norm: 0.056637669913470745, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 9098 / 20000\n",
      "gradient norm: 0.08371002005878836, minimum ratio: 2.4842105263157896\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 9099 / 20000\n",
      "gradient norm: 0.04966651799622923, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 9100 / 20000\n",
      "gradient norm: 0.06536243905429728, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00551\n",
      "epoch 9101 / 20000\n",
      "gradient norm: 0.06197185422934126, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00554\n",
      "epoch 9102 / 20000\n",
      "gradient norm: 0.052767855780984974, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 9103 / 20000\n",
      "gradient norm: 0.06141901342198253, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 9104 / 20000\n",
      "gradient norm: 0.0651708742370829, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 9105 / 20000\n",
      "gradient norm: 0.03413477027788758, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 9106 / 20000\n",
      "gradient norm: 0.07285997259896249, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 9107 / 20000\n",
      "gradient norm: 0.06152853841194883, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 9108 / 20000\n",
      "gradient norm: 0.093567740987055, minimum ratio: 2.4421052631578952\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 9109 / 20000\n",
      "gradient norm: 0.05442066949035507, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 9110 / 20000\n",
      "gradient norm: 0.0982898036018014, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 9111 / 20000\n",
      "gradient norm: 0.0653130715363659, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00551\n",
      "epoch 9112 / 20000\n",
      "gradient norm: 0.03716082597384229, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 9113 / 20000\n",
      "gradient norm: 0.07663474953733385, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 9114 / 20000\n",
      "gradient norm: 0.04343327056267299, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 9115 / 20000\n",
      "gradient norm: 0.06642724329140037, minimum ratio: 2.460526315789474\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 9116 / 20000\n",
      "gradient norm: 0.031758719094796106, minimum ratio: 2.4631578947368427\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 9117 / 20000\n",
      "gradient norm: 0.06803557298553642, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 9118 / 20000\n",
      "gradient norm: 0.044624458998441696, minimum ratio: 2.4236842105263157\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 9119 / 20000\n",
      "gradient norm: 0.041449250013101846, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 9120 / 20000\n",
      "gradient norm: 0.041309961496153846, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 9121 / 20000\n",
      "gradient norm: 0.0631528663507197, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 9122 / 20000\n",
      "gradient norm: 0.05940402706619352, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00554\n",
      "epoch 9123 / 20000\n",
      "gradient norm: 0.04713208359316923, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 9124 / 20000\n",
      "gradient norm: 0.08483385486761108, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 9125 / 20000\n",
      "gradient norm: 0.045846171415178105, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 9126 / 20000\n",
      "gradient norm: 0.08436409599380568, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 9127 / 20000\n",
      "gradient norm: 0.0715246909239795, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 9128 / 20000\n",
      "gradient norm: 0.04106788139324635, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 9129 / 20000\n",
      "gradient norm: 0.07202576694544405, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 9130 / 20000\n",
      "gradient norm: 0.05661920295096934, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 9131 / 20000\n",
      "gradient norm: 0.040954582422273234, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 9132 / 20000\n",
      "gradient norm: 0.05275376889039762, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 9133 / 20000\n",
      "gradient norm: 0.10106706863734871, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 9134 / 20000\n",
      "gradient norm: 0.03486516265547834, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 9135 / 20000\n",
      "gradient norm: 0.0651113710628124, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 9136 / 20000\n",
      "gradient norm: 0.055178864451590925, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 9137 / 20000\n",
      "gradient norm: 0.06836389866657555, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 9138 / 20000\n",
      "gradient norm: 0.05588390081538819, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 9139 / 20000\n",
      "gradient norm: 0.07724075641453965, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 9140 / 20000\n",
      "gradient norm: 0.07641251335735433, minimum ratio: 2.46578947368421\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 9141 / 20000\n",
      "gradient norm: 0.045409697864670306, minimum ratio: 2.4447368421052635\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 9142 / 20000\n",
      "gradient norm: 0.057448178762570024, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 9143 / 20000\n",
      "gradient norm: 0.07448744523571804, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 9144 / 20000\n",
      "gradient norm: 0.044541871538967825, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 9145 / 20000\n",
      "gradient norm: 0.07738568278728053, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 9146 / 20000\n",
      "gradient norm: 0.060523093183292076, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 9147 / 20000\n",
      "gradient norm: 0.062331209250260144, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 9148 / 20000\n",
      "gradient norm: 0.10524142859503627, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 9149 / 20000\n",
      "gradient norm: 0.07784765097312629, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 9150 / 20000\n",
      "gradient norm: 0.12447740836068988, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 9151 / 20000\n",
      "gradient norm: 0.0372281494201161, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 9152 / 20000\n",
      "gradient norm: 0.05877521447837353, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 9153 / 20000\n",
      "gradient norm: 0.036993104236898944, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 9154 / 20000\n",
      "gradient norm: 0.06310587719781324, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 9155 / 20000\n",
      "gradient norm: 0.03665415647265036, minimum ratio: 2.489473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 9156 / 20000\n",
      "gradient norm: 0.04964329654467292, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 9157 / 20000\n",
      "gradient norm: 0.07531707668385934, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 9158 / 20000\n",
      "gradient norm: 0.06835505028720945, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 9159 / 20000\n",
      "gradient norm: 0.03673493587120902, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 9160 / 20000\n",
      "gradient norm: 0.06560901738703251, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 9161 / 20000\n",
      "gradient norm: 0.10903995667467825, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 9162 / 20000\n",
      "gradient norm: 0.05820819624932483, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 9163 / 20000\n",
      "gradient norm: 0.06862774299224839, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 9164 / 20000\n",
      "gradient norm: 0.07115156878717244, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 9165 / 20000\n",
      "gradient norm: 0.08057887737231795, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 9166 / 20000\n",
      "gradient norm: 0.04436408635228872, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 9167 / 20000\n",
      "gradient norm: 0.07880859124998096, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 9168 / 20000\n",
      "gradient norm: 0.04744729358935729, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 9169 / 20000\n",
      "gradient norm: 0.0894206230295822, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 9170 / 20000\n",
      "gradient norm: 0.061355317855486646, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 9171 / 20000\n",
      "gradient norm: 0.06547133158892393, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 9172 / 20000\n",
      "gradient norm: 0.03597000257286709, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 9173 / 20000\n",
      "gradient norm: 0.07427094003651291, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 9174 / 20000\n",
      "gradient norm: 0.09257363376673311, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 9175 / 20000\n",
      "gradient norm: 0.09528764394053724, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 9176 / 20000\n",
      "gradient norm: 0.07544842321658507, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 9177 / 20000\n",
      "gradient norm: 0.04042680893326178, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 9178 / 20000\n",
      "gradient norm: 0.05617097194772214, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 9179 / 20000\n",
      "gradient norm: 0.02842525475716684, minimum ratio: 2.4842105263157896\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 9180 / 20000\n",
      "gradient norm: 0.0654454521209118, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 9181 / 20000\n",
      "gradient norm: 0.02091865465627052, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 9182 / 20000\n",
      "gradient norm: 0.0667214727436658, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 9183 / 20000\n",
      "gradient norm: 0.04595902632718207, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 9184 / 20000\n",
      "gradient norm: 0.03706181397137698, minimum ratio: 2.4868421052631575\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 9185 / 20000\n",
      "gradient norm: 0.1029184437065851, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 9186 / 20000\n",
      "gradient norm: 0.09659840521635488, minimum ratio: 2.4868421052631575\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 9187 / 20000\n",
      "gradient norm: 0.05341379134915769, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 9188 / 20000\n",
      "gradient norm: 0.032987988903187215, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 9189 / 20000\n",
      "gradient norm: 0.07977127289632335, minimum ratio: 2.4894736842105267\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 9190 / 20000\n",
      "gradient norm: 0.10227926305378787, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 9191 / 20000\n",
      "gradient norm: 0.042649013514164835, minimum ratio: 2.4736842105263155\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 9192 / 20000\n",
      "gradient norm: 0.09442981769097969, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00554\n",
      "epoch 9193 / 20000\n",
      "gradient norm: 0.041101649490883574, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 9194 / 20000\n",
      "gradient norm: 0.0963405616930686, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 9195 / 20000\n",
      "gradient norm: 0.05783615232212469, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 9196 / 20000\n",
      "gradient norm: 0.04870406902045943, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 9197 / 20000\n",
      "gradient norm: 0.09136799463885836, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 9198 / 20000\n",
      "gradient norm: 0.17875681689474732, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 9199 / 20000\n",
      "gradient norm: 0.03352841202286072, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 9200 / 20000\n",
      "gradient norm: 0.05616357910912484, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 9201 / 20000\n",
      "gradient norm: 0.04310826092842035, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 9202 / 20000\n",
      "gradient norm: 0.04006593947997317, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 9203 / 20000\n",
      "gradient norm: 0.02462480030953884, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00551\n",
      "epoch 9204 / 20000\n",
      "gradient norm: 0.11007422360125929, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 9205 / 20000\n",
      "gradient norm: 0.06430157623253763, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 9206 / 20000\n",
      "gradient norm: 0.059430955385323614, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 9207 / 20000\n",
      "gradient norm: 0.0296942997520091, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 9208 / 20000\n",
      "gradient norm: 0.08623053936753422, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 9209 / 20000\n",
      "gradient norm: 0.04886393828201108, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 9210 / 20000\n",
      "gradient norm: 0.04863230307819322, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 9211 / 20000\n",
      "gradient norm: 0.039312628214247525, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 9212 / 20000\n",
      "gradient norm: 0.132812628231477, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00551\n",
      "epoch 9213 / 20000\n",
      "gradient norm: 0.07323301379801705, minimum ratio: 2.4684210526315784\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00554\n",
      "epoch 9214 / 20000\n",
      "gradient norm: 0.0452315520378761, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 9215 / 20000\n",
      "gradient norm: 0.08006810152437538, minimum ratio: 2.465789473684211\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 9216 / 20000\n",
      "gradient norm: 0.085121066251304, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 9217 / 20000\n",
      "gradient norm: 0.038584586494835094, minimum ratio: 2.4421052631578943\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 9218 / 20000\n",
      "gradient norm: 0.026777883307659067, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 9219 / 20000\n",
      "gradient norm: 0.04597150074550882, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 9220 / 20000\n",
      "gradient norm: 0.07913438999094069, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 9221 / 20000\n",
      "gradient norm: 0.04070260882144794, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 9222 / 20000\n",
      "gradient norm: 0.0554959794098977, minimum ratio: 2.492105263157895\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 9223 / 20000\n",
      "gradient norm: 0.03726672285120003, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 9224 / 20000\n",
      "gradient norm: 0.04900951834861189, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 9225 / 20000\n",
      "gradient norm: 0.07633316935971379, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00553\n",
      "epoch 9226 / 20000\n",
      "gradient norm: 0.05422174384875689, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 9227 / 20000\n",
      "gradient norm: 0.03930628625676036, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00551\n",
      "epoch 9228 / 20000\n",
      "gradient norm: 0.0383323716087034, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 9229 / 20000\n",
      "gradient norm: 0.09663355111842975, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 9230 / 20000\n",
      "gradient norm: 0.040299245418282226, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 9231 / 20000\n",
      "gradient norm: 0.11058925511315465, minimum ratio: 2.4736842105263155\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 9232 / 20000\n",
      "gradient norm: 0.07846806233283132, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 9233 / 20000\n",
      "gradient norm: 0.06845374454860575, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 9234 / 20000\n",
      "gradient norm: 0.06625458139751572, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 9235 / 20000\n",
      "gradient norm: 0.08287912825471722, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 9236 / 20000\n",
      "gradient norm: 0.09757687314413488, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 9237 / 20000\n",
      "gradient norm: 0.05552421959146159, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 9238 / 20000\n",
      "gradient norm: 0.08869697886984795, minimum ratio: 2.4499999999999997\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 9239 / 20000\n",
      "gradient norm: 0.10145304066827521, minimum ratio: 2.4868421052631575\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 9240 / 20000\n",
      "gradient norm: 0.020073644711374072, minimum ratio: 2.4842105263157896\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 9241 / 20000\n",
      "gradient norm: 0.07517640400328673, minimum ratio: 2.465789473684211\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 9242 / 20000\n",
      "gradient norm: 0.07990626327227801, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 9243 / 20000\n",
      "gradient norm: 0.06653960805851966, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 9244 / 20000\n",
      "gradient norm: 0.08891074592247605, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 9245 / 20000\n",
      "gradient norm: 0.06212242488982156, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 9246 / 20000\n",
      "gradient norm: 0.05401408553007059, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 9247 / 20000\n",
      "gradient norm: 0.11615713231731206, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00551\n",
      "epoch 9248 / 20000\n",
      "gradient norm: 0.05129756023234222, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 9249 / 20000\n",
      "gradient norm: 0.032993765504215844, minimum ratio: 2.46578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 9250 / 20000\n",
      "gradient norm: 0.054584537603659555, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 9251 / 20000\n",
      "gradient norm: 0.031961494125425816, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 9252 / 20000\n",
      "gradient norm: 0.04675901145674288, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 9253 / 20000\n",
      "gradient norm: 0.06759267917368561, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 9254 / 20000\n",
      "gradient norm: 0.05215080257039517, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 9255 / 20000\n",
      "gradient norm: 0.05533447644847911, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 9256 / 20000\n",
      "gradient norm: 0.04527766682440415, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 9257 / 20000\n",
      "gradient norm: 0.03133750807319302, minimum ratio: 2.4736842105263155\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 9258 / 20000\n",
      "gradient norm: 0.05841975996736437, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 9259 / 20000\n",
      "gradient norm: 0.04326182029035408, minimum ratio: 2.492105263157895\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 9260 / 20000\n",
      "gradient norm: 0.08142871409654617, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 9261 / 20000\n",
      "gradient norm: 0.04873747983947396, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 9262 / 20000\n",
      "gradient norm: 0.08998906923807226, minimum ratio: 2.465789473684211\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 9263 / 20000\n",
      "gradient norm: 0.020305481557443272, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 9264 / 20000\n",
      "gradient norm: 0.08910752949304879, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 9265 / 20000\n",
      "gradient norm: 0.059130818146513775, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 9266 / 20000\n",
      "gradient norm: 0.03168288337474223, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 9267 / 20000\n",
      "gradient norm: 0.07410453236661851, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 9268 / 20000\n",
      "gradient norm: 0.0878591571963625, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 9269 / 20000\n",
      "gradient norm: 0.08687975018983707, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00551\n",
      "epoch 9270 / 20000\n",
      "gradient norm: 0.07485852783429436, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00553\n",
      "epoch 9271 / 20000\n",
      "gradient norm: 0.09913230926031247, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 9272 / 20000\n",
      "gradient norm: 0.1308390877675265, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 9273 / 20000\n",
      "gradient norm: 0.08876816823612899, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 9274 / 20000\n",
      "gradient norm: 0.07883717271033674, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 9275 / 20000\n",
      "gradient norm: 0.07220026716822758, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 9276 / 20000\n",
      "gradient norm: 0.07919311599107459, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 9277 / 20000\n",
      "gradient norm: 0.0409630884823855, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 9278 / 20000\n",
      "gradient norm: 0.030843970758724026, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 9279 / 20000\n",
      "gradient norm: 0.06981851125601679, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 9280 / 20000\n",
      "gradient norm: 0.043630849570035934, minimum ratio: 2.460526315789474\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 9281 / 20000\n",
      "gradient norm: 0.058754930840223096, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 9282 / 20000\n",
      "gradient norm: 0.07101652746496256, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 9283 / 20000\n",
      "gradient norm: 0.07202116877306253, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 9284 / 20000\n",
      "gradient norm: 0.05509809247450903, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 9285 / 20000\n",
      "gradient norm: 0.07345234393142164, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 9286 / 20000\n",
      "gradient norm: 0.050605107797309756, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 9287 / 20000\n",
      "gradient norm: 0.08447681437246501, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 9288 / 20000\n",
      "gradient norm: 0.042216328176436946, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 9289 / 20000\n",
      "gradient norm: 0.06726335596977151, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 9290 / 20000\n",
      "gradient norm: 0.08224231786152814, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 9291 / 20000\n",
      "gradient norm: 0.06647817592602223, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00553\n",
      "epoch 9292 / 20000\n",
      "gradient norm: 0.09088065288960934, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 9293 / 20000\n",
      "gradient norm: 0.03194292166881496, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 9294 / 20000\n",
      "gradient norm: 0.03963324797223322, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 9295 / 20000\n",
      "gradient norm: 0.04424765834119171, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 9296 / 20000\n",
      "gradient norm: 0.043292701098835096, minimum ratio: 2.4868421052631575\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 9297 / 20000\n",
      "gradient norm: 0.03813429108413402, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 9298 / 20000\n",
      "gradient norm: 0.088168308371678, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 9299 / 20000\n",
      "gradient norm: 0.036875147139653563, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 9300 / 20000\n",
      "gradient norm: 0.09632015274837613, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 9301 / 20000\n",
      "gradient norm: 0.014453457537456416, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 9302 / 20000\n",
      "gradient norm: 0.055730657710228115, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 9303 / 20000\n",
      "gradient norm: 0.05290571635123342, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 9304 / 20000\n",
      "gradient norm: 0.06432712491368875, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 9305 / 20000\n",
      "gradient norm: 0.05522470240248367, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 9306 / 20000\n",
      "gradient norm: 0.03168843232560903, minimum ratio: 2.4394736842105265\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 9307 / 20000\n",
      "gradient norm: 0.10787382241687737, minimum ratio: 2.4894736842105267\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 9308 / 20000\n",
      "gradient norm: 0.033389829215593636, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 9309 / 20000\n",
      "gradient norm: 0.05730194773059338, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 9310 / 20000\n",
      "gradient norm: 0.03300198630313389, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 9311 / 20000\n",
      "gradient norm: 0.06491521998941607, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 9312 / 20000\n",
      "gradient norm: 0.04036092813475989, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 9313 / 20000\n",
      "gradient norm: 0.04044470483495388, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 9314 / 20000\n",
      "gradient norm: 0.0660633992520161, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 9315 / 20000\n",
      "gradient norm: 0.07846951967803761, minimum ratio: 2.4842105263157896\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 9316 / 20000\n",
      "gradient norm: 0.07430244379793294, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 9317 / 20000\n",
      "gradient norm: 0.024256728509499226, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 9318 / 20000\n",
      "gradient norm: 0.03615299586090259, minimum ratio: 2.465789473684211\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 9319 / 20000\n",
      "gradient norm: 0.04544450656248955, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 9320 / 20000\n",
      "gradient norm: 0.09018249355722219, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00551\n",
      "epoch 9321 / 20000\n",
      "gradient norm: 0.07912944004056044, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 9322 / 20000\n",
      "gradient norm: 0.08436536689987406, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 9323 / 20000\n",
      "gradient norm: 0.0772132546553621, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 9324 / 20000\n",
      "gradient norm: 0.0458858158235671, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 9325 / 20000\n",
      "gradient norm: 0.02700987421849277, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 9326 / 20000\n",
      "gradient norm: 0.08057774958433583, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 9327 / 20000\n",
      "gradient norm: 0.011032160919057787, minimum ratio: 2.4631578947368427\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 9328 / 20000\n",
      "gradient norm: 0.08156664986745454, minimum ratio: 2.4447368421052635\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 9329 / 20000\n",
      "gradient norm: 0.0615739855566062, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00552\n",
      "epoch 9330 / 20000\n",
      "gradient norm: 0.03454105929995421, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00553\n",
      "epoch 9331 / 20000\n",
      "gradient norm: 0.044453515321947634, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 9332 / 20000\n",
      "gradient norm: 0.06486290745669976, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 9333 / 20000\n",
      "gradient norm: 0.045648132218047976, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 9334 / 20000\n",
      "gradient norm: 0.032541088192374445, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 9335 / 20000\n",
      "gradient norm: 0.07900391460862011, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 9336 / 20000\n",
      "gradient norm: 0.04161064251093194, minimum ratio: 2.4868421052631575\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 9337 / 20000\n",
      "gradient norm: 0.03155448960023932, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 9338 / 20000\n",
      "gradient norm: 0.0617337306648551, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 9339 / 20000\n",
      "gradient norm: 0.05523815123888198, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 9340 / 20000\n",
      "gradient norm: 0.02763181108457502, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 9341 / 20000\n",
      "gradient norm: 0.030802716457401402, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 9342 / 20000\n",
      "gradient norm: 0.11749371548648924, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 9343 / 20000\n",
      "gradient norm: 0.09966002177679911, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 9344 / 20000\n",
      "gradient norm: 0.04917534557171166, minimum ratio: 2.4499999999999997\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 9345 / 20000\n",
      "gradient norm: 0.07228775857947767, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 9346 / 20000\n",
      "gradient norm: 0.0880630299798213, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 9347 / 20000\n",
      "gradient norm: 0.07101431884802878, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 9348 / 20000\n",
      "gradient norm: 0.07114523579366505, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 9349 / 20000\n",
      "gradient norm: 0.1712256169412285, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00554\n",
      "epoch 9350 / 20000\n",
      "gradient norm: 0.06683134764898568, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 9351 / 20000\n",
      "gradient norm: 0.09136649241554551, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 9352 / 20000\n",
      "gradient norm: 0.06545455180457793, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 9353 / 20000\n",
      "gradient norm: 0.06615595528273843, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 9354 / 20000\n",
      "gradient norm: 0.03153736541571561, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 9355 / 20000\n",
      "gradient norm: 0.09375943260965869, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 9356 / 20000\n",
      "gradient norm: 0.12125311279669404, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 9357 / 20000\n",
      "gradient norm: 0.049820030108094215, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 9358 / 20000\n",
      "gradient norm: 0.06242938328796299, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 9359 / 20000\n",
      "gradient norm: 0.0521319645922631, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 9360 / 20000\n",
      "gradient norm: 0.10495373443700373, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 9361 / 20000\n",
      "gradient norm: 0.0237565187853761, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 9362 / 20000\n",
      "gradient norm: 0.08430951391346753, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 9363 / 20000\n",
      "gradient norm: 0.04016952417441644, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 9364 / 20000\n",
      "gradient norm: 0.07722434174502268, minimum ratio: 2.4842105263157896\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 9365 / 20000\n",
      "gradient norm: 0.08126230433117598, minimum ratio: 2.4684210526315784\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00554\n",
      "epoch 9366 / 20000\n",
      "gradient norm: 0.05485076690092683, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 9367 / 20000\n",
      "gradient norm: 0.04579713474959135, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 9368 / 20000\n",
      "gradient norm: 0.05400860154986731, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 9369 / 20000\n",
      "gradient norm: 0.07519945834064856, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00553\n",
      "epoch 9370 / 20000\n",
      "gradient norm: 0.10186833189800382, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 9371 / 20000\n",
      "gradient norm: 0.07411571424745489, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 9372 / 20000\n",
      "gradient norm: 0.09889000980183482, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 9373 / 20000\n",
      "gradient norm: 0.029209874192019925, minimum ratio: 2.46578947368421\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 9374 / 20000\n",
      "gradient norm: 0.05427594418870285, minimum ratio: 2.46578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 9375 / 20000\n",
      "gradient norm: 0.07288157266157214, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 9376 / 20000\n",
      "gradient norm: 0.07123181747738272, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 9377 / 20000\n",
      "gradient norm: 0.038175203721039, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00551\n",
      "epoch 9378 / 20000\n",
      "gradient norm: 0.04757215571589768, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 9379 / 20000\n",
      "gradient norm: 0.06133292580489069, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 9380 / 20000\n",
      "gradient norm: 0.09889526013284922, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 9381 / 20000\n",
      "gradient norm: 0.03971513353462797, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 9382 / 20000\n",
      "gradient norm: 0.06824142823461443, minimum ratio: 2.4894736842105267\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 9383 / 20000\n",
      "gradient norm: 0.06226643765694462, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 9384 / 20000\n",
      "gradient norm: 0.04416427161777392, minimum ratio: 2.460526315789474\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 9385 / 20000\n",
      "gradient norm: 0.09429474594071507, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 9386 / 20000\n",
      "gradient norm: 0.03149683924857527, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 9387 / 20000\n",
      "gradient norm: 0.08862342560314573, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 9388 / 20000\n",
      "gradient norm: 0.06717356274930353, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 9389 / 20000\n",
      "gradient norm: 0.057826774660497904, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 9390 / 20000\n",
      "gradient norm: 0.06869951129192486, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 9391 / 20000\n",
      "gradient norm: 0.0924652241228614, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 9392 / 20000\n",
      "gradient norm: 0.08317445279681124, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 9393 / 20000\n",
      "gradient norm: 0.12418971443548799, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00551\n",
      "epoch 9394 / 20000\n",
      "gradient norm: 0.05166918144823285, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 9395 / 20000\n",
      "gradient norm: 0.09257014887407422, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 9396 / 20000\n",
      "gradient norm: 0.06096811851602979, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 9397 / 20000\n",
      "gradient norm: 0.03459630723227747, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 9398 / 20000\n",
      "gradient norm: 0.041758608029340394, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 9399 / 20000\n",
      "gradient norm: 0.0184829691570485, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 9400 / 20000\n",
      "gradient norm: 0.05426893330877647, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 9401 / 20000\n",
      "gradient norm: 0.0637211627617944, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 9402 / 20000\n",
      "gradient norm: 0.05597744099213742, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 9403 / 20000\n",
      "gradient norm: 0.04720218776492402, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 9404 / 20000\n",
      "gradient norm: 0.08013450668659061, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 9405 / 20000\n",
      "gradient norm: 0.03374820281169377, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 9406 / 20000\n",
      "gradient norm: 0.030124004202662036, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 9407 / 20000\n",
      "gradient norm: 0.0834226356819272, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 9408 / 20000\n",
      "gradient norm: 0.07880023750476539, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00555\n",
      "epoch 9409 / 20000\n",
      "gradient norm: 0.0627484533470124, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 9410 / 20000\n",
      "gradient norm: 0.05100684185163118, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 9411 / 20000\n",
      "gradient norm: 0.0778931108652614, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 9412 / 20000\n",
      "gradient norm: 0.10343604447552934, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 9413 / 20000\n",
      "gradient norm: 0.04541769906063564, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 9414 / 20000\n",
      "gradient norm: 0.0669119234662503, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 9415 / 20000\n",
      "gradient norm: 0.06706828548340127, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 9416 / 20000\n",
      "gradient norm: 0.04890657418582123, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 9417 / 20000\n",
      "gradient norm: 0.09260657973936759, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 9418 / 20000\n",
      "gradient norm: 0.044999265985097736, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00554\n",
      "epoch 9419 / 20000\n",
      "gradient norm: 0.0697623401938472, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 9420 / 20000\n",
      "gradient norm: 0.053484606702113524, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 9421 / 20000\n",
      "gradient norm: 0.031048317279783078, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 9422 / 20000\n",
      "gradient norm: 0.07350448606302962, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 9423 / 20000\n",
      "gradient norm: 0.03189289439615095, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 9424 / 20000\n",
      "gradient norm: 0.08225808793213218, minimum ratio: 2.492105263157895\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 9425 / 20000\n",
      "gradient norm: 0.07764902123017237, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 9426 / 20000\n",
      "gradient norm: 0.08311970219074283, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 9427 / 20000\n",
      "gradient norm: 0.027419786725658923, minimum ratio: 2.4868421052631575\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 9428 / 20000\n",
      "gradient norm: 0.04561776951595675, minimum ratio: 2.4736842105263155\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 9429 / 20000\n",
      "gradient norm: 0.045461175235686824, minimum ratio: 2.4894736842105267\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 9430 / 20000\n",
      "gradient norm: 0.09522051265230402, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00551\n",
      "epoch 9431 / 20000\n",
      "gradient norm: 0.06908030185149983, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 9432 / 20000\n",
      "gradient norm: 0.081811475509312, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 9433 / 20000\n",
      "gradient norm: 0.11489949413225986, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 9434 / 20000\n",
      "gradient norm: 0.08411366259679198, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 9435 / 20000\n",
      "gradient norm: 0.04657136450987309, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 9436 / 20000\n",
      "gradient norm: 0.02284808525291737, minimum ratio: 2.4868421052631575\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 9437 / 20000\n",
      "gradient norm: 0.11015562922693789, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 9438 / 20000\n",
      "gradient norm: 0.021582853150903247, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 9439 / 20000\n",
      "gradient norm: 0.03822116716764867, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 9440 / 20000\n",
      "gradient norm: 0.047665662918007, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 9441 / 20000\n",
      "gradient norm: 0.06246921235288028, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 9442 / 20000\n",
      "gradient norm: 0.09160183643689379, minimum ratio: 2.46578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 9443 / 20000\n",
      "gradient norm: 0.06697478052228689, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 9444 / 20000\n",
      "gradient norm: 0.03737132405512966, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 9445 / 20000\n",
      "gradient norm: 0.06725710566388443, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 9446 / 20000\n",
      "gradient norm: 0.09612944547552615, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 9447 / 20000\n",
      "gradient norm: 0.028963194316020235, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 9448 / 20000\n",
      "gradient norm: 0.03241564883501269, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 9449 / 20000\n",
      "gradient norm: 0.055325533146969974, minimum ratio: 2.465789473684211\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 9450 / 20000\n",
      "gradient norm: 0.0490492538374383, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 9451 / 20000\n",
      "gradient norm: 0.07025595734012313, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 9452 / 20000\n",
      "gradient norm: 0.10649307555286214, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00551\n",
      "epoch 9453 / 20000\n",
      "gradient norm: 0.037426194321596995, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 9454 / 20000\n",
      "gradient norm: 0.031130590999964625, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 9455 / 20000\n",
      "gradient norm: 0.054120048371260054, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 9456 / 20000\n",
      "gradient norm: 0.051603185034764465, minimum ratio: 2.46578947368421\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 9457 / 20000\n",
      "gradient norm: 0.06974100862862542, minimum ratio: 2.460526315789474\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 9458 / 20000\n",
      "gradient norm: 0.03095608134754002, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 9459 / 20000\n",
      "gradient norm: 0.07312473133788444, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 9460 / 20000\n",
      "gradient norm: 0.05871802195906639, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 9461 / 20000\n",
      "gradient norm: 0.09034994873218238, minimum ratio: 2.460526315789474\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00552\n",
      "epoch 9462 / 20000\n",
      "gradient norm: 0.15685740439221263, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00555\n",
      "epoch 9463 / 20000\n",
      "gradient norm: 0.08073694270569831, minimum ratio: 2.46578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 9464 / 20000\n",
      "gradient norm: 0.10712617979152128, minimum ratio: 2.46578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 9465 / 20000\n",
      "gradient norm: 0.10590909630991518, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 9466 / 20000\n",
      "gradient norm: 0.09891182486899197, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 9467 / 20000\n",
      "gradient norm: 0.06981858104700223, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 9468 / 20000\n",
      "gradient norm: 0.10484616761095822, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00553\n",
      "epoch 9469 / 20000\n",
      "gradient norm: 0.05542973586125299, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 9470 / 20000\n",
      "gradient norm: 0.06955766066676006, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 9471 / 20000\n",
      "gradient norm: 0.10201672444236465, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 9472 / 20000\n",
      "gradient norm: 0.0638677827664651, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 9473 / 20000\n",
      "gradient norm: 0.047116219939198345, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 9474 / 20000\n",
      "gradient norm: 0.07056334556546062, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 9475 / 20000\n",
      "gradient norm: 0.04302036348963156, minimum ratio: 2.4868421052631575\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 9476 / 20000\n",
      "gradient norm: 0.1529787932522595, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00554\n",
      "epoch 9477 / 20000\n",
      "gradient norm: 0.06284377441625111, minimum ratio: 2.436842105263158\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 9478 / 20000\n",
      "gradient norm: 0.09718478543800302, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 9479 / 20000\n",
      "gradient norm: 0.08858208515448496, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 9480 / 20000\n",
      "gradient norm: 0.12566853110911325, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 9481 / 20000\n",
      "gradient norm: 0.07243178322096355, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 9482 / 20000\n",
      "gradient norm: 0.09022927191108465, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 9483 / 20000\n",
      "gradient norm: 0.08351869447506033, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 9484 / 20000\n",
      "gradient norm: 0.048121116298716515, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 9485 / 20000\n",
      "gradient norm: 0.06413183512631804, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 9486 / 20000\n",
      "gradient norm: 0.08945876004872844, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 9487 / 20000\n",
      "gradient norm: 0.08065820220508613, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00551\n",
      "epoch 9488 / 20000\n",
      "gradient norm: 0.05023359780898318, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 9489 / 20000\n",
      "gradient norm: 0.06335510323697235, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 9490 / 20000\n",
      "gradient norm: 0.03912377028609626, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 9491 / 20000\n",
      "gradient norm: 0.08476657443679869, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 9492 / 20000\n",
      "gradient norm: 0.05034219106892124, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 9493 / 20000\n",
      "gradient norm: 0.03795834741322324, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 9494 / 20000\n",
      "gradient norm: 0.03615546922083013, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00551\n",
      "epoch 9495 / 20000\n",
      "gradient norm: 0.046056963270530105, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 9496 / 20000\n",
      "gradient norm: 0.09061715012649074, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 9497 / 20000\n",
      "gradient norm: 0.04254156909883022, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 9498 / 20000\n",
      "gradient norm: 0.07940756849711761, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 9499 / 20000\n",
      "gradient norm: 0.050781705271219835, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00553\n",
      "epoch 9500 / 20000\n",
      "gradient norm: 0.056006335362326354, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 9501 / 20000\n",
      "gradient norm: 0.06277908460469916, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 9502 / 20000\n",
      "gradient norm: 0.05632290500216186, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 9503 / 20000\n",
      "gradient norm: 0.0439355201961007, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 9504 / 20000\n",
      "gradient norm: 0.08460205816663802, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 9505 / 20000\n",
      "gradient norm: 0.09792463532357942, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 9506 / 20000\n",
      "gradient norm: 0.04273889760952443, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 9507 / 20000\n",
      "gradient norm: 0.04097702988656238, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 9508 / 20000\n",
      "gradient norm: 0.05769806742318906, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 9509 / 20000\n",
      "gradient norm: 0.03608361040824093, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 9510 / 20000\n",
      "gradient norm: 0.034593849475641036, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 9511 / 20000\n",
      "gradient norm: 0.06706756172934547, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 9512 / 20000\n",
      "gradient norm: 0.047382636985275894, minimum ratio: 2.46578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 9513 / 20000\n",
      "gradient norm: 0.02016761239792686, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 9514 / 20000\n",
      "gradient norm: 0.07661606767214835, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 9515 / 20000\n",
      "gradient norm: 0.050084018002962694, minimum ratio: 2.46578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 9516 / 20000\n",
      "gradient norm: 0.0747129485826008, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 9517 / 20000\n",
      "gradient norm: 0.11883295187726617, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 9518 / 20000\n",
      "gradient norm: 0.06449628865811974, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 9519 / 20000\n",
      "gradient norm: 0.02543102588970214, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 9520 / 20000\n",
      "gradient norm: 0.05134949047351256, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 9521 / 20000\n",
      "gradient norm: 0.06216575263533741, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 9522 / 20000\n",
      "gradient norm: 0.016964223366812803, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 9523 / 20000\n",
      "gradient norm: 0.03871072985930368, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 9524 / 20000\n",
      "gradient norm: 0.06284171919105574, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 9525 / 20000\n",
      "gradient norm: 0.08892989379819483, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 9526 / 20000\n",
      "gradient norm: 0.06288416907773353, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 9527 / 20000\n",
      "gradient norm: 0.08468384557636455, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 9528 / 20000\n",
      "gradient norm: 0.08353759627789259, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 9529 / 20000\n",
      "gradient norm: 0.11486066109500825, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 9530 / 20000\n",
      "gradient norm: 0.08408449741546065, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 9531 / 20000\n",
      "gradient norm: 0.04866137413773686, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 9532 / 20000\n",
      "gradient norm: 0.05811485409503803, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 9533 / 20000\n",
      "gradient norm: 0.06908217605086975, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 9534 / 20000\n",
      "gradient norm: 0.0764981334505137, minimum ratio: 2.4394736842105265\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 9535 / 20000\n",
      "gradient norm: 0.13114457490155473, minimum ratio: 2.452631578947368\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00551\n",
      "epoch 9536 / 20000\n",
      "gradient norm: 0.06782866601133719, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 9537 / 20000\n",
      "gradient norm: 0.1253416480612941, minimum ratio: 2.4394736842105265\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 9538 / 20000\n",
      "gradient norm: 0.023628415947314352, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 9539 / 20000\n",
      "gradient norm: 0.08413205287070014, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 9540 / 20000\n",
      "gradient norm: 0.06043478840729222, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 9541 / 20000\n",
      "gradient norm: 0.07390256901271641, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 9542 / 20000\n",
      "gradient norm: 0.07702093524858356, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 9543 / 20000\n",
      "gradient norm: 0.13933157792780548, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 9544 / 20000\n",
      "gradient norm: 0.08268766803666949, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 9545 / 20000\n",
      "gradient norm: 0.08365644060540944, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 9546 / 20000\n",
      "gradient norm: 0.04030436390894465, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00565\n",
      "\tval loss: 0.00551\n",
      "epoch 9547 / 20000\n",
      "gradient norm: 0.07921455311588943, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00551\n",
      "epoch 9548 / 20000\n",
      "gradient norm: 0.08224805237841792, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 9549 / 20000\n",
      "gradient norm: 0.05140349915018305, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 9550 / 20000\n",
      "gradient norm: 0.07183794968295842, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 9551 / 20000\n",
      "gradient norm: 0.043757248466135934, minimum ratio: 2.4447368421052635\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 9552 / 20000\n",
      "gradient norm: 0.07862502714851871, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 9553 / 20000\n",
      "gradient norm: 0.057317985221743584, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 9554 / 20000\n",
      "gradient norm: 0.05246850836556405, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 9555 / 20000\n",
      "gradient norm: 0.05746101996919606, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00551\n",
      "epoch 9556 / 20000\n",
      "gradient norm: 0.13773306569783017, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 9557 / 20000\n",
      "gradient norm: 0.12212565762456506, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 9558 / 20000\n",
      "gradient norm: 0.07034378574462608, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 9559 / 20000\n",
      "gradient norm: 0.08951523876748979, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 9560 / 20000\n",
      "gradient norm: 0.045127894525649026, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 9561 / 20000\n",
      "gradient norm: 0.037208911729976535, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 9562 / 20000\n",
      "gradient norm: 0.05959954170975834, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 9563 / 20000\n",
      "gradient norm: 0.04532490944257006, minimum ratio: 2.4736842105263155\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 9564 / 20000\n",
      "gradient norm: 0.054083316441392526, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 9565 / 20000\n",
      "gradient norm: 0.04557370484690182, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 9566 / 20000\n",
      "gradient norm: 0.060672797670122236, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 9567 / 20000\n",
      "gradient norm: 0.02955442338134162, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 9568 / 20000\n",
      "gradient norm: 0.06200445303693414, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 9569 / 20000\n",
      "gradient norm: 0.061524171265773475, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 9570 / 20000\n",
      "gradient norm: 0.044951131130801514, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 9571 / 20000\n",
      "gradient norm: 0.07155337347649038, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 9572 / 20000\n",
      "gradient norm: 0.08645798894576728, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 9573 / 20000\n",
      "gradient norm: 0.03420235113298986, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 9574 / 20000\n",
      "gradient norm: 0.05753975157858804, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 9575 / 20000\n",
      "gradient norm: 0.05323963051341707, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 9576 / 20000\n",
      "gradient norm: 0.03812163442489691, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 9577 / 20000\n",
      "gradient norm: 0.058742713976243977, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 9578 / 20000\n",
      "gradient norm: 0.10270639241207391, minimum ratio: 2.460526315789474\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 9579 / 20000\n",
      "gradient norm: 0.03640182496747002, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 9580 / 20000\n",
      "gradient norm: 0.07041092845611274, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 9581 / 20000\n",
      "gradient norm: 0.04045364435296506, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 9582 / 20000\n",
      "gradient norm: 0.07472455248353072, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 9583 / 20000\n",
      "gradient norm: 0.0933926107827574, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 9584 / 20000\n",
      "gradient norm: 0.033626396412728354, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 9585 / 20000\n",
      "gradient norm: 0.06151972297811881, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 9586 / 20000\n",
      "gradient norm: 0.050134581950260326, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 9587 / 20000\n",
      "gradient norm: 0.10086023469921201, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 9588 / 20000\n",
      "gradient norm: 0.05127688331413083, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 9589 / 20000\n",
      "gradient norm: 0.08809262554859743, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 9590 / 20000\n",
      "gradient norm: 0.06149568530963734, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 9591 / 20000\n",
      "gradient norm: 0.04135742495418526, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 9592 / 20000\n",
      "gradient norm: 0.03798760083736852, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 9593 / 20000\n",
      "gradient norm: 0.06831849008449353, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 9594 / 20000\n",
      "gradient norm: 0.04692646035255166, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 9595 / 20000\n",
      "gradient norm: 0.06502152491884772, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 9596 / 20000\n",
      "gradient norm: 0.08286084193969145, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 9597 / 20000\n",
      "gradient norm: 0.12732634274289012, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 9598 / 20000\n",
      "gradient norm: 0.032238101586699486, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 9599 / 20000\n",
      "gradient norm: 0.15504542621783912, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00551\n",
      "epoch 9600 / 20000\n",
      "gradient norm: 0.08125759137328714, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00556\n",
      "epoch 9601 / 20000\n",
      "gradient norm: 0.11555278103332967, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00551\n",
      "epoch 9602 / 20000\n",
      "gradient norm: 0.04371729516424239, minimum ratio: 2.4868421052631575\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 9603 / 20000\n",
      "gradient norm: 0.12240229663439095, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 9604 / 20000\n",
      "gradient norm: 0.0519307067443151, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 9605 / 20000\n",
      "gradient norm: 0.028690844279481098, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 9606 / 20000\n",
      "gradient norm: 0.0241402416722849, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 9607 / 20000\n",
      "gradient norm: 0.060479104111436754, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 9608 / 20000\n",
      "gradient norm: 0.05013937139301561, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 9609 / 20000\n",
      "gradient norm: 0.041224764892831445, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 9610 / 20000\n",
      "gradient norm: 0.04662990930955857, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 9611 / 20000\n",
      "gradient norm: 0.03442956242361106, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 9612 / 20000\n",
      "gradient norm: 0.07914416876155883, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 9613 / 20000\n",
      "gradient norm: 0.06951546901836991, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 9614 / 20000\n",
      "gradient norm: 0.06461641605710611, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00553\n",
      "epoch 9615 / 20000\n",
      "gradient norm: 0.05463029048405588, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 9616 / 20000\n",
      "gradient norm: 0.05001582874683663, minimum ratio: 2.4210526315789473\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 9617 / 20000\n",
      "gradient norm: 0.05376675908337347, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 9618 / 20000\n",
      "gradient norm: 0.04349174816161394, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 9619 / 20000\n",
      "gradient norm: 0.06776016263756901, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 9620 / 20000\n",
      "gradient norm: 0.04510510346881347, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 9621 / 20000\n",
      "gradient norm: 0.05647342854354065, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 9622 / 20000\n",
      "gradient norm: 0.055323715088889, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 9623 / 20000\n",
      "gradient norm: 0.023294202401302755, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 9624 / 20000\n",
      "gradient norm: 0.104342658421956, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 9625 / 20000\n",
      "gradient norm: 0.06471525703091174, minimum ratio: 2.4421052631578943\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 9626 / 20000\n",
      "gradient norm: 0.0730885406374, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 9627 / 20000\n",
      "gradient norm: 0.08110439404845238, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 9628 / 20000\n",
      "gradient norm: 0.08050501138495747, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 9629 / 20000\n",
      "gradient norm: 0.06015695941459853, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 9630 / 20000\n",
      "gradient norm: 0.06557428283849731, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 9631 / 20000\n",
      "gradient norm: 0.07795340109441895, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 9632 / 20000\n",
      "gradient norm: 0.05216727947117761, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 9633 / 20000\n",
      "gradient norm: 0.048892896418692544, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00553\n",
      "epoch 9634 / 20000\n",
      "gradient norm: 0.08615268720313907, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 9635 / 20000\n",
      "gradient norm: 0.034632788578164764, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 9636 / 20000\n",
      "gradient norm: 0.0631762187986169, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 9637 / 20000\n",
      "gradient norm: 0.10355458129197359, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 9638 / 20000\n",
      "gradient norm: 0.08133069041650742, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 9639 / 20000\n",
      "gradient norm: 0.04693712166044861, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 9640 / 20000\n",
      "gradient norm: 0.12204646074678749, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00551\n",
      "epoch 9641 / 20000\n",
      "gradient norm: 0.15563364047557116, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 9642 / 20000\n",
      "gradient norm: 0.06276444409741089, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 9643 / 20000\n",
      "gradient norm: 0.07080750103341416, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 9644 / 20000\n",
      "gradient norm: 0.07566475833300501, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 9645 / 20000\n",
      "gradient norm: 0.07525570737197995, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 9646 / 20000\n",
      "gradient norm: 0.0325932420528261, minimum ratio: 2.4394736842105265\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 9647 / 20000\n",
      "gradient norm: 0.07294272305443883, minimum ratio: 2.46578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 9648 / 20000\n",
      "gradient norm: 0.05335741851013154, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 9649 / 20000\n",
      "gradient norm: 0.10680223623057827, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 9650 / 20000\n",
      "gradient norm: 0.05113047017948702, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 9651 / 20000\n",
      "gradient norm: 0.05263800488319248, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 9652 / 20000\n",
      "gradient norm: 0.08381112510687672, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00551\n",
      "epoch 9653 / 20000\n",
      "gradient norm: 0.06571619142778218, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 9654 / 20000\n",
      "gradient norm: 0.04492598709475715, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 9655 / 20000\n",
      "gradient norm: 0.056319907860597596, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 9656 / 20000\n",
      "gradient norm: 0.03268235904397443, minimum ratio: 2.4447368421052635\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 9657 / 20000\n",
      "gradient norm: 0.04473648249404505, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 9658 / 20000\n",
      "gradient norm: 0.03450017709110398, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 9659 / 20000\n",
      "gradient norm: 0.07480700826272368, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 9660 / 20000\n",
      "gradient norm: 0.042763273435411975, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 9661 / 20000\n",
      "gradient norm: 0.06432070606388152, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 9662 / 20000\n",
      "gradient norm: 0.035326991172041744, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 9663 / 20000\n",
      "gradient norm: 0.07733029732480645, minimum ratio: 2.46578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 9664 / 20000\n",
      "gradient norm: 0.10768105901661329, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 9665 / 20000\n",
      "gradient norm: 0.05850350504624657, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 9666 / 20000\n",
      "gradient norm: 0.03137380929547362, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 9667 / 20000\n",
      "gradient norm: 0.05965046980418265, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 9668 / 20000\n",
      "gradient norm: 0.08041133839287795, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 9669 / 20000\n",
      "gradient norm: 0.035862608696334064, minimum ratio: 2.460526315789474\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 9670 / 20000\n",
      "gradient norm: 0.06381583912298083, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 9671 / 20000\n",
      "gradient norm: 0.06049896636977792, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00565\n",
      "\tval loss: 0.00552\n",
      "epoch 9672 / 20000\n",
      "gradient norm: 0.07990954944398254, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 9673 / 20000\n",
      "gradient norm: 0.05418002212536521, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 9674 / 20000\n",
      "gradient norm: 0.045466659765224904, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 9675 / 20000\n",
      "gradient norm: 0.0765585956396535, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 9676 / 20000\n",
      "gradient norm: 0.08583610132336617, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 9677 / 20000\n",
      "gradient norm: 0.06448313593864441, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 9678 / 20000\n",
      "gradient norm: 0.03736387158278376, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 9679 / 20000\n",
      "gradient norm: 0.06320762966061011, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 9680 / 20000\n",
      "gradient norm: 0.12488178233616054, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 9681 / 20000\n",
      "gradient norm: 0.03776563407154754, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 9682 / 20000\n",
      "gradient norm: 0.07415590959135443, minimum ratio: 2.4842105263157896\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 9683 / 20000\n",
      "gradient norm: 0.11131858313456178, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 9684 / 20000\n",
      "gradient norm: 0.07847367238719016, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 9685 / 20000\n",
      "gradient norm: 0.1281605146941729, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00555\n",
      "epoch 9686 / 20000\n",
      "gradient norm: 0.1006621221313253, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 9687 / 20000\n",
      "gradient norm: 0.059792600164655596, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 9688 / 20000\n",
      "gradient norm: 0.08647908491548151, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 9689 / 20000\n",
      "gradient norm: 0.12071338342502713, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 9690 / 20000\n",
      "gradient norm: 0.04668508569011465, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 9691 / 20000\n",
      "gradient norm: 0.054044490680098534, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 9692 / 20000\n",
      "gradient norm: 0.05955529396305792, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 9693 / 20000\n",
      "gradient norm: 0.05905174632789567, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 9694 / 20000\n",
      "gradient norm: 0.036243961920263246, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 9695 / 20000\n",
      "gradient norm: 0.08691081358119845, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 9696 / 20000\n",
      "gradient norm: 0.062415946085820906, minimum ratio: 2.4421052631578943\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 9697 / 20000\n",
      "gradient norm: 0.05036452469357755, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 9698 / 20000\n",
      "gradient norm: 0.04148522287141532, minimum ratio: 2.4868421052631575\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 9699 / 20000\n",
      "gradient norm: 0.04964755126275122, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 9700 / 20000\n",
      "gradient norm: 0.0479284210014157, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00553\n",
      "epoch 9701 / 20000\n",
      "gradient norm: 0.0612150079687126, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 9702 / 20000\n",
      "gradient norm: 0.03435496552265249, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 9703 / 20000\n",
      "gradient norm: 0.0670792173477821, minimum ratio: 2.452631578947368\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 9704 / 20000\n",
      "gradient norm: 0.05149849923327565, minimum ratio: 2.460526315789474\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 9705 / 20000\n",
      "gradient norm: 0.05433624051511288, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 9706 / 20000\n",
      "gradient norm: 0.05057560303248465, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 9707 / 20000\n",
      "gradient norm: 0.06271468934573932, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 9708 / 20000\n",
      "gradient norm: 0.04858463379787281, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00554\n",
      "epoch 9709 / 20000\n",
      "gradient norm: 0.09006869822042063, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00551\n",
      "epoch 9710 / 20000\n",
      "gradient norm: 0.07184489993960597, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 9711 / 20000\n",
      "gradient norm: 0.10434484295547009, minimum ratio: 2.460526315789474\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 9712 / 20000\n",
      "gradient norm: 0.021226622302492615, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 9713 / 20000\n",
      "gradient norm: 0.06766158615937456, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 9714 / 20000\n",
      "gradient norm: 0.06976237788330764, minimum ratio: 2.46578947368421\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 9715 / 20000\n",
      "gradient norm: 0.06034286848444026, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 9716 / 20000\n",
      "gradient norm: 0.07690220890799537, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 9717 / 20000\n",
      "gradient norm: 0.12669461691984907, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00551\n",
      "epoch 9718 / 20000\n",
      "gradient norm: 0.08744794910307974, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 9719 / 20000\n",
      "gradient norm: 0.08202096913009882, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 9720 / 20000\n",
      "gradient norm: 0.06053547779447399, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00551\n",
      "epoch 9721 / 20000\n",
      "gradient norm: 0.09938020212575793, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 9722 / 20000\n",
      "gradient norm: 0.07552640850190073, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 9723 / 20000\n",
      "gradient norm: 0.0635423154453747, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 9724 / 20000\n",
      "gradient norm: 0.07665910694049671, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 9725 / 20000\n",
      "gradient norm: 0.12534063041675836, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 9726 / 20000\n",
      "gradient norm: 0.04231944232014939, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 9727 / 20000\n",
      "gradient norm: 0.07828025292837992, minimum ratio: 2.46578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 9728 / 20000\n",
      "gradient norm: 0.08595012209843844, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 9729 / 20000\n",
      "gradient norm: 0.10951269464567304, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 9730 / 20000\n",
      "gradient norm: 0.09216293395729735, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 9731 / 20000\n",
      "gradient norm: 0.04105249862186611, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 9732 / 20000\n",
      "gradient norm: 0.07937119307462126, minimum ratio: 2.46578947368421\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 9733 / 20000\n",
      "gradient norm: 0.07540483796037734, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 9734 / 20000\n",
      "gradient norm: 0.055171868443721905, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 9735 / 20000\n",
      "gradient norm: 0.026958751303027384, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 9736 / 20000\n",
      "gradient norm: 0.06843650346854702, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 9737 / 20000\n",
      "gradient norm: 0.07024686725344509, minimum ratio: 2.460526315789474\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 9738 / 20000\n",
      "gradient norm: 0.058884946280159056, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 9739 / 20000\n",
      "gradient norm: 0.055084923485992476, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 9740 / 20000\n",
      "gradient norm: 0.07727348376647569, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 9741 / 20000\n",
      "gradient norm: 0.12153360337833874, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 9742 / 20000\n",
      "gradient norm: 0.11413425547652878, minimum ratio: 2.4499999999999997\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 9743 / 20000\n",
      "gradient norm: 0.029063747570035048, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 9744 / 20000\n",
      "gradient norm: 0.05917642908752896, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 9745 / 20000\n",
      "gradient norm: 0.06371004541870207, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 9746 / 20000\n",
      "gradient norm: 0.11655814660480246, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 9747 / 20000\n",
      "gradient norm: 0.02691497394698672, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 9748 / 20000\n",
      "gradient norm: 0.08355943986680359, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 9749 / 20000\n",
      "gradient norm: 0.03969424391107168, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 9750 / 20000\n",
      "gradient norm: 0.06624527979874983, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 9751 / 20000\n",
      "gradient norm: 0.054683359077898785, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 9752 / 20000\n",
      "gradient norm: 0.04129195785935735, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 9753 / 20000\n",
      "gradient norm: 0.054569770087255165, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 9754 / 20000\n",
      "gradient norm: 0.05771489045582712, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 9755 / 20000\n",
      "gradient norm: 0.08136525162262842, minimum ratio: 2.4499999999999997\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 9756 / 20000\n",
      "gradient norm: 0.01694495097035542, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 9757 / 20000\n",
      "gradient norm: 0.08186366665177047, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 9758 / 20000\n",
      "gradient norm: 0.0325985656818375, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 9759 / 20000\n",
      "gradient norm: 0.07508797012269497, minimum ratio: 2.46578947368421\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 9760 / 20000\n",
      "gradient norm: 0.12286564050009474, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 9761 / 20000\n",
      "gradient norm: 0.12115164869464934, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 9762 / 20000\n",
      "gradient norm: 0.043353028799174353, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 9763 / 20000\n",
      "gradient norm: 0.06644036434590816, minimum ratio: 2.4421052631578943\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 9764 / 20000\n",
      "gradient norm: 0.07557372531300643, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 9765 / 20000\n",
      "gradient norm: 0.05204019445227459, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 9766 / 20000\n",
      "gradient norm: 0.08243823604425415, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 9767 / 20000\n",
      "gradient norm: 0.020348881575046107, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 9768 / 20000\n",
      "gradient norm: 0.1126816037176468, minimum ratio: 2.4842105263157896\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 9769 / 20000\n",
      "gradient norm: 0.051199873531004414, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 9770 / 20000\n",
      "gradient norm: 0.10501809709239751, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00551\n",
      "epoch 9771 / 20000\n",
      "gradient norm: 0.047424995493202005, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 9772 / 20000\n",
      "gradient norm: 0.089569702220615, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 9773 / 20000\n",
      "gradient norm: 0.03543353415443562, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 9774 / 20000\n",
      "gradient norm: 0.04637803201330826, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 9775 / 20000\n",
      "gradient norm: 0.03862686094362289, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 9776 / 20000\n",
      "gradient norm: 0.054241537989582866, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 9777 / 20000\n",
      "gradient norm: 0.04456756645231508, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 9778 / 20000\n",
      "gradient norm: 0.05420111457351595, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 9779 / 20000\n",
      "gradient norm: 0.0455806825448235, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 9780 / 20000\n",
      "gradient norm: 0.09285266819642857, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00553\n",
      "epoch 9781 / 20000\n",
      "gradient norm: 0.10374090768164024, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 9782 / 20000\n",
      "gradient norm: 0.1064406810910441, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 9783 / 20000\n",
      "gradient norm: 0.047944847523467615, minimum ratio: 2.46578947368421\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 9784 / 20000\n",
      "gradient norm: 0.051181327435187995, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 9785 / 20000\n",
      "gradient norm: 0.024265024083433673, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 9786 / 20000\n",
      "gradient norm: 0.04653712076833472, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 9787 / 20000\n",
      "gradient norm: 0.07595548592507839, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 9788 / 20000\n",
      "gradient norm: 0.04482298719813116, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 9789 / 20000\n",
      "gradient norm: 0.11249210627283901, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 9790 / 20000\n",
      "gradient norm: 0.07687775534577668, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00555\n",
      "epoch 9791 / 20000\n",
      "gradient norm: 0.08198772597825155, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 9792 / 20000\n",
      "gradient norm: 0.08740264319931157, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00551\n",
      "epoch 9793 / 20000\n",
      "gradient norm: 0.08697316053439863, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00555\n",
      "epoch 9794 / 20000\n",
      "gradient norm: 0.0437087539175991, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 9795 / 20000\n",
      "gradient norm: 0.03165069833630696, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 9796 / 20000\n",
      "gradient norm: 0.10367905889870599, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00553\n",
      "epoch 9797 / 20000\n",
      "gradient norm: 0.09394106478430331, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 9798 / 20000\n",
      "gradient norm: 0.08562592405360192, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 9799 / 20000\n",
      "gradient norm: 0.05997999047394842, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 9800 / 20000\n",
      "gradient norm: 0.048885657102800906, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 9801 / 20000\n",
      "gradient norm: 0.05252286829636432, minimum ratio: 2.46578947368421\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 9802 / 20000\n",
      "gradient norm: 0.09317734732758254, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 9803 / 20000\n",
      "gradient norm: 0.08307390088157263, minimum ratio: 2.5026315789473688\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 9804 / 20000\n",
      "gradient norm: 0.024472802149830386, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 9805 / 20000\n",
      "gradient norm: 0.10301493137376383, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 9806 / 20000\n",
      "gradient norm: 0.04127830755896866, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 9807 / 20000\n",
      "gradient norm: 0.10590359929483384, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 9808 / 20000\n",
      "gradient norm: 0.060978308058111, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 9809 / 20000\n",
      "gradient norm: 0.04276887825108133, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 9810 / 20000\n",
      "gradient norm: 0.08910619525704533, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 9811 / 20000\n",
      "gradient norm: 0.04920236178440973, minimum ratio: 2.4815789473684213\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 9812 / 20000\n",
      "gradient norm: 0.044737519579939544, minimum ratio: 2.4394736842105265\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 9813 / 20000\n",
      "gradient norm: 0.06954525316541549, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 9814 / 20000\n",
      "gradient norm: 0.04366190638393164, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 9815 / 20000\n",
      "gradient norm: 0.025585692019376438, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 9816 / 20000\n",
      "gradient norm: 0.09141574567183852, minimum ratio: 2.46578947368421\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 9817 / 20000\n",
      "gradient norm: 0.10359902220079675, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00553\n",
      "epoch 9818 / 20000\n",
      "gradient norm: 0.05630498786922544, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 9819 / 20000\n",
      "gradient norm: 0.12602341437741416, minimum ratio: 2.46578947368421\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 9820 / 20000\n",
      "gradient norm: 0.03413810863276012, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 9821 / 20000\n",
      "gradient norm: 0.11904973821947351, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 9822 / 20000\n",
      "gradient norm: 0.0584050752222538, minimum ratio: 2.436842105263158\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 9823 / 20000\n",
      "gradient norm: 0.08411209285259247, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 9824 / 20000\n",
      "gradient norm: 0.09661363757913932, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 9825 / 20000\n",
      "gradient norm: 0.06679663438990247, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 9826 / 20000\n",
      "gradient norm: 0.07330158486729488, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00552\n",
      "epoch 9827 / 20000\n",
      "gradient norm: 0.10587954957736656, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 9828 / 20000\n",
      "gradient norm: 0.047269525603041984, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 9829 / 20000\n",
      "gradient norm: 0.08999536675401032, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 9830 / 20000\n",
      "gradient norm: 0.06800065183779225, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 9831 / 20000\n",
      "gradient norm: 0.0514266470563598, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 9832 / 20000\n",
      "gradient norm: 0.05191485115210526, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 9833 / 20000\n",
      "gradient norm: 0.06969958866829984, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 9834 / 20000\n",
      "gradient norm: 0.0491457138559781, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 9835 / 20000\n",
      "gradient norm: 0.070820904802531, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 9836 / 20000\n",
      "gradient norm: 0.08655845129396766, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 9837 / 20000\n",
      "gradient norm: 0.06439659144962206, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 9838 / 20000\n",
      "gradient norm: 0.07517714332789183, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 9839 / 20000\n",
      "gradient norm: 0.047242396540241316, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 9840 / 20000\n",
      "gradient norm: 0.06422380873118527, minimum ratio: 2.46578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 9841 / 20000\n",
      "gradient norm: 0.07898053072858602, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 9842 / 20000\n",
      "gradient norm: 0.056348435929976404, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 9843 / 20000\n",
      "gradient norm: 0.05410533903341275, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 9844 / 20000\n",
      "gradient norm: 0.0798015187101555, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 9845 / 20000\n",
      "gradient norm: 0.06615135984611697, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 9846 / 20000\n",
      "gradient norm: 0.09058547139284201, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 9847 / 20000\n",
      "gradient norm: 0.051487382283085026, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 9848 / 20000\n",
      "gradient norm: 0.09586995048448443, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 9849 / 20000\n",
      "gradient norm: 0.05131248524412513, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 9850 / 20000\n",
      "gradient norm: 0.048875251988647506, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 9851 / 20000\n",
      "gradient norm: 0.02098809482413344, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 9852 / 20000\n",
      "gradient norm: 0.053191683706245385, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 9853 / 20000\n",
      "gradient norm: 0.03297932889108779, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 9854 / 20000\n",
      "gradient norm: 0.10977561285835691, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 9855 / 20000\n",
      "gradient norm: 0.022379374370757432, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 9856 / 20000\n",
      "gradient norm: 0.03733058553189039, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 9857 / 20000\n",
      "gradient norm: 0.06337168347090483, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 9858 / 20000\n",
      "gradient norm: 0.017065160092897713, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 9859 / 20000\n",
      "gradient norm: 0.09630518825724721, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 9860 / 20000\n",
      "gradient norm: 0.06313712417613715, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 9861 / 20000\n",
      "gradient norm: 0.07105039447196759, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00552\n",
      "epoch 9862 / 20000\n",
      "gradient norm: 0.04521235637366772, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 9863 / 20000\n",
      "gradient norm: 0.09345136005140375, minimum ratio: 2.4736842105263155\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 9864 / 20000\n",
      "gradient norm: 0.04957896479754709, minimum ratio: 2.4868421052631575\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 9865 / 20000\n",
      "gradient norm: 0.06696841394295916, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 9866 / 20000\n",
      "gradient norm: 0.08759807646856643, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 9867 / 20000\n",
      "gradient norm: 0.0969206946901977, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 9868 / 20000\n",
      "gradient norm: 0.054692864476237446, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 9869 / 20000\n",
      "gradient norm: 0.07478216959862038, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 9870 / 20000\n",
      "gradient norm: 0.05718371318653226, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 9871 / 20000\n",
      "gradient norm: 0.049736829358153045, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 9872 / 20000\n",
      "gradient norm: 0.05422169831581414, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 9873 / 20000\n",
      "gradient norm: 0.06907928024884313, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 9874 / 20000\n",
      "gradient norm: 0.03420704750169534, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 9875 / 20000\n",
      "gradient norm: 0.08808702556416392, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 9876 / 20000\n",
      "gradient norm: 0.08774874050868675, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 9877 / 20000\n",
      "gradient norm: 0.058985769108403474, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 9878 / 20000\n",
      "gradient norm: 0.11035344959236681, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00551\n",
      "epoch 9879 / 20000\n",
      "gradient norm: 0.10464199795387685, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00551\n",
      "epoch 9880 / 20000\n",
      "gradient norm: 0.09375139011535794, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 9881 / 20000\n",
      "gradient norm: 0.07091422349913046, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 9882 / 20000\n",
      "gradient norm: 0.036817373416852206, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00551\n",
      "epoch 9883 / 20000\n",
      "gradient norm: 0.07486155506921932, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 9884 / 20000\n",
      "gradient norm: 0.05435125168878585, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 9885 / 20000\n",
      "gradient norm: 0.05624980783613864, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 9886 / 20000\n",
      "gradient norm: 0.06294372829142958, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 9887 / 20000\n",
      "gradient norm: 0.07346854492789134, minimum ratio: 2.4842105263157896\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 9888 / 20000\n",
      "gradient norm: 0.08149743340618443, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 9889 / 20000\n",
      "gradient norm: 0.06789655421744101, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 9890 / 20000\n",
      "gradient norm: 0.06903649025480263, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 9891 / 20000\n",
      "gradient norm: 0.050074196071363986, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 9892 / 20000\n",
      "gradient norm: 0.07921699015423656, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 9893 / 20000\n",
      "gradient norm: 0.04159802629146725, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 9894 / 20000\n",
      "gradient norm: 0.02846954725100659, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 9895 / 20000\n",
      "gradient norm: 0.04639259922259953, minimum ratio: 2.4447368421052635\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 9896 / 20000\n",
      "gradient norm: 0.03228854588815011, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 9897 / 20000\n",
      "gradient norm: 0.053904768981738016, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 9898 / 20000\n",
      "gradient norm: 0.04090386729512829, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 9899 / 20000\n",
      "gradient norm: 0.050977339793462306, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 9900 / 20000\n",
      "gradient norm: 0.07352188025834039, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 9901 / 20000\n",
      "gradient norm: 0.024894738104194403, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 9902 / 20000\n",
      "gradient norm: 0.058071627223398536, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 9903 / 20000\n",
      "gradient norm: 0.0876391944475472, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 9904 / 20000\n",
      "gradient norm: 0.0775619630003348, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 9905 / 20000\n",
      "gradient norm: 0.0789760845946148, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 9906 / 20000\n",
      "gradient norm: 0.06378743183449842, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 9907 / 20000\n",
      "gradient norm: 0.09818837087368593, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 9908 / 20000\n",
      "gradient norm: 0.051041854901995976, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 9909 / 20000\n",
      "gradient norm: 0.07938852359075099, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00552\n",
      "epoch 9910 / 20000\n",
      "gradient norm: 0.07800933183170855, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 9911 / 20000\n",
      "gradient norm: 0.06495117029407993, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 9912 / 20000\n",
      "gradient norm: 0.09904864197596908, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 9913 / 20000\n",
      "gradient norm: 0.06179223567596637, minimum ratio: 2.436842105263158\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 9914 / 20000\n",
      "gradient norm: 0.06280817289371043, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 9915 / 20000\n",
      "gradient norm: 0.08658390981145203, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00551\n",
      "epoch 9916 / 20000\n",
      "gradient norm: 0.1323575631249696, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 9917 / 20000\n",
      "gradient norm: 0.051990835840115324, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 9918 / 20000\n",
      "gradient norm: 0.039792830299120396, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 9919 / 20000\n",
      "gradient norm: 0.06712362906546332, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 9920 / 20000\n",
      "gradient norm: 0.07042930414900184, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 9921 / 20000\n",
      "gradient norm: 0.06635585860931315, minimum ratio: 2.460526315789474\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 9922 / 20000\n",
      "gradient norm: 0.04082777820440242, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 9923 / 20000\n",
      "gradient norm: 0.04138743688235991, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 9924 / 20000\n",
      "gradient norm: 0.05074770766077563, minimum ratio: 2.4499999999999997\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 9925 / 20000\n",
      "gradient norm: 0.1109478420112282, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 9926 / 20000\n",
      "gradient norm: 0.04843968275235966, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 9927 / 20000\n",
      "gradient norm: 0.07888895180076361, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 9928 / 20000\n",
      "gradient norm: 0.07514469366287813, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 9929 / 20000\n",
      "gradient norm: 0.08105369519034866, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 9930 / 20000\n",
      "gradient norm: 0.04702553361130413, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 9931 / 20000\n",
      "gradient norm: 0.09697566519025713, minimum ratio: 2.4394736842105265\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 9932 / 20000\n",
      "gradient norm: 0.06993858906207606, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 9933 / 20000\n",
      "gradient norm: 0.054932789847953245, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 9934 / 20000\n",
      "gradient norm: 0.027603484122664668, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 9935 / 20000\n",
      "gradient norm: 0.0850535438512452, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 9936 / 20000\n",
      "gradient norm: 0.038998228090349585, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 9937 / 20000\n",
      "gradient norm: 0.05313532137370203, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 9938 / 20000\n",
      "gradient norm: 0.06453322156448849, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 9939 / 20000\n",
      "gradient norm: 0.030042168491490884, minimum ratio: 2.4499999999999997\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 9940 / 20000\n",
      "gradient norm: 0.018225601204903796, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 9941 / 20000\n",
      "gradient norm: 0.08413538744207472, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 9942 / 20000\n",
      "gradient norm: 0.027955671277595684, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00551\n",
      "epoch 9943 / 20000\n",
      "gradient norm: 0.04944741216604598, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 9944 / 20000\n",
      "gradient norm: 0.07712754482054152, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 9945 / 20000\n",
      "gradient norm: 0.058123459632042795, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 9946 / 20000\n",
      "gradient norm: 0.050071117701008916, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 9947 / 20000\n",
      "gradient norm: 0.0483726195525378, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 9948 / 20000\n",
      "gradient norm: 0.054058039939263836, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 9949 / 20000\n",
      "gradient norm: 0.06752193596912548, minimum ratio: 2.460526315789474\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 9950 / 20000\n",
      "gradient norm: 0.07165206351783127, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 9951 / 20000\n",
      "gradient norm: 0.07326336309779435, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 9952 / 20000\n",
      "gradient norm: 0.052822251862380654, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00554\n",
      "epoch 9953 / 20000\n",
      "gradient norm: 0.0680824745359132, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 9954 / 20000\n",
      "gradient norm: 0.066279137856327, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 9955 / 20000\n",
      "gradient norm: 0.08519379544304684, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 9956 / 20000\n",
      "gradient norm: 0.043160725763300434, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 9957 / 20000\n",
      "gradient norm: 0.04793918707582634, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 9958 / 20000\n",
      "gradient norm: 0.03867060058837524, minimum ratio: 2.4236842105263157\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 9959 / 20000\n",
      "gradient norm: 0.052159446640871465, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 9960 / 20000\n",
      "gradient norm: 0.044607508287299424, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 9961 / 20000\n",
      "gradient norm: 0.028891720256069675, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 9962 / 20000\n",
      "gradient norm: 0.037313111271942034, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 9963 / 20000\n",
      "gradient norm: 0.036311993724666536, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 9964 / 20000\n",
      "gradient norm: 0.032960162992822006, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 9965 / 20000\n",
      "gradient norm: 0.05870005628094077, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 9966 / 20000\n",
      "gradient norm: 0.09333297505509108, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 9967 / 20000\n",
      "gradient norm: 0.08986777131212875, minimum ratio: 2.46578947368421\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 9968 / 20000\n",
      "gradient norm: 0.09249741351231933, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 9969 / 20000\n",
      "gradient norm: 0.0700307677325327, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 9970 / 20000\n",
      "gradient norm: 0.056788922753185034, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 9971 / 20000\n",
      "gradient norm: 0.1035563784535043, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00551\n",
      "epoch 9972 / 20000\n",
      "gradient norm: 0.10373290907591581, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 9973 / 20000\n",
      "gradient norm: 0.031520536431344226, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 9974 / 20000\n",
      "gradient norm: 0.03994442481780425, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 9975 / 20000\n",
      "gradient norm: 0.04631091408555221, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 9976 / 20000\n",
      "gradient norm: 0.027899300002900418, minimum ratio: 2.465789473684211\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 9977 / 20000\n",
      "gradient norm: 0.0664634938002564, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 9978 / 20000\n",
      "gradient norm: 0.08338673476828262, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 9979 / 20000\n",
      "gradient norm: 0.06776178616564721, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 9980 / 20000\n",
      "gradient norm: 0.05902044923277572, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 9981 / 20000\n",
      "gradient norm: 0.08337137545458972, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 9982 / 20000\n",
      "gradient norm: 0.07980706210946664, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 9983 / 20000\n",
      "gradient norm: 0.080877193773631, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 9984 / 20000\n",
      "gradient norm: 0.07096801121952012, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 9985 / 20000\n",
      "gradient norm: 0.08680977730546147, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 9986 / 20000\n",
      "gradient norm: 0.0469776818426908, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 9987 / 20000\n",
      "gradient norm: 0.057376930955797434, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 9988 / 20000\n",
      "gradient norm: 0.062035381386522204, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 9989 / 20000\n",
      "gradient norm: 0.07030110422056168, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 9990 / 20000\n",
      "gradient norm: 0.061307953466894105, minimum ratio: 2.4578947368421056\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 9991 / 20000\n",
      "gradient norm: 0.11422122817020863, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 9992 / 20000\n",
      "gradient norm: 0.04727409865881782, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 9993 / 20000\n",
      "gradient norm: 0.05033259102492593, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 9994 / 20000\n",
      "gradient norm: 0.10402596235508099, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 9995 / 20000\n",
      "gradient norm: 0.055657739168964326, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 9996 / 20000\n",
      "gradient norm: 0.08648822671966627, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 9997 / 20000\n",
      "gradient norm: 0.04093309189192951, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00553\n",
      "epoch 9998 / 20000\n",
      "gradient norm: 0.07952659425791353, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 9999 / 20000\n",
      "gradient norm: 0.0934174726717174, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 10000 / 20000\n",
      "gradient norm: 0.047613953007385135, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 10001 / 20000\n",
      "gradient norm: 0.0753217909950763, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 10002 / 20000\n",
      "gradient norm: 0.05258044882793911, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 10003 / 20000\n",
      "gradient norm: 0.07388692232780159, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00551\n",
      "epoch 10004 / 20000\n",
      "gradient norm: 0.03441844493499957, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00553\n",
      "epoch 10005 / 20000\n",
      "gradient norm: 0.054206627115490846, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 10006 / 20000\n",
      "gradient norm: 0.1213887533522211, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 10007 / 20000\n",
      "gradient norm: 0.10789616883266717, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00555\n",
      "epoch 10008 / 20000\n",
      "gradient norm: 0.05880307994084433, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 10009 / 20000\n",
      "gradient norm: 0.08106485914322548, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 10010 / 20000\n",
      "gradient norm: 0.06988291401648894, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 10011 / 20000\n",
      "gradient norm: 0.0440421059174696, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 10012 / 20000\n",
      "gradient norm: 0.05001291862572543, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 10013 / 20000\n",
      "gradient norm: 0.04179102921625599, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 10014 / 20000\n",
      "gradient norm: 0.03606017725542188, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 10015 / 20000\n",
      "gradient norm: 0.03116311930352822, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 10016 / 20000\n",
      "gradient norm: 0.06301932243513875, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 10017 / 20000\n",
      "gradient norm: 0.06074755877489224, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 10018 / 20000\n",
      "gradient norm: 0.06303589281742461, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 10019 / 20000\n",
      "gradient norm: 0.061998657998628914, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 10020 / 20000\n",
      "gradient norm: 0.07340303931050585, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 10021 / 20000\n",
      "gradient norm: 0.04065264479140751, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 10022 / 20000\n",
      "gradient norm: 0.018095130872097798, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 10023 / 20000\n",
      "gradient norm: 0.06549025425920263, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 10024 / 20000\n",
      "gradient norm: 0.09081494819838554, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 10025 / 20000\n",
      "gradient norm: 0.05761311229434796, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 10026 / 20000\n",
      "gradient norm: 0.036050630995305255, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 10027 / 20000\n",
      "gradient norm: 0.058246677450370044, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00551\n",
      "epoch 10028 / 20000\n",
      "gradient norm: 0.14644651697017252, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 10029 / 20000\n",
      "gradient norm: 0.07423728401772678, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 10030 / 20000\n",
      "gradient norm: 0.06186498858733103, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 10031 / 20000\n",
      "gradient norm: 0.0793285061372444, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 10032 / 20000\n",
      "gradient norm: 0.08191840979270637, minimum ratio: 2.452631578947368\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 10033 / 20000\n",
      "gradient norm: 0.028304426203249022, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 10034 / 20000\n",
      "gradient norm: 0.01571579357550945, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 10035 / 20000\n",
      "gradient norm: 0.04456634895177558, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 10036 / 20000\n",
      "gradient norm: 0.04429936554515734, minimum ratio: 2.4815789473684213\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 10037 / 20000\n",
      "gradient norm: 0.14611529209651053, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 10038 / 20000\n",
      "gradient norm: 0.03079658528440632, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00551\n",
      "epoch 10039 / 20000\n",
      "gradient norm: 0.07862326712347567, minimum ratio: 2.4447368421052635\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 10040 / 20000\n",
      "gradient norm: 0.0716356991615612, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 10041 / 20000\n",
      "gradient norm: 0.07802607753546908, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 10042 / 20000\n",
      "gradient norm: 0.05873365857405588, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 10043 / 20000\n",
      "gradient norm: 0.0650305311428383, minimum ratio: 2.460526315789474\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00551\n",
      "epoch 10044 / 20000\n",
      "gradient norm: 0.07190442844876088, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 10045 / 20000\n",
      "gradient norm: 0.11389843572396785, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 10046 / 20000\n",
      "gradient norm: 0.05645405931863934, minimum ratio: 2.460526315789474\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 10047 / 20000\n",
      "gradient norm: 0.062069675826933235, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 10048 / 20000\n",
      "gradient norm: 0.04682112066075206, minimum ratio: 2.460526315789474\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 10049 / 20000\n",
      "gradient norm: 0.06461203988874331, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 10050 / 20000\n",
      "gradient norm: 0.06717728285002522, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 10051 / 20000\n",
      "gradient norm: 0.03630886127939448, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 10052 / 20000\n",
      "gradient norm: 0.05122251162538305, minimum ratio: 2.465789473684211\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 10053 / 20000\n",
      "gradient norm: 0.05714966694358736, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 10054 / 20000\n",
      "gradient norm: 0.06353537843097001, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 10055 / 20000\n",
      "gradient norm: 0.08058268832974136, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 10056 / 20000\n",
      "gradient norm: 0.03891652528545819, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 10057 / 20000\n",
      "gradient norm: 0.0781457633129321, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 10058 / 20000\n",
      "gradient norm: 0.08058487670496106, minimum ratio: 2.5026315789473683\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00554\n",
      "epoch 10059 / 20000\n",
      "gradient norm: 0.07583392260130495, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 10060 / 20000\n",
      "gradient norm: 0.05849652108736336, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00551\n",
      "epoch 10061 / 20000\n",
      "gradient norm: 0.0926943636732176, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 10062 / 20000\n",
      "gradient norm: 0.016586944788286928, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00551\n",
      "epoch 10063 / 20000\n",
      "gradient norm: 0.09509871492628008, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 10064 / 20000\n",
      "gradient norm: 0.11902382283005863, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 10065 / 20000\n",
      "gradient norm: 0.11851022503105924, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 10066 / 20000\n",
      "gradient norm: 0.040252520819194615, minimum ratio: 2.4394736842105265\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 10067 / 20000\n",
      "gradient norm: 0.08280512888450176, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 10068 / 20000\n",
      "gradient norm: 0.025485261052381247, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 10069 / 20000\n",
      "gradient norm: 0.09009159589186311, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 10070 / 20000\n",
      "gradient norm: 0.05914457648759708, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 10071 / 20000\n",
      "gradient norm: 0.03824224113486707, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 10072 / 20000\n",
      "gradient norm: 0.08311478147516027, minimum ratio: 2.426315789473684\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 10073 / 20000\n",
      "gradient norm: 0.08785662357695401, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 10074 / 20000\n",
      "gradient norm: 0.09167099779006094, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 10075 / 20000\n",
      "gradient norm: 0.053489475045353174, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 10076 / 20000\n",
      "gradient norm: 0.043694059448171174, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 10077 / 20000\n",
      "gradient norm: 0.03733658936107531, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 10078 / 20000\n",
      "gradient norm: 0.10782841278705746, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 10079 / 20000\n",
      "gradient norm: 0.15044243464944884, minimum ratio: 2.4421052631578952\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 10080 / 20000\n",
      "gradient norm: 0.04990410932805389, minimum ratio: 2.4394736842105265\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 10081 / 20000\n",
      "gradient norm: 0.07491738093085587, minimum ratio: 2.4421052631578943\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 10082 / 20000\n",
      "gradient norm: 0.03516874433262274, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 10083 / 20000\n",
      "gradient norm: 0.06789006432518363, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 10084 / 20000\n",
      "gradient norm: 0.05193773936480284, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 10085 / 20000\n",
      "gradient norm: 0.0623685579339508, minimum ratio: 2.460526315789474\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 10086 / 20000\n",
      "gradient norm: 0.025512952939607203, minimum ratio: 2.4499999999999997\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 10087 / 20000\n",
      "gradient norm: 0.03756861056899652, minimum ratio: 2.436842105263158\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 10088 / 20000\n",
      "gradient norm: 0.09472689632093534, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 10089 / 20000\n",
      "gradient norm: 0.06603173798066564, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 10090 / 20000\n",
      "gradient norm: 0.02840809416375123, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 10091 / 20000\n",
      "gradient norm: 0.08426097815390676, minimum ratio: 2.413157894736842\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 10092 / 20000\n",
      "gradient norm: 0.10702458361629397, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 10093 / 20000\n",
      "gradient norm: 0.05197116656927392, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 10094 / 20000\n",
      "gradient norm: 0.08497503405669704, minimum ratio: 2.4421052631578943\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 10095 / 20000\n",
      "gradient norm: 0.0860945014283061, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 10096 / 20000\n",
      "gradient norm: 0.04133107155212201, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 10097 / 20000\n",
      "gradient norm: 0.11121274734614417, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 10098 / 20000\n",
      "gradient norm: 0.07076299807522446, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 10099 / 20000\n",
      "gradient norm: 0.10532722884090617, minimum ratio: 2.4421052631578943\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 10100 / 20000\n",
      "gradient norm: 0.08182178373681381, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 10101 / 20000\n",
      "gradient norm: 0.08590173197444528, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 10102 / 20000\n",
      "gradient norm: 0.04676491260761395, minimum ratio: 2.4499999999999997\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 10103 / 20000\n",
      "gradient norm: 0.06292850260797422, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 10104 / 20000\n",
      "gradient norm: 0.05749314480635803, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 10105 / 20000\n",
      "gradient norm: 0.10119281441438943, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 10106 / 20000\n",
      "gradient norm: 0.036632138944696635, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 10107 / 20000\n",
      "gradient norm: 0.07421459967736155, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 10108 / 20000\n",
      "gradient norm: 0.06238805199973285, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00554\n",
      "epoch 10109 / 20000\n",
      "gradient norm: 0.07131335261510685, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 10110 / 20000\n",
      "gradient norm: 0.0596945405122824, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 10111 / 20000\n",
      "gradient norm: 0.072841305838665, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00551\n",
      "epoch 10112 / 20000\n",
      "gradient norm: 0.09879426308907568, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00554\n",
      "epoch 10113 / 20000\n",
      "gradient norm: 0.07266460469691083, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 10114 / 20000\n",
      "gradient norm: 0.08251841965829954, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 10115 / 20000\n",
      "gradient norm: 0.016186279819521587, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 10116 / 20000\n",
      "gradient norm: 0.069283002987504, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 10117 / 20000\n",
      "gradient norm: 0.05036515225947369, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 10118 / 20000\n",
      "gradient norm: 0.0863878260133788, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 10119 / 20000\n",
      "gradient norm: 0.08951323728251737, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 10120 / 20000\n",
      "gradient norm: 0.08744246582500637, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 10121 / 20000\n",
      "gradient norm: 0.06305347103625536, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 10122 / 20000\n",
      "gradient norm: 0.10671633714810014, minimum ratio: 2.4421052631578943\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00553\n",
      "epoch 10123 / 20000\n",
      "gradient norm: 0.09390765856369399, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 10124 / 20000\n",
      "gradient norm: 0.06320208491524681, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 10125 / 20000\n",
      "gradient norm: 0.08685328665887937, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00556\n",
      "epoch 10126 / 20000\n",
      "gradient norm: 0.09386945780715905, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 10127 / 20000\n",
      "gradient norm: 0.0673587164201308, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 10128 / 20000\n",
      "gradient norm: 0.10675996117061004, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 10129 / 20000\n",
      "gradient norm: 0.07617377743008547, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 10130 / 20000\n",
      "gradient norm: 0.05272448428149801, minimum ratio: 2.426315789473684\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 10131 / 20000\n",
      "gradient norm: 0.09273415117058903, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 10132 / 20000\n",
      "gradient norm: 0.09759199322434142, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 10133 / 20000\n",
      "gradient norm: 0.029731430229730904, minimum ratio: 2.465789473684211\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 10134 / 20000\n",
      "gradient norm: 0.0599379611085169, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 10135 / 20000\n",
      "gradient norm: 0.04941653643618338, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 10136 / 20000\n",
      "gradient norm: 0.04593708837637678, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 10137 / 20000\n",
      "gradient norm: 0.05585136696754489, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 10138 / 20000\n",
      "gradient norm: 0.05017225464689545, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 10139 / 20000\n",
      "gradient norm: 0.1020191969582811, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 10140 / 20000\n",
      "gradient norm: 0.043857887358171865, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 10141 / 20000\n",
      "gradient norm: 0.07415504287928343, minimum ratio: 2.4421052631578943\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 10142 / 20000\n",
      "gradient norm: 0.044360794650856405, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 10143 / 20000\n",
      "gradient norm: 0.03227171770413406, minimum ratio: 2.4578947368421056\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 10144 / 20000\n",
      "gradient norm: 0.057368113310076296, minimum ratio: 2.452631578947368\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 10145 / 20000\n",
      "gradient norm: 0.10088592115789652, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 10146 / 20000\n",
      "gradient norm: 0.054354693624190986, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 10147 / 20000\n",
      "gradient norm: 0.07206020958255976, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 10148 / 20000\n",
      "gradient norm: 0.05437430407619104, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00565\n",
      "\tval loss: 0.00552\n",
      "epoch 10149 / 20000\n",
      "gradient norm: 0.06665305641945451, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 10150 / 20000\n",
      "gradient norm: 0.03851514938287437, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 10151 / 20000\n",
      "gradient norm: 0.04793388969847001, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 10152 / 20000\n",
      "gradient norm: 0.05952471667842474, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 10153 / 20000\n",
      "gradient norm: 0.052025224998942576, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 10154 / 20000\n",
      "gradient norm: 0.08289460436208174, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 10155 / 20000\n",
      "gradient norm: 0.08170794253237545, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 10156 / 20000\n",
      "gradient norm: 0.07874468379304744, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 10157 / 20000\n",
      "gradient norm: 0.05820454331114888, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 10158 / 20000\n",
      "gradient norm: 0.10670033472706564, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00551\n",
      "epoch 10159 / 20000\n",
      "gradient norm: 0.034750148486637045, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 10160 / 20000\n",
      "gradient norm: 0.04730259574716911, minimum ratio: 2.4447368421052635\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 10161 / 20000\n",
      "gradient norm: 0.09161087416578084, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 10162 / 20000\n",
      "gradient norm: 0.048785311315441504, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 10163 / 20000\n",
      "gradient norm: 0.04476875698310323, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 10164 / 20000\n",
      "gradient norm: 0.0734080909169279, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 10165 / 20000\n",
      "gradient norm: 0.03131264337571338, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 10166 / 20000\n",
      "gradient norm: 0.0799144163611345, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 10167 / 20000\n",
      "gradient norm: 0.051581605919636786, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 10168 / 20000\n",
      "gradient norm: 0.040364136213611346, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 10169 / 20000\n",
      "gradient norm: 0.04785526968043996, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 10170 / 20000\n",
      "gradient norm: 0.092435086669866, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 10171 / 20000\n",
      "gradient norm: 0.01782453186751809, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 10172 / 20000\n",
      "gradient norm: 0.10850382619537413, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 10173 / 20000\n",
      "gradient norm: 0.09315559244714677, minimum ratio: 2.452631578947368\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 10174 / 20000\n",
      "gradient norm: 0.07221069588558748, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 10175 / 20000\n",
      "gradient norm: 0.041272587783169, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 10176 / 20000\n",
      "gradient norm: 0.05516597651876509, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 10177 / 20000\n",
      "gradient norm: 0.030999057285953313, minimum ratio: 2.4394736842105265\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 10178 / 20000\n",
      "gradient norm: 0.06212650449742796, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 10179 / 20000\n",
      "gradient norm: 0.046898231405066326, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 10180 / 20000\n",
      "gradient norm: 0.06686644814908504, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 10181 / 20000\n",
      "gradient norm: 0.06218502786941826, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 10182 / 20000\n",
      "gradient norm: 0.07881897344486788, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 10183 / 20000\n",
      "gradient norm: 0.06161530179088004, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 10184 / 20000\n",
      "gradient norm: 0.07129246785189025, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 10185 / 20000\n",
      "gradient norm: 0.09147234505508095, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 10186 / 20000\n",
      "gradient norm: 0.038888147100806236, minimum ratio: 2.426315789473684\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00554\n",
      "epoch 10187 / 20000\n",
      "gradient norm: 0.06871017173398286, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 10188 / 20000\n",
      "gradient norm: 0.06291320890886709, minimum ratio: 2.4394736842105265\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 10189 / 20000\n",
      "gradient norm: 0.10540812037652358, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 10190 / 20000\n",
      "gradient norm: 0.048492262372747064, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 10191 / 20000\n",
      "gradient norm: 0.0711712707998231, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 10192 / 20000\n",
      "gradient norm: 0.04138175953994505, minimum ratio: 2.4447368421052635\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 10193 / 20000\n",
      "gradient norm: 0.0766180453938432, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 10194 / 20000\n",
      "gradient norm: 0.14036644797306508, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 10195 / 20000\n",
      "gradient norm: 0.034864041561377235, minimum ratio: 2.4210526315789473\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 10196 / 20000\n",
      "gradient norm: 0.0664539688732475, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 10197 / 20000\n",
      "gradient norm: 0.06339379044948146, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00554\n",
      "epoch 10198 / 20000\n",
      "gradient norm: 0.06268698727944866, minimum ratio: 2.423684210526315\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 10199 / 20000\n",
      "gradient norm: 0.058420138811925426, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 10200 / 20000\n",
      "gradient norm: 0.07636091863969341, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 10201 / 20000\n",
      "gradient norm: 0.07984204290551133, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 10202 / 20000\n",
      "gradient norm: 0.0751850160304457, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 10203 / 20000\n",
      "gradient norm: 0.032886153931031004, minimum ratio: 2.4263157894736844\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 10204 / 20000\n",
      "gradient norm: 0.0707358525833115, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 10205 / 20000\n",
      "gradient norm: 0.07973767048679292, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 10206 / 20000\n",
      "gradient norm: 0.06277764227706939, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 10207 / 20000\n",
      "gradient norm: 0.0438112715492025, minimum ratio: 2.4421052631578943\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 10208 / 20000\n",
      "gradient norm: 0.01709196431329474, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 10209 / 20000\n",
      "gradient norm: 0.011308908131468343, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 10210 / 20000\n",
      "gradient norm: 0.10228358930908144, minimum ratio: 2.426315789473684\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 10211 / 20000\n",
      "gradient norm: 0.07239629019750282, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 10212 / 20000\n",
      "gradient norm: 0.0497542864177376, minimum ratio: 2.4263157894736844\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 10213 / 20000\n",
      "gradient norm: 0.05807107960572466, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 10214 / 20000\n",
      "gradient norm: 0.029854217020329088, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 10215 / 20000\n",
      "gradient norm: 0.04999750942806713, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 10216 / 20000\n",
      "gradient norm: 0.07474676828132942, minimum ratio: 2.4394736842105265\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 10217 / 20000\n",
      "gradient norm: 0.11678322136867791, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 10218 / 20000\n",
      "gradient norm: 0.07793409170699306, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 10219 / 20000\n",
      "gradient norm: 0.08509528916329145, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 10220 / 20000\n",
      "gradient norm: 0.09715363834402524, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 10221 / 20000\n",
      "gradient norm: 0.07280262754647993, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 10222 / 20000\n",
      "gradient norm: 0.08915195998270065, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 10223 / 20000\n",
      "gradient norm: 0.028266002089367248, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 10224 / 20000\n",
      "gradient norm: 0.053657519863918424, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 10225 / 20000\n",
      "gradient norm: 0.051881584178772755, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 10226 / 20000\n",
      "gradient norm: 0.04298544018820394, minimum ratio: 2.4263157894736844\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 10227 / 20000\n",
      "gradient norm: 0.06818817512248643, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 10228 / 20000\n",
      "gradient norm: 0.07757084735203534, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 10229 / 20000\n",
      "gradient norm: 0.07865735038649291, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 10230 / 20000\n",
      "gradient norm: 0.09066339711716864, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 10231 / 20000\n",
      "gradient norm: 0.052618283763877116, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 10232 / 20000\n",
      "gradient norm: 0.05446113657671958, minimum ratio: 2.4263157894736844\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 10233 / 20000\n",
      "gradient norm: 0.10971070901723579, minimum ratio: 2.4499999999999997\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 10234 / 20000\n",
      "gradient norm: 0.06691016111290082, minimum ratio: 2.4499999999999997\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 10235 / 20000\n",
      "gradient norm: 0.0358770721941255, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 10236 / 20000\n",
      "gradient norm: 0.09989898803178221, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 10237 / 20000\n",
      "gradient norm: 0.036878911007079296, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 10238 / 20000\n",
      "gradient norm: 0.07145428861258551, minimum ratio: 2.4447368421052635\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 10239 / 20000\n",
      "gradient norm: 0.0502704317914322, minimum ratio: 2.46578947368421\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00554\n",
      "epoch 10240 / 20000\n",
      "gradient norm: 0.04606701826560311, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 10241 / 20000\n",
      "gradient norm: 0.07000927461194806, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 10242 / 20000\n",
      "gradient norm: 0.04592970630619675, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 10243 / 20000\n",
      "gradient norm: 0.03818877068988513, minimum ratio: 2.4289473684210523\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 10244 / 20000\n",
      "gradient norm: 0.07463410735363141, minimum ratio: 2.4868421052631575\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 10245 / 20000\n",
      "gradient norm: 0.04198576312046498, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 10246 / 20000\n",
      "gradient norm: 0.018646970129339024, minimum ratio: 2.436842105263158\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 10247 / 20000\n",
      "gradient norm: 0.047462251837714575, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 10248 / 20000\n",
      "gradient norm: 0.03164792053576093, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 10249 / 20000\n",
      "gradient norm: 0.03217717172083212, minimum ratio: 2.4421052631578943\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 10250 / 20000\n",
      "gradient norm: 0.08251213905168697, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 10251 / 20000\n",
      "gradient norm: 0.03837321177707054, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 10252 / 20000\n",
      "gradient norm: 0.07523533901257906, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 10253 / 20000\n",
      "gradient norm: 0.03046689464827068, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 10254 / 20000\n",
      "gradient norm: 0.1106199236237444, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 10255 / 20000\n",
      "gradient norm: 0.035565752084949054, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 10256 / 20000\n",
      "gradient norm: 0.11325290845707059, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 10257 / 20000\n",
      "gradient norm: 0.0600603970233351, minimum ratio: 2.4447368421052635\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 10258 / 20000\n",
      "gradient norm: 0.06593490908562671, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 10259 / 20000\n",
      "gradient norm: 0.0379073229196365, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 10260 / 20000\n",
      "gradient norm: 0.03703279959154315, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 10261 / 20000\n",
      "gradient norm: 0.07530603831401095, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 10262 / 20000\n",
      "gradient norm: 0.0375860906788148, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 10263 / 20000\n",
      "gradient norm: 0.08370587549870834, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 10264 / 20000\n",
      "gradient norm: 0.03402260033908533, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 10265 / 20000\n",
      "gradient norm: 0.07679968723095953, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 10266 / 20000\n",
      "gradient norm: 0.03664185106754303, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 10267 / 20000\n",
      "gradient norm: 0.13768206886015832, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00551\n",
      "epoch 10268 / 20000\n",
      "gradient norm: 0.03401738558022771, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 10269 / 20000\n",
      "gradient norm: 0.060662003757897764, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 10270 / 20000\n",
      "gradient norm: 0.028211460128659382, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 10271 / 20000\n",
      "gradient norm: 0.03578512044623494, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 10272 / 20000\n",
      "gradient norm: 0.05194296121771913, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 10273 / 20000\n",
      "gradient norm: 0.09086415416095406, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00551\n",
      "epoch 10274 / 20000\n",
      "gradient norm: 0.07706724322633818, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 10275 / 20000\n",
      "gradient norm: 0.0524430479563307, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 10276 / 20000\n",
      "gradient norm: 0.06706837395904586, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 10277 / 20000\n",
      "gradient norm: 0.05260658237966709, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 10278 / 20000\n",
      "gradient norm: 0.06301852210890502, minimum ratio: 2.489473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 10279 / 20000\n",
      "gradient norm: 0.024732566555030644, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 10280 / 20000\n",
      "gradient norm: 0.051105196645949036, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 10281 / 20000\n",
      "gradient norm: 0.08679788609151728, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 10282 / 20000\n",
      "gradient norm: 0.03343061120540369, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 10283 / 20000\n",
      "gradient norm: 0.07494832831434906, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 10284 / 20000\n",
      "gradient norm: 0.07918156596133485, minimum ratio: 2.4236842105263157\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 10285 / 20000\n",
      "gradient norm: 0.049085458522313274, minimum ratio: 2.436842105263158\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 10286 / 20000\n",
      "gradient norm: 0.07264257143833674, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 10287 / 20000\n",
      "gradient norm: 0.07728361972840503, minimum ratio: 2.4499999999999997\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 10288 / 20000\n",
      "gradient norm: 0.030054994087549858, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 10289 / 20000\n",
      "gradient norm: 0.07102502626366913, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 10290 / 20000\n",
      "gradient norm: 0.08918226879904978, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 10291 / 20000\n",
      "gradient norm: 0.08308410423342139, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 10292 / 20000\n",
      "gradient norm: 0.07262225280283019, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 10293 / 20000\n",
      "gradient norm: 0.03758368390845135, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 10294 / 20000\n",
      "gradient norm: 0.04474708190537058, minimum ratio: 2.46578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 10295 / 20000\n",
      "gradient norm: 0.04783986690745223, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 10296 / 20000\n",
      "gradient norm: 0.06505893648136407, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 10297 / 20000\n",
      "gradient norm: 0.0745071826968342, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 10298 / 20000\n",
      "gradient norm: 0.08229058056895155, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00553\n",
      "epoch 10299 / 20000\n",
      "gradient norm: 0.0341745819314383, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 10300 / 20000\n",
      "gradient norm: 0.06689519160136115, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 10301 / 20000\n",
      "gradient norm: 0.06154968080227263, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 10302 / 20000\n",
      "gradient norm: 0.10118703404441476, minimum ratio: 2.423684210526316\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 10303 / 20000\n",
      "gradient norm: 0.04575701669091359, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 10304 / 20000\n",
      "gradient norm: 0.08505489584058523, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 10305 / 20000\n",
      "gradient norm: 0.0759711945138406, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 10306 / 20000\n",
      "gradient norm: 0.02726287355471868, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 10307 / 20000\n",
      "gradient norm: 0.10288855049293488, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 10308 / 20000\n",
      "gradient norm: 0.03485012907185592, minimum ratio: 2.413157894736842\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 10309 / 20000\n",
      "gradient norm: 0.04916587020852603, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 10310 / 20000\n",
      "gradient norm: 0.08313625282607973, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 10311 / 20000\n",
      "gradient norm: 0.04942535812733695, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 10312 / 20000\n",
      "gradient norm: 0.06765975026064552, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 10313 / 20000\n",
      "gradient norm: 0.07179742999142036, minimum ratio: 2.465789473684211\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 10314 / 20000\n",
      "gradient norm: 0.055702143457892817, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 10315 / 20000\n",
      "gradient norm: 0.03135113604366779, minimum ratio: 2.4447368421052627\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 10316 / 20000\n",
      "gradient norm: 0.06611741497181356, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 10317 / 20000\n",
      "gradient norm: 0.07505551376380026, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 10318 / 20000\n",
      "gradient norm: 0.05401914085086901, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 10319 / 20000\n",
      "gradient norm: 0.07053486519725993, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 10320 / 20000\n",
      "gradient norm: 0.07738867017906159, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 10321 / 20000\n",
      "gradient norm: 0.03658833613735624, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 10322 / 20000\n",
      "gradient norm: 0.07396497623994946, minimum ratio: 2.4421052631578943\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 10323 / 20000\n",
      "gradient norm: 0.06457041652174667, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 10324 / 20000\n",
      "gradient norm: 0.059971921786200255, minimum ratio: 2.4394736842105265\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 10325 / 20000\n",
      "gradient norm: 0.07650527160149068, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 10326 / 20000\n",
      "gradient norm: 0.10085575096309185, minimum ratio: 2.418421052631579\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00551\n",
      "epoch 10327 / 20000\n",
      "gradient norm: 0.07166041480377316, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00554\n",
      "epoch 10328 / 20000\n",
      "gradient norm: 0.07946982188150287, minimum ratio: 2.4447368421052635\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 10329 / 20000\n",
      "gradient norm: 0.07097820925991982, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00551\n",
      "epoch 10330 / 20000\n",
      "gradient norm: 0.05460467984084971, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 10331 / 20000\n",
      "gradient norm: 0.08145629792124964, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 10332 / 20000\n",
      "gradient norm: 0.06717940367525443, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 10333 / 20000\n",
      "gradient norm: 0.09122713224496692, minimum ratio: 2.426315789473684\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 10334 / 20000\n",
      "gradient norm: 0.09747006578254513, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 10335 / 20000\n",
      "gradient norm: 0.0999708310700953, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 10336 / 20000\n",
      "gradient norm: 0.06630584906088188, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 10337 / 20000\n",
      "gradient norm: 0.03982400652603246, minimum ratio: 2.4499999999999997\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00551\n",
      "epoch 10338 / 20000\n",
      "gradient norm: 0.08797516621416435, minimum ratio: 2.4421052631578943\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 10339 / 20000\n",
      "gradient norm: 0.07149730098899454, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00554\n",
      "epoch 10340 / 20000\n",
      "gradient norm: 0.05750267213443294, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 10341 / 20000\n",
      "gradient norm: 0.04783055145526305, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 10342 / 20000\n",
      "gradient norm: 0.05759291257709265, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 10343 / 20000\n",
      "gradient norm: 0.05144593748264015, minimum ratio: 2.4394736842105265\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 10344 / 20000\n",
      "gradient norm: 0.04244944441597909, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 10345 / 20000\n",
      "gradient norm: 0.04291515515069477, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 10346 / 20000\n",
      "gradient norm: 0.06212771713035181, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00552\n",
      "epoch 10347 / 20000\n",
      "gradient norm: 0.023147468804381788, minimum ratio: 2.4421052631578943\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 10348 / 20000\n",
      "gradient norm: 0.07546075753634796, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 10349 / 20000\n",
      "gradient norm: 0.07413580105639994, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 10350 / 20000\n",
      "gradient norm: 0.13022091635502875, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 10351 / 20000\n",
      "gradient norm: 0.08625100337667391, minimum ratio: 2.4447368421052627\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 10352 / 20000\n",
      "gradient norm: 0.06587237899657339, minimum ratio: 2.4263157894736844\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 10353 / 20000\n",
      "gradient norm: 0.06375203898642212, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 10354 / 20000\n",
      "gradient norm: 0.04977152246283367, minimum ratio: 2.4447368421052635\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 10355 / 20000\n",
      "gradient norm: 0.06622678006533533, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 10356 / 20000\n",
      "gradient norm: 0.02179010729014408, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 10357 / 20000\n",
      "gradient norm: 0.06178074941271916, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 10358 / 20000\n",
      "gradient norm: 0.03541431314079091, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 10359 / 20000\n",
      "gradient norm: 0.08538306603441015, minimum ratio: 2.4236842105263157\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 10360 / 20000\n",
      "gradient norm: 0.05404398770770058, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 10361 / 20000\n",
      "gradient norm: 0.1222449567867443, minimum ratio: 2.452631578947368\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 10362 / 20000\n",
      "gradient norm: 0.09485959040466696, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00554\n",
      "epoch 10363 / 20000\n",
      "gradient norm: 0.0638219325337559, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 10364 / 20000\n",
      "gradient norm: 0.04890529299154878, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 10365 / 20000\n",
      "gradient norm: 0.12638115929439664, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 10366 / 20000\n",
      "gradient norm: 0.029014110448770225, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 10367 / 20000\n",
      "gradient norm: 0.07682831410784274, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 10368 / 20000\n",
      "gradient norm: 0.0966907566471491, minimum ratio: 2.426315789473684\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 10369 / 20000\n",
      "gradient norm: 0.08489167940570042, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00553\n",
      "epoch 10370 / 20000\n",
      "gradient norm: 0.08782821090426296, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 10371 / 20000\n",
      "gradient norm: 0.09364675352117047, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00551\n",
      "epoch 10372 / 20000\n",
      "gradient norm: 0.1663837640080601, minimum ratio: 2.4447368421052635\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00555\n",
      "epoch 10373 / 20000\n",
      "gradient norm: 0.08824724645819515, minimum ratio: 2.4447368421052635\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 10374 / 20000\n",
      "gradient norm: 0.10060874407645315, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 10375 / 20000\n",
      "gradient norm: 0.026752929436042905, minimum ratio: 2.4736842105263155\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 10376 / 20000\n",
      "gradient norm: 0.06945965602062643, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 10377 / 20000\n",
      "gradient norm: 0.04706310648180079, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 10378 / 20000\n",
      "gradient norm: 0.09092820930527523, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 10379 / 20000\n",
      "gradient norm: 0.0725074907677481, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00555\n",
      "epoch 10380 / 20000\n",
      "gradient norm: 0.10447211307473481, minimum ratio: 2.4421052631578943\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 10381 / 20000\n",
      "gradient norm: 0.05719573513488285, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 10382 / 20000\n",
      "gradient norm: 0.05695063929306343, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 10383 / 20000\n",
      "gradient norm: 0.0201220871967962, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 10384 / 20000\n",
      "gradient norm: 0.056595876696519554, minimum ratio: 2.4394736842105265\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 10385 / 20000\n",
      "gradient norm: 0.06334949235315435, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 10386 / 20000\n",
      "gradient norm: 0.09399388125166297, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 10387 / 20000\n",
      "gradient norm: 0.0408233561902307, minimum ratio: 2.4421052631578943\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 10388 / 20000\n",
      "gradient norm: 0.036374389834236354, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 10389 / 20000\n",
      "gradient norm: 0.04463947672047652, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 10390 / 20000\n",
      "gradient norm: 0.08585558563936502, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 10391 / 20000\n",
      "gradient norm: 0.08697150310035795, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 10392 / 20000\n",
      "gradient norm: 0.07952121365815401, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 10393 / 20000\n",
      "gradient norm: 0.11717027320992202, minimum ratio: 2.4499999999999997\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 10394 / 20000\n",
      "gradient norm: 0.015670660504838452, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00551\n",
      "epoch 10395 / 20000\n",
      "gradient norm: 0.112061403458938, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 10396 / 20000\n",
      "gradient norm: 0.04932704189559445, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 10397 / 20000\n",
      "gradient norm: 0.031634543905965984, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 10398 / 20000\n",
      "gradient norm: 0.06750112230656669, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 10399 / 20000\n",
      "gradient norm: 0.030775806946621742, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 10400 / 20000\n",
      "gradient norm: 0.051699447038117796, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 10401 / 20000\n",
      "gradient norm: 0.08867229142924771, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 10402 / 20000\n",
      "gradient norm: 0.09920821426203474, minimum ratio: 2.4447368421052627\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 10403 / 20000\n",
      "gradient norm: 0.07477524277055636, minimum ratio: 2.460526315789474\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 10404 / 20000\n",
      "gradient norm: 0.053851159900659695, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 10405 / 20000\n",
      "gradient norm: 0.0509841627208516, minimum ratio: 2.436842105263158\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 10406 / 20000\n",
      "gradient norm: 0.025920759770087898, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 10407 / 20000\n",
      "gradient norm: 0.07206539396429434, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 10408 / 20000\n",
      "gradient norm: 0.03087662809411995, minimum ratio: 2.4394736842105265\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 10409 / 20000\n",
      "gradient norm: 0.019999726748210378, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 10410 / 20000\n",
      "gradient norm: 0.028905933984788135, minimum ratio: 2.4447368421052635\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 10411 / 20000\n",
      "gradient norm: 0.05464860444772057, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 10412 / 20000\n",
      "gradient norm: 0.03227943475940265, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 10413 / 20000\n",
      "gradient norm: 0.04090266063576564, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 10414 / 20000\n",
      "gradient norm: 0.04475429106969386, minimum ratio: 2.452631578947368\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 10415 / 20000\n",
      "gradient norm: 0.10759574337862432, minimum ratio: 2.4447368421052635\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 10416 / 20000\n",
      "gradient norm: 0.06622672674711794, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 10417 / 20000\n",
      "gradient norm: 0.05259990177000873, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 10418 / 20000\n",
      "gradient norm: 0.013142054085619748, minimum ratio: 2.465789473684211\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 10419 / 20000\n",
      "gradient norm: 0.07078053359873593, minimum ratio: 2.439473684210527\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 10420 / 20000\n",
      "gradient norm: 0.03754486530306167, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 10421 / 20000\n",
      "gradient norm: 0.05507145059527829, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 10422 / 20000\n",
      "gradient norm: 0.08370738799567334, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 10423 / 20000\n",
      "gradient norm: 0.06999966310104355, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 10424 / 20000\n",
      "gradient norm: 0.06579224855522625, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 10425 / 20000\n",
      "gradient norm: 0.04911775072105229, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 10426 / 20000\n",
      "gradient norm: 0.1030160280643031, minimum ratio: 2.4447368421052627\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 10427 / 20000\n",
      "gradient norm: 0.041243745014071465, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 10428 / 20000\n",
      "gradient norm: 0.10812020814046264, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 10429 / 20000\n",
      "gradient norm: 0.01783506101492094, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 10430 / 20000\n",
      "gradient norm: 0.11886597785633057, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 10431 / 20000\n",
      "gradient norm: 0.06792696096817963, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 10432 / 20000\n",
      "gradient norm: 0.040237702371086925, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00551\n",
      "epoch 10433 / 20000\n",
      "gradient norm: 0.04360729633481242, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 10434 / 20000\n",
      "gradient norm: 0.07227721106028184, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 10435 / 20000\n",
      "gradient norm: 0.0528605307044927, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 10436 / 20000\n",
      "gradient norm: 0.0948287914507091, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 10437 / 20000\n",
      "gradient norm: 0.07199846225557849, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 10438 / 20000\n",
      "gradient norm: 0.07994346122723073, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00555\n",
      "epoch 10439 / 20000\n",
      "gradient norm: 0.05338593226042576, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 10440 / 20000\n",
      "gradient norm: 0.06581768346950412, minimum ratio: 2.4421052631578943\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 10441 / 20000\n",
      "gradient norm: 0.04936462489422411, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 10442 / 20000\n",
      "gradient norm: 0.045163491886341944, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 10443 / 20000\n",
      "gradient norm: 0.06715839949902147, minimum ratio: 2.4421052631578943\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 10444 / 20000\n",
      "gradient norm: 0.04097522085066885, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 10445 / 20000\n",
      "gradient norm: 0.04477757078711875, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 10446 / 20000\n",
      "gradient norm: 0.05076357803773135, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 10447 / 20000\n",
      "gradient norm: 0.08580478047952056, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 10448 / 20000\n",
      "gradient norm: 0.03602134221000597, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 10449 / 20000\n",
      "gradient norm: 0.04922783118672669, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 10450 / 20000\n",
      "gradient norm: 0.07514842564705759, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 10451 / 20000\n",
      "gradient norm: 0.09548572910716757, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 10452 / 20000\n",
      "gradient norm: 0.05182732839602977, minimum ratio: 2.4394736842105265\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00551\n",
      "epoch 10453 / 20000\n",
      "gradient norm: 0.05613622162491083, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 10454 / 20000\n",
      "gradient norm: 0.027450356574263424, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 10455 / 20000\n",
      "gradient norm: 0.07843082217732444, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 10456 / 20000\n",
      "gradient norm: 0.06829134793952107, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 10457 / 20000\n",
      "gradient norm: 0.04690422356361523, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 10458 / 20000\n",
      "gradient norm: 0.11006158462259918, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 10459 / 20000\n",
      "gradient norm: 0.023438436728611123, minimum ratio: 2.46578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 10460 / 20000\n",
      "gradient norm: 0.04738044581608847, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00551\n",
      "epoch 10461 / 20000\n",
      "gradient norm: 0.13558104273397475, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 10462 / 20000\n",
      "gradient norm: 0.08457855024607852, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 10463 / 20000\n",
      "gradient norm: 0.055574736441485584, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 10464 / 20000\n",
      "gradient norm: 0.06882472682627849, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00554\n",
      "epoch 10465 / 20000\n",
      "gradient norm: 0.055252284451853484, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 10466 / 20000\n",
      "gradient norm: 0.08135379021405242, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 10467 / 20000\n",
      "gradient norm: 0.07396231764869299, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 10468 / 20000\n",
      "gradient norm: 0.05767031793948263, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 10469 / 20000\n",
      "gradient norm: 0.04138633224647492, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 10470 / 20000\n",
      "gradient norm: 0.06590199570928235, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 10471 / 20000\n",
      "gradient norm: 0.053837168004974956, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 10472 / 20000\n",
      "gradient norm: 0.050146954017691314, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 10473 / 20000\n",
      "gradient norm: 0.0261741976137273, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 10474 / 20000\n",
      "gradient norm: 0.05533907041535713, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 10475 / 20000\n",
      "gradient norm: 0.09759145835414529, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00553\n",
      "epoch 10476 / 20000\n",
      "gradient norm: 0.016935148520133225, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 10477 / 20000\n",
      "gradient norm: 0.05241908156313002, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 10478 / 20000\n",
      "gradient norm: 0.07606571528594941, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 10479 / 20000\n",
      "gradient norm: 0.06838795557268895, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 10480 / 20000\n",
      "gradient norm: 0.04599753975344356, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 10481 / 20000\n",
      "gradient norm: 0.08198468391492497, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 10482 / 20000\n",
      "gradient norm: 0.04782912440714426, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 10483 / 20000\n",
      "gradient norm: 0.08611299691256136, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 10484 / 20000\n",
      "gradient norm: 0.04570794096798636, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 10485 / 20000\n",
      "gradient norm: 0.10946278156188782, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 10486 / 20000\n",
      "gradient norm: 0.0330770372383995, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 10487 / 20000\n",
      "gradient norm: 0.03168384311720729, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 10488 / 20000\n",
      "gradient norm: 0.06016171834198758, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 10489 / 20000\n",
      "gradient norm: 0.07737725874176249, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 10490 / 20000\n",
      "gradient norm: 0.056047936668619514, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 10491 / 20000\n",
      "gradient norm: 0.042640967963961884, minimum ratio: 2.4684210526315784\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 10492 / 20000\n",
      "gradient norm: 0.0734385714167729, minimum ratio: 2.436842105263158\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 10493 / 20000\n",
      "gradient norm: 0.06587629157002084, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 10494 / 20000\n",
      "gradient norm: 0.09046554201631807, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 10495 / 20000\n",
      "gradient norm: 0.058282200508983806, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 10496 / 20000\n",
      "gradient norm: 0.05242097689915681, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 10497 / 20000\n",
      "gradient norm: 0.040912673342972994, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 10498 / 20000\n",
      "gradient norm: 0.10281007684534416, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 10499 / 20000\n",
      "gradient norm: 0.04761563891952392, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 10500 / 20000\n",
      "gradient norm: 0.10783828003332019, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 10501 / 20000\n",
      "gradient norm: 0.0381651226489339, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 10502 / 20000\n",
      "gradient norm: 0.0800978610641323, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00551\n",
      "epoch 10503 / 20000\n",
      "gradient norm: 0.05769288563169539, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00554\n",
      "epoch 10504 / 20000\n",
      "gradient norm: 0.0442963605892146, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 10505 / 20000\n",
      "gradient norm: 0.03840312655665912, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 10506 / 20000\n",
      "gradient norm: 0.04003457532962784, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 10507 / 20000\n",
      "gradient norm: 0.03918195626465604, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 10508 / 20000\n",
      "gradient norm: 0.06194376142229885, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 10509 / 20000\n",
      "gradient norm: 0.024825608168612234, minimum ratio: 2.465789473684211\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 10510 / 20000\n",
      "gradient norm: 0.12949259870219976, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00552\n",
      "epoch 10511 / 20000\n",
      "gradient norm: 0.07461684325244278, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 10512 / 20000\n",
      "gradient norm: 0.05029481164092431, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 10513 / 20000\n",
      "gradient norm: 0.07447525102179497, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 10514 / 20000\n",
      "gradient norm: 0.07801754714455456, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00554\n",
      "epoch 10515 / 20000\n",
      "gradient norm: 0.039533191244117916, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 10516 / 20000\n",
      "gradient norm: 0.06369773074402474, minimum ratio: 2.4447368421052635\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 10517 / 20000\n",
      "gradient norm: 0.06559784716228023, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 10518 / 20000\n",
      "gradient norm: 0.08644460438517854, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 10519 / 20000\n",
      "gradient norm: 0.018430609357892536, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 10520 / 20000\n",
      "gradient norm: 0.0927082221605815, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 10521 / 20000\n",
      "gradient norm: 0.059406100190244615, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 10522 / 20000\n",
      "gradient norm: 0.14024123398121446, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 10523 / 20000\n",
      "gradient norm: 0.0916951711406, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 10524 / 20000\n",
      "gradient norm: 0.053083508159033954, minimum ratio: 2.4736842105263155\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 10525 / 20000\n",
      "gradient norm: 0.06422596250195056, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 10526 / 20000\n",
      "gradient norm: 0.11831794213503599, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 10527 / 20000\n",
      "gradient norm: 0.09989113174378872, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 10528 / 20000\n",
      "gradient norm: 0.06670686707366258, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 10529 / 20000\n",
      "gradient norm: 0.03825973533093929, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 10530 / 20000\n",
      "gradient norm: 0.022453091165516526, minimum ratio: 2.46578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 10531 / 20000\n",
      "gradient norm: 0.04354168163263239, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 10532 / 20000\n",
      "gradient norm: 0.04952370296814479, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 10533 / 20000\n",
      "gradient norm: 0.017121137214417104, minimum ratio: 2.436842105263158\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 10534 / 20000\n",
      "gradient norm: 0.05788327835034579, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 10535 / 20000\n",
      "gradient norm: 0.096869325498119, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 10536 / 20000\n",
      "gradient norm: 0.060053205059375614, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 10537 / 20000\n",
      "gradient norm: 0.0525255057727918, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 10538 / 20000\n",
      "gradient norm: 0.09555739280767739, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 10539 / 20000\n",
      "gradient norm: 0.06196897954214364, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 10540 / 20000\n",
      "gradient norm: 0.045506596492487006, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 10541 / 20000\n",
      "gradient norm: 0.020424487986019813, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 10542 / 20000\n",
      "gradient norm: 0.04027326391951647, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 10543 / 20000\n",
      "gradient norm: 0.06130475178360939, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 10544 / 20000\n",
      "gradient norm: 0.10849690402392298, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 10545 / 20000\n",
      "gradient norm: 0.060063372482545674, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 10546 / 20000\n",
      "gradient norm: 0.07474173123773653, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 10547 / 20000\n",
      "gradient norm: 0.030850091396132484, minimum ratio: 2.4421052631578943\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 10548 / 20000\n",
      "gradient norm: 0.06622795708244666, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00551\n",
      "epoch 10549 / 20000\n",
      "gradient norm: 0.09491436055395752, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 10550 / 20000\n",
      "gradient norm: 0.055328635455225594, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 10551 / 20000\n",
      "gradient norm: 0.0728720949482522, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 10552 / 20000\n",
      "gradient norm: 0.046136604476487264, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 10553 / 20000\n",
      "gradient norm: 0.042493260247283615, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 10554 / 20000\n",
      "gradient norm: 0.08424321174970828, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 10555 / 20000\n",
      "gradient norm: 0.0737629973446019, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00554\n",
      "epoch 10556 / 20000\n",
      "gradient norm: 0.04448348775622435, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 10557 / 20000\n",
      "gradient norm: 0.05678542924579233, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 10558 / 20000\n",
      "gradient norm: 0.08784693368943408, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 10559 / 20000\n",
      "gradient norm: 0.04802519892109558, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 10560 / 20000\n",
      "gradient norm: 0.029916494779172353, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 10561 / 20000\n",
      "gradient norm: 0.05356673241476528, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 10562 / 20000\n",
      "gradient norm: 0.1090841579134576, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 10563 / 20000\n",
      "gradient norm: 0.047354437556350604, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 10564 / 20000\n",
      "gradient norm: 0.043071003863587976, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 10565 / 20000\n",
      "gradient norm: 0.0823047417216003, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00554\n",
      "epoch 10566 / 20000\n",
      "gradient norm: 0.04292533971602097, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 10567 / 20000\n",
      "gradient norm: 0.125199876842089, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00551\n",
      "epoch 10568 / 20000\n",
      "gradient norm: 0.034392500878311694, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 10569 / 20000\n",
      "gradient norm: 0.07421897927997634, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 10570 / 20000\n",
      "gradient norm: 0.05751160142244771, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 10571 / 20000\n",
      "gradient norm: 0.06747147359419614, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 10572 / 20000\n",
      "gradient norm: 0.06014808529289439, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00554\n",
      "epoch 10573 / 20000\n",
      "gradient norm: 0.07751321408431977, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 10574 / 20000\n",
      "gradient norm: 0.037830290966667235, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 10575 / 20000\n",
      "gradient norm: 0.0717404538881965, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 10576 / 20000\n",
      "gradient norm: 0.09162400831701234, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00555\n",
      "epoch 10577 / 20000\n",
      "gradient norm: 0.08848537656012923, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 10578 / 20000\n",
      "gradient norm: 0.06424365984275937, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 10579 / 20000\n",
      "gradient norm: 0.06846553523791954, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 10580 / 20000\n",
      "gradient norm: 0.05827964245690964, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 10581 / 20000\n",
      "gradient norm: 0.05174538359278813, minimum ratio: 2.4394736842105265\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 10582 / 20000\n",
      "gradient norm: 0.051710038154851645, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 10583 / 20000\n",
      "gradient norm: 0.03760317692649551, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 10584 / 20000\n",
      "gradient norm: 0.07952194139943458, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 10585 / 20000\n",
      "gradient norm: 0.04546518888673745, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 10586 / 20000\n",
      "gradient norm: 0.07848439330700785, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 10587 / 20000\n",
      "gradient norm: 0.04459680961736012, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 10588 / 20000\n",
      "gradient norm: 0.027769500520662405, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 10589 / 20000\n",
      "gradient norm: 0.05398515972774476, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 10590 / 20000\n",
      "gradient norm: 0.07455116031633224, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 10591 / 20000\n",
      "gradient norm: 0.07279254068271257, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 10592 / 20000\n",
      "gradient norm: 0.09382620567339472, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 10593 / 20000\n",
      "gradient norm: 0.07195089061860926, minimum ratio: 2.4394736842105265\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 10594 / 20000\n",
      "gradient norm: 0.08655649848515168, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00554\n",
      "epoch 10595 / 20000\n",
      "gradient norm: 0.04333112854510546, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 10596 / 20000\n",
      "gradient norm: 0.050792282534530386, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 10597 / 20000\n",
      "gradient norm: 0.06159538830979727, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00551\n",
      "epoch 10598 / 20000\n",
      "gradient norm: 0.0387017151042528, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 10599 / 20000\n",
      "gradient norm: 0.07486766367219388, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 10600 / 20000\n",
      "gradient norm: 0.10546281823189929, minimum ratio: 2.4263157894736844\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 10601 / 20000\n",
      "gradient norm: 0.03493632425670512, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 10602 / 20000\n",
      "gradient norm: 0.07260187587235123, minimum ratio: 2.460526315789474\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 10603 / 20000\n",
      "gradient norm: 0.0725568599300459, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 10604 / 20000\n",
      "gradient norm: 0.04677700114552863, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 10605 / 20000\n",
      "gradient norm: 0.09522153448779136, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 10606 / 20000\n",
      "gradient norm: 0.06620776327326894, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00553\n",
      "epoch 10607 / 20000\n",
      "gradient norm: 0.08423254452645779, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 10608 / 20000\n",
      "gradient norm: 0.04535866042715497, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 10609 / 20000\n",
      "gradient norm: 0.1394496546126902, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 10610 / 20000\n",
      "gradient norm: 0.05517855007201433, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 10611 / 20000\n",
      "gradient norm: 0.03285732759832172, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 10612 / 20000\n",
      "gradient norm: 0.07145749681512825, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 10613 / 20000\n",
      "gradient norm: 0.14409886836074293, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 10614 / 20000\n",
      "gradient norm: 0.07725565775763243, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 10615 / 20000\n",
      "gradient norm: 0.04106932136346586, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 10616 / 20000\n",
      "gradient norm: 0.054252604517387226, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 10617 / 20000\n",
      "gradient norm: 0.05591234879102558, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 10618 / 20000\n",
      "gradient norm: 0.02573653838771861, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 10619 / 20000\n",
      "gradient norm: 0.042732307585538365, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 10620 / 20000\n",
      "gradient norm: 0.05296217181603424, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 10621 / 20000\n",
      "gradient norm: 0.08668436075095087, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 10622 / 20000\n",
      "gradient norm: 0.0548271115985699, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 10623 / 20000\n",
      "gradient norm: 0.11190724381594919, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 10624 / 20000\n",
      "gradient norm: 0.10717892866523471, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 10625 / 20000\n",
      "gradient norm: 0.08442256256239489, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 10626 / 20000\n",
      "gradient norm: 0.1018769753864035, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00551\n",
      "epoch 10627 / 20000\n",
      "gradient norm: 0.03822856240731198, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 10628 / 20000\n",
      "gradient norm: 0.05648228741483763, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 10629 / 20000\n",
      "gradient norm: 0.08248277386883274, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 10630 / 20000\n",
      "gradient norm: 0.056034440553048626, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 10631 / 20000\n",
      "gradient norm: 0.04832381824962795, minimum ratio: 2.4499999999999997\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 10632 / 20000\n",
      "gradient norm: 0.03201843147689942, minimum ratio: 2.4394736842105265\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 10633 / 20000\n",
      "gradient norm: 0.07369574584299698, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 10634 / 20000\n",
      "gradient norm: 0.05632274673553184, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 10635 / 20000\n",
      "gradient norm: 0.041062818199861795, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 10636 / 20000\n",
      "gradient norm: 0.0775981216575019, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 10637 / 20000\n",
      "gradient norm: 0.08987992268521339, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 10638 / 20000\n",
      "gradient norm: 0.03417325404006988, minimum ratio: 2.452631578947368\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 10639 / 20000\n",
      "gradient norm: 0.08679771207971498, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 10640 / 20000\n",
      "gradient norm: 0.031403783039422706, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 10641 / 20000\n",
      "gradient norm: 0.06441298761637881, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 10642 / 20000\n",
      "gradient norm: 0.08052932866849005, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 10643 / 20000\n",
      "gradient norm: 0.05568221710564103, minimum ratio: 2.4736842105263155\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 10644 / 20000\n",
      "gradient norm: 0.09338899073190987, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 10645 / 20000\n",
      "gradient norm: 0.09905387368053198, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 10646 / 20000\n",
      "gradient norm: 0.04252561255998444, minimum ratio: 2.4499999999999997\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 10647 / 20000\n",
      "gradient norm: 0.08616943995002657, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 10648 / 20000\n",
      "gradient norm: 0.04339324723696336, minimum ratio: 2.4421052631578943\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 10649 / 20000\n",
      "gradient norm: 0.05194255174137652, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 10650 / 20000\n",
      "gradient norm: 0.05631613539298996, minimum ratio: 2.426315789473684\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 10651 / 20000\n",
      "gradient norm: 0.11682598330662586, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 10652 / 20000\n",
      "gradient norm: 0.06374669521756005, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 10653 / 20000\n",
      "gradient norm: 0.05438572581624612, minimum ratio: 2.460526315789474\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 10654 / 20000\n",
      "gradient norm: 0.04395791835850105, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 10655 / 20000\n",
      "gradient norm: 0.07360448135295883, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 10656 / 20000\n",
      "gradient norm: 0.09401012375019491, minimum ratio: 2.4210526315789473\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00555\n",
      "epoch 10657 / 20000\n",
      "gradient norm: 0.1086991912452504, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00551\n",
      "epoch 10658 / 20000\n",
      "gradient norm: 0.06759518905892037, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 10659 / 20000\n",
      "gradient norm: 0.05494555881887209, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00553\n",
      "epoch 10660 / 20000\n",
      "gradient norm: 0.1054646915581543, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 10661 / 20000\n",
      "gradient norm: 0.12036023696418852, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00554\n",
      "epoch 10662 / 20000\n",
      "gradient norm: 0.06065751740243286, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 10663 / 20000\n",
      "gradient norm: 0.04254754746216349, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 10664 / 20000\n",
      "gradient norm: 0.03848049676162191, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 10665 / 20000\n",
      "gradient norm: 0.05681372567778453, minimum ratio: 2.423684210526316\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 10666 / 20000\n",
      "gradient norm: 0.1004139008000493, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 10667 / 20000\n",
      "gradient norm: 0.1354848991613835, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 10668 / 20000\n",
      "gradient norm: 0.11356565728783607, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 10669 / 20000\n",
      "gradient norm: 0.094149473705329, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 10670 / 20000\n",
      "gradient norm: 0.06975417441572063, minimum ratio: 2.4289473684210523\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 10671 / 20000\n",
      "gradient norm: 0.06562618835596368, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 10672 / 20000\n",
      "gradient norm: 0.08757196791702881, minimum ratio: 2.4394736842105265\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 10673 / 20000\n",
      "gradient norm: 0.1431437551509589, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 10674 / 20000\n",
      "gradient norm: 0.02804675867082551, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 10675 / 20000\n",
      "gradient norm: 0.02422235229460057, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 10676 / 20000\n",
      "gradient norm: 0.08945365287945606, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 10677 / 20000\n",
      "gradient norm: 0.12198751315008849, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 10678 / 20000\n",
      "gradient norm: 0.1013497035310138, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 10679 / 20000\n",
      "gradient norm: 0.09480961586814374, minimum ratio: 2.4447368421052635\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 10680 / 20000\n",
      "gradient norm: 0.0807489474536851, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 10681 / 20000\n",
      "gradient norm: 0.06911867414601147, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 10682 / 20000\n",
      "gradient norm: 0.03295501388492994, minimum ratio: 2.4447368421052627\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00553\n",
      "epoch 10683 / 20000\n",
      "gradient norm: 0.07880731363547966, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 10684 / 20000\n",
      "gradient norm: 0.034544871479738504, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 10685 / 20000\n",
      "gradient norm: 0.06674400123301893, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00554\n",
      "epoch 10686 / 20000\n",
      "gradient norm: 0.06186166568659246, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 10687 / 20000\n",
      "gradient norm: 0.07296810147818178, minimum ratio: 2.4499999999999997\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 10688 / 20000\n",
      "gradient norm: 0.046445720159681514, minimum ratio: 2.460526315789474\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 10689 / 20000\n",
      "gradient norm: 0.06211770104710013, minimum ratio: 2.418421052631579\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 10690 / 20000\n",
      "gradient norm: 0.07078613247722387, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 10691 / 20000\n",
      "gradient norm: 0.06502083838859107, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00554\n",
      "epoch 10692 / 20000\n",
      "gradient norm: 0.060108052304713055, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00553\n",
      "epoch 10693 / 20000\n",
      "gradient norm: 0.10993319086264819, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 10694 / 20000\n",
      "gradient norm: 0.039072882413165644, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 10695 / 20000\n",
      "gradient norm: 0.07709211160545237, minimum ratio: 2.4157894736842103\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 10696 / 20000\n",
      "gradient norm: 0.03700212776311673, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 10697 / 20000\n",
      "gradient norm: 0.06165494791639503, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 10698 / 20000\n",
      "gradient norm: 0.06018154289631639, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 10699 / 20000\n",
      "gradient norm: 0.01655609426961746, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 10700 / 20000\n",
      "gradient norm: 0.06216035917168483, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 10701 / 20000\n",
      "gradient norm: 0.09528188389958814, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 10702 / 20000\n",
      "gradient norm: 0.03093980241101235, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 10703 / 20000\n",
      "gradient norm: 0.02257395735796308, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 10704 / 20000\n",
      "gradient norm: 0.04877078397839796, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 10705 / 20000\n",
      "gradient norm: 0.08875364623963833, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 10706 / 20000\n",
      "gradient norm: 0.0595562377711758, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 10707 / 20000\n",
      "gradient norm: 0.05643362388946116, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 10708 / 20000\n",
      "gradient norm: 0.06078886112663895, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 10709 / 20000\n",
      "gradient norm: 0.08031626290176064, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00565\n",
      "\tval loss: 0.00552\n",
      "epoch 10710 / 20000\n",
      "gradient norm: 0.05169268505414948, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 10711 / 20000\n",
      "gradient norm: 0.05999140950734727, minimum ratio: 2.4447368421052627\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 10712 / 20000\n",
      "gradient norm: 0.06993974235956557, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 10713 / 20000\n",
      "gradient norm: 0.08040039002662525, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00554\n",
      "epoch 10714 / 20000\n",
      "gradient norm: 0.0925527325598523, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 10715 / 20000\n",
      "gradient norm: 0.04100424237549305, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 10716 / 20000\n",
      "gradient norm: 0.08521862991619855, minimum ratio: 2.423684210526316\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 10717 / 20000\n",
      "gradient norm: 0.02730479898309568, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00551\n",
      "epoch 10718 / 20000\n",
      "gradient norm: 0.06079150253208354, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 10719 / 20000\n",
      "gradient norm: 0.030465512885712087, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 10720 / 20000\n",
      "gradient norm: 0.09524758788757026, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 10721 / 20000\n",
      "gradient norm: 0.05868031329009682, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00551\n",
      "epoch 10722 / 20000\n",
      "gradient norm: 0.08293571468675509, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 10723 / 20000\n",
      "gradient norm: 0.052966426708735526, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 10724 / 20000\n",
      "gradient norm: 0.10388526890892535, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 10725 / 20000\n",
      "gradient norm: 0.0730449800612405, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 10726 / 20000\n",
      "gradient norm: 0.04360830911900848, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 10727 / 20000\n",
      "gradient norm: 0.05988060819800012, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 10728 / 20000\n",
      "gradient norm: 0.11427712900331244, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 10729 / 20000\n",
      "gradient norm: 0.049587061832426116, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00551\n",
      "epoch 10730 / 20000\n",
      "gradient norm: 0.06082938192412257, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 10731 / 20000\n",
      "gradient norm: 0.08846370421815664, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 10732 / 20000\n",
      "gradient norm: 0.08108523197006434, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00553\n",
      "epoch 10733 / 20000\n",
      "gradient norm: 0.059876622748561203, minimum ratio: 2.4394736842105265\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 10734 / 20000\n",
      "gradient norm: 0.08461131918011233, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 10735 / 20000\n",
      "gradient norm: 0.059127973683644086, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00555\n",
      "epoch 10736 / 20000\n",
      "gradient norm: 0.055724729085341096, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 10737 / 20000\n",
      "gradient norm: 0.09169357232167386, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 10738 / 20000\n",
      "gradient norm: 0.0736451921693515, minimum ratio: 2.4236842105263157\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 10739 / 20000\n",
      "gradient norm: 0.07934142265003175, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 10740 / 20000\n",
      "gradient norm: 0.09328361001098529, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 10741 / 20000\n",
      "gradient norm: 0.10153003397863358, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 10742 / 20000\n",
      "gradient norm: 0.067547976388596, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 10743 / 20000\n",
      "gradient norm: 0.11384055009693839, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 10744 / 20000\n",
      "gradient norm: 0.03179933212231845, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 10745 / 20000\n",
      "gradient norm: 0.11112967261578888, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 10746 / 20000\n",
      "gradient norm: 0.017887886613607407, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 10747 / 20000\n",
      "gradient norm: 0.04454595354036428, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 10748 / 20000\n",
      "gradient norm: 0.07645780026723514, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 10749 / 20000\n",
      "gradient norm: 0.06716309778857976, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 10750 / 20000\n",
      "gradient norm: 0.07027671777177602, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 10751 / 20000\n",
      "gradient norm: 0.04393485258333385, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 10752 / 20000\n",
      "gradient norm: 0.0607589150313288, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 10753 / 20000\n",
      "gradient norm: 0.09495883353520185, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 10754 / 20000\n",
      "gradient norm: 0.08604473754530773, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 10755 / 20000\n",
      "gradient norm: 0.09864993504015729, minimum ratio: 2.436842105263158\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 10756 / 20000\n",
      "gradient norm: 0.08082269161241129, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 10757 / 20000\n",
      "gradient norm: 0.02975654907641001, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 10758 / 20000\n",
      "gradient norm: 0.09495362074812874, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 10759 / 20000\n",
      "gradient norm: 0.0805910563794896, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 10760 / 20000\n",
      "gradient norm: 0.026767107447085436, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 10761 / 20000\n",
      "gradient norm: 0.027423309395089746, minimum ratio: 2.46578947368421\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 10762 / 20000\n",
      "gradient norm: 0.060477319988422096, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 10763 / 20000\n",
      "gradient norm: 0.03579586642445065, minimum ratio: 2.4499999999999997\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 10764 / 20000\n",
      "gradient norm: 0.07689263677457348, minimum ratio: 2.460526315789474\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 10765 / 20000\n",
      "gradient norm: 0.05579904522164725, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 10766 / 20000\n",
      "gradient norm: 0.08716288197319955, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 10767 / 20000\n",
      "gradient norm: 0.05029530967294704, minimum ratio: 2.4394736842105265\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 10768 / 20000\n",
      "gradient norm: 0.02764849858067464, minimum ratio: 2.4394736842105265\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 10769 / 20000\n",
      "gradient norm: 0.062258576130261645, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 10770 / 20000\n",
      "gradient norm: 0.06686889289994724, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 10771 / 20000\n",
      "gradient norm: 0.06268701277440414, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 10772 / 20000\n",
      "gradient norm: 0.06523848648066632, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 10773 / 20000\n",
      "gradient norm: 0.07778026757296175, minimum ratio: 2.4421052631578943\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 10774 / 20000\n",
      "gradient norm: 0.05480467397137545, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 10775 / 20000\n",
      "gradient norm: 0.030800621723756194, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 10776 / 20000\n",
      "gradient norm: 0.046081452252110466, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 10777 / 20000\n",
      "gradient norm: 0.08800676511600614, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 10778 / 20000\n",
      "gradient norm: 0.05076814717904199, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 10779 / 20000\n",
      "gradient norm: 0.03372125681198668, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 10780 / 20000\n",
      "gradient norm: 0.02932021502056159, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 10781 / 20000\n",
      "gradient norm: 0.0428258789179381, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 10782 / 20000\n",
      "gradient norm: 0.049286803987342864, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 10783 / 20000\n",
      "gradient norm: 0.06410654712817632, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 10784 / 20000\n",
      "gradient norm: 0.04966388497268781, minimum ratio: 2.4263157894736844\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 10785 / 20000\n",
      "gradient norm: 0.05178321168932598, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 10786 / 20000\n",
      "gradient norm: 0.07065126043744385, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 10787 / 20000\n",
      "gradient norm: 0.0917281464789994, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 10788 / 20000\n",
      "gradient norm: 0.03300835157278925, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 10789 / 20000\n",
      "gradient norm: 0.06207652285229415, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 10790 / 20000\n",
      "gradient norm: 0.09592250996502116, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 10791 / 20000\n",
      "gradient norm: 0.020251618370821234, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 10792 / 20000\n",
      "gradient norm: 0.0927890840684995, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 10793 / 20000\n",
      "gradient norm: 0.048377186816651374, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 10794 / 20000\n",
      "gradient norm: 0.11235952872084454, minimum ratio: 2.4394736842105265\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 10795 / 20000\n",
      "gradient norm: 0.07655098306713626, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 10796 / 20000\n",
      "gradient norm: 0.08236739208223298, minimum ratio: 2.421052631578948\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 10797 / 20000\n",
      "gradient norm: 0.04509838510421105, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 10798 / 20000\n",
      "gradient norm: 0.06247051263926551, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 10799 / 20000\n",
      "gradient norm: 0.05590659903828055, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 10800 / 20000\n",
      "gradient norm: 0.09930026810616255, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 10801 / 20000\n",
      "gradient norm: 0.053927795408526435, minimum ratio: 2.4447368421052635\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 10802 / 20000\n",
      "gradient norm: 0.09817969118012115, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 10803 / 20000\n",
      "gradient norm: 0.11047385999700055, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 10804 / 20000\n",
      "gradient norm: 0.05086207776912488, minimum ratio: 2.460526315789474\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 10805 / 20000\n",
      "gradient norm: 0.08302001660922542, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 10806 / 20000\n",
      "gradient norm: 0.0559964231797494, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00554\n",
      "epoch 10807 / 20000\n",
      "gradient norm: 0.09730736294295639, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 10808 / 20000\n",
      "gradient norm: 0.040701698657358065, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00551\n",
      "epoch 10809 / 20000\n",
      "gradient norm: 0.09712341497652233, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 10810 / 20000\n",
      "gradient norm: 0.05470218590926379, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00555\n",
      "epoch 10811 / 20000\n",
      "gradient norm: 0.08874013461172581, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 10812 / 20000\n",
      "gradient norm: 0.11401244578883052, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 10813 / 20000\n",
      "gradient norm: 0.07307417556876317, minimum ratio: 2.460526315789474\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00552\n",
      "epoch 10814 / 20000\n",
      "gradient norm: 0.09641590598039329, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00556\n",
      "epoch 10815 / 20000\n",
      "gradient norm: 0.08866424183361232, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 10816 / 20000\n",
      "gradient norm: 0.08914552867645398, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 10817 / 20000\n",
      "gradient norm: 0.06854088918771595, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00553\n",
      "epoch 10818 / 20000\n",
      "gradient norm: 0.057417103787884116, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 10819 / 20000\n",
      "gradient norm: 0.054218759934883565, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 10820 / 20000\n",
      "gradient norm: 0.03604847160750069, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 10821 / 20000\n",
      "gradient norm: 0.046550101575121516, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 10822 / 20000\n",
      "gradient norm: 0.04180616243684199, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 10823 / 20000\n",
      "gradient norm: 0.05796275197644718, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 10824 / 20000\n",
      "gradient norm: 0.08927414432400838, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 10825 / 20000\n",
      "gradient norm: 0.058972193219233304, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 10826 / 20000\n",
      "gradient norm: 0.06870950548909605, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 10827 / 20000\n",
      "gradient norm: 0.06021380466700066, minimum ratio: 2.4236842105263157\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 10828 / 20000\n",
      "gradient norm: 0.065119824022986, minimum ratio: 2.4842105263157896\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 10829 / 20000\n",
      "gradient norm: 0.05218570836586878, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 10830 / 20000\n",
      "gradient norm: 0.06408108305186033, minimum ratio: 2.4499999999999997\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 10831 / 20000\n",
      "gradient norm: 0.09740068539394997, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00551\n",
      "epoch 10832 / 20000\n",
      "gradient norm: 0.025191918641212396, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 10833 / 20000\n",
      "gradient norm: 0.0524293088237755, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 10834 / 20000\n",
      "gradient norm: 0.07149045032565482, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 10835 / 20000\n",
      "gradient norm: 0.05092300465912558, minimum ratio: 2.4578947368421056\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 10836 / 20000\n",
      "gradient norm: 0.041222416708478704, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 10837 / 20000\n",
      "gradient norm: 0.10635358130093664, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 10838 / 20000\n",
      "gradient norm: 0.030756811262108386, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00551\n",
      "epoch 10839 / 20000\n",
      "gradient norm: 0.08642035920638591, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00551\n",
      "epoch 10840 / 20000\n",
      "gradient norm: 0.0633476724033244, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 10841 / 20000\n",
      "gradient norm: 0.06778139062225819, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 10842 / 20000\n",
      "gradient norm: 0.08080339073785581, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 10843 / 20000\n",
      "gradient norm: 0.04240963366464712, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 10844 / 20000\n",
      "gradient norm: 0.06721606221981347, minimum ratio: 2.4263157894736844\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 10845 / 20000\n",
      "gradient norm: 0.06552439194638282, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 10846 / 20000\n",
      "gradient norm: 0.03841003464185633, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 10847 / 20000\n",
      "gradient norm: 0.09403946640668437, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 10848 / 20000\n",
      "gradient norm: 0.04346880466619041, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 10849 / 20000\n",
      "gradient norm: 0.06820078624878079, minimum ratio: 2.4447368421052635\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 10850 / 20000\n",
      "gradient norm: 0.04029919307504315, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 10851 / 20000\n",
      "gradient norm: 0.026655875029973686, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 10852 / 20000\n",
      "gradient norm: 0.026754773818538524, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 10853 / 20000\n",
      "gradient norm: 0.07986155449179932, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 10854 / 20000\n",
      "gradient norm: 0.06433072171057574, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 10855 / 20000\n",
      "gradient norm: 0.05943743369425647, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 10856 / 20000\n",
      "gradient norm: 0.0588606413512025, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 10857 / 20000\n",
      "gradient norm: 0.051274892495712265, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 10858 / 20000\n",
      "gradient norm: 0.06774879232398234, minimum ratio: 2.4394736842105265\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 10859 / 20000\n",
      "gradient norm: 0.05445707030594349, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 10860 / 20000\n",
      "gradient norm: 0.0532085876329802, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 10861 / 20000\n",
      "gradient norm: 0.07581033738097176, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00551\n",
      "epoch 10862 / 20000\n",
      "gradient norm: 0.0360686146595981, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 10863 / 20000\n",
      "gradient norm: 0.05822830199031159, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 10864 / 20000\n",
      "gradient norm: 0.047951002372428775, minimum ratio: 2.4499999999999997\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 10865 / 20000\n",
      "gradient norm: 0.05692350692697801, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 10866 / 20000\n",
      "gradient norm: 0.11940753110684454, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 10867 / 20000\n",
      "gradient norm: 0.0570643944083713, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 10868 / 20000\n",
      "gradient norm: 0.11068526213057339, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 10869 / 20000\n",
      "gradient norm: 0.07728986607980914, minimum ratio: 2.465789473684211\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 10870 / 20000\n",
      "gradient norm: 0.048495947899937164, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 10871 / 20000\n",
      "gradient norm: 0.08295544690918177, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 10872 / 20000\n",
      "gradient norm: 0.022841768455691636, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 10873 / 20000\n",
      "gradient norm: 0.0885756645584479, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00551\n",
      "epoch 10874 / 20000\n",
      "gradient norm: 0.056137829553335905, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 10875 / 20000\n",
      "gradient norm: 0.09802912682062015, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 10876 / 20000\n",
      "gradient norm: 0.07142208272125572, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 10877 / 20000\n",
      "gradient norm: 0.07183073996566236, minimum ratio: 2.460526315789474\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 10878 / 20000\n",
      "gradient norm: 0.04362355271587148, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 10879 / 20000\n",
      "gradient norm: 0.0676711243140744, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 10880 / 20000\n",
      "gradient norm: 0.054367461532820016, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 10881 / 20000\n",
      "gradient norm: 0.11952719127293676, minimum ratio: 2.465789473684211\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 10882 / 20000\n",
      "gradient norm: 0.06940252322237939, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 10883 / 20000\n",
      "gradient norm: 0.04325178972794674, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 10884 / 20000\n",
      "gradient norm: 0.1237158285221085, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 10885 / 20000\n",
      "gradient norm: 0.04688734114461113, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 10886 / 20000\n",
      "gradient norm: 0.06344847907894291, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 10887 / 20000\n",
      "gradient norm: 0.07476577296620235, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 10888 / 20000\n",
      "gradient norm: 0.04507381224539131, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 10889 / 20000\n",
      "gradient norm: 0.05725916469236836, minimum ratio: 2.4394736842105265\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 10890 / 20000\n",
      "gradient norm: 0.10230461740866303, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 10891 / 20000\n",
      "gradient norm: 0.05685393523890525, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 10892 / 20000\n",
      "gradient norm: 0.042974515294190496, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 10893 / 20000\n",
      "gradient norm: 0.06850437493994832, minimum ratio: 2.4499999999999997\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 10894 / 20000\n",
      "gradient norm: 0.07319892756640911, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 10895 / 20000\n",
      "gradient norm: 0.07946579350391403, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 10896 / 20000\n",
      "gradient norm: 0.07017680356511846, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 10897 / 20000\n",
      "gradient norm: 0.09768924611853436, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 10898 / 20000\n",
      "gradient norm: 0.03019343406049302, minimum ratio: 2.460526315789474\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 10899 / 20000\n",
      "gradient norm: 0.10397880873642862, minimum ratio: 2.418421052631579\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 10900 / 20000\n",
      "gradient norm: 0.062212077231379226, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 10901 / 20000\n",
      "gradient norm: 0.040396750715444796, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 10902 / 20000\n",
      "gradient norm: 0.03416030009975657, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 10903 / 20000\n",
      "gradient norm: 0.0833793111378327, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 10904 / 20000\n",
      "gradient norm: 0.06198212818708271, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 10905 / 20000\n",
      "gradient norm: 0.06343413794820663, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 10906 / 20000\n",
      "gradient norm: 0.0862988627050072, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 10907 / 20000\n",
      "gradient norm: 0.04921991235460155, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 10908 / 20000\n",
      "gradient norm: 0.07506769499741495, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00551\n",
      "epoch 10909 / 20000\n",
      "gradient norm: 0.05525319330627099, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 10910 / 20000\n",
      "gradient norm: 0.08651012857444584, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 10911 / 20000\n",
      "gradient norm: 0.1159642789280042, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 10912 / 20000\n",
      "gradient norm: 0.0701479469134938, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 10913 / 20000\n",
      "gradient norm: 0.10088081902358681, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 10914 / 20000\n",
      "gradient norm: 0.07132186408853158, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 10915 / 20000\n",
      "gradient norm: 0.08837131725158542, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 10916 / 20000\n",
      "gradient norm: 0.06286099411954638, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00553\n",
      "epoch 10917 / 20000\n",
      "gradient norm: 0.05648631742224097, minimum ratio: 2.436842105263158\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 10918 / 20000\n",
      "gradient norm: 0.07721557252807543, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 10919 / 20000\n",
      "gradient norm: 0.018243022335809655, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 10920 / 20000\n",
      "gradient norm: 0.08067318494431674, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 10921 / 20000\n",
      "gradient norm: 0.04338747661677189, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 10922 / 20000\n",
      "gradient norm: 0.06952397775603458, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 10923 / 20000\n",
      "gradient norm: 0.059832443308550864, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 10924 / 20000\n",
      "gradient norm: 0.027500255848281085, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 10925 / 20000\n",
      "gradient norm: 0.03734346909914166, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 10926 / 20000\n",
      "gradient norm: 0.03660166868939996, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 10927 / 20000\n",
      "gradient norm: 0.03744431697123218, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 10928 / 20000\n",
      "gradient norm: 0.048898200620897114, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 10929 / 20000\n",
      "gradient norm: 0.03716802327835467, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00553\n",
      "epoch 10930 / 20000\n",
      "gradient norm: 0.07469318102812394, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 10931 / 20000\n",
      "gradient norm: 0.10219516273355111, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 10932 / 20000\n",
      "gradient norm: 0.043691210594261065, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 10933 / 20000\n",
      "gradient norm: 0.05496763654809911, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 10934 / 20000\n",
      "gradient norm: 0.0829763735528104, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 10935 / 20000\n",
      "gradient norm: 0.054739098384743556, minimum ratio: 2.426315789473684\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 10936 / 20000\n",
      "gradient norm: 0.06652377592399716, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 10937 / 20000\n",
      "gradient norm: 0.06093818449880928, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 10938 / 20000\n",
      "gradient norm: 0.04955376667203382, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 10939 / 20000\n",
      "gradient norm: 0.05294805683661252, minimum ratio: 2.4499999999999997\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 10940 / 20000\n",
      "gradient norm: 0.05741294613108039, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 10941 / 20000\n",
      "gradient norm: 0.055720361226121895, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 10942 / 20000\n",
      "gradient norm: 0.059158862379263155, minimum ratio: 2.46578947368421\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 10943 / 20000\n",
      "gradient norm: 0.08463317627320066, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 10944 / 20000\n",
      "gradient norm: 0.04900787406950258, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 10945 / 20000\n",
      "gradient norm: 0.07805428304709494, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 10946 / 20000\n",
      "gradient norm: 0.05124192262883298, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 10947 / 20000\n",
      "gradient norm: 0.10494189884047955, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 10948 / 20000\n",
      "gradient norm: 0.05824681979720481, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 10949 / 20000\n",
      "gradient norm: 0.06447656296950299, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 10950 / 20000\n",
      "gradient norm: 0.09415876062121242, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 10951 / 20000\n",
      "gradient norm: 0.06888776464620605, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 10952 / 20000\n",
      "gradient norm: 0.042031268239952624, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 10953 / 20000\n",
      "gradient norm: 0.07791467926290352, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 10954 / 20000\n",
      "gradient norm: 0.053576011734548956, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 10955 / 20000\n",
      "gradient norm: 0.04634349944535643, minimum ratio: 2.4236842105263157\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 10956 / 20000\n",
      "gradient norm: 0.018826521292794496, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 10957 / 20000\n",
      "gradient norm: 0.047053975926246494, minimum ratio: 2.460526315789474\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 10958 / 20000\n",
      "gradient norm: 0.09522497729631141, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 10959 / 20000\n",
      "gradient norm: 0.0797364478930831, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 10960 / 20000\n",
      "gradient norm: 0.08773123216815293, minimum ratio: 2.460526315789474\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 10961 / 20000\n",
      "gradient norm: 0.08087713096756488, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 10962 / 20000\n",
      "gradient norm: 0.04782777244690806, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 10963 / 20000\n",
      "gradient norm: 0.04533450883172918, minimum ratio: 2.460526315789474\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 10964 / 20000\n",
      "gradient norm: 0.0614796873414889, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 10965 / 20000\n",
      "gradient norm: 0.04663870029617101, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 10966 / 20000\n",
      "gradient norm: 0.035977465711766854, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 10967 / 20000\n",
      "gradient norm: 0.025087371526751667, minimum ratio: 2.4394736842105265\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 10968 / 20000\n",
      "gradient norm: 0.054043815936893225, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 10969 / 20000\n",
      "gradient norm: 0.08322737102571409, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 10970 / 20000\n",
      "gradient norm: 0.0844284157792572, minimum ratio: 2.460526315789474\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 10971 / 20000\n",
      "gradient norm: 0.0892757864203304, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 10972 / 20000\n",
      "gradient norm: 0.05101354839280248, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 10973 / 20000\n",
      "gradient norm: 0.05973615904804319, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 10974 / 20000\n",
      "gradient norm: 0.06679218061617576, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 10975 / 20000\n",
      "gradient norm: 0.08249763824278489, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 10976 / 20000\n",
      "gradient norm: 0.05516563553828746, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 10977 / 20000\n",
      "gradient norm: 0.03813909040763974, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 10978 / 20000\n",
      "gradient norm: 0.04331428956356831, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 10979 / 20000\n",
      "gradient norm: 0.05112605598696973, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 10980 / 20000\n",
      "gradient norm: 0.11124128266237676, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 10981 / 20000\n",
      "gradient norm: 0.06715785845881328, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00551\n",
      "epoch 10982 / 20000\n",
      "gradient norm: 0.06955386808840558, minimum ratio: 2.4447368421052635\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 10983 / 20000\n",
      "gradient norm: 0.12159559957217425, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 10984 / 20000\n",
      "gradient norm: 0.07211638800799847, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 10985 / 20000\n",
      "gradient norm: 0.06356044681160711, minimum ratio: 2.418421052631579\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 10986 / 20000\n",
      "gradient norm: 0.07250570208998397, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 10987 / 20000\n",
      "gradient norm: 0.04822349129244685, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 10988 / 20000\n",
      "gradient norm: 0.06971504405373707, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 10989 / 20000\n",
      "gradient norm: 0.06387923132569995, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 10990 / 20000\n",
      "gradient norm: 0.05936870384539361, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00553\n",
      "epoch 10991 / 20000\n",
      "gradient norm: 0.0567543966753874, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 10992 / 20000\n",
      "gradient norm: 0.049375325499568135, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 10993 / 20000\n",
      "gradient norm: 0.10939497384242713, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 10994 / 20000\n",
      "gradient norm: 0.038487065976369195, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 10995 / 20000\n",
      "gradient norm: 0.05368811689550057, minimum ratio: 2.436842105263158\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 10996 / 20000\n",
      "gradient norm: 0.08229471539380029, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 10997 / 20000\n",
      "gradient norm: 0.07076518484973349, minimum ratio: 2.452631578947368\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 10998 / 20000\n",
      "gradient norm: 0.016387523166486062, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 10999 / 20000\n",
      "gradient norm: 0.06640643934952095, minimum ratio: 2.4499999999999997\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 11000 / 20000\n",
      "gradient norm: 0.04341141087934375, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 11001 / 20000\n",
      "gradient norm: 0.049273572891252115, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 11002 / 20000\n",
      "gradient norm: 0.04293790858355351, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 11003 / 20000\n",
      "gradient norm: 0.11233731417451054, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 11004 / 20000\n",
      "gradient norm: 0.06542916019679978, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 11005 / 20000\n",
      "gradient norm: 0.12600786716211587, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 11006 / 20000\n",
      "gradient norm: 0.10272441327106208, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 11007 / 20000\n",
      "gradient norm: 0.0226617516236729, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 11008 / 20000\n",
      "gradient norm: 0.04850273800548166, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 11009 / 20000\n",
      "gradient norm: 0.09830728359520435, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 11010 / 20000\n",
      "gradient norm: 0.06217970800935291, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 11011 / 20000\n",
      "gradient norm: 0.020405007526278496, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 11012 / 20000\n",
      "gradient norm: 0.06799679083633237, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 11013 / 20000\n",
      "gradient norm: 0.08222344517707825, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 11014 / 20000\n",
      "gradient norm: 0.057081216684309766, minimum ratio: 2.460526315789474\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 11015 / 20000\n",
      "gradient norm: 0.04511977324727923, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 11016 / 20000\n",
      "gradient norm: 0.06396527506876737, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 11017 / 20000\n",
      "gradient norm: 0.05865862139035016, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 11018 / 20000\n",
      "gradient norm: 0.05042038965621032, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 11019 / 20000\n",
      "gradient norm: 0.02412204672873486, minimum ratio: 2.4736842105263155\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 11020 / 20000\n",
      "gradient norm: 0.049536150763742626, minimum ratio: 2.465789473684211\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 11021 / 20000\n",
      "gradient norm: 0.07444042677525431, minimum ratio: 2.4210526315789473\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 11022 / 20000\n",
      "gradient norm: 0.04958809819072485, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 11023 / 20000\n",
      "gradient norm: 0.07323663000715896, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 11024 / 20000\n",
      "gradient norm: 0.04364726614585379, minimum ratio: 2.4447368421052635\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 11025 / 20000\n",
      "gradient norm: 0.06525025848532096, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00551\n",
      "epoch 11026 / 20000\n",
      "gradient norm: 0.06404735025716946, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 11027 / 20000\n",
      "gradient norm: 0.06381844374118373, minimum ratio: 2.436842105263158\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 11028 / 20000\n",
      "gradient norm: 0.08071072242455557, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 11029 / 20000\n",
      "gradient norm: 0.04962739553593565, minimum ratio: 2.4447368421052635\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 11030 / 20000\n",
      "gradient norm: 0.07844463578658178, minimum ratio: 2.4421052631578943\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 11031 / 20000\n",
      "gradient norm: 0.06043573361239396, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 11032 / 20000\n",
      "gradient norm: 0.04972738737706095, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 11033 / 20000\n",
      "gradient norm: 0.08286924473941326, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 11034 / 20000\n",
      "gradient norm: 0.10904228180879727, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00551\n",
      "epoch 11035 / 20000\n",
      "gradient norm: 0.06363402091665193, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 11036 / 20000\n",
      "gradient norm: 0.12330102294799872, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 11037 / 20000\n",
      "gradient norm: 0.08667925768531859, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 11038 / 20000\n",
      "gradient norm: 0.06608577880251687, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 11039 / 20000\n",
      "gradient norm: 0.09488845820305869, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 11040 / 20000\n",
      "gradient norm: 0.09452915017027408, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00555\n",
      "epoch 11041 / 20000\n",
      "gradient norm: 0.1389207800384611, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00551\n",
      "epoch 11042 / 20000\n",
      "gradient norm: 0.060172587109263986, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 11043 / 20000\n",
      "gradient norm: 0.08492059202399105, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 11044 / 20000\n",
      "gradient norm: 0.046479716285830364, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 11045 / 20000\n",
      "gradient norm: 0.054321706789778545, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 11046 / 20000\n",
      "gradient norm: 0.09203652065480128, minimum ratio: 2.436842105263158\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 11047 / 20000\n",
      "gradient norm: 0.1185748337302357, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 11048 / 20000\n",
      "gradient norm: 0.0667510205094004, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00555\n",
      "epoch 11049 / 20000\n",
      "gradient norm: 0.05731178348651156, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 11050 / 20000\n",
      "gradient norm: 0.06794426479609683, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 11051 / 20000\n",
      "gradient norm: 0.06762971825082786, minimum ratio: 2.4578947368421056\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 11052 / 20000\n",
      "gradient norm: 0.1077120709232986, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 11053 / 20000\n",
      "gradient norm: 0.05382708681281656, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 11054 / 20000\n",
      "gradient norm: 0.07687703217379749, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 11055 / 20000\n",
      "gradient norm: 0.062387908110395074, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 11056 / 20000\n",
      "gradient norm: 0.07239174890855793, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 11057 / 20000\n",
      "gradient norm: 0.12014648734475486, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 11058 / 20000\n",
      "gradient norm: 0.035539218864869326, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 11059 / 20000\n",
      "gradient norm: 0.053479510272154585, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 11060 / 20000\n",
      "gradient norm: 0.04926563211483881, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 11061 / 20000\n",
      "gradient norm: 0.05247400511871092, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 11062 / 20000\n",
      "gradient norm: 0.08034733583917841, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 11063 / 20000\n",
      "gradient norm: 0.0926648136228323, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 11064 / 20000\n",
      "gradient norm: 0.02787827790598385, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 11065 / 20000\n",
      "gradient norm: 0.030700856470502913, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 11066 / 20000\n",
      "gradient norm: 0.04506549335201271, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 11067 / 20000\n",
      "gradient norm: 0.0827476933482103, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 11068 / 20000\n",
      "gradient norm: 0.05505985557101667, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 11069 / 20000\n",
      "gradient norm: 0.07706750615034252, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 11070 / 20000\n",
      "gradient norm: 0.07386124151526019, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 11071 / 20000\n",
      "gradient norm: 0.03260143739316845, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 11072 / 20000\n",
      "gradient norm: 0.08669174276292324, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 11073 / 20000\n",
      "gradient norm: 0.0694053421029821, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 11074 / 20000\n",
      "gradient norm: 0.056853204034268856, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 11075 / 20000\n",
      "gradient norm: 0.05498761890339665, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00553\n",
      "epoch 11076 / 20000\n",
      "gradient norm: 0.05842525284970179, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 11077 / 20000\n",
      "gradient norm: 0.08001306816004217, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 11078 / 20000\n",
      "gradient norm: 0.08203432022128254, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 11079 / 20000\n",
      "gradient norm: 0.035288993778522126, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 11080 / 20000\n",
      "gradient norm: 0.07799534406512976, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 11081 / 20000\n",
      "gradient norm: 0.1346131413592957, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 11082 / 20000\n",
      "gradient norm: 0.037862678203964606, minimum ratio: 2.4842105263157896\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 11083 / 20000\n",
      "gradient norm: 0.09881752176443115, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 11084 / 20000\n",
      "gradient norm: 0.09070474433247, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 11085 / 20000\n",
      "gradient norm: 0.08323901129188016, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 11086 / 20000\n",
      "gradient norm: 0.05813364278583322, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 11087 / 20000\n",
      "gradient norm: 0.08928035094868392, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 11088 / 20000\n",
      "gradient norm: 0.026533207143074833, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 11089 / 20000\n",
      "gradient norm: 0.06733946746680886, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 11090 / 20000\n",
      "gradient norm: 0.037987335614161566, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 11091 / 20000\n",
      "gradient norm: 0.04895635286811739, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 11092 / 20000\n",
      "gradient norm: 0.0662927299272269, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 11093 / 20000\n",
      "gradient norm: 0.0592156283382792, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 11094 / 20000\n",
      "gradient norm: 0.03892961774545256, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 11095 / 20000\n",
      "gradient norm: 0.07248466939199716, minimum ratio: 2.4394736842105265\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 11096 / 20000\n",
      "gradient norm: 0.03232073798426427, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 11097 / 20000\n",
      "gradient norm: 0.08485489443410188, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 11098 / 20000\n",
      "gradient norm: 0.07199662289349362, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 11099 / 20000\n",
      "gradient norm: 0.11183157621417195, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 11100 / 20000\n",
      "gradient norm: 0.07002427001134492, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 11101 / 20000\n",
      "gradient norm: 0.05092603602679446, minimum ratio: 2.4421052631578943\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 11102 / 20000\n",
      "gradient norm: 0.048803138197399676, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 11103 / 20000\n",
      "gradient norm: 0.07133565333788283, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 11104 / 20000\n",
      "gradient norm: 0.06903174407489132, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 11105 / 20000\n",
      "gradient norm: 0.0343116020958405, minimum ratio: 2.4447368421052635\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 11106 / 20000\n",
      "gradient norm: 0.055315276549663395, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 11107 / 20000\n",
      "gradient norm: 0.061987905617570505, minimum ratio: 2.436842105263158\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 11108 / 20000\n",
      "gradient norm: 0.06652898830361664, minimum ratio: 2.4289473684210523\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 11109 / 20000\n",
      "gradient norm: 0.04590098457993008, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 11110 / 20000\n",
      "gradient norm: 0.08297707117162645, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 11111 / 20000\n",
      "gradient norm: 0.04423107084585354, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 11112 / 20000\n",
      "gradient norm: 0.03424387049744837, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 11113 / 20000\n",
      "gradient norm: 0.07557114883093163, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 11114 / 20000\n",
      "gradient norm: 0.04918079877097625, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 11115 / 20000\n",
      "gradient norm: 0.079827094450593, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 11116 / 20000\n",
      "gradient norm: 0.11024869047105312, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00555\n",
      "epoch 11117 / 20000\n",
      "gradient norm: 0.08033539193274919, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 11118 / 20000\n",
      "gradient norm: 0.1206001514219679, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00551\n",
      "epoch 11119 / 20000\n",
      "gradient norm: 0.07929111766861752, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 11120 / 20000\n",
      "gradient norm: 0.06996382809302304, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 11121 / 20000\n",
      "gradient norm: 0.08482064178679138, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 11122 / 20000\n",
      "gradient norm: 0.057626537047326565, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 11123 / 20000\n",
      "gradient norm: 0.047820904495893046, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 11124 / 20000\n",
      "gradient norm: 0.06724219070747495, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 11125 / 20000\n",
      "gradient norm: 0.06736340944189578, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 11126 / 20000\n",
      "gradient norm: 0.11030846065841615, minimum ratio: 2.460526315789474\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 11127 / 20000\n",
      "gradient norm: 0.033822278695879504, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 11128 / 20000\n",
      "gradient norm: 0.07723116199485958, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 11129 / 20000\n",
      "gradient norm: 0.04415603447705507, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 11130 / 20000\n",
      "gradient norm: 0.08026332833105698, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 11131 / 20000\n",
      "gradient norm: 0.028280386264668778, minimum ratio: 2.4421052631578943\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 11132 / 20000\n",
      "gradient norm: 0.06905505759641528, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00551\n",
      "epoch 11133 / 20000\n",
      "gradient norm: 0.07815807216684334, minimum ratio: 2.4236842105263157\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 11134 / 20000\n",
      "gradient norm: 0.0534600192331709, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 11135 / 20000\n",
      "gradient norm: 0.0750013769720681, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 11136 / 20000\n",
      "gradient norm: 0.15043411613442004, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 11137 / 20000\n",
      "gradient norm: 0.06511818556464277, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00555\n",
      "epoch 11138 / 20000\n",
      "gradient norm: 0.07229953023488633, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 11139 / 20000\n",
      "gradient norm: 0.06813974631950259, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 11140 / 20000\n",
      "gradient norm: 0.08855622378177941, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 11141 / 20000\n",
      "gradient norm: 0.05691849719733, minimum ratio: 2.4842105263157896\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 11142 / 20000\n",
      "gradient norm: 0.04691660089883953, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 11143 / 20000\n",
      "gradient norm: 0.07460787176387385, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 11144 / 20000\n",
      "gradient norm: 0.05085013201460242, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 11145 / 20000\n",
      "gradient norm: 0.06745814948226325, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 11146 / 20000\n",
      "gradient norm: 0.03140976681606844, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 11147 / 20000\n",
      "gradient norm: 0.04816098260926083, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00551\n",
      "epoch 11148 / 20000\n",
      "gradient norm: 0.037700899672927335, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 11149 / 20000\n",
      "gradient norm: 0.06018872559070587, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 11150 / 20000\n",
      "gradient norm: 0.05904711299808696, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 11151 / 20000\n",
      "gradient norm: 0.10046095424331725, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00551\n",
      "epoch 11152 / 20000\n",
      "gradient norm: 0.10264843422919512, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 11153 / 20000\n",
      "gradient norm: 0.06717871990986168, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 11154 / 20000\n",
      "gradient norm: 0.08546348655363545, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 11155 / 20000\n",
      "gradient norm: 0.0642778734327294, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 11156 / 20000\n",
      "gradient norm: 0.07834015466505662, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 11157 / 20000\n",
      "gradient norm: 0.1165425778599456, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 11158 / 20000\n",
      "gradient norm: 0.05668711167527363, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 11159 / 20000\n",
      "gradient norm: 0.06785747612593696, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 11160 / 20000\n",
      "gradient norm: 0.05562999245012179, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 11161 / 20000\n",
      "gradient norm: 0.054414679878391325, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 11162 / 20000\n",
      "gradient norm: 0.07464333309326321, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 11163 / 20000\n",
      "gradient norm: 0.020888681094220374, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 11164 / 20000\n",
      "gradient norm: 0.05505760165397078, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 11165 / 20000\n",
      "gradient norm: 0.0578178430441767, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 11166 / 20000\n",
      "gradient norm: 0.07002270565135404, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 11167 / 20000\n",
      "gradient norm: 0.04793541581602767, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00551\n",
      "epoch 11168 / 20000\n",
      "gradient norm: 0.04137363362679025, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 11169 / 20000\n",
      "gradient norm: 0.037466380032128654, minimum ratio: 2.4421052631578943\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 11170 / 20000\n",
      "gradient norm: 0.09068490227218717, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 11171 / 20000\n",
      "gradient norm: 0.0400891003664583, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 11172 / 20000\n",
      "gradient norm: 0.036833182792179286, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 11173 / 20000\n",
      "gradient norm: 0.03696577434311621, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 11174 / 20000\n",
      "gradient norm: 0.0577849464607425, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 11175 / 20000\n",
      "gradient norm: 0.08057274401653558, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 11176 / 20000\n",
      "gradient norm: 0.10400393651798368, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 11177 / 20000\n",
      "gradient norm: 0.05527114098367747, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 11178 / 20000\n",
      "gradient norm: 0.0475950778927654, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 11179 / 20000\n",
      "gradient norm: 0.06737826543394476, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 11180 / 20000\n",
      "gradient norm: 0.039367822944768704, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 11181 / 20000\n",
      "gradient norm: 0.03873471560655162, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 11182 / 20000\n",
      "gradient norm: 0.08085357581148855, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 11183 / 20000\n",
      "gradient norm: 0.025989557510911254, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 11184 / 20000\n",
      "gradient norm: 0.05018302872485947, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 11185 / 20000\n",
      "gradient norm: 0.07390875104465522, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 11186 / 20000\n",
      "gradient norm: 0.051880224054912105, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 11187 / 20000\n",
      "gradient norm: 0.044974165393796284, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 11188 / 20000\n",
      "gradient norm: 0.05414769580238499, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 11189 / 20000\n",
      "gradient norm: 0.06066726957214996, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 11190 / 20000\n",
      "gradient norm: 0.0515127796534216, minimum ratio: 2.4394736842105265\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 11191 / 20000\n",
      "gradient norm: 0.0820318593760021, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 11192 / 20000\n",
      "gradient norm: 0.08778018911834806, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 11193 / 20000\n",
      "gradient norm: 0.09402200346812606, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 11194 / 20000\n",
      "gradient norm: 0.0701496111578308, minimum ratio: 2.46578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 11195 / 20000\n",
      "gradient norm: 0.044004022754961625, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 11196 / 20000\n",
      "gradient norm: 0.04237216721230652, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 11197 / 20000\n",
      "gradient norm: 0.04306208618800156, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 11198 / 20000\n",
      "gradient norm: 0.06123839697102085, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 11199 / 20000\n",
      "gradient norm: 0.03563196703908034, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 11200 / 20000\n",
      "gradient norm: 0.07086124044144526, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 11201 / 20000\n",
      "gradient norm: 0.08993346081115305, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 11202 / 20000\n",
      "gradient norm: 0.09961753658717498, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 11203 / 20000\n",
      "gradient norm: 0.09614951342518907, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 11204 / 20000\n",
      "gradient norm: 0.04600580681290012, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 11205 / 20000\n",
      "gradient norm: 0.0595723464502953, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 11206 / 20000\n",
      "gradient norm: 0.03789489895279985, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 11207 / 20000\n",
      "gradient norm: 0.04771122784586623, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 11208 / 20000\n",
      "gradient norm: 0.0925518884905614, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00551\n",
      "epoch 11209 / 20000\n",
      "gradient norm: 0.073046890553087, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 11210 / 20000\n",
      "gradient norm: 0.08573004096979275, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 11211 / 20000\n",
      "gradient norm: 0.06866200361400843, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00551\n",
      "epoch 11212 / 20000\n",
      "gradient norm: 0.06072618783218786, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 11213 / 20000\n",
      "gradient norm: 0.0462019108235836, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00553\n",
      "epoch 11214 / 20000\n",
      "gradient norm: 0.10385113267693669, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 11215 / 20000\n",
      "gradient norm: 0.07165746568352915, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00551\n",
      "epoch 11216 / 20000\n",
      "gradient norm: 0.069001056952402, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 11217 / 20000\n",
      "gradient norm: 0.11445136513793841, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 11218 / 20000\n",
      "gradient norm: 0.09051313996315002, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 11219 / 20000\n",
      "gradient norm: 0.0706501254462637, minimum ratio: 2.4736842105263155\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 11220 / 20000\n",
      "gradient norm: 0.057211746694520116, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 11221 / 20000\n",
      "gradient norm: 0.05328200233634561, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 11222 / 20000\n",
      "gradient norm: 0.02735308522824198, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 11223 / 20000\n",
      "gradient norm: 0.12916287104599178, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 11224 / 20000\n",
      "gradient norm: 0.041294754249975085, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 11225 / 20000\n",
      "gradient norm: 0.05299509782344103, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 11226 / 20000\n",
      "gradient norm: 0.07808255375130102, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 11227 / 20000\n",
      "gradient norm: 0.1069791042318684, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 11228 / 20000\n",
      "gradient norm: 0.07254341334919445, minimum ratio: 2.4842105263157896\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 11229 / 20000\n",
      "gradient norm: 0.05441962355689611, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 11230 / 20000\n",
      "gradient norm: 0.11663701559882611, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 11231 / 20000\n",
      "gradient norm: 0.03639917718828656, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 11232 / 20000\n",
      "gradient norm: 0.08794196182861924, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 11233 / 20000\n",
      "gradient norm: 0.062296636460814625, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 11234 / 20000\n",
      "gradient norm: 0.027789785235654563, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 11235 / 20000\n",
      "gradient norm: 0.06019468110753223, minimum ratio: 2.4499999999999997\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 11236 / 20000\n",
      "gradient norm: 0.06340216309763491, minimum ratio: 2.4842105263157896\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 11237 / 20000\n",
      "gradient norm: 0.10604171641170979, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 11238 / 20000\n",
      "gradient norm: 0.07540485792560503, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 11239 / 20000\n",
      "gradient norm: 0.02953444236482028, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 11240 / 20000\n",
      "gradient norm: 0.09293454105500132, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00553\n",
      "epoch 11241 / 20000\n",
      "gradient norm: 0.0875338758341968, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 11242 / 20000\n",
      "gradient norm: 0.08126682363217697, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 11243 / 20000\n",
      "gradient norm: 0.03811233415035531, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 11244 / 20000\n",
      "gradient norm: 0.023739217227557674, minimum ratio: 2.4499999999999997\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 11245 / 20000\n",
      "gradient norm: 0.09608257905347273, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00551\n",
      "epoch 11246 / 20000\n",
      "gradient norm: 0.108488943107659, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00555\n",
      "epoch 11247 / 20000\n",
      "gradient norm: 0.056739651336101815, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 11248 / 20000\n",
      "gradient norm: 0.07902948139235377, minimum ratio: 2.4868421052631584\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 11249 / 20000\n",
      "gradient norm: 0.08991231524851173, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 11250 / 20000\n",
      "gradient norm: 0.049554832570720464, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 11251 / 20000\n",
      "gradient norm: 0.0418288174259942, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00551\n",
      "epoch 11252 / 20000\n",
      "gradient norm: 0.04748215580184478, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 11253 / 20000\n",
      "gradient norm: 0.14584798133000731, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 11254 / 20000\n",
      "gradient norm: 0.0683851619833149, minimum ratio: 2.4394736842105265\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 11255 / 20000\n",
      "gradient norm: 0.07705688767600805, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 11256 / 20000\n",
      "gradient norm: 0.07734945806441829, minimum ratio: 2.460526315789474\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 11257 / 20000\n",
      "gradient norm: 0.051324578089406714, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 11258 / 20000\n",
      "gradient norm: 0.06053228591918014, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 11259 / 20000\n",
      "gradient norm: 0.06024275565869175, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 11260 / 20000\n",
      "gradient norm: 0.029503339988877997, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 11261 / 20000\n",
      "gradient norm: 0.05592515524040209, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 11262 / 20000\n",
      "gradient norm: 0.07910837954841554, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 11263 / 20000\n",
      "gradient norm: 0.028530356954433955, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 11264 / 20000\n",
      "gradient norm: 0.042465853854082525, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 11265 / 20000\n",
      "gradient norm: 0.07245803566183895, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 11266 / 20000\n",
      "gradient norm: 0.06939269811846316, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 11267 / 20000\n",
      "gradient norm: 0.03369892323826207, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 11268 / 20000\n",
      "gradient norm: 0.07248463190626353, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 11269 / 20000\n",
      "gradient norm: 0.06788993714144453, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 11270 / 20000\n",
      "gradient norm: 0.11475422827061266, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 11271 / 20000\n",
      "gradient norm: 0.0517768130011973, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 11272 / 20000\n",
      "gradient norm: 0.05431612872052938, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 11273 / 20000\n",
      "gradient norm: 0.09624987212009728, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 11274 / 20000\n",
      "gradient norm: 0.0750962647725828, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 11275 / 20000\n",
      "gradient norm: 0.05559469695435837, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 11276 / 20000\n",
      "gradient norm: 0.07761390379164368, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 11277 / 20000\n",
      "gradient norm: 0.09285022306721658, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 11278 / 20000\n",
      "gradient norm: 0.03739693379611708, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 11279 / 20000\n",
      "gradient norm: 0.13750503567280248, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 11280 / 20000\n",
      "gradient norm: 0.056300218508113176, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 11281 / 20000\n",
      "gradient norm: 0.07176720461575314, minimum ratio: 2.460526315789474\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 11282 / 20000\n",
      "gradient norm: 0.11066913569811732, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 11283 / 20000\n",
      "gradient norm: 0.10380111672566272, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 11284 / 20000\n",
      "gradient norm: 0.07384285720763728, minimum ratio: 2.460526315789474\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 11285 / 20000\n",
      "gradient norm: 0.08759330003522336, minimum ratio: 2.4394736842105265\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 11286 / 20000\n",
      "gradient norm: 0.09492708113975823, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 11287 / 20000\n",
      "gradient norm: 0.06448998031555675, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 11288 / 20000\n",
      "gradient norm: 0.0598064262594562, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 11289 / 20000\n",
      "gradient norm: 0.029883590759709477, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 11290 / 20000\n",
      "gradient norm: 0.07911129764397629, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 11291 / 20000\n",
      "gradient norm: 0.03515203972347081, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 11292 / 20000\n",
      "gradient norm: 0.032254168938379735, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 11293 / 20000\n",
      "gradient norm: 0.05375775313586928, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00553\n",
      "epoch 11294 / 20000\n",
      "gradient norm: 0.03274908346065786, minimum ratio: 2.465789473684211\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 11295 / 20000\n",
      "gradient norm: 0.11268078786088154, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 11296 / 20000\n",
      "gradient norm: 0.09437861084006727, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 11297 / 20000\n",
      "gradient norm: 0.09550852884422056, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 11298 / 20000\n",
      "gradient norm: 0.04944642377085984, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 11299 / 20000\n",
      "gradient norm: 0.07494806905742735, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 11300 / 20000\n",
      "gradient norm: 0.04955766416969709, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 11301 / 20000\n",
      "gradient norm: 0.056804615247529, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 11302 / 20000\n",
      "gradient norm: 0.04729656194103882, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 11303 / 20000\n",
      "gradient norm: 0.04848712671082467, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 11304 / 20000\n",
      "gradient norm: 0.05042311450233683, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 11305 / 20000\n",
      "gradient norm: 0.04616618328145705, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 11306 / 20000\n",
      "gradient norm: 0.035172365456674015, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 11307 / 20000\n",
      "gradient norm: 0.06100883340695873, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 11308 / 20000\n",
      "gradient norm: 0.05214114837144734, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 11309 / 20000\n",
      "gradient norm: 0.10853616561507806, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 11310 / 20000\n",
      "gradient norm: 0.024545808060793206, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 11311 / 20000\n",
      "gradient norm: 0.0746529178286437, minimum ratio: 2.460526315789474\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 11312 / 20000\n",
      "gradient norm: 0.07428197910485324, minimum ratio: 2.4447368421052627\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 11313 / 20000\n",
      "gradient norm: 0.06927155278390273, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 11314 / 20000\n",
      "gradient norm: 0.0852619684592355, minimum ratio: 2.4684210526315784\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 11315 / 20000\n",
      "gradient norm: 0.056968424760270864, minimum ratio: 2.4842105263157896\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 11316 / 20000\n",
      "gradient norm: 0.0677577558089979, minimum ratio: 2.4868421052631575\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 11317 / 20000\n",
      "gradient norm: 0.06483043171465397, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 11318 / 20000\n",
      "gradient norm: 0.09641893190564588, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00555\n",
      "epoch 11319 / 20000\n",
      "gradient norm: 0.08723554396419786, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 11320 / 20000\n",
      "gradient norm: 0.042627388960681856, minimum ratio: 2.426315789473684\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 11321 / 20000\n",
      "gradient norm: 0.1056577272247523, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 11322 / 20000\n",
      "gradient norm: 0.07716617212281562, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 11323 / 20000\n",
      "gradient norm: 0.029874187777750194, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 11324 / 20000\n",
      "gradient norm: 0.06720099033555016, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 11325 / 20000\n",
      "gradient norm: 0.07372240338008851, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 11326 / 20000\n",
      "gradient norm: 0.04919901554239914, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 11327 / 20000\n",
      "gradient norm: 0.03297357654082589, minimum ratio: 2.460526315789474\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 11328 / 20000\n",
      "gradient norm: 0.025087123940465972, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 11329 / 20000\n",
      "gradient norm: 0.03494272104580887, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 11330 / 20000\n",
      "gradient norm: 0.07823819768964313, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 11331 / 20000\n",
      "gradient norm: 0.05956381669966504, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 11332 / 20000\n",
      "gradient norm: 0.049816143335192464, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 11333 / 20000\n",
      "gradient norm: 0.0364770810410846, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 11334 / 20000\n",
      "gradient norm: 0.033907421107869595, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 11335 / 20000\n",
      "gradient norm: 0.040704269107664004, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 11336 / 20000\n",
      "gradient norm: 0.028939211566466838, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 11337 / 20000\n",
      "gradient norm: 0.0749739990424132, minimum ratio: 2.4447368421052635\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 11338 / 20000\n",
      "gradient norm: 0.10415923089021817, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 11339 / 20000\n",
      "gradient norm: 0.0398914090328617, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 11340 / 20000\n",
      "gradient norm: 0.07775309901626315, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 11341 / 20000\n",
      "gradient norm: 0.026835398664843524, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 11342 / 20000\n",
      "gradient norm: 0.06782682254561223, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00553\n",
      "epoch 11343 / 20000\n",
      "gradient norm: 0.05750695872120559, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 11344 / 20000\n",
      "gradient norm: 0.0477150721126236, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 11345 / 20000\n",
      "gradient norm: 0.03178148262668401, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 11346 / 20000\n",
      "gradient norm: 0.05962361901765689, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 11347 / 20000\n",
      "gradient norm: 0.11165176157373935, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00551\n",
      "epoch 11348 / 20000\n",
      "gradient norm: 0.050218580407090485, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 11349 / 20000\n",
      "gradient norm: 0.08811456407420337, minimum ratio: 2.4578947368421056\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00554\n",
      "epoch 11350 / 20000\n",
      "gradient norm: 0.08302564575569704, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 11351 / 20000\n",
      "gradient norm: 0.11808992235455662, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00551\n",
      "epoch 11352 / 20000\n",
      "gradient norm: 0.0682679150486365, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 11353 / 20000\n",
      "gradient norm: 0.06650200294097885, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 11354 / 20000\n",
      "gradient norm: 0.042547664139419794, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 11355 / 20000\n",
      "gradient norm: 0.08711328217032133, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 11356 / 20000\n",
      "gradient norm: 0.06066819332772866, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 11357 / 20000\n",
      "gradient norm: 0.05568787275115028, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 11358 / 20000\n",
      "gradient norm: 0.13572160818148404, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00551\n",
      "epoch 11359 / 20000\n",
      "gradient norm: 0.1261062320554629, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 11360 / 20000\n",
      "gradient norm: 0.05439253512304276, minimum ratio: 2.46578947368421\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 11361 / 20000\n",
      "gradient norm: 0.048040060995845124, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 11362 / 20000\n",
      "gradient norm: 0.03252419256023131, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 11363 / 20000\n",
      "gradient norm: 0.04516334383515641, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 11364 / 20000\n",
      "gradient norm: 0.060029824351659045, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 11365 / 20000\n",
      "gradient norm: 0.08331950512365438, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 11366 / 20000\n",
      "gradient norm: 0.028322075406322256, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 11367 / 20000\n",
      "gradient norm: 0.090936298831366, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 11368 / 20000\n",
      "gradient norm: 0.03151137600070797, minimum ratio: 2.4447368421052635\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 11369 / 20000\n",
      "gradient norm: 0.030451007347437553, minimum ratio: 2.4421052631578943\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 11370 / 20000\n",
      "gradient norm: 0.05452488755690865, minimum ratio: 2.4578947368421056\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 11371 / 20000\n",
      "gradient norm: 0.046498221810907125, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 11372 / 20000\n",
      "gradient norm: 0.07539247319800779, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 11373 / 20000\n",
      "gradient norm: 0.04267880620318465, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 11374 / 20000\n",
      "gradient norm: 0.0829077762318775, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 11375 / 20000\n",
      "gradient norm: 0.06683339775190689, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 11376 / 20000\n",
      "gradient norm: 0.018892116466304287, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 11377 / 20000\n",
      "gradient norm: 0.08492144700721838, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 11378 / 20000\n",
      "gradient norm: 0.05264976079342887, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 11379 / 20000\n",
      "gradient norm: 0.0431484114669729, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 11380 / 20000\n",
      "gradient norm: 0.05131927222828381, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 11381 / 20000\n",
      "gradient norm: 0.03819314428255893, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 11382 / 20000\n",
      "gradient norm: 0.08155694743618369, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 11383 / 20000\n",
      "gradient norm: 0.05631366663146764, minimum ratio: 2.4421052631578943\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 11384 / 20000\n",
      "gradient norm: 0.051744870317634195, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 11385 / 20000\n",
      "gradient norm: 0.07549204264068976, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 11386 / 20000\n",
      "gradient norm: 0.046483290745527484, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 11387 / 20000\n",
      "gradient norm: 0.05294829292688519, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 11388 / 20000\n",
      "gradient norm: 0.09511356899747625, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 11389 / 20000\n",
      "gradient norm: 0.03868647781200707, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 11390 / 20000\n",
      "gradient norm: 0.1141525162383914, minimum ratio: 2.4263157894736844\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00551\n",
      "epoch 11391 / 20000\n",
      "gradient norm: 0.05883892529527657, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 11392 / 20000\n",
      "gradient norm: 0.05635207252635155, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 11393 / 20000\n",
      "gradient norm: 0.03368626581504941, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 11394 / 20000\n",
      "gradient norm: 0.056399807072011754, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 11395 / 20000\n",
      "gradient norm: 0.07047244708519429, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 11396 / 20000\n",
      "gradient norm: 0.04759692463267129, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 11397 / 20000\n",
      "gradient norm: 0.03493067646923009, minimum ratio: 2.4421052631578943\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 11398 / 20000\n",
      "gradient norm: 0.08014069391356315, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 11399 / 20000\n",
      "gradient norm: 0.10431551325018518, minimum ratio: 2.4210526315789473\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 11400 / 20000\n",
      "gradient norm: 0.052517106727464125, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 11401 / 20000\n",
      "gradient norm: 0.05397601641016081, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 11402 / 20000\n",
      "gradient norm: 0.07281360193155706, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 11403 / 20000\n",
      "gradient norm: 0.11629291874123737, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00552\n",
      "epoch 11404 / 20000\n",
      "gradient norm: 0.08146175352158025, minimum ratio: 2.4499999999999997\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00555\n",
      "epoch 11405 / 20000\n",
      "gradient norm: 0.07612999982666224, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 11406 / 20000\n",
      "gradient norm: 0.05803136064787395, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00551\n",
      "epoch 11407 / 20000\n",
      "gradient norm: 0.06931236607488245, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 11408 / 20000\n",
      "gradient norm: 0.0658144960179925, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 11409 / 20000\n",
      "gradient norm: 0.09469534340314567, minimum ratio: 2.4394736842105265\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 11410 / 20000\n",
      "gradient norm: 0.03131302000474534, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 11411 / 20000\n",
      "gradient norm: 0.061332065146416426, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 11412 / 20000\n",
      "gradient norm: 0.06966931442730129, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00565\n",
      "\tval loss: 0.00551\n",
      "epoch 11413 / 20000\n",
      "gradient norm: 0.07445389367057942, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 11414 / 20000\n",
      "gradient norm: 0.09069069381803274, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 11415 / 20000\n",
      "gradient norm: 0.10179956955835223, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 11416 / 20000\n",
      "gradient norm: 0.05324399709934369, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 11417 / 20000\n",
      "gradient norm: 0.111287722713314, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 11418 / 20000\n",
      "gradient norm: 0.061407998320646584, minimum ratio: 2.436842105263158\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 11419 / 20000\n",
      "gradient norm: 0.0399829914822476, minimum ratio: 2.4289473684210523\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 11420 / 20000\n",
      "gradient norm: 0.02865785820176825, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00553\n",
      "epoch 11421 / 20000\n",
      "gradient norm: 0.10946387553121895, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 11422 / 20000\n",
      "gradient norm: 0.07441414461936802, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 11423 / 20000\n",
      "gradient norm: 0.08234869397711009, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 11424 / 20000\n",
      "gradient norm: 0.06803335866425186, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00554\n",
      "epoch 11425 / 20000\n",
      "gradient norm: 0.04990029435430188, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 11426 / 20000\n",
      "gradient norm: 0.07155078189680353, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 11427 / 20000\n",
      "gradient norm: 0.045829246439097915, minimum ratio: 2.4499999999999997\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 11428 / 20000\n",
      "gradient norm: 0.04810386340250261, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 11429 / 20000\n",
      "gradient norm: 0.04727515912964009, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 11430 / 20000\n",
      "gradient norm: 0.07468866475392133, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 11431 / 20000\n",
      "gradient norm: 0.09600544651038945, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 11432 / 20000\n",
      "gradient norm: 0.03452318377094343, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 11433 / 20000\n",
      "gradient norm: 0.07849784128484316, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 11434 / 20000\n",
      "gradient norm: 0.09071062103612348, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 11435 / 20000\n",
      "gradient norm: 0.07229799116612412, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 11436 / 20000\n",
      "gradient norm: 0.06620325619587675, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 11437 / 20000\n",
      "gradient norm: 0.06279656969127245, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 11438 / 20000\n",
      "gradient norm: 0.07140051980968565, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 11439 / 20000\n",
      "gradient norm: 0.05235017904669803, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 11440 / 20000\n",
      "gradient norm: 0.0502637037425302, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 11441 / 20000\n",
      "gradient norm: 0.06608200253685936, minimum ratio: 2.465789473684211\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 11442 / 20000\n",
      "gradient norm: 0.0403165238967631, minimum ratio: 2.452631578947368\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 11443 / 20000\n",
      "gradient norm: 0.06926025269785896, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 11444 / 20000\n",
      "gradient norm: 0.058786365523701534, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 11445 / 20000\n",
      "gradient norm: 0.06902724941028282, minimum ratio: 2.4394736842105265\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 11446 / 20000\n",
      "gradient norm: 0.07888104853918776, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 11447 / 20000\n",
      "gradient norm: 0.043611937668174505, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 11448 / 20000\n",
      "gradient norm: 0.06400925136404112, minimum ratio: 2.4447368421052635\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 11449 / 20000\n",
      "gradient norm: 0.07359581429045647, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 11450 / 20000\n",
      "gradient norm: 0.08049357769777998, minimum ratio: 2.4684210526315784\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00554\n",
      "epoch 11451 / 20000\n",
      "gradient norm: 0.058947702578734607, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 11452 / 20000\n",
      "gradient norm: 0.07244662055745721, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 11453 / 20000\n",
      "gradient norm: 0.06850084575125948, minimum ratio: 2.4499999999999997\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00553\n",
      "epoch 11454 / 20000\n",
      "gradient norm: 0.05915114426170476, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 11455 / 20000\n",
      "gradient norm: 0.06956311946851201, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 11456 / 20000\n",
      "gradient norm: 0.07034538115840405, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 11457 / 20000\n",
      "gradient norm: 0.08683274261420593, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00555\n",
      "epoch 11458 / 20000\n",
      "gradient norm: 0.03832603764021769, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 11459 / 20000\n",
      "gradient norm: 0.10182108148001134, minimum ratio: 2.460526315789474\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 11460 / 20000\n",
      "gradient norm: 0.13692117179743946, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00555\n",
      "epoch 11461 / 20000\n",
      "gradient norm: 0.051128418010193855, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 11462 / 20000\n",
      "gradient norm: 0.05074979516211897, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 11463 / 20000\n",
      "gradient norm: 0.04929858649848029, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 11464 / 20000\n",
      "gradient norm: 0.06426945177372545, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 11465 / 20000\n",
      "gradient norm: 0.07204605313017964, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 11466 / 20000\n",
      "gradient norm: 0.042115161078982055, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 11467 / 20000\n",
      "gradient norm: 0.0677456064731814, minimum ratio: 2.465789473684211\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 11468 / 20000\n",
      "gradient norm: 0.045221777574624866, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 11469 / 20000\n",
      "gradient norm: 0.03362993861082941, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 11470 / 20000\n",
      "gradient norm: 0.08795252133859321, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 11471 / 20000\n",
      "gradient norm: 0.11286368779838085, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 11472 / 20000\n",
      "gradient norm: 0.055119161756010726, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 11473 / 20000\n",
      "gradient norm: 0.0777047710143961, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 11474 / 20000\n",
      "gradient norm: 0.09468339703744277, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 11475 / 20000\n",
      "gradient norm: 0.04033366018848028, minimum ratio: 2.46578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 11476 / 20000\n",
      "gradient norm: 0.07157423516036943, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 11477 / 20000\n",
      "gradient norm: 0.08923411648720503, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 11478 / 20000\n",
      "gradient norm: 0.061225446639582515, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00551\n",
      "epoch 11479 / 20000\n",
      "gradient norm: 0.07079032203182578, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 11480 / 20000\n",
      "gradient norm: 0.11900554900057614, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 11481 / 20000\n",
      "gradient norm: 0.029478174197720364, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 11482 / 20000\n",
      "gradient norm: 0.08956803585169837, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 11483 / 20000\n",
      "gradient norm: 0.03820756825734861, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 11484 / 20000\n",
      "gradient norm: 0.086785473220516, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 11485 / 20000\n",
      "gradient norm: 0.06739928567549214, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 11486 / 20000\n",
      "gradient norm: 0.08355470432434231, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 11487 / 20000\n",
      "gradient norm: 0.10706983858835883, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 11488 / 20000\n",
      "gradient norm: 0.06340922965318896, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 11489 / 20000\n",
      "gradient norm: 0.06217202381230891, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 11490 / 20000\n",
      "gradient norm: 0.043153248727321625, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 11491 / 20000\n",
      "gradient norm: 0.07571103128429968, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 11492 / 20000\n",
      "gradient norm: 0.04593370857764967, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 11493 / 20000\n",
      "gradient norm: 0.07510778587311506, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 11494 / 20000\n",
      "gradient norm: 0.05350113054737449, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 11495 / 20000\n",
      "gradient norm: 0.06249514047522098, minimum ratio: 2.46578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 11496 / 20000\n",
      "gradient norm: 0.04598548013018444, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 11497 / 20000\n",
      "gradient norm: 0.026412811363115907, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 11498 / 20000\n",
      "gradient norm: 0.09034509351477027, minimum ratio: 2.4447368421052635\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 11499 / 20000\n",
      "gradient norm: 0.10073424782603979, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 11500 / 20000\n",
      "gradient norm: 0.08500646171160042, minimum ratio: 2.460526315789474\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00551\n",
      "epoch 11501 / 20000\n",
      "gradient norm: 0.11210047540953383, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 11502 / 20000\n",
      "gradient norm: 0.050345946656307206, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 11503 / 20000\n",
      "gradient norm: 0.036924637912306935, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 11504 / 20000\n",
      "gradient norm: 0.06663359148660675, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 11505 / 20000\n",
      "gradient norm: 0.09842940070666373, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 11506 / 20000\n",
      "gradient norm: 0.07922858279198408, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 11507 / 20000\n",
      "gradient norm: 0.08346402319148183, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00551\n",
      "epoch 11508 / 20000\n",
      "gradient norm: 0.07366137608187273, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 11509 / 20000\n",
      "gradient norm: 0.03233682086283807, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 11510 / 20000\n",
      "gradient norm: 0.048516276525333524, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 11511 / 20000\n",
      "gradient norm: 0.05817538156406954, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 11512 / 20000\n",
      "gradient norm: 0.08610043267253786, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 11513 / 20000\n",
      "gradient norm: 0.07692965543537866, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 11514 / 20000\n",
      "gradient norm: 0.1014412899967283, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 11515 / 20000\n",
      "gradient norm: 0.02562782310997136, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 11516 / 20000\n",
      "gradient norm: 0.07316977099981159, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 11517 / 20000\n",
      "gradient norm: 0.07371314300689846, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 11518 / 20000\n",
      "gradient norm: 0.04408509127097204, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 11519 / 20000\n",
      "gradient norm: 0.028783080182620324, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 11520 / 20000\n",
      "gradient norm: 0.036027060908963904, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 11521 / 20000\n",
      "gradient norm: 0.034243918300489895, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 11522 / 20000\n",
      "gradient norm: 0.0949782780953683, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 11523 / 20000\n",
      "gradient norm: 0.06958505653892644, minimum ratio: 2.4842105263157896\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 11524 / 20000\n",
      "gradient norm: 0.08761019294615835, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 11525 / 20000\n",
      "gradient norm: 0.061269483470823616, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 11526 / 20000\n",
      "gradient norm: 0.05470187932951376, minimum ratio: 2.4421052631578952\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 11527 / 20000\n",
      "gradient norm: 0.04272879727068357, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 11528 / 20000\n",
      "gradient norm: 0.0834961220389232, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 11529 / 20000\n",
      "gradient norm: 0.06155460843001492, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 11530 / 20000\n",
      "gradient norm: 0.07930076296906918, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 11531 / 20000\n",
      "gradient norm: 0.05399982599192299, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00554\n",
      "epoch 11532 / 20000\n",
      "gradient norm: 0.06088280479889363, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 11533 / 20000\n",
      "gradient norm: 0.041028288658708334, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 11534 / 20000\n",
      "gradient norm: 0.056197756523033604, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 11535 / 20000\n",
      "gradient norm: 0.061997205863008276, minimum ratio: 2.4394736842105265\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00552\n",
      "epoch 11536 / 20000\n",
      "gradient norm: 0.03582861251197755, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 11537 / 20000\n",
      "gradient norm: 0.04685424151830375, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 11538 / 20000\n",
      "gradient norm: 0.05335149908205494, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 11539 / 20000\n",
      "gradient norm: 0.04310421607806347, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 11540 / 20000\n",
      "gradient norm: 0.061230219376739115, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 11541 / 20000\n",
      "gradient norm: 0.03239101669169031, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 11542 / 20000\n",
      "gradient norm: 0.0811833612533519, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 11543 / 20000\n",
      "gradient norm: 0.05631960110622458, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 11544 / 20000\n",
      "gradient norm: 0.06487192230997607, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 11545 / 20000\n",
      "gradient norm: 0.09127929774695076, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 11546 / 20000\n",
      "gradient norm: 0.1040410902351141, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 11547 / 20000\n",
      "gradient norm: 0.06658798953867517, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00554\n",
      "epoch 11548 / 20000\n",
      "gradient norm: 0.048610872647259384, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 11549 / 20000\n",
      "gradient norm: 0.10479183972347528, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00551\n",
      "epoch 11550 / 20000\n",
      "gradient norm: 0.06133912812219933, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 11551 / 20000\n",
      "gradient norm: 0.12814746296498924, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 11552 / 20000\n",
      "gradient norm: 0.04026103738578968, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 11553 / 20000\n",
      "gradient norm: 0.03762176363670733, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 11554 / 20000\n",
      "gradient norm: 0.09783570651779883, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 11555 / 20000\n",
      "gradient norm: 0.046142896404489875, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 11556 / 20000\n",
      "gradient norm: 0.0576312827761285, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 11557 / 20000\n",
      "gradient norm: 0.08970074480748735, minimum ratio: 2.4842105263157896\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 11558 / 20000\n",
      "gradient norm: 0.05282700463430956, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 11559 / 20000\n",
      "gradient norm: 0.08201253484003246, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 11560 / 20000\n",
      "gradient norm: 0.05645055667264387, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 11561 / 20000\n",
      "gradient norm: 0.07343550681252964, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 11562 / 20000\n",
      "gradient norm: 0.0824206632678397, minimum ratio: 2.4842105263157896\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 11563 / 20000\n",
      "gradient norm: 0.02433139056665823, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 11564 / 20000\n",
      "gradient norm: 0.03539012680994347, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 11565 / 20000\n",
      "gradient norm: 0.09094927853584522, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 11566 / 20000\n",
      "gradient norm: 0.07589395687682554, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 11567 / 20000\n",
      "gradient norm: 0.018075467000016943, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 11568 / 20000\n",
      "gradient norm: 0.060135962019558065, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00551\n",
      "epoch 11569 / 20000\n",
      "gradient norm: 0.058933804408297874, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 11570 / 20000\n",
      "gradient norm: 0.05293796074693091, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 11571 / 20000\n",
      "gradient norm: 0.07094759563915431, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 11572 / 20000\n",
      "gradient norm: 0.077442880399758, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 11573 / 20000\n",
      "gradient norm: 0.05649806186556816, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 11574 / 20000\n",
      "gradient norm: 0.07035612656181911, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 11575 / 20000\n",
      "gradient norm: 0.025292404548963532, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 11576 / 20000\n",
      "gradient norm: 0.08307100122328848, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 11577 / 20000\n",
      "gradient norm: 0.01820608487469144, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 11578 / 20000\n",
      "gradient norm: 0.045383854398096446, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 11579 / 20000\n",
      "gradient norm: 0.04611836504773237, minimum ratio: 2.4815789473684213\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 11580 / 20000\n",
      "gradient norm: 0.0929400259628892, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 11581 / 20000\n",
      "gradient norm: 0.11395321402233094, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00555\n",
      "epoch 11582 / 20000\n",
      "gradient norm: 0.08171500457683578, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 11583 / 20000\n",
      "gradient norm: 0.08626666048076004, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 11584 / 20000\n",
      "gradient norm: 0.0419489207706647, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 11585 / 20000\n",
      "gradient norm: 0.05050389235839248, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 11586 / 20000\n",
      "gradient norm: 0.03028254004311748, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 11587 / 20000\n",
      "gradient norm: 0.057315692625707015, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 11588 / 20000\n",
      "gradient norm: 0.053178779198788106, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 11589 / 20000\n",
      "gradient norm: 0.13123316824203357, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00551\n",
      "epoch 11590 / 20000\n",
      "gradient norm: 0.06681422400288284, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 11591 / 20000\n",
      "gradient norm: 0.06756933394353837, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 11592 / 20000\n",
      "gradient norm: 0.06502236821688712, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 11593 / 20000\n",
      "gradient norm: 0.0581622050376609, minimum ratio: 2.494736842105263\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 11594 / 20000\n",
      "gradient norm: 0.06749854033114389, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 11595 / 20000\n",
      "gradient norm: 0.07145572797162458, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 11596 / 20000\n",
      "gradient norm: 0.03918137223809026, minimum ratio: 2.4447368421052635\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 11597 / 20000\n",
      "gradient norm: 0.05925483163446188, minimum ratio: 2.460526315789474\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 11598 / 20000\n",
      "gradient norm: 0.08895168476738036, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 11599 / 20000\n",
      "gradient norm: 0.05760253797052428, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 11600 / 20000\n",
      "gradient norm: 0.1087673424044624, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 11601 / 20000\n",
      "gradient norm: 0.036176204957882874, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 11602 / 20000\n",
      "gradient norm: 0.035257675364846364, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 11603 / 20000\n",
      "gradient norm: 0.062384584394749254, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 11604 / 20000\n",
      "gradient norm: 0.055467533034970984, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 11605 / 20000\n",
      "gradient norm: 0.059676110628061, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 11606 / 20000\n",
      "gradient norm: 0.04853786283638328, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00553\n",
      "epoch 11607 / 20000\n",
      "gradient norm: 0.08320286910748109, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 11608 / 20000\n",
      "gradient norm: 0.027115711229271255, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 11609 / 20000\n",
      "gradient norm: 0.10026177729014307, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 11610 / 20000\n",
      "gradient norm: 0.09855780054931529, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00551\n",
      "epoch 11611 / 20000\n",
      "gradient norm: 0.04778246826026589, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 11612 / 20000\n",
      "gradient norm: 0.0702854658011347, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 11613 / 20000\n",
      "gradient norm: 0.042868922973866574, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 11614 / 20000\n",
      "gradient norm: 0.053500533336773515, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 11615 / 20000\n",
      "gradient norm: 0.0824813419021666, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 11616 / 20000\n",
      "gradient norm: 0.06729367579100654, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 11617 / 20000\n",
      "gradient norm: 0.037848580948775634, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 11618 / 20000\n",
      "gradient norm: 0.05759366322308779, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 11619 / 20000\n",
      "gradient norm: 0.04205890517914668, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 11620 / 20000\n",
      "gradient norm: 0.07326802908210084, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 11621 / 20000\n",
      "gradient norm: 0.05770056894107256, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 11622 / 20000\n",
      "gradient norm: 0.07009482145076618, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 11623 / 20000\n",
      "gradient norm: 0.06634145928546786, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 11624 / 20000\n",
      "gradient norm: 0.06220744305755943, minimum ratio: 2.492105263157895\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 11625 / 20000\n",
      "gradient norm: 0.08460831831325777, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 11626 / 20000\n",
      "gradient norm: 0.08637058024760336, minimum ratio: 2.4842105263157896\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 11627 / 20000\n",
      "gradient norm: 0.08586606977041811, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 11628 / 20000\n",
      "gradient norm: 0.021105807045387337, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 11629 / 20000\n",
      "gradient norm: 0.09604983392637223, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 11630 / 20000\n",
      "gradient norm: 0.0793602995108813, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 11631 / 20000\n",
      "gradient norm: 0.04327695187384961, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 11632 / 20000\n",
      "gradient norm: 0.04882618220290169, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 11633 / 20000\n",
      "gradient norm: 0.09472199704032391, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 11634 / 20000\n",
      "gradient norm: 0.09482729324372485, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 11635 / 20000\n",
      "gradient norm: 0.04272517003118992, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00554\n",
      "epoch 11636 / 20000\n",
      "gradient norm: 0.03544517468253616, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 11637 / 20000\n",
      "gradient norm: 0.09732956148218364, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 11638 / 20000\n",
      "gradient norm: 0.0637726066634059, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00554\n",
      "epoch 11639 / 20000\n",
      "gradient norm: 0.07712109154090285, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 11640 / 20000\n",
      "gradient norm: 0.041945363889681175, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 11641 / 20000\n",
      "gradient norm: 0.09526052483124658, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00551\n",
      "epoch 11642 / 20000\n",
      "gradient norm: 0.05318449076730758, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00555\n",
      "epoch 11643 / 20000\n",
      "gradient norm: 0.07613030419452116, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 11644 / 20000\n",
      "gradient norm: 0.04550151323201135, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 11645 / 20000\n",
      "gradient norm: 0.0469937464222312, minimum ratio: 2.4868421052631575\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 11646 / 20000\n",
      "gradient norm: 0.07746004813816398, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 11647 / 20000\n",
      "gradient norm: 0.06711330304096919, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 11648 / 20000\n",
      "gradient norm: 0.04694184203981422, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 11649 / 20000\n",
      "gradient norm: 0.06420945416903123, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 11650 / 20000\n",
      "gradient norm: 0.07225353320245631, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 11651 / 20000\n",
      "gradient norm: 0.07848860090598464, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 11652 / 20000\n",
      "gradient norm: 0.03932483798416797, minimum ratio: 2.4499999999999997\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 11653 / 20000\n",
      "gradient norm: 0.05117341433651745, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 11654 / 20000\n",
      "gradient norm: 0.08187996930791996, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 11655 / 20000\n",
      "gradient norm: 0.046967350819613785, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 11656 / 20000\n",
      "gradient norm: 0.08172095615009312, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00553\n",
      "epoch 11657 / 20000\n",
      "gradient norm: 0.07085477595683187, minimum ratio: 2.492105263157895\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 11658 / 20000\n",
      "gradient norm: 0.07882229273673147, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 11659 / 20000\n",
      "gradient norm: 0.04726653831312433, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 11660 / 20000\n",
      "gradient norm: 0.05838777852477506, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 11661 / 20000\n",
      "gradient norm: 0.04637007461860776, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 11662 / 20000\n",
      "gradient norm: 0.04677295536384918, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 11663 / 20000\n",
      "gradient norm: 0.04141193220857531, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 11664 / 20000\n",
      "gradient norm: 0.030143526106257923, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 11665 / 20000\n",
      "gradient norm: 0.07178044028114527, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 11666 / 20000\n",
      "gradient norm: 0.07922831848554779, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 11667 / 20000\n",
      "gradient norm: 0.04940338377491571, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 11668 / 20000\n",
      "gradient norm: 0.0848509332863614, minimum ratio: 2.4815789473684213\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 11669 / 20000\n",
      "gradient norm: 0.049201502988580614, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 11670 / 20000\n",
      "gradient norm: 0.06600834446726367, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 11671 / 20000\n",
      "gradient norm: 0.07541127962758765, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 11672 / 20000\n",
      "gradient norm: 0.06778864914667793, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 11673 / 20000\n",
      "gradient norm: 0.06703187778475694, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 11674 / 20000\n",
      "gradient norm: 0.06191757105989382, minimum ratio: 2.460526315789474\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 11675 / 20000\n",
      "gradient norm: 0.038045721557864454, minimum ratio: 2.4894736842105267\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 11676 / 20000\n",
      "gradient norm: 0.06031171849463135, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 11677 / 20000\n",
      "gradient norm: 0.0745818541618064, minimum ratio: 2.460526315789474\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 11678 / 20000\n",
      "gradient norm: 0.08497341873589903, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 11679 / 20000\n",
      "gradient norm: 0.03672450053272769, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 11680 / 20000\n",
      "gradient norm: 0.09368052799254656, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 11681 / 20000\n",
      "gradient norm: 0.03074725129408762, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 11682 / 20000\n",
      "gradient norm: 0.03120757768920157, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 11683 / 20000\n",
      "gradient norm: 0.05985825401148759, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 11684 / 20000\n",
      "gradient norm: 0.08308147097704932, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 11685 / 20000\n",
      "gradient norm: 0.0937466932227835, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 11686 / 20000\n",
      "gradient norm: 0.06313424895051867, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 11687 / 20000\n",
      "gradient norm: 0.04170732930651866, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 11688 / 20000\n",
      "gradient norm: 0.06981130316853523, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 11689 / 20000\n",
      "gradient norm: 0.0633946766029112, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 11690 / 20000\n",
      "gradient norm: 0.05847914010519162, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 11691 / 20000\n",
      "gradient norm: 0.06345153960864991, minimum ratio: 2.4499999999999997\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 11692 / 20000\n",
      "gradient norm: 0.04076175346199307, minimum ratio: 2.465789473684211\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 11693 / 20000\n",
      "gradient norm: 0.059042227541795, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 11694 / 20000\n",
      "gradient norm: 0.0557228357065469, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 11695 / 20000\n",
      "gradient norm: 0.029424192616716027, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 11696 / 20000\n",
      "gradient norm: 0.07970146562729497, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 11697 / 20000\n",
      "gradient norm: 0.058943059761077166, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 11698 / 20000\n",
      "gradient norm: 0.05547274948912673, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 11699 / 20000\n",
      "gradient norm: 0.074838089174591, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 11700 / 20000\n",
      "gradient norm: 0.05206199441454373, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 11701 / 20000\n",
      "gradient norm: 0.1274913478991948, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 11702 / 20000\n",
      "gradient norm: 0.04868584286305122, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 11703 / 20000\n",
      "gradient norm: 0.015404858233523555, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 11704 / 20000\n",
      "gradient norm: 0.09711731178686023, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 11705 / 20000\n",
      "gradient norm: 0.0475344680598937, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 11706 / 20000\n",
      "gradient norm: 0.07125549984630197, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 11707 / 20000\n",
      "gradient norm: 0.07586281024850905, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 11708 / 20000\n",
      "gradient norm: 0.05813859682530165, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 11709 / 20000\n",
      "gradient norm: 0.05225384132063482, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 11710 / 20000\n",
      "gradient norm: 0.037286747407051735, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 11711 / 20000\n",
      "gradient norm: 0.04209510874352418, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 11712 / 20000\n",
      "gradient norm: 0.06524221657309681, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 11713 / 20000\n",
      "gradient norm: 0.01957540967850946, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 11714 / 20000\n",
      "gradient norm: 0.02306822402169928, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 11715 / 20000\n",
      "gradient norm: 0.0451406053325627, minimum ratio: 2.4578947368421056\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 11716 / 20000\n",
      "gradient norm: 0.054582471173489466, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 11717 / 20000\n",
      "gradient norm: 0.051900252350606024, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 11718 / 20000\n",
      "gradient norm: 0.0619168564589927, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 11719 / 20000\n",
      "gradient norm: 0.05522087818826549, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 11720 / 20000\n",
      "gradient norm: 0.11239255731925368, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 11721 / 20000\n",
      "gradient norm: 0.07896339101716876, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 11722 / 20000\n",
      "gradient norm: 0.0615298607153818, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 11723 / 20000\n",
      "gradient norm: 0.03978533180634258, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 11724 / 20000\n",
      "gradient norm: 0.09981049608904868, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 11725 / 20000\n",
      "gradient norm: 0.030882309612934478, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 11726 / 20000\n",
      "gradient norm: 0.07087099156342447, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 11727 / 20000\n",
      "gradient norm: 0.12409078702330589, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00551\n",
      "epoch 11728 / 20000\n",
      "gradient norm: 0.08364989573601633, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 11729 / 20000\n",
      "gradient norm: 0.03038796325563453, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 11730 / 20000\n",
      "gradient norm: 0.03650408986140974, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00551\n",
      "epoch 11731 / 20000\n",
      "gradient norm: 0.03162037623405922, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 11732 / 20000\n",
      "gradient norm: 0.08425127738155425, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 11733 / 20000\n",
      "gradient norm: 0.05134997592540458, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 11734 / 20000\n",
      "gradient norm: 0.0803649440058507, minimum ratio: 2.4868421052631575\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00551\n",
      "epoch 11735 / 20000\n",
      "gradient norm: 0.06218299875035882, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 11736 / 20000\n",
      "gradient norm: 0.09671426494605839, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 11737 / 20000\n",
      "gradient norm: 0.060166975352331065, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 11738 / 20000\n",
      "gradient norm: 0.07638230963493697, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 11739 / 20000\n",
      "gradient norm: 0.1135473834383447, minimum ratio: 2.4631578947368427\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 11740 / 20000\n",
      "gradient norm: 0.08682070177746937, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 11741 / 20000\n",
      "gradient norm: 0.11924402747536078, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00552\n",
      "epoch 11742 / 20000\n",
      "gradient norm: 0.09128711716039106, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 11743 / 20000\n",
      "gradient norm: 0.035751376854022965, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 11744 / 20000\n",
      "gradient norm: 0.09787828649859875, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00553\n",
      "epoch 11745 / 20000\n",
      "gradient norm: 0.09041455341503024, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 11746 / 20000\n",
      "gradient norm: 0.06157286625239067, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 11747 / 20000\n",
      "gradient norm: 0.0815397224505432, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 11748 / 20000\n",
      "gradient norm: 0.11661750276107341, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00552\n",
      "epoch 11749 / 20000\n",
      "gradient norm: 0.07111293784691952, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 11750 / 20000\n",
      "gradient norm: 0.058364536715089343, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 11751 / 20000\n",
      "gradient norm: 0.0915552619844675, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 11752 / 20000\n",
      "gradient norm: 0.049702308198902756, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 11753 / 20000\n",
      "gradient norm: 0.06808685345458798, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 11754 / 20000\n",
      "gradient norm: 0.10147908597718924, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 11755 / 20000\n",
      "gradient norm: 0.04360691210604273, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 11756 / 20000\n",
      "gradient norm: 0.06804075758554973, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 11757 / 20000\n",
      "gradient norm: 0.06104125929414295, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 11758 / 20000\n",
      "gradient norm: 0.03735673305345699, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 11759 / 20000\n",
      "gradient norm: 0.031139803482801653, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 11760 / 20000\n",
      "gradient norm: 0.08044126408640295, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 11761 / 20000\n",
      "gradient norm: 0.08062698974390514, minimum ratio: 2.4499999999999997\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 11762 / 20000\n",
      "gradient norm: 0.07098242832580581, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 11763 / 20000\n",
      "gradient norm: 0.09915769111830741, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 11764 / 20000\n",
      "gradient norm: 0.0423375087993918, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 11765 / 20000\n",
      "gradient norm: 0.06916316517163068, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 11766 / 20000\n",
      "gradient norm: 0.0557723767706193, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 11767 / 20000\n",
      "gradient norm: 0.042618426377885044, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 11768 / 20000\n",
      "gradient norm: 0.07057067297864705, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 11769 / 20000\n",
      "gradient norm: 0.07502542115980759, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 11770 / 20000\n",
      "gradient norm: 0.07875948704895563, minimum ratio: 2.476315789473684\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 11771 / 20000\n",
      "gradient norm: 0.09377277817111462, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 11772 / 20000\n",
      "gradient norm: 0.06980354123516008, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 11773 / 20000\n",
      "gradient norm: 0.0903402422554791, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 11774 / 20000\n",
      "gradient norm: 0.06002531968988478, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 11775 / 20000\n",
      "gradient norm: 0.05011846197885461, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 11776 / 20000\n",
      "gradient norm: 0.053829544136533514, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 11777 / 20000\n",
      "gradient norm: 0.07865748496260494, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 11778 / 20000\n",
      "gradient norm: 0.08896537590771914, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 11779 / 20000\n",
      "gradient norm: 0.04691750355414115, minimum ratio: 2.4447368421052635\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 11780 / 20000\n",
      "gradient norm: 0.10192340414505452, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 11781 / 20000\n",
      "gradient norm: 0.026648604456568137, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 11782 / 20000\n",
      "gradient norm: 0.07878672680817544, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 11783 / 20000\n",
      "gradient norm: 0.07123263337416574, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 11784 / 20000\n",
      "gradient norm: 0.0672980074014049, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 11785 / 20000\n",
      "gradient norm: 0.06954893446527421, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00554\n",
      "epoch 11786 / 20000\n",
      "gradient norm: 0.05089703414705582, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 11787 / 20000\n",
      "gradient norm: 0.060050970496376976, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 11788 / 20000\n",
      "gradient norm: 0.03509915785980411, minimum ratio: 2.4421052631578943\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 11789 / 20000\n",
      "gradient norm: 0.10942081396933645, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 11790 / 20000\n",
      "gradient norm: 0.07187266589608043, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 11791 / 20000\n",
      "gradient norm: 0.08519966690801084, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00552\n",
      "epoch 11792 / 20000\n",
      "gradient norm: 0.055850790813565254, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 11793 / 20000\n",
      "gradient norm: 0.052303539792774245, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 11794 / 20000\n",
      "gradient norm: 0.08634648151928559, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 11795 / 20000\n",
      "gradient norm: 0.07942543702665716, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 11796 / 20000\n",
      "gradient norm: 0.0204480588727165, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 11797 / 20000\n",
      "gradient norm: 0.06569443878834136, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 11798 / 20000\n",
      "gradient norm: 0.1009887715918012, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 11799 / 20000\n",
      "gradient norm: 0.06577557729906403, minimum ratio: 2.4578947368421056\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 11800 / 20000\n",
      "gradient norm: 0.03644073707982898, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 11801 / 20000\n",
      "gradient norm: 0.10109690413810313, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 11802 / 20000\n",
      "gradient norm: 0.051902256498578936, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 11803 / 20000\n",
      "gradient norm: 0.05719366640551016, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 11804 / 20000\n",
      "gradient norm: 0.056761801592074335, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 11805 / 20000\n",
      "gradient norm: 0.06306661371490918, minimum ratio: 2.5105263157894733\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 11806 / 20000\n",
      "gradient norm: 0.05373524420429021, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 11807 / 20000\n",
      "gradient norm: 0.07389762467937544, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 11808 / 20000\n",
      "gradient norm: 0.07959891058271751, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 11809 / 20000\n",
      "gradient norm: 0.043559906305745244, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 11810 / 20000\n",
      "gradient norm: 0.0607475292054005, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 11811 / 20000\n",
      "gradient norm: 0.033935159946850035, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 11812 / 20000\n",
      "gradient norm: 0.04841666738502681, minimum ratio: 2.46578947368421\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 11813 / 20000\n",
      "gradient norm: 0.049121875839773566, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 11814 / 20000\n",
      "gradient norm: 0.05313474830472842, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 11815 / 20000\n",
      "gradient norm: 0.07889157894533128, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 11816 / 20000\n",
      "gradient norm: 0.0905891468282789, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 11817 / 20000\n",
      "gradient norm: 0.02486488825525157, minimum ratio: 2.4447368421052627\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 11818 / 20000\n",
      "gradient norm: 0.09430459584109485, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 11819 / 20000\n",
      "gradient norm: 0.08084024337586015, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 11820 / 20000\n",
      "gradient norm: 0.04400986019754782, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 11821 / 20000\n",
      "gradient norm: 0.04355823274818249, minimum ratio: 2.4394736842105265\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 11822 / 20000\n",
      "gradient norm: 0.08962485048687086, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 11823 / 20000\n",
      "gradient norm: 0.0904657564824447, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 11824 / 20000\n",
      "gradient norm: 0.041667897945444565, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 11825 / 20000\n",
      "gradient norm: 0.04505224904278293, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 11826 / 20000\n",
      "gradient norm: 0.029023554918239824, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 11827 / 20000\n",
      "gradient norm: 0.025486242360784672, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 11828 / 20000\n",
      "gradient norm: 0.05958500335691497, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 11829 / 20000\n",
      "gradient norm: 0.10678238706896082, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00551\n",
      "epoch 11830 / 20000\n",
      "gradient norm: 0.06323009743937291, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 11831 / 20000\n",
      "gradient norm: 0.06790748331695795, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 11832 / 20000\n",
      "gradient norm: 0.06780840712599456, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 11833 / 20000\n",
      "gradient norm: 0.04339337628334761, minimum ratio: 2.4263157894736844\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 11834 / 20000\n",
      "gradient norm: 0.06868566114280839, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00553\n",
      "epoch 11835 / 20000\n",
      "gradient norm: 0.04618990374729037, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 11836 / 20000\n",
      "gradient norm: 0.09244923320511589, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 11837 / 20000\n",
      "gradient norm: 0.10501160356216133, minimum ratio: 2.4631578947368427\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 11838 / 20000\n",
      "gradient norm: 0.02968337055062875, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00554\n",
      "epoch 11839 / 20000\n",
      "gradient norm: 0.0535952705249656, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 11840 / 20000\n",
      "gradient norm: 0.10162851167842746, minimum ratio: 2.460526315789474\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 11841 / 20000\n",
      "gradient norm: 0.08993252238724381, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 11842 / 20000\n",
      "gradient norm: 0.06989642383996397, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 11843 / 20000\n",
      "gradient norm: 0.05000991068664007, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 11844 / 20000\n",
      "gradient norm: 0.05205736024072394, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 11845 / 20000\n",
      "gradient norm: 0.07193440641276538, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 11846 / 20000\n",
      "gradient norm: 0.06463430967414752, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 11847 / 20000\n",
      "gradient norm: 0.08435330324573442, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 11848 / 20000\n",
      "gradient norm: 0.07005093380576, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00554\n",
      "epoch 11849 / 20000\n",
      "gradient norm: 0.040661157690919936, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 11850 / 20000\n",
      "gradient norm: 0.058057499409187585, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 11851 / 20000\n",
      "gradient norm: 0.010174904200539459, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 11852 / 20000\n",
      "gradient norm: 0.04700254986528307, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 11853 / 20000\n",
      "gradient norm: 0.039621282950975, minimum ratio: 2.4236842105263157\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 11854 / 20000\n",
      "gradient norm: 0.05604691687040031, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00551\n",
      "epoch 11855 / 20000\n",
      "gradient norm: 0.08422404233715497, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 11856 / 20000\n",
      "gradient norm: 0.0650881537294481, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 11857 / 20000\n",
      "gradient norm: 0.0976193270762451, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 11858 / 20000\n",
      "gradient norm: 0.0717097299057059, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 11859 / 20000\n",
      "gradient norm: 0.05799763629329391, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 11860 / 20000\n",
      "gradient norm: 0.05849833555112127, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 11861 / 20000\n",
      "gradient norm: 0.06144582951674238, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 11862 / 20000\n",
      "gradient norm: 0.05416384457203094, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 11863 / 20000\n",
      "gradient norm: 0.07028275047196075, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 11864 / 20000\n",
      "gradient norm: 0.05231634131632745, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 11865 / 20000\n",
      "gradient norm: 0.0920195363505627, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 11866 / 20000\n",
      "gradient norm: 0.030289757531136274, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 11867 / 20000\n",
      "gradient norm: 0.06345606190734543, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 11868 / 20000\n",
      "gradient norm: 0.07637464115396142, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 11869 / 20000\n",
      "gradient norm: 0.0617405274824705, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 11870 / 20000\n",
      "gradient norm: 0.0868256000103429, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 11871 / 20000\n",
      "gradient norm: 0.0816903953673318, minimum ratio: 2.4684210526315784\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 11872 / 20000\n",
      "gradient norm: 0.1309853483689949, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00551\n",
      "epoch 11873 / 20000\n",
      "gradient norm: 0.045544704305939376, minimum ratio: 2.4447368421052635\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 11874 / 20000\n",
      "gradient norm: 0.07230833632638678, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 11875 / 20000\n",
      "gradient norm: 0.04816629026026931, minimum ratio: 2.4236842105263157\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 11876 / 20000\n",
      "gradient norm: 0.1239200864220038, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00551\n",
      "epoch 11877 / 20000\n",
      "gradient norm: 0.0651449208962731, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00556\n",
      "epoch 11878 / 20000\n",
      "gradient norm: 0.0563780773036342, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 11879 / 20000\n",
      "gradient norm: 0.0682997262047138, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 11880 / 20000\n",
      "gradient norm: 0.04584371083183214, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 11881 / 20000\n",
      "gradient norm: 0.035353143903193995, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 11882 / 20000\n",
      "gradient norm: 0.03756586491363123, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 11883 / 20000\n",
      "gradient norm: 0.051470024773152545, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 11884 / 20000\n",
      "gradient norm: 0.07731007784605026, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 11885 / 20000\n",
      "gradient norm: 0.10339221265166998, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 11886 / 20000\n",
      "gradient norm: 0.06366374611388892, minimum ratio: 2.4447368421052635\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 11887 / 20000\n",
      "gradient norm: 0.06225077292765491, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 11888 / 20000\n",
      "gradient norm: 0.07145893265260383, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00551\n",
      "epoch 11889 / 20000\n",
      "gradient norm: 0.058409921533893794, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 11890 / 20000\n",
      "gradient norm: 0.02800121792824939, minimum ratio: 2.4578947368421056\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 11891 / 20000\n",
      "gradient norm: 0.06675626221112907, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 11892 / 20000\n",
      "gradient norm: 0.029715804921579547, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 11893 / 20000\n",
      "gradient norm: 0.05438036657869816, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 11894 / 20000\n",
      "gradient norm: 0.08393911691382527, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 11895 / 20000\n",
      "gradient norm: 0.07096771976648597, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 11896 / 20000\n",
      "gradient norm: 0.05650178628275171, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 11897 / 20000\n",
      "gradient norm: 0.07074119313620031, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 11898 / 20000\n",
      "gradient norm: 0.0662521536287386, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 11899 / 20000\n",
      "gradient norm: 0.0433194279903546, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 11900 / 20000\n",
      "gradient norm: 0.06334015220636502, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 11901 / 20000\n",
      "gradient norm: 0.06742418551584706, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 11902 / 20000\n",
      "gradient norm: 0.05580981416278519, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 11903 / 20000\n",
      "gradient norm: 0.06694049033103511, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 11904 / 20000\n",
      "gradient norm: 0.0544650437659584, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 11905 / 20000\n",
      "gradient norm: 0.05420738073007669, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 11906 / 20000\n",
      "gradient norm: 0.1519767960999161, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 11907 / 20000\n",
      "gradient norm: 0.061865031137131155, minimum ratio: 2.436842105263158\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 11908 / 20000\n",
      "gradient norm: 0.06985351612092927, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 11909 / 20000\n",
      "gradient norm: 0.07373272947734222, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 11910 / 20000\n",
      "gradient norm: 0.10783521478879265, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00551\n",
      "epoch 11911 / 20000\n",
      "gradient norm: 0.02281757542368723, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 11912 / 20000\n",
      "gradient norm: 0.10490388551261276, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 11913 / 20000\n",
      "gradient norm: 0.058831542439293116, minimum ratio: 2.436842105263158\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 11914 / 20000\n",
      "gradient norm: 0.10176972395856865, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 11915 / 20000\n",
      "gradient norm: 0.1258235971617978, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 11916 / 20000\n",
      "gradient norm: 0.03873659489909187, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 11917 / 20000\n",
      "gradient norm: 0.07183135315426625, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 11918 / 20000\n",
      "gradient norm: 0.04170228500152007, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 11919 / 20000\n",
      "gradient norm: 0.04603902256349102, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 11920 / 20000\n",
      "gradient norm: 0.012922273352160119, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 11921 / 20000\n",
      "gradient norm: 0.04365575508563779, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 11922 / 20000\n",
      "gradient norm: 0.04748693050350994, minimum ratio: 2.4447368421052635\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 11923 / 20000\n",
      "gradient norm: 0.04909614239295479, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 11924 / 20000\n",
      "gradient norm: 0.04608242807444185, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 11925 / 20000\n",
      "gradient norm: 0.047141932634986006, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 11926 / 20000\n",
      "gradient norm: 0.06093030294869095, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 11927 / 20000\n",
      "gradient norm: 0.019597770835389383, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 11928 / 20000\n",
      "gradient norm: 0.056779398379148915, minimum ratio: 2.436842105263158\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 11929 / 20000\n",
      "gradient norm: 0.07356535940198228, minimum ratio: 2.4263157894736844\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 11930 / 20000\n",
      "gradient norm: 0.05353851872496307, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 11931 / 20000\n",
      "gradient norm: 0.05003789282636717, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 11932 / 20000\n",
      "gradient norm: 0.10710314649622887, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 11933 / 20000\n",
      "gradient norm: 0.04049427158315666, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 11934 / 20000\n",
      "gradient norm: 0.01004977103730198, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 11935 / 20000\n",
      "gradient norm: 0.05816527645220049, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 11936 / 20000\n",
      "gradient norm: 0.06930274033220485, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 11937 / 20000\n",
      "gradient norm: 0.056065114244120196, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 11938 / 20000\n",
      "gradient norm: 0.04733878211118281, minimum ratio: 2.4421052631578943\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 11939 / 20000\n",
      "gradient norm: 0.06582382232591044, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 11940 / 20000\n",
      "gradient norm: 0.09269353304989636, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 11941 / 20000\n",
      "gradient norm: 0.051310735230799764, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 11942 / 20000\n",
      "gradient norm: 0.05984269994223723, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 11943 / 20000\n",
      "gradient norm: 0.05522570590255782, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 11944 / 20000\n",
      "gradient norm: 0.08675680274609476, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 11945 / 20000\n",
      "gradient norm: 0.07243338375701569, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 11946 / 20000\n",
      "gradient norm: 0.08741056470898911, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 11947 / 20000\n",
      "gradient norm: 0.06687780754873529, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 11948 / 20000\n",
      "gradient norm: 0.0264469023240963, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 11949 / 20000\n",
      "gradient norm: 0.04514319647569209, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 11950 / 20000\n",
      "gradient norm: 0.07967278207070194, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 11951 / 20000\n",
      "gradient norm: 0.041975956919486634, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 11952 / 20000\n",
      "gradient norm: 0.08599666552618146, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 11953 / 20000\n",
      "gradient norm: 0.05011578119592741, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 11954 / 20000\n",
      "gradient norm: 0.07707752112764865, minimum ratio: 2.436842105263158\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 11955 / 20000\n",
      "gradient norm: 0.04504765322781168, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 11956 / 20000\n",
      "gradient norm: 0.04706969553080853, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 11957 / 20000\n",
      "gradient norm: 0.12146444100653753, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 11958 / 20000\n",
      "gradient norm: 0.06629882857669145, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 11959 / 20000\n",
      "gradient norm: 0.08430359308840707, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 11960 / 20000\n",
      "gradient norm: 0.08265519526321441, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 11961 / 20000\n",
      "gradient norm: 0.09331266972003505, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 11962 / 20000\n",
      "gradient norm: 0.07339236899861135, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 11963 / 20000\n",
      "gradient norm: 0.03398389957146719, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 11964 / 20000\n",
      "gradient norm: 0.08801114004745614, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 11965 / 20000\n",
      "gradient norm: 0.04051219407665485, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 11966 / 20000\n",
      "gradient norm: 0.0703704915358685, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 11967 / 20000\n",
      "gradient norm: 0.05890226483461447, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 11968 / 20000\n",
      "gradient norm: 0.03186344340792857, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 11969 / 20000\n",
      "gradient norm: 0.03772112797014415, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 11970 / 20000\n",
      "gradient norm: 0.031476733231102116, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 11971 / 20000\n",
      "gradient norm: 0.06958665768615901, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 11972 / 20000\n",
      "gradient norm: 0.03571366486721672, minimum ratio: 2.4447368421052635\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 11973 / 20000\n",
      "gradient norm: 0.08347106439759955, minimum ratio: 2.460526315789474\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 11974 / 20000\n",
      "gradient norm: 0.02809846625314094, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 11975 / 20000\n",
      "gradient norm: 0.0673644722555764, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 11976 / 20000\n",
      "gradient norm: 0.12019114903523587, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 11977 / 20000\n",
      "gradient norm: 0.06497032684274018, minimum ratio: 2.4210526315789473\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 11978 / 20000\n",
      "gradient norm: 0.07289315841626376, minimum ratio: 2.4394736842105265\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 11979 / 20000\n",
      "gradient norm: 0.09161030416726135, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 11980 / 20000\n",
      "gradient norm: 0.06827208783943206, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 11981 / 20000\n",
      "gradient norm: 0.07400121900718659, minimum ratio: 2.426315789473684\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 11982 / 20000\n",
      "gradient norm: 0.05381538160145283, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 11983 / 20000\n",
      "gradient norm: 0.051178553054342046, minimum ratio: 2.447368421052631\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 11984 / 20000\n",
      "gradient norm: 0.08107647141150665, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 11985 / 20000\n",
      "gradient norm: 0.07383720422512852, minimum ratio: 2.4447368421052627\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 11986 / 20000\n",
      "gradient norm: 0.04572604226996191, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 11987 / 20000\n",
      "gradient norm: 0.04683858987118583, minimum ratio: 2.4263157894736844\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 11988 / 20000\n",
      "gradient norm: 0.05605421696964186, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 11989 / 20000\n",
      "gradient norm: 0.04208504530834034, minimum ratio: 2.4499999999999997\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 11990 / 20000\n",
      "gradient norm: 0.05473811289994046, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 11991 / 20000\n",
      "gradient norm: 0.048464784005773254, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 11992 / 20000\n",
      "gradient norm: 0.04641730058938265, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 11993 / 20000\n",
      "gradient norm: 0.0366493085239199, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 11994 / 20000\n",
      "gradient norm: 0.09942210087319836, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 11995 / 20000\n",
      "gradient norm: 0.05600459469133057, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 11996 / 20000\n",
      "gradient norm: 0.04133889265358448, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 11997 / 20000\n",
      "gradient norm: 0.08808897092239931, minimum ratio: 2.4499999999999997\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00553\n",
      "epoch 11998 / 20000\n",
      "gradient norm: 0.04583416919922456, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 11999 / 20000\n",
      "gradient norm: 0.05190112252603285, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 12000 / 20000\n",
      "gradient norm: 0.08980534243164584, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 12001 / 20000\n",
      "gradient norm: 0.12848146702162921, minimum ratio: 2.4263157894736844\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00553\n",
      "epoch 12002 / 20000\n",
      "gradient norm: 0.034674055845243856, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 12003 / 20000\n",
      "gradient norm: 0.06388866336783394, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 12004 / 20000\n",
      "gradient norm: 0.07864292617887259, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 12005 / 20000\n",
      "gradient norm: 0.08830611049779691, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00554\n",
      "epoch 12006 / 20000\n",
      "gradient norm: 0.08921661233762279, minimum ratio: 2.4421052631578943\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 12007 / 20000\n",
      "gradient norm: 0.07750525535084307, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 12008 / 20000\n",
      "gradient norm: 0.041707580516231246, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 12009 / 20000\n",
      "gradient norm: 0.07181176444282755, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 12010 / 20000\n",
      "gradient norm: 0.06516071679652669, minimum ratio: 2.4210526315789473\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 12011 / 20000\n",
      "gradient norm: 0.04930424556368962, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 12012 / 20000\n",
      "gradient norm: 0.06447958454373293, minimum ratio: 2.4210526315789473\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 12013 / 20000\n",
      "gradient norm: 0.042503099131863564, minimum ratio: 2.460526315789474\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00553\n",
      "epoch 12014 / 20000\n",
      "gradient norm: 0.11845121462829411, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 12015 / 20000\n",
      "gradient norm: 0.05779665621230379, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 12016 / 20000\n",
      "gradient norm: 0.09642662719124928, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 12017 / 20000\n",
      "gradient norm: 0.060871786627103575, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 12018 / 20000\n",
      "gradient norm: 0.05096522776875645, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 12019 / 20000\n",
      "gradient norm: 0.038380797661375254, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00552\n",
      "epoch 12020 / 20000\n",
      "gradient norm: 0.06133659672923386, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 12021 / 20000\n",
      "gradient norm: 0.08459812216460705, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 12022 / 20000\n",
      "gradient norm: 0.11421994108241051, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 12023 / 20000\n",
      "gradient norm: 0.06693433418695349, minimum ratio: 2.460526315789474\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 12024 / 20000\n",
      "gradient norm: 0.14260203100275248, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 12025 / 20000\n",
      "gradient norm: 0.08366817579371855, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 12026 / 20000\n",
      "gradient norm: 0.05865204078145325, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 12027 / 20000\n",
      "gradient norm: 0.03342665371019393, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 12028 / 20000\n",
      "gradient norm: 0.0890609051566571, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 12029 / 20000\n",
      "gradient norm: 0.05544818233465776, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 12030 / 20000\n",
      "gradient norm: 0.05638136016204953, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 12031 / 20000\n",
      "gradient norm: 0.06630409645731561, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00555\n",
      "epoch 12032 / 20000\n",
      "gradient norm: 0.09587971994187683, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 12033 / 20000\n",
      "gradient norm: 0.0670339009957388, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 12034 / 20000\n",
      "gradient norm: 0.07721448433585465, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 12035 / 20000\n",
      "gradient norm: 0.05126786982873455, minimum ratio: 2.4447368421052635\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 12036 / 20000\n",
      "gradient norm: 0.0593458379371441, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 12037 / 20000\n",
      "gradient norm: 0.057355357334017754, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 12038 / 20000\n",
      "gradient norm: 0.07505615835543722, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 12039 / 20000\n",
      "gradient norm: 0.07738987077027559, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00555\n",
      "epoch 12040 / 20000\n",
      "gradient norm: 0.049553735996596515, minimum ratio: 2.4421052631578943\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 12041 / 20000\n",
      "gradient norm: 0.06298871577018872, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 12042 / 20000\n",
      "gradient norm: 0.08632797130849212, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 12043 / 20000\n",
      "gradient norm: 0.09019826236180961, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 12044 / 20000\n",
      "gradient norm: 0.06957780750235543, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 12045 / 20000\n",
      "gradient norm: 0.11575187341077253, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 12046 / 20000\n",
      "gradient norm: 0.07419671042589471, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 12047 / 20000\n",
      "gradient norm: 0.03076638224592898, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 12048 / 20000\n",
      "gradient norm: 0.03125153490691446, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 12049 / 20000\n",
      "gradient norm: 0.04883732652524486, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 12050 / 20000\n",
      "gradient norm: 0.08307591325137764, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 12051 / 20000\n",
      "gradient norm: 0.03849378088489175, minimum ratio: 2.465789473684211\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00551\n",
      "epoch 12052 / 20000\n",
      "gradient norm: 0.10641389200463891, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 12053 / 20000\n",
      "gradient norm: 0.036603379994630814, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 12054 / 20000\n",
      "gradient norm: 0.028680291019554716, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 12055 / 20000\n",
      "gradient norm: 0.06277825322467834, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 12056 / 20000\n",
      "gradient norm: 0.0646543453913182, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 12057 / 20000\n",
      "gradient norm: 0.05674767529126257, minimum ratio: 2.452631578947368\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 12058 / 20000\n",
      "gradient norm: 0.06700316080241464, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 12059 / 20000\n",
      "gradient norm: 0.07192608382320032, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 12060 / 20000\n",
      "gradient norm: 0.08554055646527559, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 12061 / 20000\n",
      "gradient norm: 0.06464106208295561, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 12062 / 20000\n",
      "gradient norm: 0.027353597339242697, minimum ratio: 2.4499999999999997\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 12063 / 20000\n",
      "gradient norm: 0.06749328598380089, minimum ratio: 2.4447368421052635\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 12064 / 20000\n",
      "gradient norm: 0.025704666262754472, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 12065 / 20000\n",
      "gradient norm: 0.06077658213325776, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 12066 / 20000\n",
      "gradient norm: 0.050425422901753336, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 12067 / 20000\n",
      "gradient norm: 0.03351321103400551, minimum ratio: 2.4394736842105265\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 12068 / 20000\n",
      "gradient norm: 0.030508821699186228, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 12069 / 20000\n",
      "gradient norm: 0.09684146515792236, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 12070 / 20000\n",
      "gradient norm: 0.07279085530899465, minimum ratio: 2.4157894736842103\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 12071 / 20000\n",
      "gradient norm: 0.06703412291244604, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00554\n",
      "epoch 12072 / 20000\n",
      "gradient norm: 0.08202894782880321, minimum ratio: 2.426315789473684\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 12073 / 20000\n",
      "gradient norm: 0.05282771895872429, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 12074 / 20000\n",
      "gradient norm: 0.09041286769206636, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 12075 / 20000\n",
      "gradient norm: 0.07887644384754822, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 12076 / 20000\n",
      "gradient norm: 0.060623531870078295, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 12077 / 20000\n",
      "gradient norm: 0.10503343434538692, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00551\n",
      "epoch 12078 / 20000\n",
      "gradient norm: 0.02927135259960778, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00553\n",
      "epoch 12079 / 20000\n",
      "gradient norm: 0.07716187836194877, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 12080 / 20000\n",
      "gradient norm: 0.06130909494822845, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 12081 / 20000\n",
      "gradient norm: 0.06598353770095855, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 12082 / 20000\n",
      "gradient norm: 0.034047169145196676, minimum ratio: 2.423684210526316\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 12083 / 20000\n",
      "gradient norm: 0.01447938330238685, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 12084 / 20000\n",
      "gradient norm: 0.04386565712047741, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 12085 / 20000\n",
      "gradient norm: 0.05455344075744506, minimum ratio: 2.4236842105263157\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 12086 / 20000\n",
      "gradient norm: 0.08461548417108133, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 12087 / 20000\n",
      "gradient norm: 0.059878271364141256, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 12088 / 20000\n",
      "gradient norm: 0.058773724420461804, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 12089 / 20000\n",
      "gradient norm: 0.09117585851345211, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 12090 / 20000\n",
      "gradient norm: 0.05797275074291974, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 12091 / 20000\n",
      "gradient norm: 0.05649151228135452, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 12092 / 20000\n",
      "gradient norm: 0.051959689473733306, minimum ratio: 2.413157894736842\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 12093 / 20000\n",
      "gradient norm: 0.0715241395519115, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 12094 / 20000\n",
      "gradient norm: 0.07687227363931015, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00553\n",
      "epoch 12095 / 20000\n",
      "gradient norm: 0.08550486247986555, minimum ratio: 2.46578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 12096 / 20000\n",
      "gradient norm: 0.03912904910976067, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 12097 / 20000\n",
      "gradient norm: 0.06485276453895494, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 12098 / 20000\n",
      "gradient norm: 0.044961459905607626, minimum ratio: 2.421052631578947\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 12099 / 20000\n",
      "gradient norm: 0.08536149247083813, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 12100 / 20000\n",
      "gradient norm: 0.057133605470880866, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 12101 / 20000\n",
      "gradient norm: 0.13718017854262143, minimum ratio: 2.4263157894736844\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00551\n",
      "epoch 12102 / 20000\n",
      "gradient norm: 0.050079769745934755, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00554\n",
      "epoch 12103 / 20000\n",
      "gradient norm: 0.06658512679859996, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 12104 / 20000\n",
      "gradient norm: 0.06747148151043802, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 12105 / 20000\n",
      "gradient norm: 0.09585822082590312, minimum ratio: 2.423684210526316\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 12106 / 20000\n",
      "gradient norm: 0.028827803762396798, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 12107 / 20000\n",
      "gradient norm: 0.0768805245461408, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 12108 / 20000\n",
      "gradient norm: 0.06771119416225702, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 12109 / 20000\n",
      "gradient norm: 0.06497636449057609, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 12110 / 20000\n",
      "gradient norm: 0.07591906934976578, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 12111 / 20000\n",
      "gradient norm: 0.08673727104905993, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 12112 / 20000\n",
      "gradient norm: 0.09458840952720493, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00551\n",
      "epoch 12113 / 20000\n",
      "gradient norm: 0.043042225937824696, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 12114 / 20000\n",
      "gradient norm: 0.05649504327448085, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 12115 / 20000\n",
      "gradient norm: 0.07144164713099599, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 12116 / 20000\n",
      "gradient norm: 0.041585028055123985, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 12117 / 20000\n",
      "gradient norm: 0.046791633634711616, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 12118 / 20000\n",
      "gradient norm: 0.09780706820311025, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 12119 / 20000\n",
      "gradient norm: 0.06274405794101767, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00552\n",
      "epoch 12120 / 20000\n",
      "gradient norm: 0.11823724943678826, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 12121 / 20000\n",
      "gradient norm: 0.036644563464506064, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 12122 / 20000\n",
      "gradient norm: 0.05334677938662935, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 12123 / 20000\n",
      "gradient norm: 0.047395698755281046, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 12124 / 20000\n",
      "gradient norm: 0.04252480482682586, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 12125 / 20000\n",
      "gradient norm: 0.09182818443514407, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 12126 / 20000\n",
      "gradient norm: 0.04991917306324467, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 12127 / 20000\n",
      "gradient norm: 0.044546840246766806, minimum ratio: 2.4421052631578943\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 12128 / 20000\n",
      "gradient norm: 0.027930127835134044, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00551\n",
      "epoch 12129 / 20000\n",
      "gradient norm: 0.05473436348256655, minimum ratio: 2.4394736842105265\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 12130 / 20000\n",
      "gradient norm: 0.029015323554631323, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 12131 / 20000\n",
      "gradient norm: 0.07832347467774525, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 12132 / 20000\n",
      "gradient norm: 0.07854387845145538, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 12133 / 20000\n",
      "gradient norm: 0.12059701984981075, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00553\n",
      "epoch 12134 / 20000\n",
      "gradient norm: 0.048718306759838015, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 12135 / 20000\n",
      "gradient norm: 0.03184629431052599, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 12136 / 20000\n",
      "gradient norm: 0.0485378626617603, minimum ratio: 2.4236842105263157\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 12137 / 20000\n",
      "gradient norm: 0.07864143908955157, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 12138 / 20000\n",
      "gradient norm: 0.11467643434298225, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 12139 / 20000\n",
      "gradient norm: 0.05638683075085282, minimum ratio: 2.4394736842105265\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 12140 / 20000\n",
      "gradient norm: 0.0409343033679761, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 12141 / 20000\n",
      "gradient norm: 0.08340922158095054, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 12142 / 20000\n",
      "gradient norm: 0.07777925430855248, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 12143 / 20000\n",
      "gradient norm: 0.04050769726745784, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 12144 / 20000\n",
      "gradient norm: 0.044800970557844266, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 12145 / 20000\n",
      "gradient norm: 0.03910750905924942, minimum ratio: 2.4026315789473682\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 12146 / 20000\n",
      "gradient norm: 0.07846987870289013, minimum ratio: 2.4236842105263157\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 12147 / 20000\n",
      "gradient norm: 0.03916950718848966, minimum ratio: 2.4421052631578943\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 12148 / 20000\n",
      "gradient norm: 0.11480809166096151, minimum ratio: 2.426315789473684\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 12149 / 20000\n",
      "gradient norm: 0.06714122944686096, minimum ratio: 2.4289473684210523\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 12150 / 20000\n",
      "gradient norm: 0.06302352991770022, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 12151 / 20000\n",
      "gradient norm: 0.06233255393453874, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 12152 / 20000\n",
      "gradient norm: 0.07084678078535944, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 12153 / 20000\n",
      "gradient norm: 0.05737520387629047, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 12154 / 20000\n",
      "gradient norm: 0.04620688041904941, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 12155 / 20000\n",
      "gradient norm: 0.04404791959677823, minimum ratio: 2.4236842105263157\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 12156 / 20000\n",
      "gradient norm: 0.04131394947762601, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 12157 / 20000\n",
      "gradient norm: 0.019709477659489494, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00552\n",
      "epoch 12158 / 20000\n",
      "gradient norm: 0.035737494108616374, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 12159 / 20000\n",
      "gradient norm: 0.07715926232049242, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 12160 / 20000\n",
      "gradient norm: 0.02969585838582134, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 12161 / 20000\n",
      "gradient norm: 0.040739069125265814, minimum ratio: 2.436842105263158\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 12162 / 20000\n",
      "gradient norm: 0.057374650408746675, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 12163 / 20000\n",
      "gradient norm: 0.11678464867873117, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 12164 / 20000\n",
      "gradient norm: 0.08062710320518818, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 12165 / 20000\n",
      "gradient norm: 0.0627547926887928, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 12166 / 20000\n",
      "gradient norm: 0.055769353624782525, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 12167 / 20000\n",
      "gradient norm: 0.09606165590230376, minimum ratio: 2.4184210526315786\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 12168 / 20000\n",
      "gradient norm: 0.07596460750210099, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00565\n",
      "\tval loss: 0.00554\n",
      "epoch 12169 / 20000\n",
      "gradient norm: 0.06638945618760772, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 12170 / 20000\n",
      "gradient norm: 0.06285919295623899, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 12171 / 20000\n",
      "gradient norm: 0.04538166674319655, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 12172 / 20000\n",
      "gradient norm: 0.049876267672516406, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 12173 / 20000\n",
      "gradient norm: 0.04312380441115238, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 12174 / 20000\n",
      "gradient norm: 0.08233035355806351, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 12175 / 20000\n",
      "gradient norm: 0.03847374630277045, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 12176 / 20000\n",
      "gradient norm: 0.05353912399732508, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 12177 / 20000\n",
      "gradient norm: 0.07133059049374424, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 12178 / 20000\n",
      "gradient norm: 0.06073659978574142, minimum ratio: 2.4394736842105265\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 12179 / 20000\n",
      "gradient norm: 0.08924207405652851, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 12180 / 20000\n",
      "gradient norm: 0.040954805619549006, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 12181 / 20000\n",
      "gradient norm: 0.028079380121198483, minimum ratio: 2.423684210526316\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 12182 / 20000\n",
      "gradient norm: 0.07241322292247787, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 12183 / 20000\n",
      "gradient norm: 0.06102024659048766, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 12184 / 20000\n",
      "gradient norm: 0.05616064523928799, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 12185 / 20000\n",
      "gradient norm: 0.06866404836182483, minimum ratio: 2.4394736842105265\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 12186 / 20000\n",
      "gradient norm: 0.06852417997288285, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00565\n",
      "\tval loss: 0.00551\n",
      "epoch 12187 / 20000\n",
      "gradient norm: 0.06920252623967826, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 12188 / 20000\n",
      "gradient norm: 0.05749499792000279, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00554\n",
      "epoch 12189 / 20000\n",
      "gradient norm: 0.060442350688390434, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 12190 / 20000\n",
      "gradient norm: 0.07423335564089939, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 12191 / 20000\n",
      "gradient norm: 0.05445557051280048, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 12192 / 20000\n",
      "gradient norm: 0.044150238478323445, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 12193 / 20000\n",
      "gradient norm: 0.07371771586258546, minimum ratio: 2.4184210526315786\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 12194 / 20000\n",
      "gradient norm: 0.05164697801228613, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 12195 / 20000\n",
      "gradient norm: 0.08370095782447606, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 12196 / 20000\n",
      "gradient norm: 0.06605895404936746, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 12197 / 20000\n",
      "gradient norm: 0.1010055395308882, minimum ratio: 2.426315789473684\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 12198 / 20000\n",
      "gradient norm: 0.10329751914832741, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 12199 / 20000\n",
      "gradient norm: 0.03469791685347445, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 12200 / 20000\n",
      "gradient norm: 0.019852175741107203, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 12201 / 20000\n",
      "gradient norm: 0.017766995559213683, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 12202 / 20000\n",
      "gradient norm: 0.02983122163277585, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 12203 / 20000\n",
      "gradient norm: 0.05992596730357036, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 12204 / 20000\n",
      "gradient norm: 0.06483260792447254, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 12205 / 20000\n",
      "gradient norm: 0.09365652705309913, minimum ratio: 2.4394736842105265\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 12206 / 20000\n",
      "gradient norm: 0.04245096640079282, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 12207 / 20000\n",
      "gradient norm: 0.10752955736825243, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 12208 / 20000\n",
      "gradient norm: 0.04532069052220322, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 12209 / 20000\n",
      "gradient norm: 0.07146870816359296, minimum ratio: 2.426315789473684\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 12210 / 20000\n",
      "gradient norm: 0.05624365559197031, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 12211 / 20000\n",
      "gradient norm: 0.0329743516194867, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 12212 / 20000\n",
      "gradient norm: 0.058723191541503184, minimum ratio: 2.421052631578947\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 12213 / 20000\n",
      "gradient norm: 0.025395298667717725, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 12214 / 20000\n",
      "gradient norm: 0.09534988680388778, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 12215 / 20000\n",
      "gradient norm: 0.037463864107849076, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 12216 / 20000\n",
      "gradient norm: 0.055752272775862366, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 12217 / 20000\n",
      "gradient norm: 0.06333672507025767, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 12218 / 20000\n",
      "gradient norm: 0.15870520565658808, minimum ratio: 2.4578947368421056\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 12219 / 20000\n",
      "gradient norm: 0.11725072358967736, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 12220 / 20000\n",
      "gradient norm: 0.09788322320673615, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 12221 / 20000\n",
      "gradient norm: 0.08762387128081173, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00556\n",
      "epoch 12222 / 20000\n",
      "gradient norm: 0.13630043738521636, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 12223 / 20000\n",
      "gradient norm: 0.10258554673055187, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 12224 / 20000\n",
      "gradient norm: 0.07629369560163468, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00555\n",
      "epoch 12225 / 20000\n",
      "gradient norm: 0.06681285984814167, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 12226 / 20000\n",
      "gradient norm: 0.08452188014052808, minimum ratio: 2.436842105263158\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00551\n",
      "epoch 12227 / 20000\n",
      "gradient norm: 0.0851096137193963, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 12228 / 20000\n",
      "gradient norm: 0.05840384413022548, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 12229 / 20000\n",
      "gradient norm: 0.15513894555624574, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00551\n",
      "epoch 12230 / 20000\n",
      "gradient norm: 0.07156610139645636, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00555\n",
      "epoch 12231 / 20000\n",
      "gradient norm: 0.10045458830427378, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 12232 / 20000\n",
      "gradient norm: 0.056999418171471916, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 12233 / 20000\n",
      "gradient norm: 0.09332816759706475, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 12234 / 20000\n",
      "gradient norm: 0.0900432980270125, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 12235 / 20000\n",
      "gradient norm: 0.07119365764083341, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 12236 / 20000\n",
      "gradient norm: 0.07800239171774592, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 12237 / 20000\n",
      "gradient norm: 0.08713292991160415, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 12238 / 20000\n",
      "gradient norm: 0.043928310624323785, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 12239 / 20000\n",
      "gradient norm: 0.04834885188029148, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 12240 / 20000\n",
      "gradient norm: 0.05393850477412343, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 12241 / 20000\n",
      "gradient norm: 0.13868894008919597, minimum ratio: 2.4842105263157896\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 12242 / 20000\n",
      "gradient norm: 0.055411462497431785, minimum ratio: 2.4394736842105265\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 12243 / 20000\n",
      "gradient norm: 0.05685266462387517, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 12244 / 20000\n",
      "gradient norm: 0.060578403528779745, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 12245 / 20000\n",
      "gradient norm: 0.12333252094686031, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 12246 / 20000\n",
      "gradient norm: 0.05348603369202465, minimum ratio: 2.423684210526316\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 12247 / 20000\n",
      "gradient norm: 0.09237685840344056, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 12248 / 20000\n",
      "gradient norm: 0.06940498214680701, minimum ratio: 2.4394736842105265\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 12249 / 20000\n",
      "gradient norm: 0.08291833486873657, minimum ratio: 2.4210526315789473\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 12250 / 20000\n",
      "gradient norm: 0.0820806206902489, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 12251 / 20000\n",
      "gradient norm: 0.062186578870750964, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 12252 / 20000\n",
      "gradient norm: 0.03424057910888223, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 12253 / 20000\n",
      "gradient norm: 0.048534652742091566, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 12254 / 20000\n",
      "gradient norm: 0.061283486807951704, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 12255 / 20000\n",
      "gradient norm: 0.04664631752530113, minimum ratio: 2.4421052631578943\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 12256 / 20000\n",
      "gradient norm: 0.03910920050111599, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 12257 / 20000\n",
      "gradient norm: 0.0418887148698559, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 12258 / 20000\n",
      "gradient norm: 0.018669222816242836, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 12259 / 20000\n",
      "gradient norm: 0.045874655537772924, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 12260 / 20000\n",
      "gradient norm: 0.08153705357108265, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 12261 / 20000\n",
      "gradient norm: 0.060494217701489106, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 12262 / 20000\n",
      "gradient norm: 0.032761157053755596, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 12263 / 20000\n",
      "gradient norm: 0.10917293844977394, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 12264 / 20000\n",
      "gradient norm: 0.04238594573689625, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00551\n",
      "epoch 12265 / 20000\n",
      "gradient norm: 0.051706486905459315, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 12266 / 20000\n",
      "gradient norm: 0.016031346065574326, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 12267 / 20000\n",
      "gradient norm: 0.0523749528802, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 12268 / 20000\n",
      "gradient norm: 0.06425965085509233, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 12269 / 20000\n",
      "gradient norm: 0.05711576296016574, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 12270 / 20000\n",
      "gradient norm: 0.0850343318306841, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 12271 / 20000\n",
      "gradient norm: 0.05608515161293326, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 12272 / 20000\n",
      "gradient norm: 0.04598437316599302, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 12273 / 20000\n",
      "gradient norm: 0.09628004347905517, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 12274 / 20000\n",
      "gradient norm: 0.04242924648860935, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00551\n",
      "epoch 12275 / 20000\n",
      "gradient norm: 0.10238270158879459, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00551\n",
      "epoch 12276 / 20000\n",
      "gradient norm: 0.0979001895757392, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 12277 / 20000\n",
      "gradient norm: 0.10500482015777379, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 12278 / 20000\n",
      "gradient norm: 0.07724980916827917, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 12279 / 20000\n",
      "gradient norm: 0.04977118219539989, minimum ratio: 2.460526315789474\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 12280 / 20000\n",
      "gradient norm: 0.06758881424320862, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 12281 / 20000\n",
      "gradient norm: 0.05095038663421292, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 12282 / 20000\n",
      "gradient norm: 0.04625696764560416, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 12283 / 20000\n",
      "gradient norm: 0.08360085738240741, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 12284 / 20000\n",
      "gradient norm: 0.07746236464299727, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 12285 / 20000\n",
      "gradient norm: 0.04514525245758705, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 12286 / 20000\n",
      "gradient norm: 0.03555875597521663, minimum ratio: 2.4421052631578943\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 12287 / 20000\n",
      "gradient norm: 0.05856287249480374, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00554\n",
      "epoch 12288 / 20000\n",
      "gradient norm: 0.06693622365128249, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 12289 / 20000\n",
      "gradient norm: 0.07685863252845593, minimum ratio: 2.4394736842105265\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 12290 / 20000\n",
      "gradient norm: 0.034075971954734996, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 12291 / 20000\n",
      "gradient norm: 0.10513617179822177, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 12292 / 20000\n",
      "gradient norm: 0.07820000083302148, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00551\n",
      "epoch 12293 / 20000\n",
      "gradient norm: 0.11134279961697757, minimum ratio: 2.4421052631578943\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 12294 / 20000\n",
      "gradient norm: 0.059836000320501626, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 12295 / 20000\n",
      "gradient norm: 0.07322612509597093, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 12296 / 20000\n",
      "gradient norm: 0.09218366595450789, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 12297 / 20000\n",
      "gradient norm: 0.06609272037167102, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 12298 / 20000\n",
      "gradient norm: 0.07515174895524979, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 12299 / 20000\n",
      "gradient norm: 0.0600236477330327, minimum ratio: 2.4499999999999997\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 12300 / 20000\n",
      "gradient norm: 0.0786292107659392, minimum ratio: 2.4421052631578943\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 12301 / 20000\n",
      "gradient norm: 0.09588907600846142, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 12302 / 20000\n",
      "gradient norm: 0.10665946709923446, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 12303 / 20000\n",
      "gradient norm: 0.060505626461235806, minimum ratio: 2.4499999999999997\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 12304 / 20000\n",
      "gradient norm: 0.059198756178375334, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 12305 / 20000\n",
      "gradient norm: 0.10449722153134644, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 12306 / 20000\n",
      "gradient norm: 0.1284679729724303, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 12307 / 20000\n",
      "gradient norm: 0.1010610000230372, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 12308 / 20000\n",
      "gradient norm: 0.06891515757888556, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 12309 / 20000\n",
      "gradient norm: 0.1209300875198096, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 12310 / 20000\n",
      "gradient norm: 0.0947275172220543, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 12311 / 20000\n",
      "gradient norm: 0.09682696498930454, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 12312 / 20000\n",
      "gradient norm: 0.047123552416451275, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 12313 / 20000\n",
      "gradient norm: 0.056392167462036014, minimum ratio: 2.4236842105263157\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 12314 / 20000\n",
      "gradient norm: 0.11003152868943289, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 12315 / 20000\n",
      "gradient norm: 0.08871954990900122, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00551\n",
      "epoch 12316 / 20000\n",
      "gradient norm: 0.08030086525832303, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 12317 / 20000\n",
      "gradient norm: 0.02636346672079526, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 12318 / 20000\n",
      "gradient norm: 0.07080298097571358, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 12319 / 20000\n",
      "gradient norm: 0.09546854870859534, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 12320 / 20000\n",
      "gradient norm: 0.04401399150083307, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 12321 / 20000\n",
      "gradient norm: 0.10288000316359103, minimum ratio: 2.4289473684210523\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 12322 / 20000\n",
      "gradient norm: 0.06916028149134945, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 12323 / 20000\n",
      "gradient norm: 0.03067136276513338, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 12324 / 20000\n",
      "gradient norm: 0.05024180699547287, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 12325 / 20000\n",
      "gradient norm: 0.052276499758590944, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 12326 / 20000\n",
      "gradient norm: 0.03710033334209584, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 12327 / 20000\n",
      "gradient norm: 0.03585898905294016, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 12328 / 20000\n",
      "gradient norm: 0.033203972765477374, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 12329 / 20000\n",
      "gradient norm: 0.06794598803389817, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 12330 / 20000\n",
      "gradient norm: 0.06923338133492507, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 12331 / 20000\n",
      "gradient norm: 0.08153187233256176, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 12332 / 20000\n",
      "gradient norm: 0.06126806035172194, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 12333 / 20000\n",
      "gradient norm: 0.02857287702499889, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 12334 / 20000\n",
      "gradient norm: 0.07355718821054325, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 12335 / 20000\n",
      "gradient norm: 0.08628821815364063, minimum ratio: 2.418421052631579\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 12336 / 20000\n",
      "gradient norm: 0.08437796228099614, minimum ratio: 2.4394736842105265\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 12337 / 20000\n",
      "gradient norm: 0.04929008362523746, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 12338 / 20000\n",
      "gradient norm: 0.0568130872270558, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 12339 / 20000\n",
      "gradient norm: 0.08027572807623073, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 12340 / 20000\n",
      "gradient norm: 0.06063002842711285, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 12341 / 20000\n",
      "gradient norm: 0.05377923880587332, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 12342 / 20000\n",
      "gradient norm: 0.04476104769855738, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 12343 / 20000\n",
      "gradient norm: 0.04348882965859957, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 12344 / 20000\n",
      "gradient norm: 0.03730678471765714, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 12345 / 20000\n",
      "gradient norm: 0.10275319358333945, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 12346 / 20000\n",
      "gradient norm: 0.14183754345867783, minimum ratio: 2.4394736842105265\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 12347 / 20000\n",
      "gradient norm: 0.07586328269098885, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00551\n",
      "epoch 12348 / 20000\n",
      "gradient norm: 0.050803115154849365, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 12349 / 20000\n",
      "gradient norm: 0.06162339268485084, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 12350 / 20000\n",
      "gradient norm: 0.05850255012046546, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 12351 / 20000\n",
      "gradient norm: 0.11842611362226307, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00551\n",
      "epoch 12352 / 20000\n",
      "gradient norm: 0.08880107349250466, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 12353 / 20000\n",
      "gradient norm: 0.0645564976730384, minimum ratio: 2.460526315789474\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 12354 / 20000\n",
      "gradient norm: 0.06449148850515485, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 12355 / 20000\n",
      "gradient norm: 0.08675295003922656, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 12356 / 20000\n",
      "gradient norm: 0.06015783504699357, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00555\n",
      "epoch 12357 / 20000\n",
      "gradient norm: 0.05429691052995622, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 12358 / 20000\n",
      "gradient norm: 0.0469126118987333, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 12359 / 20000\n",
      "gradient norm: 0.10249870174448006, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 12360 / 20000\n",
      "gradient norm: 0.12392778892535716, minimum ratio: 2.4421052631578943\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00556\n",
      "epoch 12361 / 20000\n",
      "gradient norm: 0.04858327703550458, minimum ratio: 2.4236842105263157\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 12362 / 20000\n",
      "gradient norm: 0.07419072423363104, minimum ratio: 2.4421052631578943\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 12363 / 20000\n",
      "gradient norm: 0.0797298452234827, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 12364 / 20000\n",
      "gradient norm: 0.07534119446063414, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 12365 / 20000\n",
      "gradient norm: 0.07491061871405691, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 12366 / 20000\n",
      "gradient norm: 0.05286657967371866, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 12367 / 20000\n",
      "gradient norm: 0.09176789107732475, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 12368 / 20000\n",
      "gradient norm: 0.022250979745876975, minimum ratio: 2.418421052631579\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 12369 / 20000\n",
      "gradient norm: 0.040860964567400515, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 12370 / 20000\n",
      "gradient norm: 0.06462438416201621, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 12371 / 20000\n",
      "gradient norm: 0.10702644917182624, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 12372 / 20000\n",
      "gradient norm: 0.06680663366569206, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 12373 / 20000\n",
      "gradient norm: 0.09129617299186066, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 12374 / 20000\n",
      "gradient norm: 0.019682158177602105, minimum ratio: 2.4184210526315786\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 12375 / 20000\n",
      "gradient norm: 0.061663503031013533, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 12376 / 20000\n",
      "gradient norm: 0.10529134946409613, minimum ratio: 2.46578947368421\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 12377 / 20000\n",
      "gradient norm: 0.09438331190904137, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 12378 / 20000\n",
      "gradient norm: 0.05562202833243646, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 12379 / 20000\n",
      "gradient norm: 0.10200667343451641, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 12380 / 20000\n",
      "gradient norm: 0.04920617208699696, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 12381 / 20000\n",
      "gradient norm: 0.06258814345346764, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 12382 / 20000\n",
      "gradient norm: 0.059055056946817786, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 12383 / 20000\n",
      "gradient norm: 0.040081711660604924, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 12384 / 20000\n",
      "gradient norm: 0.02641643024981022, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 12385 / 20000\n",
      "gradient norm: 0.10654929850716144, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 12386 / 20000\n",
      "gradient norm: 0.028183208851260133, minimum ratio: 2.460526315789474\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 12387 / 20000\n",
      "gradient norm: 0.057984973886050284, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 12388 / 20000\n",
      "gradient norm: 0.06891173509939108, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 12389 / 20000\n",
      "gradient norm: 0.02987129069515504, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 12390 / 20000\n",
      "gradient norm: 0.05754808470373973, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 12391 / 20000\n",
      "gradient norm: 0.04035780887352303, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 12392 / 20000\n",
      "gradient norm: 0.03365633693465497, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 12393 / 20000\n",
      "gradient norm: 0.04523252256331034, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 12394 / 20000\n",
      "gradient norm: 0.08012929151300341, minimum ratio: 2.4394736842105265\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 12395 / 20000\n",
      "gradient norm: 0.04536798066692427, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 12396 / 20000\n",
      "gradient norm: 0.060957760841120034, minimum ratio: 2.4447368421052635\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 12397 / 20000\n",
      "gradient norm: 0.07759709589299746, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00551\n",
      "epoch 12398 / 20000\n",
      "gradient norm: 0.06648108299123123, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00554\n",
      "epoch 12399 / 20000\n",
      "gradient norm: 0.0699564152455423, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 12400 / 20000\n",
      "gradient norm: 0.08100596745498478, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00551\n",
      "epoch 12401 / 20000\n",
      "gradient norm: 0.06377424573292956, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 12402 / 20000\n",
      "gradient norm: 0.05135601502843201, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00553\n",
      "epoch 12403 / 20000\n",
      "gradient norm: 0.06556085258489475, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 12404 / 20000\n",
      "gradient norm: 0.050474470073822886, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 12405 / 20000\n",
      "gradient norm: 0.05859385326766642, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 12406 / 20000\n",
      "gradient norm: 0.12120892223902047, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 12407 / 20000\n",
      "gradient norm: 0.04436674316821154, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 12408 / 20000\n",
      "gradient norm: 0.0259633122041123, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 12409 / 20000\n",
      "gradient norm: 0.047124113072641194, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 12410 / 20000\n",
      "gradient norm: 0.052359589899424464, minimum ratio: 2.46578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 12411 / 20000\n",
      "gradient norm: 0.05032889900030568, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 12412 / 20000\n",
      "gradient norm: 0.04971353296423331, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 12413 / 20000\n",
      "gradient norm: 0.06908741884399205, minimum ratio: 2.4631578947368427\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 12414 / 20000\n",
      "gradient norm: 0.05992754126782529, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00554\n",
      "epoch 12415 / 20000\n",
      "gradient norm: 0.07828861195594072, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 12416 / 20000\n",
      "gradient norm: 0.03169911079748999, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 12417 / 20000\n",
      "gradient norm: 0.06077758013270795, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 12418 / 20000\n",
      "gradient norm: 0.09257708955556154, minimum ratio: 2.46578947368421\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00552\n",
      "epoch 12419 / 20000\n",
      "gradient norm: 0.03745551622705534, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 12420 / 20000\n",
      "gradient norm: 0.09027627619798295, minimum ratio: 2.4447368421052627\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 12421 / 20000\n",
      "gradient norm: 0.09228342660935596, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 12422 / 20000\n",
      "gradient norm: 0.057580585533287376, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 12423 / 20000\n",
      "gradient norm: 0.04316871322225779, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 12424 / 20000\n",
      "gradient norm: 0.059762864926597103, minimum ratio: 2.436842105263158\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 12425 / 20000\n",
      "gradient norm: 0.06114740725024603, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 12426 / 20000\n",
      "gradient norm: 0.0579535986908013, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 12427 / 20000\n",
      "gradient norm: 0.04179125383961946, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 12428 / 20000\n",
      "gradient norm: 0.03808037150884047, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 12429 / 20000\n",
      "gradient norm: 0.05949016392696649, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 12430 / 20000\n",
      "gradient norm: 0.08635842002695426, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 12431 / 20000\n",
      "gradient norm: 0.03883099583617877, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 12432 / 20000\n",
      "gradient norm: 0.07846532203257084, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 12433 / 20000\n",
      "gradient norm: 0.04234794717922341, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 12434 / 20000\n",
      "gradient norm: 0.06802359531866387, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 12435 / 20000\n",
      "gradient norm: 0.07250922867387999, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 12436 / 20000\n",
      "gradient norm: 0.11744878554600291, minimum ratio: 2.4394736842105265\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 12437 / 20000\n",
      "gradient norm: 0.09550332877552137, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 12438 / 20000\n",
      "gradient norm: 0.12812068581115454, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00555\n",
      "epoch 12439 / 20000\n",
      "gradient norm: 0.09340682293986902, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 12440 / 20000\n",
      "gradient norm: 0.09778687392827123, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 12441 / 20000\n",
      "gradient norm: 0.06366687425179407, minimum ratio: 2.4421052631578943\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 12442 / 20000\n",
      "gradient norm: 0.0682205226039514, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 12443 / 20000\n",
      "gradient norm: 0.04661559591477271, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00551\n",
      "epoch 12444 / 20000\n",
      "gradient norm: 0.09104519129323307, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 12445 / 20000\n",
      "gradient norm: 0.07449076202465221, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 12446 / 20000\n",
      "gradient norm: 0.039204755681566894, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 12447 / 20000\n",
      "gradient norm: 0.0864990308182314, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 12448 / 20000\n",
      "gradient norm: 0.06735244343872182, minimum ratio: 2.4236842105263157\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 12449 / 20000\n",
      "gradient norm: 0.04192905087256804, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 12450 / 20000\n",
      "gradient norm: 0.08468199748313054, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 12451 / 20000\n",
      "gradient norm: 0.04466953326482326, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 12452 / 20000\n",
      "gradient norm: 0.06080004229443148, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 12453 / 20000\n",
      "gradient norm: 0.09300382505171001, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00551\n",
      "epoch 12454 / 20000\n",
      "gradient norm: 0.07076438411604613, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 12455 / 20000\n",
      "gradient norm: 0.07096482574706897, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 12456 / 20000\n",
      "gradient norm: 0.0530885576736182, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 12457 / 20000\n",
      "gradient norm: 0.061832293547922745, minimum ratio: 2.4421052631578943\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 12458 / 20000\n",
      "gradient norm: 0.055142980185337365, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 12459 / 20000\n",
      "gradient norm: 0.07599318097345531, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 12460 / 20000\n",
      "gradient norm: 0.07524124963674694, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 12461 / 20000\n",
      "gradient norm: 0.0755671197839547, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 12462 / 20000\n",
      "gradient norm: 0.10813844233052805, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 12463 / 20000\n",
      "gradient norm: 0.06599140408798121, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 12464 / 20000\n",
      "gradient norm: 0.07035392834222876, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 12465 / 20000\n",
      "gradient norm: 0.0467122727422975, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 12466 / 20000\n",
      "gradient norm: 0.09357821405865252, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 12467 / 20000\n",
      "gradient norm: 0.0842472072399687, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 12468 / 20000\n",
      "gradient norm: 0.0713441971456632, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 12469 / 20000\n",
      "gradient norm: 0.03931166231632233, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 12470 / 20000\n",
      "gradient norm: 0.056450294388923794, minimum ratio: 2.4736842105263155\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 12471 / 20000\n",
      "gradient norm: 0.03384779058978893, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 12472 / 20000\n",
      "gradient norm: 0.06150950465234928, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 12473 / 20000\n",
      "gradient norm: 0.029460148805810604, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 12474 / 20000\n",
      "gradient norm: 0.07081533808377571, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 12475 / 20000\n",
      "gradient norm: 0.047713689447846264, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 12476 / 20000\n",
      "gradient norm: 0.033426987123675644, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 12477 / 20000\n",
      "gradient norm: 0.015376887538877781, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 12478 / 20000\n",
      "gradient norm: 0.10332333331461996, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 12479 / 20000\n",
      "gradient norm: 0.08371477123000659, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 12480 / 20000\n",
      "gradient norm: 0.0878997955005616, minimum ratio: 2.4394736842105265\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 12481 / 20000\n",
      "gradient norm: 0.07641423537279479, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 12482 / 20000\n",
      "gradient norm: 0.05975618469528854, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00551\n",
      "epoch 12483 / 20000\n",
      "gradient norm: 0.05906815661001019, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 12484 / 20000\n",
      "gradient norm: 0.06176386558217928, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 12485 / 20000\n",
      "gradient norm: 0.06011388829210773, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 12486 / 20000\n",
      "gradient norm: 0.05179804898216389, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 12487 / 20000\n",
      "gradient norm: 0.08320994791574776, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 12488 / 20000\n",
      "gradient norm: 0.08201031261705793, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 12489 / 20000\n",
      "gradient norm: 0.1011732395272702, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 12490 / 20000\n",
      "gradient norm: 0.06291636294918135, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 12491 / 20000\n",
      "gradient norm: 0.09115466964431107, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 12492 / 20000\n",
      "gradient norm: 0.05653446173528209, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 12493 / 20000\n",
      "gradient norm: 0.05798216490074992, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 12494 / 20000\n",
      "gradient norm: 0.04162599879782647, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 12495 / 20000\n",
      "gradient norm: 0.04892727348487824, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 12496 / 20000\n",
      "gradient norm: 0.07301167679543141, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 12497 / 20000\n",
      "gradient norm: 0.05591712283785455, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 12498 / 20000\n",
      "gradient norm: 0.0545036657131277, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 12499 / 20000\n",
      "gradient norm: 0.13522673887200654, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 12500 / 20000\n",
      "gradient norm: 0.032830542826559395, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 12501 / 20000\n",
      "gradient norm: 0.07646445580758154, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 12502 / 20000\n",
      "gradient norm: 0.07290358757018112, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 12503 / 20000\n",
      "gradient norm: 0.07261039986042306, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 12504 / 20000\n",
      "gradient norm: 0.09703803731827065, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 12505 / 20000\n",
      "gradient norm: 0.033954038728552405, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00551\n",
      "epoch 12506 / 20000\n",
      "gradient norm: 0.07010141073260456, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 12507 / 20000\n",
      "gradient norm: 0.06102499715052545, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 12508 / 20000\n",
      "gradient norm: 0.06789099733578041, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 12509 / 20000\n",
      "gradient norm: 0.09424219117499888, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 12510 / 20000\n",
      "gradient norm: 0.04182744977879338, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 12511 / 20000\n",
      "gradient norm: 0.055395646108081564, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 12512 / 20000\n",
      "gradient norm: 0.05418921960517764, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 12513 / 20000\n",
      "gradient norm: 0.07437287434004247, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 12514 / 20000\n",
      "gradient norm: 0.05211838550167158, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 12515 / 20000\n",
      "gradient norm: 0.08541109983343631, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 12516 / 20000\n",
      "gradient norm: 0.04150796917383559, minimum ratio: 2.4421052631578943\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 12517 / 20000\n",
      "gradient norm: 0.05449057373334654, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 12518 / 20000\n",
      "gradient norm: 0.0729992660926655, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 12519 / 20000\n",
      "gradient norm: 0.05046808364568278, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 12520 / 20000\n",
      "gradient norm: 0.0748354378156364, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 12521 / 20000\n",
      "gradient norm: 0.09776808039168827, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 12522 / 20000\n",
      "gradient norm: 0.05081092510954477, minimum ratio: 2.4394736842105265\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 12523 / 20000\n",
      "gradient norm: 0.07157101191114634, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 12524 / 20000\n",
      "gradient norm: 0.0460444780474063, minimum ratio: 2.4499999999999997\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 12525 / 20000\n",
      "gradient norm: 0.03200499789090827, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 12526 / 20000\n",
      "gradient norm: 0.028107296195230447, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 12527 / 20000\n",
      "gradient norm: 0.06668265513144433, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 12528 / 20000\n",
      "gradient norm: 0.10583182860864326, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 12529 / 20000\n",
      "gradient norm: 0.06569446856155992, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 12530 / 20000\n",
      "gradient norm: 0.11808845342602581, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 12531 / 20000\n",
      "gradient norm: 0.0738458926207386, minimum ratio: 2.4394736842105265\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00555\n",
      "epoch 12532 / 20000\n",
      "gradient norm: 0.047973410750273615, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 12533 / 20000\n",
      "gradient norm: 0.13010223326273263, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 12534 / 20000\n",
      "gradient norm: 0.07206452870741487, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 12535 / 20000\n",
      "gradient norm: 0.07623412902466953, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 12536 / 20000\n",
      "gradient norm: 0.04745342695969157, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 12537 / 20000\n",
      "gradient norm: 0.08671487265382893, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 12538 / 20000\n",
      "gradient norm: 0.035731798721826635, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 12539 / 20000\n",
      "gradient norm: 0.04467760067200288, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 12540 / 20000\n",
      "gradient norm: 0.04336313249950763, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 12541 / 20000\n",
      "gradient norm: 0.06471158459316939, minimum ratio: 2.4263157894736844\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 12542 / 20000\n",
      "gradient norm: 0.041767494374653324, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 12543 / 20000\n",
      "gradient norm: 0.021245376410661265, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 12544 / 20000\n",
      "gradient norm: 0.09213282485143282, minimum ratio: 2.46578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 12545 / 20000\n",
      "gradient norm: 0.03200692660175264, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 12546 / 20000\n",
      "gradient norm: 0.04534223797963932, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 12547 / 20000\n",
      "gradient norm: 0.07249840389704332, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 12548 / 20000\n",
      "gradient norm: 0.10820742993382737, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00552\n",
      "epoch 12549 / 20000\n",
      "gradient norm: 0.07264686812413856, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 12550 / 20000\n",
      "gradient norm: 0.04071404106798582, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 12551 / 20000\n",
      "gradient norm: 0.06978043273556978, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00551\n",
      "epoch 12552 / 20000\n",
      "gradient norm: 0.07730582402655273, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 12553 / 20000\n",
      "gradient norm: 0.047415752604138106, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 12554 / 20000\n",
      "gradient norm: 0.04853878077119589, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 12555 / 20000\n",
      "gradient norm: 0.04858595202676952, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 12556 / 20000\n",
      "gradient norm: 0.054374112689401954, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 12557 / 20000\n",
      "gradient norm: 0.039153577032266185, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 12558 / 20000\n",
      "gradient norm: 0.07075624173739925, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 12559 / 20000\n",
      "gradient norm: 0.047585202803020366, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 12560 / 20000\n",
      "gradient norm: 0.038398178381612524, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 12561 / 20000\n",
      "gradient norm: 0.05726283404510468, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 12562 / 20000\n",
      "gradient norm: 0.08542770869098604, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 12563 / 20000\n",
      "gradient norm: 0.05221577431075275, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 12564 / 20000\n",
      "gradient norm: 0.0659037558361888, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 12565 / 20000\n",
      "gradient norm: 0.035894959699362516, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 12566 / 20000\n",
      "gradient norm: 0.06747044698568061, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 12567 / 20000\n",
      "gradient norm: 0.062440899200737476, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 12568 / 20000\n",
      "gradient norm: 0.08666857989737764, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 12569 / 20000\n",
      "gradient norm: 0.08845224924152717, minimum ratio: 2.4736842105263155\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 12570 / 20000\n",
      "gradient norm: 0.06338433409109712, minimum ratio: 2.4868421052631575\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 12571 / 20000\n",
      "gradient norm: 0.05116864095907658, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 12572 / 20000\n",
      "gradient norm: 0.06762405572226271, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 12573 / 20000\n",
      "gradient norm: 0.08830981169012375, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 12574 / 20000\n",
      "gradient norm: 0.019215865613659844, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 12575 / 20000\n",
      "gradient norm: 0.08846643206197768, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 12576 / 20000\n",
      "gradient norm: 0.060951154853682965, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 12577 / 20000\n",
      "gradient norm: 0.04146142251556739, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 12578 / 20000\n",
      "gradient norm: 0.0868413649732247, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 12579 / 20000\n",
      "gradient norm: 0.07771001319633797, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 12580 / 20000\n",
      "gradient norm: 0.0482969284084902, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 12581 / 20000\n",
      "gradient norm: 0.04054395473212935, minimum ratio: 2.4447368421052635\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 12582 / 20000\n",
      "gradient norm: 0.10166339110583067, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 12583 / 20000\n",
      "gradient norm: 0.03509961722011212, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 12584 / 20000\n",
      "gradient norm: 0.04185460152802989, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 12585 / 20000\n",
      "gradient norm: 0.0317720372840995, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 12586 / 20000\n",
      "gradient norm: 0.030379571850062348, minimum ratio: 2.4894736842105267\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 12587 / 20000\n",
      "gradient norm: 0.03741851725499146, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 12588 / 20000\n",
      "gradient norm: 0.05325864831684157, minimum ratio: 2.460526315789474\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 12589 / 20000\n",
      "gradient norm: 0.021495391716598533, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 12590 / 20000\n",
      "gradient norm: 0.09402753133326769, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 12591 / 20000\n",
      "gradient norm: 0.07760527663049288, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 12592 / 20000\n",
      "gradient norm: 0.031772995309438556, minimum ratio: 2.46578947368421\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 12593 / 20000\n",
      "gradient norm: 0.056009618332609534, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 12594 / 20000\n",
      "gradient norm: 0.053415626563946716, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 12595 / 20000\n",
      "gradient norm: 0.046037673178943805, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 12596 / 20000\n",
      "gradient norm: 0.04104029948939569, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 12597 / 20000\n",
      "gradient norm: 0.038125269376905635, minimum ratio: 2.423684210526316\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 12598 / 20000\n",
      "gradient norm: 0.0641817063005874, minimum ratio: 2.46578947368421\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 12599 / 20000\n",
      "gradient norm: 0.09438138676341623, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 12600 / 20000\n",
      "gradient norm: 0.11624779424164444, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 12601 / 20000\n",
      "gradient norm: 0.0486058467940893, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 12602 / 20000\n",
      "gradient norm: 0.0855629169382155, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00554\n",
      "epoch 12603 / 20000\n",
      "gradient norm: 0.07818464888259768, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 12604 / 20000\n",
      "gradient norm: 0.05587144927994814, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 12605 / 20000\n",
      "gradient norm: 0.05912909051403403, minimum ratio: 2.4578947368421056\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 12606 / 20000\n",
      "gradient norm: 0.042309841490350664, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 12607 / 20000\n",
      "gradient norm: 0.041803640575380996, minimum ratio: 2.4210526315789473\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 12608 / 20000\n",
      "gradient norm: 0.041049362043850124, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 12609 / 20000\n",
      "gradient norm: 0.07528315734816715, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 12610 / 20000\n",
      "gradient norm: 0.05042652934207581, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 12611 / 20000\n",
      "gradient norm: 0.05836193051072769, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 12612 / 20000\n",
      "gradient norm: 0.03579082705255132, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 12613 / 20000\n",
      "gradient norm: 0.0365834022522904, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 12614 / 20000\n",
      "gradient norm: 0.05319263821002096, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 12615 / 20000\n",
      "gradient norm: 0.067469306581188, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 12616 / 20000\n",
      "gradient norm: 0.06231146975187585, minimum ratio: 2.436842105263158\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 12617 / 20000\n",
      "gradient norm: 0.08742707406054251, minimum ratio: 2.436842105263158\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00551\n",
      "epoch 12618 / 20000\n",
      "gradient norm: 0.04286578393657692, minimum ratio: 2.4578947368421056\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 12619 / 20000\n",
      "gradient norm: 0.07501971581950784, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00554\n",
      "epoch 12620 / 20000\n",
      "gradient norm: 0.0731214775441913, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 12621 / 20000\n",
      "gradient norm: 0.09672132483683527, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 12622 / 20000\n",
      "gradient norm: 0.05689191952114925, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00554\n",
      "epoch 12623 / 20000\n",
      "gradient norm: 0.042456596755073406, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 12624 / 20000\n",
      "gradient norm: 0.05251214205054566, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 12625 / 20000\n",
      "gradient norm: 0.022460885520558804, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 12626 / 20000\n",
      "gradient norm: 0.040797947032842785, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 12627 / 20000\n",
      "gradient norm: 0.06537388439755887, minimum ratio: 2.418421052631579\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 12628 / 20000\n",
      "gradient norm: 0.06000793821294792, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 12629 / 20000\n",
      "gradient norm: 0.04156677454011515, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 12630 / 20000\n",
      "gradient norm: 0.10005774104502052, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 12631 / 20000\n",
      "gradient norm: 0.06411650404334068, minimum ratio: 2.4421052631578943\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 12632 / 20000\n",
      "gradient norm: 0.030962077260483056, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 12633 / 20000\n",
      "gradient norm: 0.06748012674506754, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 12634 / 20000\n",
      "gradient norm: 0.052487394656054676, minimum ratio: 2.460526315789474\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 12635 / 20000\n",
      "gradient norm: 0.03803906188113615, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 12636 / 20000\n",
      "gradient norm: 0.04380750632844865, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 12637 / 20000\n",
      "gradient norm: 0.03646437427960336, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 12638 / 20000\n",
      "gradient norm: 0.04632761172251776, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 12639 / 20000\n",
      "gradient norm: 0.06194753077579662, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 12640 / 20000\n",
      "gradient norm: 0.07592313693021424, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 12641 / 20000\n",
      "gradient norm: 0.043272807786706835, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 12642 / 20000\n",
      "gradient norm: 0.04905413213418797, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 12643 / 20000\n",
      "gradient norm: 0.07938796147936955, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 12644 / 20000\n",
      "gradient norm: 0.10327103489544243, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 12645 / 20000\n",
      "gradient norm: 0.028333782669506036, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00553\n",
      "epoch 12646 / 20000\n",
      "gradient norm: 0.08484110468998551, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00553\n",
      "epoch 12647 / 20000\n",
      "gradient norm: 0.047790970449568704, minimum ratio: 2.4157894736842107\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 12648 / 20000\n",
      "gradient norm: 0.06602119043236598, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 12649 / 20000\n",
      "gradient norm: 0.09347251569852233, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 12650 / 20000\n",
      "gradient norm: 0.028081780183129013, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 12651 / 20000\n",
      "gradient norm: 0.03939546609763056, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00565\n",
      "\tval loss: 0.00551\n",
      "epoch 12652 / 20000\n",
      "gradient norm: 0.051413885317742825, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 12653 / 20000\n",
      "gradient norm: 0.050290056999074295, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 12654 / 20000\n",
      "gradient norm: 0.04691810875374358, minimum ratio: 2.4394736842105265\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00552\n",
      "epoch 12655 / 20000\n",
      "gradient norm: 0.054487028712173924, minimum ratio: 2.46578947368421\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 12656 / 20000\n",
      "gradient norm: 0.06134611100424081, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 12657 / 20000\n",
      "gradient norm: 0.04738227088819258, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 12658 / 20000\n",
      "gradient norm: 0.10603797191288322, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 12659 / 20000\n",
      "gradient norm: 0.07524162449408323, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 12660 / 20000\n",
      "gradient norm: 0.07617779064457864, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 12661 / 20000\n",
      "gradient norm: 0.08345127891516313, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 12662 / 20000\n",
      "gradient norm: 0.059295651473803446, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 12663 / 20000\n",
      "gradient norm: 0.07544533823238453, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 12664 / 20000\n",
      "gradient norm: 0.052594678913010284, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 12665 / 20000\n",
      "gradient norm: 0.0809159314376302, minimum ratio: 2.4421052631578943\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 12666 / 20000\n",
      "gradient norm: 0.05797269713366404, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 12667 / 20000\n",
      "gradient norm: 0.03919861273607239, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 12668 / 20000\n",
      "gradient norm: 0.06733775856264401, minimum ratio: 2.4263157894736844\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 12669 / 20000\n",
      "gradient norm: 0.05521164483798202, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 12670 / 20000\n",
      "gradient norm: 0.0906957674305886, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 12671 / 20000\n",
      "gradient norm: 0.07399053772678599, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 12672 / 20000\n",
      "gradient norm: 0.07044558427878655, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 12673 / 20000\n",
      "gradient norm: 0.031218420510413125, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 12674 / 20000\n",
      "gradient norm: 0.036757569236215204, minimum ratio: 2.4578947368421056\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 12675 / 20000\n",
      "gradient norm: 0.036013624659972265, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 12676 / 20000\n",
      "gradient norm: 0.06559104967163876, minimum ratio: 2.4684210526315784\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 12677 / 20000\n",
      "gradient norm: 0.0528273102681851, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 12678 / 20000\n",
      "gradient norm: 0.0324630769318901, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 12679 / 20000\n",
      "gradient norm: 0.06839612103067338, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 12680 / 20000\n",
      "gradient norm: 0.08116564573720098, minimum ratio: 2.4684210526315784\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 12681 / 20000\n",
      "gradient norm: 0.07549931947141886, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 12682 / 20000\n",
      "gradient norm: 0.041954087908379734, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 12683 / 20000\n",
      "gradient norm: 0.06776492253993638, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 12684 / 20000\n",
      "gradient norm: 0.06288928061439947, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 12685 / 20000\n",
      "gradient norm: 0.07294597187137697, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 12686 / 20000\n",
      "gradient norm: 0.031546746962703764, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 12687 / 20000\n",
      "gradient norm: 0.06380559841636568, minimum ratio: 2.4394736842105265\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00551\n",
      "epoch 12688 / 20000\n",
      "gradient norm: 0.07611889904364944, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 12689 / 20000\n",
      "gradient norm: 0.06905235920567065, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00554\n",
      "epoch 12690 / 20000\n",
      "gradient norm: 0.05057778977788985, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 12691 / 20000\n",
      "gradient norm: 0.04712070542154834, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 12692 / 20000\n",
      "gradient norm: 0.1014130909461528, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 12693 / 20000\n",
      "gradient norm: 0.07490001164842397, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 12694 / 20000\n",
      "gradient norm: 0.05131723830709234, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 12695 / 20000\n",
      "gradient norm: 0.055823289323598146, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 12696 / 20000\n",
      "gradient norm: 0.051242168294265866, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 12697 / 20000\n",
      "gradient norm: 0.05598770757205784, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 12698 / 20000\n",
      "gradient norm: 0.06270697590662166, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 12699 / 20000\n",
      "gradient norm: 0.033364314935170114, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 12700 / 20000\n",
      "gradient norm: 0.07628919917624444, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 12701 / 20000\n",
      "gradient norm: 0.054734879995521624, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 12702 / 20000\n",
      "gradient norm: 0.06925036531174555, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 12703 / 20000\n",
      "gradient norm: 0.04454822612387943, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 12704 / 20000\n",
      "gradient norm: 0.096771391981747, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 12705 / 20000\n",
      "gradient norm: 0.039409680874086916, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 12706 / 20000\n",
      "gradient norm: 0.06522174041310791, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 12707 / 20000\n",
      "gradient norm: 0.07710040829260834, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 12708 / 20000\n",
      "gradient norm: 0.05875578208360821, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 12709 / 20000\n",
      "gradient norm: 0.044125707499915734, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 12710 / 20000\n",
      "gradient norm: 0.05937057069968432, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 12711 / 20000\n",
      "gradient norm: 0.07044929431867786, minimum ratio: 2.4263157894736844\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 12712 / 20000\n",
      "gradient norm: 0.04716609881143086, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 12713 / 20000\n",
      "gradient norm: 0.05328823302988894, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 12714 / 20000\n",
      "gradient norm: 0.08414516784250736, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 12715 / 20000\n",
      "gradient norm: 0.0358740629744716, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00553\n",
      "epoch 12716 / 20000\n",
      "gradient norm: 0.07746306655462831, minimum ratio: 2.4236842105263157\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 12717 / 20000\n",
      "gradient norm: 0.03342212224379182, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 12718 / 20000\n",
      "gradient norm: 0.038294335769023746, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 12719 / 20000\n",
      "gradient norm: 0.08428125926002394, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 12720 / 20000\n",
      "gradient norm: 0.031579378606693354, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 12721 / 20000\n",
      "gradient norm: 0.04133017288404517, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 12722 / 20000\n",
      "gradient norm: 0.09535792528185993, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00554\n",
      "epoch 12723 / 20000\n",
      "gradient norm: 0.05220539536094293, minimum ratio: 2.4421052631578943\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00551\n",
      "epoch 12724 / 20000\n",
      "gradient norm: 0.12224429834168404, minimum ratio: 2.4157894736842107\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00551\n",
      "epoch 12725 / 20000\n",
      "gradient norm: 0.03830369611387141, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00555\n",
      "epoch 12726 / 20000\n",
      "gradient norm: 0.0708604998071678, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 12727 / 20000\n",
      "gradient norm: 0.06944850134459557, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 12728 / 20000\n",
      "gradient norm: 0.05246057649492286, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 12729 / 20000\n",
      "gradient norm: 0.03223190893186256, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 12730 / 20000\n",
      "gradient norm: 0.06343907944392413, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00553\n",
      "epoch 12731 / 20000\n",
      "gradient norm: 0.033903733994520735, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 12732 / 20000\n",
      "gradient norm: 0.06522493128431961, minimum ratio: 2.4236842105263157\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 12733 / 20000\n",
      "gradient norm: 0.08324652386363596, minimum ratio: 2.4499999999999997\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00555\n",
      "epoch 12734 / 20000\n",
      "gradient norm: 0.0626583129633218, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 12735 / 20000\n",
      "gradient norm: 0.06693589457427152, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 12736 / 20000\n",
      "gradient norm: 0.09676632919581607, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00555\n",
      "epoch 12737 / 20000\n",
      "gradient norm: 0.07972376781981438, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 12738 / 20000\n",
      "gradient norm: 0.09195930868736468, minimum ratio: 2.465789473684211\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 12739 / 20000\n",
      "gradient norm: 0.06543859804514796, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 12740 / 20000\n",
      "gradient norm: 0.12034920125734061, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 12741 / 20000\n",
      "gradient norm: 0.030564336659153923, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 12742 / 20000\n",
      "gradient norm: 0.05428954883245751, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 12743 / 20000\n",
      "gradient norm: 0.06557596771745011, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 12744 / 20000\n",
      "gradient norm: 0.06689175780047663, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 12745 / 20000\n",
      "gradient norm: 0.09462581615662202, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00551\n",
      "epoch 12746 / 20000\n",
      "gradient norm: 0.030850153911160305, minimum ratio: 2.4499999999999997\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 12747 / 20000\n",
      "gradient norm: 0.0862618992687203, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 12748 / 20000\n",
      "gradient norm: 0.03954035139759071, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 12749 / 20000\n",
      "gradient norm: 0.05827673012390733, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 12750 / 20000\n",
      "gradient norm: 0.0758245483157225, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00554\n",
      "epoch 12751 / 20000\n",
      "gradient norm: 0.07826486934209242, minimum ratio: 2.4263157894736844\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 12752 / 20000\n",
      "gradient norm: 0.07098242177744396, minimum ratio: 2.4289473684210523\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 12753 / 20000\n",
      "gradient norm: 0.03477576607838273, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 12754 / 20000\n",
      "gradient norm: 0.0819748395588249, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00554\n",
      "epoch 12755 / 20000\n",
      "gradient norm: 0.09012928139418364, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 12756 / 20000\n",
      "gradient norm: 0.0683562807389535, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 12757 / 20000\n",
      "gradient norm: 0.05439156020293012, minimum ratio: 2.4394736842105265\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 12758 / 20000\n",
      "gradient norm: 0.07539891637861729, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00554\n",
      "epoch 12759 / 20000\n",
      "gradient norm: 0.04781441614613868, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 12760 / 20000\n",
      "gradient norm: 0.07626891217660159, minimum ratio: 2.4447368421052627\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 12761 / 20000\n",
      "gradient norm: 0.03058182605309412, minimum ratio: 2.4157894736842103\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00554\n",
      "epoch 12762 / 20000\n",
      "gradient norm: 0.1084513796668034, minimum ratio: 2.4421052631578943\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 12763 / 20000\n",
      "gradient norm: 0.0885120501043275, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 12764 / 20000\n",
      "gradient norm: 0.01868430407193955, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 12765 / 20000\n",
      "gradient norm: 0.0354562183492817, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 12766 / 20000\n",
      "gradient norm: 0.07292183540994301, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 12767 / 20000\n",
      "gradient norm: 0.03152197023155168, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 12768 / 20000\n",
      "gradient norm: 0.08304388303076848, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 12769 / 20000\n",
      "gradient norm: 0.0762471369234845, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 12770 / 20000\n",
      "gradient norm: 0.046875183121301234, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 12771 / 20000\n",
      "gradient norm: 0.09243282931856811, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 12772 / 20000\n",
      "gradient norm: 0.09162312495755032, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 12773 / 20000\n",
      "gradient norm: 0.04077975213294849, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 12774 / 20000\n",
      "gradient norm: 0.13036275119520724, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 12775 / 20000\n",
      "gradient norm: 0.06136578036239371, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00555\n",
      "epoch 12776 / 20000\n",
      "gradient norm: 0.046338172804098576, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 12777 / 20000\n",
      "gradient norm: 0.07388434384483844, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 12778 / 20000\n",
      "gradient norm: 0.05753531970549375, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 12779 / 20000\n",
      "gradient norm: 0.06837472054758109, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 12780 / 20000\n",
      "gradient norm: 0.08135796585702337, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 12781 / 20000\n",
      "gradient norm: 0.02519376431882847, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 12782 / 20000\n",
      "gradient norm: 0.05847725452622399, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 12783 / 20000\n",
      "gradient norm: 0.027663966844556853, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 12784 / 20000\n",
      "gradient norm: 0.059518769732676446, minimum ratio: 2.436842105263158\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 12785 / 20000\n",
      "gradient norm: 0.05648286343785003, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 12786 / 20000\n",
      "gradient norm: 0.06906351895304397, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 12787 / 20000\n",
      "gradient norm: 0.11780160549096763, minimum ratio: 2.436842105263158\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 12788 / 20000\n",
      "gradient norm: 0.12344848446082324, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 12789 / 20000\n",
      "gradient norm: 0.052101219771429896, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 12790 / 20000\n",
      "gradient norm: 0.0558011278626509, minimum ratio: 2.4263157894736844\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 12791 / 20000\n",
      "gradient norm: 0.05493513005785644, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 12792 / 20000\n",
      "gradient norm: 0.056709355252678506, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 12793 / 20000\n",
      "gradient norm: 0.08657764724921435, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 12794 / 20000\n",
      "gradient norm: 0.10823555151000619, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 12795 / 20000\n",
      "gradient norm: 0.07788480981253088, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 12796 / 20000\n",
      "gradient norm: 0.044494799396488816, minimum ratio: 2.46578947368421\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 12797 / 20000\n",
      "gradient norm: 0.06788327742833644, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 12798 / 20000\n",
      "gradient norm: 0.012937841165694408, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 12799 / 20000\n",
      "gradient norm: 0.11120439498336054, minimum ratio: 2.465789473684211\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 12800 / 20000\n",
      "gradient norm: 0.04581059954944067, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 12801 / 20000\n",
      "gradient norm: 0.04929846482264111, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 12802 / 20000\n",
      "gradient norm: 0.047910606663208455, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 12803 / 20000\n",
      "gradient norm: 0.04195456278102938, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 12804 / 20000\n",
      "gradient norm: 0.07395636514411308, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 12805 / 20000\n",
      "gradient norm: 0.10679476411314681, minimum ratio: 2.452631578947368\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00551\n",
      "epoch 12806 / 20000\n",
      "gradient norm: 0.08140515291597694, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 12807 / 20000\n",
      "gradient norm: 0.032063975027995184, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 12808 / 20000\n",
      "gradient norm: 0.04179735662182793, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 12809 / 20000\n",
      "gradient norm: 0.09973738738335669, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 12810 / 20000\n",
      "gradient norm: 0.06784650817280635, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 12811 / 20000\n",
      "gradient norm: 0.06367108557606116, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 12812 / 20000\n",
      "gradient norm: 0.11545453261351213, minimum ratio: 2.447368421052631\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 12813 / 20000\n",
      "gradient norm: 0.11130295204930007, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 12814 / 20000\n",
      "gradient norm: 0.048373403027653694, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 12815 / 20000\n",
      "gradient norm: 0.050677208477281965, minimum ratio: 2.4394736842105265\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 12816 / 20000\n",
      "gradient norm: 0.04185291679459624, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 12817 / 20000\n",
      "gradient norm: 0.040736525756074116, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 12818 / 20000\n",
      "gradient norm: 0.08320856839418411, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 12819 / 20000\n",
      "gradient norm: 0.06131299113621935, minimum ratio: 2.4289473684210523\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 12820 / 20000\n",
      "gradient norm: 0.04076377180899726, minimum ratio: 2.4210526315789473\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 12821 / 20000\n",
      "gradient norm: 0.06618680417886935, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 12822 / 20000\n",
      "gradient norm: 0.04193258142913692, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 12823 / 20000\n",
      "gradient norm: 0.06205425306688994, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 12824 / 20000\n",
      "gradient norm: 0.09421118212048896, minimum ratio: 2.4842105263157896\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 12825 / 20000\n",
      "gradient norm: 0.03535059840942267, minimum ratio: 2.4394736842105265\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 12826 / 20000\n",
      "gradient norm: 0.050973898702068254, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00553\n",
      "epoch 12827 / 20000\n",
      "gradient norm: 0.06565623759524897, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 12828 / 20000\n",
      "gradient norm: 0.06110569735756144, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 12829 / 20000\n",
      "gradient norm: 0.05140107305487618, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 12830 / 20000\n",
      "gradient norm: 0.06588924513198435, minimum ratio: 2.4236842105263157\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 12831 / 20000\n",
      "gradient norm: 0.10015702270902693, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 12832 / 20000\n",
      "gradient norm: 0.024450016324408352, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 12833 / 20000\n",
      "gradient norm: 0.06332178312004544, minimum ratio: 2.4394736842105265\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 12834 / 20000\n",
      "gradient norm: 0.08586723287589848, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 12835 / 20000\n",
      "gradient norm: 0.10696451331023127, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 12836 / 20000\n",
      "gradient norm: 0.09479425239260308, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 12837 / 20000\n",
      "gradient norm: 0.019378109485842288, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 12838 / 20000\n",
      "gradient norm: 0.031165643042186275, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 12839 / 20000\n",
      "gradient norm: 0.059282305010128766, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 12840 / 20000\n",
      "gradient norm: 0.061740113800624385, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 12841 / 20000\n",
      "gradient norm: 0.08762681134976447, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 12842 / 20000\n",
      "gradient norm: 0.05474490110646002, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 12843 / 20000\n",
      "gradient norm: 0.0681710211247264, minimum ratio: 2.4499999999999997\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 12844 / 20000\n",
      "gradient norm: 0.05303249670396326, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 12845 / 20000\n",
      "gradient norm: 0.10046477857395075, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 12846 / 20000\n",
      "gradient norm: 0.040735438393312506, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 12847 / 20000\n",
      "gradient norm: 0.04984486510511488, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 12848 / 20000\n",
      "gradient norm: 0.028168325748993084, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 12849 / 20000\n",
      "gradient norm: 0.0772288660518825, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 12850 / 20000\n",
      "gradient norm: 0.036356731958221644, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00554\n",
      "epoch 12851 / 20000\n",
      "gradient norm: 0.05624764016829431, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 12852 / 20000\n",
      "gradient norm: 0.07015720452181995, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00551\n",
      "epoch 12853 / 20000\n",
      "gradient norm: 0.057341576350154355, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 12854 / 20000\n",
      "gradient norm: 0.0466715891379863, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00554\n",
      "epoch 12855 / 20000\n",
      "gradient norm: 0.07811582728754729, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 12856 / 20000\n",
      "gradient norm: 0.0288031933887396, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 12857 / 20000\n",
      "gradient norm: 0.019625656423158944, minimum ratio: 2.4394736842105265\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 12858 / 20000\n",
      "gradient norm: 0.06021727860206738, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 12859 / 20000\n",
      "gradient norm: 0.04006806138204411, minimum ratio: 2.4157894736842103\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 12860 / 20000\n",
      "gradient norm: 0.06316349847475067, minimum ratio: 2.4499999999999997\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 12861 / 20000\n",
      "gradient norm: 0.07968984363833442, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 12862 / 20000\n",
      "gradient norm: 0.03306351479841396, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00551\n",
      "epoch 12863 / 20000\n",
      "gradient norm: 0.07779999851481989, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 12864 / 20000\n",
      "gradient norm: 0.08496781531721354, minimum ratio: 2.421052631578947\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 12865 / 20000\n",
      "gradient norm: 0.05316447495351895, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 12866 / 20000\n",
      "gradient norm: 0.025949428862077184, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 12867 / 20000\n",
      "gradient norm: 0.06741749015054666, minimum ratio: 2.4394736842105265\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 12868 / 20000\n",
      "gradient norm: 0.05969655036460608, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 12869 / 20000\n",
      "gradient norm: 0.047509020660072565, minimum ratio: 2.447368421052631\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 12870 / 20000\n",
      "gradient norm: 0.05200549817527644, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 12871 / 20000\n",
      "gradient norm: 0.10204882925609127, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 12872 / 20000\n",
      "gradient norm: 0.038953759874857496, minimum ratio: 2.46578947368421\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 12873 / 20000\n",
      "gradient norm: 0.09840412065386772, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 12874 / 20000\n",
      "gradient norm: 0.08328468474792317, minimum ratio: 2.4499999999999997\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 12875 / 20000\n",
      "gradient norm: 0.06697492231614888, minimum ratio: 2.4394736842105265\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 12876 / 20000\n",
      "gradient norm: 0.13123406772501767, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 12877 / 20000\n",
      "gradient norm: 0.05367595230927691, minimum ratio: 2.4447368421052635\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 12878 / 20000\n",
      "gradient norm: 0.07266202862956561, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 12879 / 20000\n",
      "gradient norm: 0.0413147967774421, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 12880 / 20000\n",
      "gradient norm: 0.04790228296769783, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 12881 / 20000\n",
      "gradient norm: 0.04244580373051576, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 12882 / 20000\n",
      "gradient norm: 0.05756023380672559, minimum ratio: 2.4394736842105265\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 12883 / 20000\n",
      "gradient norm: 0.03291177816572599, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 12884 / 20000\n",
      "gradient norm: 0.06058593199122697, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 12885 / 20000\n",
      "gradient norm: 0.05613737506791949, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 12886 / 20000\n",
      "gradient norm: 0.04264495510869892, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 12887 / 20000\n",
      "gradient norm: 0.06919260827999096, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 12888 / 20000\n",
      "gradient norm: 0.05739324503520038, minimum ratio: 2.46578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 12889 / 20000\n",
      "gradient norm: 0.07265253079822287, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 12890 / 20000\n",
      "gradient norm: 0.01721419914974831, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 12891 / 20000\n",
      "gradient norm: 0.09180832956917584, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 12892 / 20000\n",
      "gradient norm: 0.03409794651088305, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00551\n",
      "epoch 12893 / 20000\n",
      "gradient norm: 0.04839527388685383, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 12894 / 20000\n",
      "gradient norm: 0.03787344277952798, minimum ratio: 2.4394736842105265\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 12895 / 20000\n",
      "gradient norm: 0.06526108412072062, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 12896 / 20000\n",
      "gradient norm: 0.05488989769946784, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 12897 / 20000\n",
      "gradient norm: 0.06267403089441359, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 12898 / 20000\n",
      "gradient norm: 0.07132353444467299, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 12899 / 20000\n",
      "gradient norm: 0.0625884320033947, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 12900 / 20000\n",
      "gradient norm: 0.0340501005994156, minimum ratio: 2.4394736842105265\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 12901 / 20000\n",
      "gradient norm: 0.03628640092210844, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 12902 / 20000\n",
      "gradient norm: 0.044946610811166465, minimum ratio: 2.4421052631578943\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 12903 / 20000\n",
      "gradient norm: 0.11372289317660034, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 12904 / 20000\n",
      "gradient norm: 0.07214873578050174, minimum ratio: 2.4868421052631575\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 12905 / 20000\n",
      "gradient norm: 0.03427855542395264, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 12906 / 20000\n",
      "gradient norm: 0.06124913942767307, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 12907 / 20000\n",
      "gradient norm: 0.05504534090869129, minimum ratio: 2.4578947368421056\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 12908 / 20000\n",
      "gradient norm: 0.07656764681451023, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 12909 / 20000\n",
      "gradient norm: 0.10385624959599227, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 12910 / 20000\n",
      "gradient norm: 0.060235432581976056, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00553\n",
      "epoch 12911 / 20000\n",
      "gradient norm: 0.05392432305961847, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 12912 / 20000\n",
      "gradient norm: 0.057539778732461855, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 12913 / 20000\n",
      "gradient norm: 0.08527685987064615, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 12914 / 20000\n",
      "gradient norm: 0.0699814057443291, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 12915 / 20000\n",
      "gradient norm: 0.04664767213398591, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 12916 / 20000\n",
      "gradient norm: 0.0361196865378588, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 12917 / 20000\n",
      "gradient norm: 0.05436029121847241, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 12918 / 20000\n",
      "gradient norm: 0.04727824646397494, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 12919 / 20000\n",
      "gradient norm: 0.1205848466779571, minimum ratio: 2.4289473684210523\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 12920 / 20000\n",
      "gradient norm: 0.026184477072092704, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 12921 / 20000\n",
      "gradient norm: 0.0392748767771991, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 12922 / 20000\n",
      "gradient norm: 0.06284785497700796, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 12923 / 20000\n",
      "gradient norm: 0.055797963141230866, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00554\n",
      "epoch 12924 / 20000\n",
      "gradient norm: 0.024258499266579747, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 12925 / 20000\n",
      "gradient norm: 0.08186141203623265, minimum ratio: 2.452631578947368\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 12926 / 20000\n",
      "gradient norm: 0.048517069226363674, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 12927 / 20000\n",
      "gradient norm: 0.08828029269352555, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 12928 / 20000\n",
      "gradient norm: 0.06978878707741387, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 12929 / 20000\n",
      "gradient norm: 0.06647884682752192, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 12930 / 20000\n",
      "gradient norm: 0.08656291062652599, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 12931 / 20000\n",
      "gradient norm: 0.05848657590104267, minimum ratio: 2.4263157894736844\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 12932 / 20000\n",
      "gradient norm: 0.019312727672513574, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 12933 / 20000\n",
      "gradient norm: 0.10055667511187494, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 12934 / 20000\n",
      "gradient norm: 0.06465513829607517, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 12935 / 20000\n",
      "gradient norm: 0.022730239579686895, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 12936 / 20000\n",
      "gradient norm: 0.08856267982628196, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 12937 / 20000\n",
      "gradient norm: 0.014866094839817379, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 12938 / 20000\n",
      "gradient norm: 0.0750425715232268, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 12939 / 20000\n",
      "gradient norm: 0.047252323769498616, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 12940 / 20000\n",
      "gradient norm: 0.0523605830676388, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 12941 / 20000\n",
      "gradient norm: 0.027977034435025416, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 12942 / 20000\n",
      "gradient norm: 0.10062530264258385, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 12943 / 20000\n",
      "gradient norm: 0.060564098006580025, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 12944 / 20000\n",
      "gradient norm: 0.054299716372042894, minimum ratio: 2.4394736842105265\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 12945 / 20000\n",
      "gradient norm: 0.05610650416929275, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00554\n",
      "epoch 12946 / 20000\n",
      "gradient norm: 0.10619411675725132, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 12947 / 20000\n",
      "gradient norm: 0.0378852296853438, minimum ratio: 2.4499999999999997\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 12948 / 20000\n",
      "gradient norm: 0.03467464045388624, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 12949 / 20000\n",
      "gradient norm: 0.06275407495559193, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 12950 / 20000\n",
      "gradient norm: 0.028610801105969585, minimum ratio: 2.4394736842105265\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 12951 / 20000\n",
      "gradient norm: 0.03482290515967179, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 12952 / 20000\n",
      "gradient norm: 0.0874582483083941, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00554\n",
      "epoch 12953 / 20000\n",
      "gradient norm: 0.035373761391383596, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00551\n",
      "epoch 12954 / 20000\n",
      "gradient norm: 0.0626049236743711, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 12955 / 20000\n",
      "gradient norm: 0.04049776867032051, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00554\n",
      "epoch 12956 / 20000\n",
      "gradient norm: 0.04436409151821863, minimum ratio: 2.4157894736842103\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 12957 / 20000\n",
      "gradient norm: 0.0637324123235885, minimum ratio: 2.418421052631579\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 12958 / 20000\n",
      "gradient norm: 0.09116919822554337, minimum ratio: 2.4421052631578943\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 12959 / 20000\n",
      "gradient norm: 0.065786984981969, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 12960 / 20000\n",
      "gradient norm: 0.08893383332178928, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 12961 / 20000\n",
      "gradient norm: 0.10370731283910573, minimum ratio: 2.4289473684210523\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 12962 / 20000\n",
      "gradient norm: 0.034587704212754034, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 12963 / 20000\n",
      "gradient norm: 0.029889798461226746, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 12964 / 20000\n",
      "gradient norm: 0.10895084269577637, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 12965 / 20000\n",
      "gradient norm: 0.03094257155316882, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 12966 / 20000\n",
      "gradient norm: 0.0682952131901402, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 12967 / 20000\n",
      "gradient norm: 0.0645341258496046, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 12968 / 20000\n",
      "gradient norm: 0.11020182346692309, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 12969 / 20000\n",
      "gradient norm: 0.07043810887262225, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 12970 / 20000\n",
      "gradient norm: 0.03687330341199413, minimum ratio: 2.4394736842105265\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 12971 / 20000\n",
      "gradient norm: 0.04487005491682794, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 12972 / 20000\n",
      "gradient norm: 0.034483320399886, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 12973 / 20000\n",
      "gradient norm: 0.041680581285618246, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00551\n",
      "epoch 12974 / 20000\n",
      "gradient norm: 0.014939537097234279, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 12975 / 20000\n",
      "gradient norm: 0.044567343895323575, minimum ratio: 2.4421052631578943\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 12976 / 20000\n",
      "gradient norm: 0.07160077488515526, minimum ratio: 2.423684210526316\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 12977 / 20000\n",
      "gradient norm: 0.03851856128312647, minimum ratio: 2.4499999999999997\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 12978 / 20000\n",
      "gradient norm: 0.06548338360153139, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 12979 / 20000\n",
      "gradient norm: 0.04978356332867406, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 12980 / 20000\n",
      "gradient norm: 0.08527876192238182, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 12981 / 20000\n",
      "gradient norm: 0.06984090188052505, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 12982 / 20000\n",
      "gradient norm: 0.06151144742034376, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 12983 / 20000\n",
      "gradient norm: 0.030675803602207452, minimum ratio: 2.4157894736842107\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 12984 / 20000\n",
      "gradient norm: 0.0717240032972768, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 12985 / 20000\n",
      "gradient norm: 0.07262255786918104, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 12986 / 20000\n",
      "gradient norm: 0.02247140937106451, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 12987 / 20000\n",
      "gradient norm: 0.052203673287294805, minimum ratio: 2.4684210526315784\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 12988 / 20000\n",
      "gradient norm: 0.04739880419219844, minimum ratio: 2.4210526315789473\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 12989 / 20000\n",
      "gradient norm: 0.037172049982473254, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 12990 / 20000\n",
      "gradient norm: 0.034587791917147115, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 12991 / 20000\n",
      "gradient norm: 0.13403435773216188, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 12992 / 20000\n",
      "gradient norm: 0.07063261643634178, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 12993 / 20000\n",
      "gradient norm: 0.04542619606945664, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 12994 / 20000\n",
      "gradient norm: 0.06928003166103736, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00553\n",
      "epoch 12995 / 20000\n",
      "gradient norm: 0.0962825637543574, minimum ratio: 2.436842105263158\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 12996 / 20000\n",
      "gradient norm: 0.06607200086727971, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 12997 / 20000\n",
      "gradient norm: 0.0878868215077091, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 12998 / 20000\n",
      "gradient norm: 0.06537674402352422, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 12999 / 20000\n",
      "gradient norm: 0.05342188884969801, minimum ratio: 2.405263157894737\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 13000 / 20000\n",
      "gradient norm: 0.07968974875984713, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 13001 / 20000\n",
      "gradient norm: 0.07774452597368509, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 13002 / 20000\n",
      "gradient norm: 0.0716627353685908, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 13003 / 20000\n",
      "gradient norm: 0.08228935083025135, minimum ratio: 2.4447368421052635\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 13004 / 20000\n",
      "gradient norm: 0.02576185209909454, minimum ratio: 2.4499999999999997\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 13005 / 20000\n",
      "gradient norm: 0.0532790836005006, minimum ratio: 2.452631578947368\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 13006 / 20000\n",
      "gradient norm: 0.015927634718536865, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 13007 / 20000\n",
      "gradient norm: 0.07218512543477118, minimum ratio: 2.4263157894736844\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 13008 / 20000\n",
      "gradient norm: 0.0323498188809026, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 13009 / 20000\n",
      "gradient norm: 0.07334434910444543, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 13010 / 20000\n",
      "gradient norm: 0.044072892575059086, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 13011 / 20000\n",
      "gradient norm: 0.06866125328815542, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 13012 / 20000\n",
      "gradient norm: 0.06780241639353335, minimum ratio: 2.4263157894736844\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 13013 / 20000\n",
      "gradient norm: 0.0419034538208507, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 13014 / 20000\n",
      "gradient norm: 0.035959857937996276, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 13015 / 20000\n",
      "gradient norm: 0.027744802777306177, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 13016 / 20000\n",
      "gradient norm: 0.06421378994127735, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 13017 / 20000\n",
      "gradient norm: 0.038252387050306424, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 13018 / 20000\n",
      "gradient norm: 0.07884695491520688, minimum ratio: 2.4421052631578943\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 13019 / 20000\n",
      "gradient norm: 0.08456531685078517, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 13020 / 20000\n",
      "gradient norm: 0.05138072758563794, minimum ratio: 2.4210526315789473\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 13021 / 20000\n",
      "gradient norm: 0.07363720401190221, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 13022 / 20000\n",
      "gradient norm: 0.08779627946205437, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 13023 / 20000\n",
      "gradient norm: 0.06485118437558413, minimum ratio: 2.426315789473684\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 13024 / 20000\n",
      "gradient norm: 0.05429888004437089, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 13025 / 20000\n",
      "gradient norm: 0.029743195249466226, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 13026 / 20000\n",
      "gradient norm: 0.0663154711946845, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 13027 / 20000\n",
      "gradient norm: 0.07605393615085632, minimum ratio: 2.418421052631579\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 13028 / 20000\n",
      "gradient norm: 0.029372690012678504, minimum ratio: 2.4184210526315786\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 13029 / 20000\n",
      "gradient norm: 0.05914305173791945, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 13030 / 20000\n",
      "gradient norm: 0.03954903612611815, minimum ratio: 2.4263157894736844\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 13031 / 20000\n",
      "gradient norm: 0.07646713682333939, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 13032 / 20000\n",
      "gradient norm: 0.08588527587562567, minimum ratio: 2.4236842105263157\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 13033 / 20000\n",
      "gradient norm: 0.07166352242347784, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 13034 / 20000\n",
      "gradient norm: 0.07674358534859493, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 13035 / 20000\n",
      "gradient norm: 0.11122890375554562, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 13036 / 20000\n",
      "gradient norm: 0.07020550535526127, minimum ratio: 2.4236842105263157\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00555\n",
      "epoch 13037 / 20000\n",
      "gradient norm: 0.10112674147239886, minimum ratio: 2.4499999999999997\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 13038 / 20000\n",
      "gradient norm: 0.03009611884772312, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 13039 / 20000\n",
      "gradient norm: 0.017750512939528562, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 13040 / 20000\n",
      "gradient norm: 0.0322716151131317, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 13041 / 20000\n",
      "gradient norm: 0.13713325548451394, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 13042 / 20000\n",
      "gradient norm: 0.07710721116745844, minimum ratio: 2.4236842105263157\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 13043 / 20000\n",
      "gradient norm: 0.07629414508119226, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 13044 / 20000\n",
      "gradient norm: 0.08417242544237524, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 13045 / 20000\n",
      "gradient norm: 0.056694746599532664, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 13046 / 20000\n",
      "gradient norm: 0.06431770004564896, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 13047 / 20000\n",
      "gradient norm: 0.04815652358956868, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 13048 / 20000\n",
      "gradient norm: 0.0728056400839705, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 13049 / 20000\n",
      "gradient norm: 0.06867373595014215, minimum ratio: 2.4394736842105265\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 13050 / 20000\n",
      "gradient norm: 0.11923879434471019, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 13051 / 20000\n",
      "gradient norm: 0.0553314616845455, minimum ratio: 2.4394736842105265\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 13052 / 20000\n",
      "gradient norm: 0.05377574506564997, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 13053 / 20000\n",
      "gradient norm: 0.020584795938702882, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 13054 / 20000\n",
      "gradient norm: 0.0849012368125841, minimum ratio: 2.4684210526315784\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 13055 / 20000\n",
      "gradient norm: 0.08037357463035733, minimum ratio: 2.418421052631579\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 13056 / 20000\n",
      "gradient norm: 0.05954155666404404, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 13057 / 20000\n",
      "gradient norm: 0.05786196682311129, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 13058 / 20000\n",
      "gradient norm: 0.10503731796052307, minimum ratio: 2.4210526315789473\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 13059 / 20000\n",
      "gradient norm: 0.06091440233285539, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 13060 / 20000\n",
      "gradient norm: 0.1012520354706794, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 13061 / 20000\n",
      "gradient norm: 0.044727451022481546, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 13062 / 20000\n",
      "gradient norm: 0.1305818393593654, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 13063 / 20000\n",
      "gradient norm: 0.03297843743348494, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 13064 / 20000\n",
      "gradient norm: 0.0581787345581688, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 13065 / 20000\n",
      "gradient norm: 0.059566479991190135, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 13066 / 20000\n",
      "gradient norm: 0.06247327575692907, minimum ratio: 2.4263157894736844\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 13067 / 20000\n",
      "gradient norm: 0.07957337831612676, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 13068 / 20000\n",
      "gradient norm: 0.042469241860089824, minimum ratio: 2.4447368421052627\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 13069 / 20000\n",
      "gradient norm: 0.02163561957422644, minimum ratio: 2.426315789473684\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 13070 / 20000\n",
      "gradient norm: 0.057556364830816165, minimum ratio: 2.4289473684210523\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 13071 / 20000\n",
      "gradient norm: 0.11379854567348957, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 13072 / 20000\n",
      "gradient norm: 0.04931258107535541, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 13073 / 20000\n",
      "gradient norm: 0.07179292727960274, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 13074 / 20000\n",
      "gradient norm: 0.03881783066026401, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 13075 / 20000\n",
      "gradient norm: 0.1298066363669932, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 13076 / 20000\n",
      "gradient norm: 0.06857791088987142, minimum ratio: 2.423684210526316\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 13077 / 20000\n",
      "gradient norm: 0.0735341610852629, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 13078 / 20000\n",
      "gradient norm: 0.0871912648435682, minimum ratio: 2.405263157894737\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 13079 / 20000\n",
      "gradient norm: 0.0642878728103824, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 13080 / 20000\n",
      "gradient norm: 0.09517568408045918, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 13081 / 20000\n",
      "gradient norm: 0.020755244957399555, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 13082 / 20000\n",
      "gradient norm: 0.09165569487959146, minimum ratio: 2.423684210526316\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 13083 / 20000\n",
      "gradient norm: 0.06257535296026617, minimum ratio: 2.4263157894736844\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 13084 / 20000\n",
      "gradient norm: 0.0787205781089142, minimum ratio: 2.452631578947368\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 13085 / 20000\n",
      "gradient norm: 0.11060323496349156, minimum ratio: 2.4184210526315786\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00551\n",
      "epoch 13086 / 20000\n",
      "gradient norm: 0.033642852955381386, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 13087 / 20000\n",
      "gradient norm: 0.09367447684053332, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 13088 / 20000\n",
      "gradient norm: 0.05683915235567838, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00551\n",
      "epoch 13089 / 20000\n",
      "gradient norm: 0.07826575604849495, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 13090 / 20000\n",
      "gradient norm: 0.121290517388843, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 13091 / 20000\n",
      "gradient norm: 0.08870699477847666, minimum ratio: 2.4421052631578943\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00555\n",
      "epoch 13092 / 20000\n",
      "gradient norm: 0.049047711479943246, minimum ratio: 2.4421052631578943\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 13093 / 20000\n",
      "gradient norm: 0.0894167599035427, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 13094 / 20000\n",
      "gradient norm: 0.15148105332627892, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00555\n",
      "epoch 13095 / 20000\n",
      "gradient norm: 0.10323108627926558, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 13096 / 20000\n",
      "gradient norm: 0.05280642188154161, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 13097 / 20000\n",
      "gradient norm: 0.05714118221658282, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 13098 / 20000\n",
      "gradient norm: 0.035006463644094765, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 13099 / 20000\n",
      "gradient norm: 0.08534321977640502, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 13100 / 20000\n",
      "gradient norm: 0.04914841538993642, minimum ratio: 2.4157894736842103\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 13101 / 20000\n",
      "gradient norm: 0.06261296395678073, minimum ratio: 2.4210526315789473\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 13102 / 20000\n",
      "gradient norm: 0.042454558206372894, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 13103 / 20000\n",
      "gradient norm: 0.08806143188849092, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 13104 / 20000\n",
      "gradient norm: 0.07126796861120965, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 13105 / 20000\n",
      "gradient norm: 0.08659817714942619, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00555\n",
      "epoch 13106 / 20000\n",
      "gradient norm: 0.09197314889752306, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 13107 / 20000\n",
      "gradient norm: 0.06831512047210708, minimum ratio: 2.4394736842105265\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 13108 / 20000\n",
      "gradient norm: 0.03603633973398246, minimum ratio: 2.4263157894736844\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 13109 / 20000\n",
      "gradient norm: 0.0907347509637475, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 13110 / 20000\n",
      "gradient norm: 0.10984515509335324, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 13111 / 20000\n",
      "gradient norm: 0.08301867841510102, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00551\n",
      "epoch 13112 / 20000\n",
      "gradient norm: 0.09635791450273246, minimum ratio: 2.4447368421052627\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 13113 / 20000\n",
      "gradient norm: 0.08940023992909119, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00552\n",
      "epoch 13114 / 20000\n",
      "gradient norm: 0.06387142807943746, minimum ratio: 2.4157894736842103\n",
      "\ttrain loss: 0.00565\n",
      "\tval loss: 0.00552\n",
      "epoch 13115 / 20000\n",
      "gradient norm: 0.06044133838440757, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 13116 / 20000\n",
      "gradient norm: 0.04592510321526788, minimum ratio: 2.4499999999999997\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 13117 / 20000\n",
      "gradient norm: 0.02455445875239093, minimum ratio: 2.4289473684210523\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 13118 / 20000\n",
      "gradient norm: 0.08893677231390029, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 13119 / 20000\n",
      "gradient norm: 0.07182951521826908, minimum ratio: 2.4447368421052627\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 13120 / 20000\n",
      "gradient norm: 0.10052254574839026, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 13121 / 20000\n",
      "gradient norm: 0.12562913168221712, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 13122 / 20000\n",
      "gradient norm: 0.05073705778340809, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 13123 / 20000\n",
      "gradient norm: 0.11092999810352921, minimum ratio: 2.413157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 13124 / 20000\n",
      "gradient norm: 0.03219335281755775, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 13125 / 20000\n",
      "gradient norm: 0.07122219743905589, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 13126 / 20000\n",
      "gradient norm: 0.08636434661457315, minimum ratio: 2.413157894736842\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 13127 / 20000\n",
      "gradient norm: 0.06341030696057715, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 13128 / 20000\n",
      "gradient norm: 0.02679736356367357, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 13129 / 20000\n",
      "gradient norm: 0.06480053882114589, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 13130 / 20000\n",
      "gradient norm: 0.07970784170902334, minimum ratio: 2.4421052631578943\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 13131 / 20000\n",
      "gradient norm: 0.05775663458916824, minimum ratio: 2.4394736842105265\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 13132 / 20000\n",
      "gradient norm: 0.07483505553682335, minimum ratio: 2.4421052631578943\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00551\n",
      "epoch 13133 / 20000\n",
      "gradient norm: 0.09325503156287596, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 13134 / 20000\n",
      "gradient norm: 0.10487209918210283, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 13135 / 20000\n",
      "gradient norm: 0.041928989870939404, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 13136 / 20000\n",
      "gradient norm: 0.04682685135048814, minimum ratio: 2.4210526315789473\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 13137 / 20000\n",
      "gradient norm: 0.028199983964441344, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 13138 / 20000\n",
      "gradient norm: 0.08444843420875259, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 13139 / 20000\n",
      "gradient norm: 0.052133599936496466, minimum ratio: 2.4263157894736844\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 13140 / 20000\n",
      "gradient norm: 0.07550730201182887, minimum ratio: 2.436842105263158\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 13141 / 20000\n",
      "gradient norm: 0.06530394195578992, minimum ratio: 2.4157894736842103\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 13142 / 20000\n",
      "gradient norm: 0.054236303782090545, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00551\n",
      "epoch 13143 / 20000\n",
      "gradient norm: 0.03759988900856115, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 13144 / 20000\n",
      "gradient norm: 0.04737013697740622, minimum ratio: 2.4499999999999997\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 13145 / 20000\n",
      "gradient norm: 0.029997740435646847, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 13146 / 20000\n",
      "gradient norm: 0.041375278698978946, minimum ratio: 2.4394736842105265\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 13147 / 20000\n",
      "gradient norm: 0.09144025412388146, minimum ratio: 2.423684210526316\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 13148 / 20000\n",
      "gradient norm: 0.02383085606561508, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 13149 / 20000\n",
      "gradient norm: 0.02863473244360648, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 13150 / 20000\n",
      "gradient norm: 0.07160233473405242, minimum ratio: 2.4184210526315786\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 13151 / 20000\n",
      "gradient norm: 0.06364269874757156, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 13152 / 20000\n",
      "gradient norm: 0.06287968985270709, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 13153 / 20000\n",
      "gradient norm: 0.050952705802046694, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 13154 / 20000\n",
      "gradient norm: 0.04243356257211417, minimum ratio: 2.4210526315789473\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 13155 / 20000\n",
      "gradient norm: 0.07069025369855808, minimum ratio: 2.426315789473684\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 13156 / 20000\n",
      "gradient norm: 0.058905718848109245, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 13157 / 20000\n",
      "gradient norm: 0.07319192576687783, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 13158 / 20000\n",
      "gradient norm: 0.0891895173699595, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 13159 / 20000\n",
      "gradient norm: 0.05785679491236806, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 13160 / 20000\n",
      "gradient norm: 0.05106178781716153, minimum ratio: 2.436842105263158\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 13161 / 20000\n",
      "gradient norm: 0.030078672047238797, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 13162 / 20000\n",
      "gradient norm: 0.08612928458023816, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 13163 / 20000\n",
      "gradient norm: 0.03744264569832012, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 13164 / 20000\n",
      "gradient norm: 0.06237088260240853, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 13165 / 20000\n",
      "gradient norm: 0.06224558886606246, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 13166 / 20000\n",
      "gradient norm: 0.06323923706077039, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 13167 / 20000\n",
      "gradient norm: 0.05783341565984301, minimum ratio: 2.4394736842105265\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 13168 / 20000\n",
      "gradient norm: 0.04167468036757782, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 13169 / 20000\n",
      "gradient norm: 0.08502857858547941, minimum ratio: 2.4394736842105265\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 13170 / 20000\n",
      "gradient norm: 0.03799840805004351, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 13171 / 20000\n",
      "gradient norm: 0.06907963240519166, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 13172 / 20000\n",
      "gradient norm: 0.06786916853161529, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 13173 / 20000\n",
      "gradient norm: 0.0759631214896217, minimum ratio: 2.4447368421052635\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 13174 / 20000\n",
      "gradient norm: 0.07723494782112539, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 13175 / 20000\n",
      "gradient norm: 0.04280085088976193, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 13176 / 20000\n",
      "gradient norm: 0.036650170281063765, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 13177 / 20000\n",
      "gradient norm: 0.07792845484800637, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 13178 / 20000\n",
      "gradient norm: 0.058191447154968046, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 13179 / 20000\n",
      "gradient norm: 0.04985307899187319, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 13180 / 20000\n",
      "gradient norm: 0.10276050609536469, minimum ratio: 2.4157894736842107\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 13181 / 20000\n",
      "gradient norm: 0.02280657867959235, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 13182 / 20000\n",
      "gradient norm: 0.10120408271905035, minimum ratio: 2.426315789473684\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 13183 / 20000\n",
      "gradient norm: 0.0591870674979873, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 13184 / 20000\n",
      "gradient norm: 0.05190008942736313, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 13185 / 20000\n",
      "gradient norm: 0.08227277989499271, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 13186 / 20000\n",
      "gradient norm: 0.07584874934400432, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 13187 / 20000\n",
      "gradient norm: 0.09795061679324135, minimum ratio: 2.4157894736842103\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 13188 / 20000\n",
      "gradient norm: 0.021376988501287997, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 13189 / 20000\n",
      "gradient norm: 0.0896426429389976, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 13190 / 20000\n",
      "gradient norm: 0.026604582177242264, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 13191 / 20000\n",
      "gradient norm: 0.06355076556792483, minimum ratio: 2.4184210526315786\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 13192 / 20000\n",
      "gradient norm: 0.03967769144219346, minimum ratio: 2.421052631578947\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 13193 / 20000\n",
      "gradient norm: 0.10070302418898791, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 13194 / 20000\n",
      "gradient norm: 0.06773411898757331, minimum ratio: 2.4447368421052635\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 13195 / 20000\n",
      "gradient norm: 0.06259190570563078, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 13196 / 20000\n",
      "gradient norm: 0.08139799314085394, minimum ratio: 2.4184210526315786\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 13197 / 20000\n",
      "gradient norm: 0.03476176103868056, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 13198 / 20000\n",
      "gradient norm: 0.06360326241701841, minimum ratio: 2.4105263157894736\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 13199 / 20000\n",
      "gradient norm: 0.07677859143586829, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 13200 / 20000\n",
      "gradient norm: 0.08649273007176816, minimum ratio: 2.4421052631578943\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 13201 / 20000\n",
      "gradient norm: 0.055509336532850284, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 13202 / 20000\n",
      "gradient norm: 0.03735543158836663, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 13203 / 20000\n",
      "gradient norm: 0.054510329209733754, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 13204 / 20000\n",
      "gradient norm: 0.053875376921496354, minimum ratio: 2.4315789473684206\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 13205 / 20000\n",
      "gradient norm: 0.05391057863016613, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 13206 / 20000\n",
      "gradient norm: 0.06577694416046143, minimum ratio: 2.413157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 13207 / 20000\n",
      "gradient norm: 0.08542409568326548, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 13208 / 20000\n",
      "gradient norm: 0.014625425370468292, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 13209 / 20000\n",
      "gradient norm: 0.09391891991253942, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 13210 / 20000\n",
      "gradient norm: 0.10926662205019966, minimum ratio: 2.418421052631579\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 13211 / 20000\n",
      "gradient norm: 0.07115015291492455, minimum ratio: 2.4236842105263157\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 13212 / 20000\n",
      "gradient norm: 0.053728484257590026, minimum ratio: 2.4236842105263157\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 13213 / 20000\n",
      "gradient norm: 0.09476874675601721, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00553\n",
      "epoch 13214 / 20000\n",
      "gradient norm: 0.04760766727849841, minimum ratio: 2.423684210526316\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 13215 / 20000\n",
      "gradient norm: 0.044357507780659944, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 13216 / 20000\n",
      "gradient norm: 0.04175782311358489, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 13217 / 20000\n",
      "gradient norm: 0.04504057567100972, minimum ratio: 2.4447368421052635\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 13218 / 20000\n",
      "gradient norm: 0.06737040700681973, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 13219 / 20000\n",
      "gradient norm: 0.06275006112991832, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 13220 / 20000\n",
      "gradient norm: 0.055414039408788085, minimum ratio: 2.4236842105263157\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 13221 / 20000\n",
      "gradient norm: 0.0962163299554959, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 13222 / 20000\n",
      "gradient norm: 0.04982138687046245, minimum ratio: 2.4236842105263157\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 13223 / 20000\n",
      "gradient norm: 0.06698381451133173, minimum ratio: 2.4157894736842103\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 13224 / 20000\n",
      "gradient norm: 0.0588070402154699, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 13225 / 20000\n",
      "gradient norm: 0.07820389681728557, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 13226 / 20000\n",
      "gradient norm: 0.01671740876918193, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 13227 / 20000\n",
      "gradient norm: 0.06999635542160831, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 13228 / 20000\n",
      "gradient norm: 0.07360741282172967, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 13229 / 20000\n",
      "gradient norm: 0.030748645003768615, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 13230 / 20000\n",
      "gradient norm: 0.04867957659007516, minimum ratio: 2.421052631578947\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 13231 / 20000\n",
      "gradient norm: 0.06880266952794045, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 13232 / 20000\n",
      "gradient norm: 0.09683110954938456, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 13233 / 20000\n",
      "gradient norm: 0.06089684157632291, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 13234 / 20000\n",
      "gradient norm: 0.04754615240381099, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 13235 / 20000\n",
      "gradient norm: 0.06314846739405766, minimum ratio: 2.426315789473684\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 13236 / 20000\n",
      "gradient norm: 0.09386710054241121, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 13237 / 20000\n",
      "gradient norm: 0.039090582096832804, minimum ratio: 2.418421052631579\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 13238 / 20000\n",
      "gradient norm: 0.036795827458263375, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 13239 / 20000\n",
      "gradient norm: 0.08975749718956649, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 13240 / 20000\n",
      "gradient norm: 0.037770701077533886, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 13241 / 20000\n",
      "gradient norm: 0.06348494833218865, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 13242 / 20000\n",
      "gradient norm: 0.06220822338946164, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 13243 / 20000\n",
      "gradient norm: 0.08603981081978418, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 13244 / 20000\n",
      "gradient norm: 0.033625917276367545, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 13245 / 20000\n",
      "gradient norm: 0.05345463426783681, minimum ratio: 2.4236842105263157\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 13246 / 20000\n",
      "gradient norm: 0.04106575052719563, minimum ratio: 2.4210526315789473\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 13247 / 20000\n",
      "gradient norm: 0.07286304724402726, minimum ratio: 2.4421052631578943\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 13248 / 20000\n",
      "gradient norm: 0.06116914114682004, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 13249 / 20000\n",
      "gradient norm: 0.056031415093457326, minimum ratio: 2.4421052631578943\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 13250 / 20000\n",
      "gradient norm: 0.058963715098798275, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 13251 / 20000\n",
      "gradient norm: 0.05242557855672203, minimum ratio: 2.421052631578947\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 13252 / 20000\n",
      "gradient norm: 0.045246164401760325, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 13253 / 20000\n",
      "gradient norm: 0.055056320095900446, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 13254 / 20000\n",
      "gradient norm: 0.06653212296077982, minimum ratio: 2.4394736842105265\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 13255 / 20000\n",
      "gradient norm: 0.08042244394891895, minimum ratio: 2.4263157894736844\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 13256 / 20000\n",
      "gradient norm: 0.032717226873501204, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 13257 / 20000\n",
      "gradient norm: 0.03606953514099587, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 13258 / 20000\n",
      "gradient norm: 0.03670110902749002, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 13259 / 20000\n",
      "gradient norm: 0.02966953319264576, minimum ratio: 2.4078947368421053\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 13260 / 20000\n",
      "gradient norm: 0.05616397794801742, minimum ratio: 2.4447368421052627\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 13261 / 20000\n",
      "gradient norm: 0.060915231180842966, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 13262 / 20000\n",
      "gradient norm: 0.08711671363562346, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 13263 / 20000\n",
      "gradient norm: 0.07074184500379488, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 13264 / 20000\n",
      "gradient norm: 0.07661935474607162, minimum ratio: 2.423684210526316\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 13265 / 20000\n",
      "gradient norm: 0.08829705259995535, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 13266 / 20000\n",
      "gradient norm: 0.060409134661313146, minimum ratio: 2.423684210526316\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 13267 / 20000\n",
      "gradient norm: 0.043267895467579365, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 13268 / 20000\n",
      "gradient norm: 0.06622037763008848, minimum ratio: 2.4263157894736844\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 13269 / 20000\n",
      "gradient norm: 0.04656289369449951, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 13270 / 20000\n",
      "gradient norm: 0.03947428285027854, minimum ratio: 2.4210526315789473\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 13271 / 20000\n",
      "gradient norm: 0.07718876760918647, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 13272 / 20000\n",
      "gradient norm: 0.05942583683645353, minimum ratio: 2.436842105263158\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 13273 / 20000\n",
      "gradient norm: 0.0716585589107126, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 13274 / 20000\n",
      "gradient norm: 0.0898159086718806, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 13275 / 20000\n",
      "gradient norm: 0.055994076596107334, minimum ratio: 2.4184210526315786\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 13276 / 20000\n",
      "gradient norm: 0.08590065367752686, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 13277 / 20000\n",
      "gradient norm: 0.021723657671827823, minimum ratio: 2.418421052631579\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 13278 / 20000\n",
      "gradient norm: 0.04802275853580795, minimum ratio: 2.4210526315789473\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 13279 / 20000\n",
      "gradient norm: 0.10642202832968906, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 13280 / 20000\n",
      "gradient norm: 0.08473129040794447, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 13281 / 20000\n",
      "gradient norm: 0.0611864582169801, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 13282 / 20000\n",
      "gradient norm: 0.09628778300248086, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00554\n",
      "epoch 13283 / 20000\n",
      "gradient norm: 0.0565545471617952, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 13284 / 20000\n",
      "gradient norm: 0.043675866501871496, minimum ratio: 2.413157894736842\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 13285 / 20000\n",
      "gradient norm: 0.06320907844929025, minimum ratio: 2.418421052631579\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 13286 / 20000\n",
      "gradient norm: 0.05997066479176283, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 13287 / 20000\n",
      "gradient norm: 0.01580270761041902, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00551\n",
      "epoch 13288 / 20000\n",
      "gradient norm: 0.07327606584294699, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 13289 / 20000\n",
      "gradient norm: 0.03444550976564642, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 13290 / 20000\n",
      "gradient norm: 0.062398983573075384, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 13291 / 20000\n",
      "gradient norm: 0.04264763472019695, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 13292 / 20000\n",
      "gradient norm: 0.058855188435700256, minimum ratio: 2.4421052631578943\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 13293 / 20000\n",
      "gradient norm: 0.06489984833751805, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 13294 / 20000\n",
      "gradient norm: 0.03123042540391907, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 13295 / 20000\n",
      "gradient norm: 0.07556303276214749, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 13296 / 20000\n",
      "gradient norm: 0.049552881566341966, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 13297 / 20000\n",
      "gradient norm: 0.04608527250820771, minimum ratio: 2.4184210526315786\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 13298 / 20000\n",
      "gradient norm: 0.06796973763266578, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00565\n",
      "\tval loss: 0.00552\n",
      "epoch 13299 / 20000\n",
      "gradient norm: 0.025884681701427326, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 13300 / 20000\n",
      "gradient norm: 0.062215869409556035, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 13301 / 20000\n",
      "gradient norm: 0.035190522932680324, minimum ratio: 2.413157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 13302 / 20000\n",
      "gradient norm: 0.09407970705069602, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 13303 / 20000\n",
      "gradient norm: 0.08494424517266452, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 13304 / 20000\n",
      "gradient norm: 0.07670103965210728, minimum ratio: 2.3973684210526316\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 13305 / 20000\n",
      "gradient norm: 0.09440127620473504, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 13306 / 20000\n",
      "gradient norm: 0.05500194017076865, minimum ratio: 2.423684210526316\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 13307 / 20000\n",
      "gradient norm: 0.04918098947382532, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 13308 / 20000\n",
      "gradient norm: 0.057535870000720024, minimum ratio: 2.426315789473684\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 13309 / 20000\n",
      "gradient norm: 0.06576492480235174, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 13310 / 20000\n",
      "gradient norm: 0.06849602839793079, minimum ratio: 2.4210526315789473\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 13311 / 20000\n",
      "gradient norm: 0.09237142623169348, minimum ratio: 2.4078947368421053\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 13312 / 20000\n",
      "gradient norm: 0.053782746403157944, minimum ratio: 2.421052631578948\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00554\n",
      "epoch 13313 / 20000\n",
      "gradient norm: 0.09989455554750748, minimum ratio: 2.426315789473684\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 13314 / 20000\n",
      "gradient norm: 0.02269728935425519, minimum ratio: 2.421052631578948\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 13315 / 20000\n",
      "gradient norm: 0.026886316052696202, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 13316 / 20000\n",
      "gradient norm: 0.07388177067332435, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 13317 / 20000\n",
      "gradient norm: 0.04762605948781129, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 13318 / 20000\n",
      "gradient norm: 0.0953987529501319, minimum ratio: 2.4\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 13319 / 20000\n",
      "gradient norm: 0.09466553729726002, minimum ratio: 2.4157894736842103\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 13320 / 20000\n",
      "gradient norm: 0.050038970133755356, minimum ratio: 2.413157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 13321 / 20000\n",
      "gradient norm: 0.07195439087809063, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 13322 / 20000\n",
      "gradient norm: 0.033636517910053954, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 13323 / 20000\n",
      "gradient norm: 0.07433848691653111, minimum ratio: 2.4421052631578943\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 13324 / 20000\n",
      "gradient norm: 0.11822351880255155, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00551\n",
      "epoch 13325 / 20000\n",
      "gradient norm: 0.05225971504114568, minimum ratio: 2.4447368421052627\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00554\n",
      "epoch 13326 / 20000\n",
      "gradient norm: 0.09773275081533939, minimum ratio: 2.4499999999999997\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 13327 / 20000\n",
      "gradient norm: 0.09170011099195108, minimum ratio: 2.4157894736842103\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 13328 / 20000\n",
      "gradient norm: 0.04462996436632238, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00551\n",
      "epoch 13329 / 20000\n",
      "gradient norm: 0.06616189476335421, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 13330 / 20000\n",
      "gradient norm: 0.051330625370610505, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 13331 / 20000\n",
      "gradient norm: 0.07680591649841517, minimum ratio: 2.436842105263158\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 13332 / 20000\n",
      "gradient norm: 0.08844067330937833, minimum ratio: 2.4421052631578943\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 13333 / 20000\n",
      "gradient norm: 0.03143837978132069, minimum ratio: 2.4499999999999997\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00553\n",
      "epoch 13334 / 20000\n",
      "gradient norm: 0.09477355028502643, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 13335 / 20000\n",
      "gradient norm: 0.08513893379131332, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 13336 / 20000\n",
      "gradient norm: 0.025542502669850364, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 13337 / 20000\n",
      "gradient norm: 0.045189853306510486, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 13338 / 20000\n",
      "gradient norm: 0.08838499087141827, minimum ratio: 2.4157894736842103\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 13339 / 20000\n",
      "gradient norm: 0.048756015254184604, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 13340 / 20000\n",
      "gradient norm: 0.06549047422595322, minimum ratio: 2.4184210526315786\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 13341 / 20000\n",
      "gradient norm: 0.07915607903851196, minimum ratio: 2.4289473684210523\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 13342 / 20000\n",
      "gradient norm: 0.04502564822905697, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 13343 / 20000\n",
      "gradient norm: 0.12617927335668355, minimum ratio: 2.4447368421052627\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00551\n",
      "epoch 13344 / 20000\n",
      "gradient norm: 0.0622748535242863, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00556\n",
      "epoch 13345 / 20000\n",
      "gradient norm: 0.05443460568494629, minimum ratio: 2.4157894736842103\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 13346 / 20000\n",
      "gradient norm: 0.058714273560326546, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 13347 / 20000\n",
      "gradient norm: 0.07321815745672211, minimum ratio: 2.4210526315789473\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 13348 / 20000\n",
      "gradient norm: 0.09072903444757685, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 13349 / 20000\n",
      "gradient norm: 0.03494064597180113, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 13350 / 20000\n",
      "gradient norm: 0.0430344101623632, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 13351 / 20000\n",
      "gradient norm: 0.042899448540993035, minimum ratio: 2.4263157894736844\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 13352 / 20000\n",
      "gradient norm: 0.03592857441253727, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 13353 / 20000\n",
      "gradient norm: 0.05939863054663874, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 13354 / 20000\n",
      "gradient norm: 0.0666078234789893, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 13355 / 20000\n",
      "gradient norm: 0.05899064434925094, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 13356 / 20000\n",
      "gradient norm: 0.0814813980832696, minimum ratio: 2.4394736842105265\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 13357 / 20000\n",
      "gradient norm: 0.08091741119278595, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 13358 / 20000\n",
      "gradient norm: 0.06911238451721147, minimum ratio: 2.4499999999999997\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 13359 / 20000\n",
      "gradient norm: 0.0590164526947774, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 13360 / 20000\n",
      "gradient norm: 0.12465493893250823, minimum ratio: 2.4236842105263157\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 13361 / 20000\n",
      "gradient norm: 0.05070268581039272, minimum ratio: 2.4210526315789473\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 13362 / 20000\n",
      "gradient norm: 0.04904260815237649, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 13363 / 20000\n",
      "gradient norm: 0.07027173083042726, minimum ratio: 2.4236842105263157\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 13364 / 20000\n",
      "gradient norm: 0.11801063641905785, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 13365 / 20000\n",
      "gradient norm: 0.0747549967491068, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 13366 / 20000\n",
      "gradient norm: 0.04274960601469502, minimum ratio: 2.4184210526315786\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00551\n",
      "epoch 13367 / 20000\n",
      "gradient norm: 0.055611196876270697, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 13368 / 20000\n",
      "gradient norm: 0.07599472068250179, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00555\n",
      "epoch 13369 / 20000\n",
      "gradient norm: 0.07360354653792456, minimum ratio: 2.4184210526315786\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 13370 / 20000\n",
      "gradient norm: 0.09088743419852108, minimum ratio: 2.4236842105263157\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 13371 / 20000\n",
      "gradient norm: 0.03635229327483103, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 13372 / 20000\n",
      "gradient norm: 0.10031897341832519, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 13373 / 20000\n",
      "gradient norm: 0.06505988462595269, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 13374 / 20000\n",
      "gradient norm: 0.07266236818395555, minimum ratio: 2.418421052631579\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 13375 / 20000\n",
      "gradient norm: 0.10905773646663874, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00555\n",
      "epoch 13376 / 20000\n",
      "gradient norm: 0.05170157554675825, minimum ratio: 2.4\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 13377 / 20000\n",
      "gradient norm: 0.0511866151355207, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 13378 / 20000\n",
      "gradient norm: 0.07527832640334964, minimum ratio: 2.4499999999999997\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 13379 / 20000\n",
      "gradient norm: 0.0950898626470007, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 13380 / 20000\n",
      "gradient norm: 0.06803826076793484, minimum ratio: 2.4210526315789473\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 13381 / 20000\n",
      "gradient norm: 0.07583025400526822, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 13382 / 20000\n",
      "gradient norm: 0.02456635792623274, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 13383 / 20000\n",
      "gradient norm: 0.09958698996342719, minimum ratio: 2.4184210526315786\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 13384 / 20000\n",
      "gradient norm: 0.08065196720417589, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 13385 / 20000\n",
      "gradient norm: 0.06068858770595398, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 13386 / 20000\n",
      "gradient norm: 0.17360679036937654, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00572\n",
      "\tval loss: 0.00551\n",
      "epoch 13387 / 20000\n",
      "gradient norm: 0.0508569257799536, minimum ratio: 2.4394736842105265\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00555\n",
      "epoch 13388 / 20000\n",
      "gradient norm: 0.07699966052314267, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 13389 / 20000\n",
      "gradient norm: 0.10096477321349084, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 13390 / 20000\n",
      "gradient norm: 0.09479401540011168, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 13391 / 20000\n",
      "gradient norm: 0.0390557760183583, minimum ratio: 2.423684210526316\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 13392 / 20000\n",
      "gradient norm: 0.05590550025226548, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 13393 / 20000\n",
      "gradient norm: 0.08189572097035125, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 13394 / 20000\n",
      "gradient norm: 0.07286982634104788, minimum ratio: 2.4499999999999997\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 13395 / 20000\n",
      "gradient norm: 0.08920794737059623, minimum ratio: 2.426315789473684\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 13396 / 20000\n",
      "gradient norm: 0.10856766448705457, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 13397 / 20000\n",
      "gradient norm: 0.044275780353927985, minimum ratio: 2.4394736842105265\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 13398 / 20000\n",
      "gradient norm: 0.019960098801675485, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 13399 / 20000\n",
      "gradient norm: 0.056037419475615025, minimum ratio: 2.4499999999999997\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 13400 / 20000\n",
      "gradient norm: 0.06569248146843165, minimum ratio: 2.418421052631579\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 13401 / 20000\n",
      "gradient norm: 0.045005833671893924, minimum ratio: 2.4157894736842107\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 13402 / 20000\n",
      "gradient norm: 0.06920126790646464, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 13403 / 20000\n",
      "gradient norm: 0.10109359177295119, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00551\n",
      "epoch 13404 / 20000\n",
      "gradient norm: 0.057060131832258776, minimum ratio: 2.4421052631578952\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 13405 / 20000\n",
      "gradient norm: 0.07024476974038407, minimum ratio: 2.4263157894736844\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 13406 / 20000\n",
      "gradient norm: 0.05845382466213778, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00553\n",
      "epoch 13407 / 20000\n",
      "gradient norm: 0.06978987748152576, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 13408 / 20000\n",
      "gradient norm: 0.05959453564719297, minimum ratio: 2.413157894736842\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 13409 / 20000\n",
      "gradient norm: 0.07938920811284333, minimum ratio: 2.460526315789474\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 13410 / 20000\n",
      "gradient norm: 0.05705626595590729, minimum ratio: 2.426315789473684\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 13411 / 20000\n",
      "gradient norm: 0.06960924091981724, minimum ratio: 2.4236842105263157\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 13412 / 20000\n",
      "gradient norm: 0.03413545581861399, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 13413 / 20000\n",
      "gradient norm: 0.02750685792125296, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 13414 / 20000\n",
      "gradient norm: 0.049032433569664136, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 13415 / 20000\n",
      "gradient norm: 0.08278902433812618, minimum ratio: 2.4263157894736844\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 13416 / 20000\n",
      "gradient norm: 0.06176493159728125, minimum ratio: 2.436842105263158\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 13417 / 20000\n",
      "gradient norm: 0.027572525723371655, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 13418 / 20000\n",
      "gradient norm: 0.08338484773412347, minimum ratio: 2.4394736842105265\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 13419 / 20000\n",
      "gradient norm: 0.049394403118640184, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00554\n",
      "epoch 13420 / 20000\n",
      "gradient norm: 0.10573865281185135, minimum ratio: 2.4236842105263157\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00551\n",
      "epoch 13421 / 20000\n",
      "gradient norm: 0.03547577187418938, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 13422 / 20000\n",
      "gradient norm: 0.05668686355056707, minimum ratio: 2.4421052631578943\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 13423 / 20000\n",
      "gradient norm: 0.08336769475135952, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00554\n",
      "epoch 13424 / 20000\n",
      "gradient norm: 0.06492223383975215, minimum ratio: 2.4499999999999997\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 13425 / 20000\n",
      "gradient norm: 0.04518787289271131, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 13426 / 20000\n",
      "gradient norm: 0.03794673993252218, minimum ratio: 2.426315789473684\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 13427 / 20000\n",
      "gradient norm: 0.03658356607775204, minimum ratio: 2.4210526315789473\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 13428 / 20000\n",
      "gradient norm: 0.03762262040982023, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 13429 / 20000\n",
      "gradient norm: 0.03084785425744485, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 13430 / 20000\n",
      "gradient norm: 0.08077455156308133, minimum ratio: 2.436842105263158\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 13431 / 20000\n",
      "gradient norm: 0.10469861359160859, minimum ratio: 2.4394736842105265\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 13432 / 20000\n",
      "gradient norm: 0.09503668983234093, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 13433 / 20000\n",
      "gradient norm: 0.062367308943066746, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 13434 / 20000\n",
      "gradient norm: 0.07463697891216725, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 13435 / 20000\n",
      "gradient norm: 0.09511060983641073, minimum ratio: 2.426315789473684\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00551\n",
      "epoch 13436 / 20000\n",
      "gradient norm: 0.03573872143169865, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00554\n",
      "epoch 13437 / 20000\n",
      "gradient norm: 0.08055263373535126, minimum ratio: 2.4\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00553\n",
      "epoch 13438 / 20000\n",
      "gradient norm: 0.04500802559778094, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 13439 / 20000\n",
      "gradient norm: 0.0910805988823995, minimum ratio: 2.4499999999999997\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00551\n",
      "epoch 13440 / 20000\n",
      "gradient norm: 0.08031780924648046, minimum ratio: 2.460526315789474\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00555\n",
      "epoch 13441 / 20000\n",
      "gradient norm: 0.06059888075105846, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 13442 / 20000\n",
      "gradient norm: 0.07572113757487386, minimum ratio: 2.46578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 13443 / 20000\n",
      "gradient norm: 0.061364232387859374, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 13444 / 20000\n",
      "gradient norm: 0.02978280650859233, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 13445 / 20000\n",
      "gradient norm: 0.09741298231529072, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 13446 / 20000\n",
      "gradient norm: 0.022968904755543917, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 13447 / 20000\n",
      "gradient norm: 0.029432594034005888, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 13448 / 20000\n",
      "gradient norm: 0.05355392204364762, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 13449 / 20000\n",
      "gradient norm: 0.07878007850376889, minimum ratio: 2.4421052631578952\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 13450 / 20000\n",
      "gradient norm: 0.04616130408248864, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 13451 / 20000\n",
      "gradient norm: 0.025994574396463577, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 13452 / 20000\n",
      "gradient norm: 0.017114037065766752, minimum ratio: 2.423684210526316\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 13453 / 20000\n",
      "gradient norm: 0.037694830432883464, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 13454 / 20000\n",
      "gradient norm: 0.05898904363857582, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00551\n",
      "epoch 13455 / 20000\n",
      "gradient norm: 0.02665228897240013, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 13456 / 20000\n",
      "gradient norm: 0.023437553871190175, minimum ratio: 2.4499999999999997\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 13457 / 20000\n",
      "gradient norm: 0.07175771135371178, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 13458 / 20000\n",
      "gradient norm: 0.1299191026482731, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 13459 / 20000\n",
      "gradient norm: 0.10517155303386971, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 13460 / 20000\n",
      "gradient norm: 0.05197120492812246, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 13461 / 20000\n",
      "gradient norm: 0.03988764132373035, minimum ratio: 2.4263157894736844\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 13462 / 20000\n",
      "gradient norm: 0.05525922658125637, minimum ratio: 2.423684210526316\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 13463 / 20000\n",
      "gradient norm: 0.04673007095698267, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 13464 / 20000\n",
      "gradient norm: 0.04423097523977049, minimum ratio: 2.4078947368421053\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 13465 / 20000\n",
      "gradient norm: 0.048347759642638266, minimum ratio: 2.4394736842105265\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 13466 / 20000\n",
      "gradient norm: 0.06662588339531794, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 13467 / 20000\n",
      "gradient norm: 0.053687550371250836, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 13468 / 20000\n",
      "gradient norm: 0.04852616076823324, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 13469 / 20000\n",
      "gradient norm: 0.07430592854507267, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 13470 / 20000\n",
      "gradient norm: 0.07921361736953259, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 13471 / 20000\n",
      "gradient norm: 0.04342859724420123, minimum ratio: 2.4421052631578952\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 13472 / 20000\n",
      "gradient norm: 0.11059303377987817, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 13473 / 20000\n",
      "gradient norm: 0.04563957376376493, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00554\n",
      "epoch 13474 / 20000\n",
      "gradient norm: 0.0787380727706477, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 13475 / 20000\n",
      "gradient norm: 0.088759352453053, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 13476 / 20000\n",
      "gradient norm: 0.04596239194506779, minimum ratio: 2.4105263157894736\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 13477 / 20000\n",
      "gradient norm: 0.04818638903088868, minimum ratio: 2.4184210526315786\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 13478 / 20000\n",
      "gradient norm: 0.0462963359314017, minimum ratio: 2.4157894736842107\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 13479 / 20000\n",
      "gradient norm: 0.05845603661146015, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 13480 / 20000\n",
      "gradient norm: 0.07318479917012155, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 13481 / 20000\n",
      "gradient norm: 0.03920767322415486, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 13482 / 20000\n",
      "gradient norm: 0.06056533139781095, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 13483 / 20000\n",
      "gradient norm: 0.09464515332365409, minimum ratio: 2.4263157894736844\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 13484 / 20000\n",
      "gradient norm: 0.07911018538288772, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 13485 / 20000\n",
      "gradient norm: 0.08371662691934034, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 13486 / 20000\n",
      "gradient norm: 0.06743772864138009, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 13487 / 20000\n",
      "gradient norm: 0.07260969461640343, minimum ratio: 2.4421052631578943\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 13488 / 20000\n",
      "gradient norm: 0.044583386996237095, minimum ratio: 2.4499999999999997\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 13489 / 20000\n",
      "gradient norm: 0.054405136208515614, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 13490 / 20000\n",
      "gradient norm: 0.04314705776050687, minimum ratio: 2.4447368421052627\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 13491 / 20000\n",
      "gradient norm: 0.06295169476652518, minimum ratio: 2.421052631578947\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 13492 / 20000\n",
      "gradient norm: 0.07396842670277692, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 13493 / 20000\n",
      "gradient norm: 0.10754594230093062, minimum ratio: 2.418421052631579\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 13494 / 20000\n",
      "gradient norm: 0.09368237212765962, minimum ratio: 2.4\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 13495 / 20000\n",
      "gradient norm: 0.07777697220444679, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 13496 / 20000\n",
      "gradient norm: 0.09043260134058073, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 13497 / 20000\n",
      "gradient norm: 0.07530444220174104, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 13498 / 20000\n",
      "gradient norm: 0.0789899091469124, minimum ratio: 2.423684210526316\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 13499 / 20000\n",
      "gradient norm: 0.06479624850908294, minimum ratio: 2.4236842105263157\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 13500 / 20000\n",
      "gradient norm: 0.06340793881099671, minimum ratio: 2.4184210526315786\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 13501 / 20000\n",
      "gradient norm: 0.10530456434935331, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00551\n",
      "epoch 13502 / 20000\n",
      "gradient norm: 0.046057862375164405, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 13503 / 20000\n",
      "gradient norm: 0.09084079093008768, minimum ratio: 2.4210526315789473\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 13504 / 20000\n",
      "gradient norm: 0.0901217691716738, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 13505 / 20000\n",
      "gradient norm: 0.055401797930244356, minimum ratio: 2.4499999999999997\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 13506 / 20000\n",
      "gradient norm: 0.05942330075777136, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 13507 / 20000\n",
      "gradient norm: 0.04631387013068888, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 13508 / 20000\n",
      "gradient norm: 0.07568861352046952, minimum ratio: 2.4499999999999997\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 13509 / 20000\n",
      "gradient norm: 0.03557024654583074, minimum ratio: 2.4263157894736844\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 13510 / 20000\n",
      "gradient norm: 0.11203365097753704, minimum ratio: 2.421052631578948\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00552\n",
      "epoch 13511 / 20000\n",
      "gradient norm: 0.08459991402924061, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 13512 / 20000\n",
      "gradient norm: 0.06266209506429732, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 13513 / 20000\n",
      "gradient norm: 0.06141730782110244, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 13514 / 20000\n",
      "gradient norm: 0.07335729035548866, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 13515 / 20000\n",
      "gradient norm: 0.034352543676504865, minimum ratio: 2.4394736842105265\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 13516 / 20000\n",
      "gradient norm: 0.10039785970002413, minimum ratio: 2.4236842105263157\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 13517 / 20000\n",
      "gradient norm: 0.11745201563462615, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00555\n",
      "epoch 13518 / 20000\n",
      "gradient norm: 0.08362700571888126, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00551\n",
      "epoch 13519 / 20000\n",
      "gradient norm: 0.058880303520709276, minimum ratio: 2.4184210526315786\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 13520 / 20000\n",
      "gradient norm: 0.06343737663701177, minimum ratio: 2.4289473684210523\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00553\n",
      "epoch 13521 / 20000\n",
      "gradient norm: 0.09188293927581981, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 13522 / 20000\n",
      "gradient norm: 0.05332817800808698, minimum ratio: 2.418421052631579\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 13523 / 20000\n",
      "gradient norm: 0.06945184129290283, minimum ratio: 2.4157894736842107\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 13524 / 20000\n",
      "gradient norm: 0.040056080717477016, minimum ratio: 2.418421052631579\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 13525 / 20000\n",
      "gradient norm: 0.033711489420966245, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 13526 / 20000\n",
      "gradient norm: 0.04890755827364046, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 13527 / 20000\n",
      "gradient norm: 0.04856572284188587, minimum ratio: 2.452631578947368\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 13528 / 20000\n",
      "gradient norm: 0.051465356547851115, minimum ratio: 2.4210526315789473\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 13529 / 20000\n",
      "gradient norm: 0.0450438191764988, minimum ratio: 2.418421052631579\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 13530 / 20000\n",
      "gradient norm: 0.07802266115322709, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 13531 / 20000\n",
      "gradient norm: 0.04872934578452259, minimum ratio: 2.4157894736842103\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 13532 / 20000\n",
      "gradient norm: 0.05090571955952328, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 13533 / 20000\n",
      "gradient norm: 0.06316628187778406, minimum ratio: 2.4157894736842107\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 13534 / 20000\n",
      "gradient norm: 0.05387296847766265, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 13535 / 20000\n",
      "gradient norm: 0.06732820783508942, minimum ratio: 2.4210526315789473\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 13536 / 20000\n",
      "gradient norm: 0.03968765835452359, minimum ratio: 2.4263157894736844\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 13537 / 20000\n",
      "gradient norm: 0.055137583149189595, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 13538 / 20000\n",
      "gradient norm: 0.06296156803728081, minimum ratio: 2.4447368421052635\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 13539 / 20000\n",
      "gradient norm: 0.1091129906126298, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 13540 / 20000\n",
      "gradient norm: 0.0302585857862141, minimum ratio: 2.4236842105263157\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 13541 / 20000\n",
      "gradient norm: 0.10383914056001231, minimum ratio: 2.426315789473684\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 13542 / 20000\n",
      "gradient norm: 0.048228218547592405, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 13543 / 20000\n",
      "gradient norm: 0.03667558899905998, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 13544 / 20000\n",
      "gradient norm: 0.022617497292230837, minimum ratio: 2.4421052631578943\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 13545 / 20000\n",
      "gradient norm: 0.04955992134637199, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 13546 / 20000\n",
      "gradient norm: 0.0350795136182569, minimum ratio: 2.4421052631578943\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 13547 / 20000\n",
      "gradient norm: 0.08650577859953046, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 13548 / 20000\n",
      "gradient norm: 0.1339982154313475, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 13549 / 20000\n",
      "gradient norm: 0.15815689112059772, minimum ratio: 2.4499999999999997\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00555\n",
      "epoch 13550 / 20000\n",
      "gradient norm: 0.05816492086159997, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 13551 / 20000\n",
      "gradient norm: 0.0977776610525325, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 13552 / 20000\n",
      "gradient norm: 0.07057767570950091, minimum ratio: 2.4447368421052635\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 13553 / 20000\n",
      "gradient norm: 0.0730245649756398, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 13554 / 20000\n",
      "gradient norm: 0.06749557034345344, minimum ratio: 2.423684210526316\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 13555 / 20000\n",
      "gradient norm: 0.028364985424559563, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 13556 / 20000\n",
      "gradient norm: 0.10687726363539696, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 13557 / 20000\n",
      "gradient norm: 0.037001528864493594, minimum ratio: 2.421052631578948\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 13558 / 20000\n",
      "gradient norm: 0.06496508678537793, minimum ratio: 2.4184210526315786\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 13559 / 20000\n",
      "gradient norm: 0.04642513074213639, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 13560 / 20000\n",
      "gradient norm: 0.08227935584727675, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 13561 / 20000\n",
      "gradient norm: 0.06980943423695862, minimum ratio: 2.4289473684210523\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 13562 / 20000\n",
      "gradient norm: 0.04041690644226037, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 13563 / 20000\n",
      "gradient norm: 0.07551382132805884, minimum ratio: 2.426315789473684\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 13564 / 20000\n",
      "gradient norm: 0.1674002124927938, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00555\n",
      "epoch 13565 / 20000\n",
      "gradient norm: 0.02366747532505542, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 13566 / 20000\n",
      "gradient norm: 0.07274894183501601, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 13567 / 20000\n",
      "gradient norm: 0.06155546911759302, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 13568 / 20000\n",
      "gradient norm: 0.07447516289539635, minimum ratio: 2.423684210526316\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 13569 / 20000\n",
      "gradient norm: 0.05316364686586894, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 13570 / 20000\n",
      "gradient norm: 0.08966480463277549, minimum ratio: 2.4263157894736844\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00551\n",
      "epoch 13571 / 20000\n",
      "gradient norm: 0.05770509800640866, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 13572 / 20000\n",
      "gradient norm: 0.06308455773978494, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 13573 / 20000\n",
      "gradient norm: 0.11871455208165571, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00551\n",
      "epoch 13574 / 20000\n",
      "gradient norm: 0.0625389376655221, minimum ratio: 2.423684210526316\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 13575 / 20000\n",
      "gradient norm: 0.045842802413972095, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 13576 / 20000\n",
      "gradient norm: 0.059700450030504726, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 13577 / 20000\n",
      "gradient norm: 0.07385304430499673, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 13578 / 20000\n",
      "gradient norm: 0.07107813359471038, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 13579 / 20000\n",
      "gradient norm: 0.05596161974244751, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 13580 / 20000\n",
      "gradient norm: 0.07350387063343078, minimum ratio: 2.4289473684210523\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 13581 / 20000\n",
      "gradient norm: 0.02355048689787509, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 13582 / 20000\n",
      "gradient norm: 0.05708153691375628, minimum ratio: 2.423684210526316\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 13583 / 20000\n",
      "gradient norm: 0.017161343508632854, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 13584 / 20000\n",
      "gradient norm: 0.14366579696070403, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00551\n",
      "epoch 13585 / 20000\n",
      "gradient norm: 0.08267230269848369, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00556\n",
      "epoch 13586 / 20000\n",
      "gradient norm: 0.05009477874773438, minimum ratio: 2.3973684210526316\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 13587 / 20000\n",
      "gradient norm: 0.06844109058147296, minimum ratio: 2.436842105263158\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 13588 / 20000\n",
      "gradient norm: 0.08870308648329228, minimum ratio: 2.4499999999999997\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 13589 / 20000\n",
      "gradient norm: 0.05731895277858712, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 13590 / 20000\n",
      "gradient norm: 0.026333203684771433, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 13591 / 20000\n",
      "gradient norm: 0.078060865518637, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 13592 / 20000\n",
      "gradient norm: 0.05749119014944881, minimum ratio: 2.4026315789473687\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 13593 / 20000\n",
      "gradient norm: 0.07272090943297371, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 13594 / 20000\n",
      "gradient norm: 0.07746243287692778, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 13595 / 20000\n",
      "gradient norm: 0.06200472975615412, minimum ratio: 2.4105263157894736\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 13596 / 20000\n",
      "gradient norm: 0.06086707295617089, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 13597 / 20000\n",
      "gradient norm: 0.06074263801565394, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 13598 / 20000\n",
      "gradient norm: 0.1376867291983217, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 13599 / 20000\n",
      "gradient norm: 0.07788268505828455, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 13600 / 20000\n",
      "gradient norm: 0.09082916754414327, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 13601 / 20000\n",
      "gradient norm: 0.04550060845213011, minimum ratio: 2.423684210526316\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 13602 / 20000\n",
      "gradient norm: 0.08631162611709442, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 13603 / 20000\n",
      "gradient norm: 0.024356767848075833, minimum ratio: 2.4421052631578943\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 13604 / 20000\n",
      "gradient norm: 0.058904376812279224, minimum ratio: 2.4263157894736844\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 13605 / 20000\n",
      "gradient norm: 0.03760886599775404, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 13606 / 20000\n",
      "gradient norm: 0.07522234885254875, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 13607 / 20000\n",
      "gradient norm: 0.036474573746090755, minimum ratio: 2.4184210526315786\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 13608 / 20000\n",
      "gradient norm: 0.05293399322545156, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 13609 / 20000\n",
      "gradient norm: 0.10663878620835021, minimum ratio: 2.4421052631578943\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 13610 / 20000\n",
      "gradient norm: 0.028509782016044483, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 13611 / 20000\n",
      "gradient norm: 0.0599348699033726, minimum ratio: 2.4421052631578943\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 13612 / 20000\n",
      "gradient norm: 0.03178286674665287, minimum ratio: 2.4105263157894736\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 13613 / 20000\n",
      "gradient norm: 0.07498595581273548, minimum ratio: 2.4394736842105265\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 13614 / 20000\n",
      "gradient norm: 0.06718515133252367, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 13615 / 20000\n",
      "gradient norm: 0.06040933775511803, minimum ratio: 2.4157894736842107\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 13616 / 20000\n",
      "gradient norm: 0.0415685327607207, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 13617 / 20000\n",
      "gradient norm: 0.054463266278617084, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 13618 / 20000\n",
      "gradient norm: 0.08149431284982711, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 13619 / 20000\n",
      "gradient norm: 0.08254084130749106, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 13620 / 20000\n",
      "gradient norm: 0.05556695304403547, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 13621 / 20000\n",
      "gradient norm: 0.04486194485798478, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 13622 / 20000\n",
      "gradient norm: 0.06797960834228434, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 13623 / 20000\n",
      "gradient norm: 0.08299602264014538, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 13624 / 20000\n",
      "gradient norm: 0.0625342606799677, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 13625 / 20000\n",
      "gradient norm: 0.022881361044710502, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 13626 / 20000\n",
      "gradient norm: 0.0419800512609072, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 13627 / 20000\n",
      "gradient norm: 0.08745376596198184, minimum ratio: 2.423684210526316\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 13628 / 20000\n",
      "gradient norm: 0.081446650729049, minimum ratio: 2.4157894736842103\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 13629 / 20000\n",
      "gradient norm: 0.057593395991716534, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 13630 / 20000\n",
      "gradient norm: 0.026083931894390844, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 13631 / 20000\n",
      "gradient norm: 0.03618207429826725, minimum ratio: 2.4263157894736844\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 13632 / 20000\n",
      "gradient norm: 0.06306970585137606, minimum ratio: 2.4210526315789473\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 13633 / 20000\n",
      "gradient norm: 0.10787948920915369, minimum ratio: 2.43421052631579\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 13634 / 20000\n",
      "gradient norm: 0.06226321522262879, minimum ratio: 2.4394736842105265\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 13635 / 20000\n",
      "gradient norm: 0.07794214872410521, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 13636 / 20000\n",
      "gradient norm: 0.03902222329634242, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 13637 / 20000\n",
      "gradient norm: 0.04439656384056434, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 13638 / 20000\n",
      "gradient norm: 0.04835783279850148, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 13639 / 20000\n",
      "gradient norm: 0.05308759940089658, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 13640 / 20000\n",
      "gradient norm: 0.03725295864569489, minimum ratio: 2.4157894736842103\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 13641 / 20000\n",
      "gradient norm: 0.04852858048980124, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 13642 / 20000\n",
      "gradient norm: 0.07476240170944948, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 13643 / 20000\n",
      "gradient norm: 0.09271704871207476, minimum ratio: 2.4105263157894736\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 13644 / 20000\n",
      "gradient norm: 0.06008821178693324, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 13645 / 20000\n",
      "gradient norm: 0.08520574639260303, minimum ratio: 2.4263157894736844\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00554\n",
      "epoch 13646 / 20000\n",
      "gradient norm: 0.08384457742795348, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00551\n",
      "epoch 13647 / 20000\n",
      "gradient norm: 0.05599130742484704, minimum ratio: 2.4421052631578943\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 13648 / 20000\n",
      "gradient norm: 0.06600086501566693, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 13649 / 20000\n",
      "gradient norm: 0.0742152757011354, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 13650 / 20000\n",
      "gradient norm: 0.03918976699060295, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00551\n",
      "epoch 13651 / 20000\n",
      "gradient norm: 0.10334033262915909, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 13652 / 20000\n",
      "gradient norm: 0.07816804153844714, minimum ratio: 2.4105263157894736\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 13653 / 20000\n",
      "gradient norm: 0.03496438334695995, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 13654 / 20000\n",
      "gradient norm: 0.08849132375326008, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 13655 / 20000\n",
      "gradient norm: 0.1405876778298989, minimum ratio: 2.4289473684210523\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00554\n",
      "epoch 13656 / 20000\n",
      "gradient norm: 0.022044436947908252, minimum ratio: 2.4394736842105265\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 13657 / 20000\n",
      "gradient norm: 0.07607295276829973, minimum ratio: 2.4105263157894736\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 13658 / 20000\n",
      "gradient norm: 0.09982695139478892, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 13659 / 20000\n",
      "gradient norm: 0.05003940290771425, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 13660 / 20000\n",
      "gradient norm: 0.04956391538144089, minimum ratio: 2.4026315789473687\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 13661 / 20000\n",
      "gradient norm: 0.08044574083760381, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 13662 / 20000\n",
      "gradient norm: 0.08221697603585199, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 13663 / 20000\n",
      "gradient norm: 0.04810600355267525, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 13664 / 20000\n",
      "gradient norm: 0.053288727591279894, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 13665 / 20000\n",
      "gradient norm: 0.04209035699022934, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 13666 / 20000\n",
      "gradient norm: 0.07526641280855983, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 13667 / 20000\n",
      "gradient norm: 0.08787100861081854, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 13668 / 20000\n",
      "gradient norm: 0.05637281876988709, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 13669 / 20000\n",
      "gradient norm: 0.0805972853777348, minimum ratio: 2.4236842105263157\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 13670 / 20000\n",
      "gradient norm: 0.0342438435764052, minimum ratio: 2.4421052631578943\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 13671 / 20000\n",
      "gradient norm: 0.06489680893719196, minimum ratio: 2.4157894736842103\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 13672 / 20000\n",
      "gradient norm: 0.06387843473930843, minimum ratio: 2.413157894736842\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 13673 / 20000\n",
      "gradient norm: 0.034044493979308754, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 13674 / 20000\n",
      "gradient norm: 0.03173971548676491, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 13675 / 20000\n",
      "gradient norm: 0.0525073941971641, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 13676 / 20000\n",
      "gradient norm: 0.05184553725848673, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 13677 / 20000\n",
      "gradient norm: 0.06408053851919249, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 13678 / 20000\n",
      "gradient norm: 0.05686759852687828, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 13679 / 20000\n",
      "gradient norm: 0.062393553380388767, minimum ratio: 2.46578947368421\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 13680 / 20000\n",
      "gradient norm: 0.038560278073418885, minimum ratio: 2.4236842105263157\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 13681 / 20000\n",
      "gradient norm: 0.13239543815143406, minimum ratio: 2.423684210526316\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 13682 / 20000\n",
      "gradient norm: 0.02875028045673389, minimum ratio: 2.413157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 13683 / 20000\n",
      "gradient norm: 0.05142174835782498, minimum ratio: 2.4263157894736844\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 13684 / 20000\n",
      "gradient norm: 0.10794560794602148, minimum ratio: 2.4263157894736844\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 13685 / 20000\n",
      "gradient norm: 0.030735614418517798, minimum ratio: 2.4210526315789473\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 13686 / 20000\n",
      "gradient norm: 0.08302951016230509, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 13687 / 20000\n",
      "gradient norm: 0.06340997194638476, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 13688 / 20000\n",
      "gradient norm: 0.055926199071109295, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 13689 / 20000\n",
      "gradient norm: 0.09994068510422949, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 13690 / 20000\n",
      "gradient norm: 0.08957109821494669, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 13691 / 20000\n",
      "gradient norm: 0.09262266737641767, minimum ratio: 2.4236842105263157\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 13692 / 20000\n",
      "gradient norm: 0.026036164112156257, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 13693 / 20000\n",
      "gradient norm: 0.05790362093830481, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 13694 / 20000\n",
      "gradient norm: 0.03090242759208195, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 13695 / 20000\n",
      "gradient norm: 0.09410054079489782, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 13696 / 20000\n",
      "gradient norm: 0.05813944461988285, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 13697 / 20000\n",
      "gradient norm: 0.12782417493872344, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 13698 / 20000\n",
      "gradient norm: 0.05853700420993846, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 13699 / 20000\n",
      "gradient norm: 0.07552024762844667, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 13700 / 20000\n",
      "gradient norm: 0.06811730866320431, minimum ratio: 2.4157894736842103\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 13701 / 20000\n",
      "gradient norm: 0.03462927152577322, minimum ratio: 2.436842105263158\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 13702 / 20000\n",
      "gradient norm: 0.057477471098536626, minimum ratio: 2.4289473684210523\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 13703 / 20000\n",
      "gradient norm: 0.10687928722472861, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 13704 / 20000\n",
      "gradient norm: 0.10377020842861384, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 13705 / 20000\n",
      "gradient norm: 0.07734759181039408, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 13706 / 20000\n",
      "gradient norm: 0.12181246210820973, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 13707 / 20000\n",
      "gradient norm: 0.04940204811282456, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 13708 / 20000\n",
      "gradient norm: 0.050390880671329796, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 13709 / 20000\n",
      "gradient norm: 0.0807931215967983, minimum ratio: 2.418421052631579\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 13710 / 20000\n",
      "gradient norm: 0.08582395805569831, minimum ratio: 2.4210526315789473\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 13711 / 20000\n",
      "gradient norm: 0.04671653229161166, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 13712 / 20000\n",
      "gradient norm: 0.07478960463777184, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 13713 / 20000\n",
      "gradient norm: 0.06250415375689045, minimum ratio: 2.418421052631579\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00553\n",
      "epoch 13714 / 20000\n",
      "gradient norm: 0.07629369164351374, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 13715 / 20000\n",
      "gradient norm: 0.03277718566823751, minimum ratio: 2.4157894736842107\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 13716 / 20000\n",
      "gradient norm: 0.0669001821661368, minimum ratio: 2.436842105263158\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 13717 / 20000\n",
      "gradient norm: 0.06354367596213706, minimum ratio: 2.4236842105263157\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 13718 / 20000\n",
      "gradient norm: 0.09890138969058171, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 13719 / 20000\n",
      "gradient norm: 0.09238414815627038, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 13720 / 20000\n",
      "gradient norm: 0.06393307854887098, minimum ratio: 2.426315789473684\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 13721 / 20000\n",
      "gradient norm: 0.032919128047069535, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 13722 / 20000\n",
      "gradient norm: 0.037403763373731636, minimum ratio: 2.4157894736842107\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 13723 / 20000\n",
      "gradient norm: 0.03876256587682292, minimum ratio: 2.4157894736842103\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 13724 / 20000\n",
      "gradient norm: 0.05837822941248305, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 13725 / 20000\n",
      "gradient norm: 0.04160956965642981, minimum ratio: 2.426315789473684\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 13726 / 20000\n",
      "gradient norm: 0.04103554277389776, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 13727 / 20000\n",
      "gradient norm: 0.056889140148996376, minimum ratio: 2.4263157894736844\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 13728 / 20000\n",
      "gradient norm: 0.04556064639473334, minimum ratio: 2.4263157894736844\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 13729 / 20000\n",
      "gradient norm: 0.04449495323933661, minimum ratio: 2.4394736842105265\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 13730 / 20000\n",
      "gradient norm: 0.08409974974347278, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 13731 / 20000\n",
      "gradient norm: 0.10565450607100502, minimum ratio: 2.4105263157894736\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 13732 / 20000\n",
      "gradient norm: 0.09463203937048092, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 13733 / 20000\n",
      "gradient norm: 0.1159900845377706, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 13734 / 20000\n",
      "gradient norm: 0.035968740136013366, minimum ratio: 2.4157894736842107\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 13735 / 20000\n",
      "gradient norm: 0.056771476491121575, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 13736 / 20000\n",
      "gradient norm: 0.08005980215966702, minimum ratio: 2.418421052631579\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 13737 / 20000\n",
      "gradient norm: 0.09338559443131089, minimum ratio: 2.421052631578948\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 13738 / 20000\n",
      "gradient norm: 0.08753405956667848, minimum ratio: 2.405263157894737\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 13739 / 20000\n",
      "gradient norm: 0.06943762904847972, minimum ratio: 2.4421052631578943\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 13740 / 20000\n",
      "gradient norm: 0.031402765118400566, minimum ratio: 2.4263157894736844\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 13741 / 20000\n",
      "gradient norm: 0.03705919795902446, minimum ratio: 2.421052631578948\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 13742 / 20000\n",
      "gradient norm: 0.11787544953403994, minimum ratio: 2.413157894736842\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 13743 / 20000\n",
      "gradient norm: 0.03686017444124445, minimum ratio: 2.4105263157894736\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 13744 / 20000\n",
      "gradient norm: 0.03684056276688352, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 13745 / 20000\n",
      "gradient norm: 0.0893138651154004, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 13746 / 20000\n",
      "gradient norm: 0.06053794932086021, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 13747 / 20000\n",
      "gradient norm: 0.16550540452590212, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 13748 / 20000\n",
      "gradient norm: 0.0877059533377178, minimum ratio: 2.426315789473684\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 13749 / 20000\n",
      "gradient norm: 0.07774419616907835, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 13750 / 20000\n",
      "gradient norm: 0.07919955044053495, minimum ratio: 2.4236842105263157\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 13751 / 20000\n",
      "gradient norm: 0.08333899104036391, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 13752 / 20000\n",
      "gradient norm: 0.038103496670373715, minimum ratio: 2.4263157894736844\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 13753 / 20000\n",
      "gradient norm: 0.07568056767922826, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00551\n",
      "epoch 13754 / 20000\n",
      "gradient norm: 0.04729827612754889, minimum ratio: 2.423684210526316\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 13755 / 20000\n",
      "gradient norm: 0.07955438550561666, minimum ratio: 2.4499999999999997\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 13756 / 20000\n",
      "gradient norm: 0.038436029717558995, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 13757 / 20000\n",
      "gradient norm: 0.06725656613707542, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 13758 / 20000\n",
      "gradient norm: 0.079485721711535, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 13759 / 20000\n",
      "gradient norm: 0.03905543781729648, minimum ratio: 2.4026315789473687\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00551\n",
      "epoch 13760 / 20000\n",
      "gradient norm: 0.050897263863589615, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 13761 / 20000\n",
      "gradient norm: 0.067236859962577, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 13762 / 20000\n",
      "gradient norm: 0.06358568137511611, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 13763 / 20000\n",
      "gradient norm: 0.04680734552675858, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 13764 / 20000\n",
      "gradient norm: 0.08887717520701699, minimum ratio: 2.405263157894737\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 13765 / 20000\n",
      "gradient norm: 0.0914836075680796, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 13766 / 20000\n",
      "gradient norm: 0.10249968414427713, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 13767 / 20000\n",
      "gradient norm: 0.05281084461603314, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 13768 / 20000\n",
      "gradient norm: 0.06584874261170626, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 13769 / 20000\n",
      "gradient norm: 0.08559573569800705, minimum ratio: 2.4263157894736844\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 13770 / 20000\n",
      "gradient norm: 0.015468038647668436, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 13771 / 20000\n",
      "gradient norm: 0.09786961995996535, minimum ratio: 2.4421052631578943\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 13772 / 20000\n",
      "gradient norm: 0.04689209858770482, minimum ratio: 2.418421052631579\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 13773 / 20000\n",
      "gradient norm: 0.10790462151635438, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 13774 / 20000\n",
      "gradient norm: 0.06682636897312477, minimum ratio: 2.4184210526315786\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 13775 / 20000\n",
      "gradient norm: 0.07604646915569901, minimum ratio: 2.407894736842105\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 13776 / 20000\n",
      "gradient norm: 0.10865670640487224, minimum ratio: 2.4236842105263157\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00551\n",
      "epoch 13777 / 20000\n",
      "gradient norm: 0.17226488958112895, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00556\n",
      "epoch 13778 / 20000\n",
      "gradient norm: 0.05191026508691721, minimum ratio: 2.4105263157894736\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 13779 / 20000\n",
      "gradient norm: 0.06717724062036723, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 13780 / 20000\n",
      "gradient norm: 0.06593529850943014, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 13781 / 20000\n",
      "gradient norm: 0.06099484434525948, minimum ratio: 2.4078947368421053\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 13782 / 20000\n",
      "gradient norm: 0.05511354608461261, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 13783 / 20000\n",
      "gradient norm: 0.06766590813640505, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 13784 / 20000\n",
      "gradient norm: 0.04951285291463137, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 13785 / 20000\n",
      "gradient norm: 0.09129152959212661, minimum ratio: 2.426315789473684\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 13786 / 20000\n",
      "gradient norm: 0.04147316637681797, minimum ratio: 2.418421052631579\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 13787 / 20000\n",
      "gradient norm: 0.04282393898756709, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 13788 / 20000\n",
      "gradient norm: 0.02776142692891881, minimum ratio: 2.413157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 13789 / 20000\n",
      "gradient norm: 0.04209626489318907, minimum ratio: 2.4263157894736844\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 13790 / 20000\n",
      "gradient norm: 0.03905455941276159, minimum ratio: 2.4157894736842107\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 13791 / 20000\n",
      "gradient norm: 0.07277075524325483, minimum ratio: 2.4078947368421053\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 13792 / 20000\n",
      "gradient norm: 0.07636512233875692, minimum ratio: 2.4078947368421053\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 13793 / 20000\n",
      "gradient norm: 0.07421513786539435, minimum ratio: 2.4157894736842103\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 13794 / 20000\n",
      "gradient norm: 0.03160631499486044, minimum ratio: 2.426315789473684\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 13795 / 20000\n",
      "gradient norm: 0.03803674649680033, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 13796 / 20000\n",
      "gradient norm: 0.027143499988596886, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 13797 / 20000\n",
      "gradient norm: 0.030885746295098215, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 13798 / 20000\n",
      "gradient norm: 0.07564624809310772, minimum ratio: 2.4263157894736844\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 13799 / 20000\n",
      "gradient norm: 0.04517183183634188, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 13800 / 20000\n",
      "gradient norm: 0.10493163269711658, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 13801 / 20000\n",
      "gradient norm: 0.028025158593663946, minimum ratio: 2.418421052631579\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 13802 / 20000\n",
      "gradient norm: 0.06065786600811407, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 13803 / 20000\n",
      "gradient norm: 0.07094439351931214, minimum ratio: 2.4157894736842107\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 13804 / 20000\n",
      "gradient norm: 0.10549176414497197, minimum ratio: 2.426315789473684\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 13805 / 20000\n",
      "gradient norm: 0.06959449732676148, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 13806 / 20000\n",
      "gradient norm: 0.07124294084496796, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 13807 / 20000\n",
      "gradient norm: 0.05200292792869732, minimum ratio: 2.405263157894737\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 13808 / 20000\n",
      "gradient norm: 0.03983703104313463, minimum ratio: 2.4236842105263157\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00551\n",
      "epoch 13809 / 20000\n",
      "gradient norm: 0.03818891650007572, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 13810 / 20000\n",
      "gradient norm: 0.054559632670134306, minimum ratio: 2.4026315789473682\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 13811 / 20000\n",
      "gradient norm: 0.056548452557763085, minimum ratio: 2.4078947368421053\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 13812 / 20000\n",
      "gradient norm: 0.0537336046108976, minimum ratio: 2.4105263157894736\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00551\n",
      "epoch 13813 / 20000\n",
      "gradient norm: 0.03288320063438732, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 13814 / 20000\n",
      "gradient norm: 0.033854123641503975, minimum ratio: 2.4263157894736844\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 13815 / 20000\n",
      "gradient norm: 0.04610858766682213, minimum ratio: 2.4236842105263157\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 13816 / 20000\n",
      "gradient norm: 0.09857364810886793, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 13817 / 20000\n",
      "gradient norm: 0.036457186899497174, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 13818 / 20000\n",
      "gradient norm: 0.05297614283335861, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00553\n",
      "epoch 13819 / 20000\n",
      "gradient norm: 0.047175953950500116, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 13820 / 20000\n",
      "gradient norm: 0.09047488973010331, minimum ratio: 2.418421052631579\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 13821 / 20000\n",
      "gradient norm: 0.032041981641668826, minimum ratio: 2.4421052631578943\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 13822 / 20000\n",
      "gradient norm: 0.05654036850319244, minimum ratio: 2.4157894736842103\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 13823 / 20000\n",
      "gradient norm: 0.034706792735960335, minimum ratio: 2.4394736842105265\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 13824 / 20000\n",
      "gradient norm: 0.09329146693926305, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 13825 / 20000\n",
      "gradient norm: 0.06283983238972723, minimum ratio: 2.4\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 13826 / 20000\n",
      "gradient norm: 0.11309798969887197, minimum ratio: 2.4263157894736844\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 13827 / 20000\n",
      "gradient norm: 0.09877404745202512, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 13828 / 20000\n",
      "gradient norm: 0.06260067131370306, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 13829 / 20000\n",
      "gradient norm: 0.04135866346769035, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 13830 / 20000\n",
      "gradient norm: 0.059642215754138306, minimum ratio: 2.4499999999999997\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 13831 / 20000\n",
      "gradient norm: 0.07993920566514134, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 13832 / 20000\n",
      "gradient norm: 0.06569320886046626, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 13833 / 20000\n",
      "gradient norm: 0.08993007789831609, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 13834 / 20000\n",
      "gradient norm: 0.08502478929585777, minimum ratio: 2.4394736842105265\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00551\n",
      "epoch 13835 / 20000\n",
      "gradient norm: 0.09255116694839671, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 13836 / 20000\n",
      "gradient norm: 0.07232804308296181, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00555\n",
      "epoch 13837 / 20000\n",
      "gradient norm: 0.07851183856837451, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 13838 / 20000\n",
      "gradient norm: 0.07789996935753152, minimum ratio: 2.4289473684210523\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 13839 / 20000\n",
      "gradient norm: 0.07196061819558963, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 13840 / 20000\n",
      "gradient norm: 0.05572777794441208, minimum ratio: 2.4210526315789473\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 13841 / 20000\n",
      "gradient norm: 0.06471002288162708, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 13842 / 20000\n",
      "gradient norm: 0.04721687808341812, minimum ratio: 2.4236842105263157\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 13843 / 20000\n",
      "gradient norm: 0.1215692154946737, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 13844 / 20000\n",
      "gradient norm: 0.060073988628573716, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 13845 / 20000\n",
      "gradient norm: 0.0505875031958567, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 13846 / 20000\n",
      "gradient norm: 0.04736452871293295, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 13847 / 20000\n",
      "gradient norm: 0.0632331506931223, minimum ratio: 2.426315789473684\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00551\n",
      "epoch 13848 / 20000\n",
      "gradient norm: 0.0755257586715743, minimum ratio: 2.4394736842105265\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 13849 / 20000\n",
      "gradient norm: 0.09672619949560612, minimum ratio: 2.4078947368421053\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 13850 / 20000\n",
      "gradient norm: 0.052572930813767016, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 13851 / 20000\n",
      "gradient norm: 0.0404268561542267, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 13852 / 20000\n",
      "gradient norm: 0.09002875292208046, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 13853 / 20000\n",
      "gradient norm: 0.04930820601293817, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 13854 / 20000\n",
      "gradient norm: 0.0670234730350785, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 13855 / 20000\n",
      "gradient norm: 0.05911702994490042, minimum ratio: 2.4236842105263157\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00551\n",
      "epoch 13856 / 20000\n",
      "gradient norm: 0.052391031495062634, minimum ratio: 2.4184210526315786\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 13857 / 20000\n",
      "gradient norm: 0.08648618182633072, minimum ratio: 2.4263157894736844\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 13858 / 20000\n",
      "gradient norm: 0.08383500843774527, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 13859 / 20000\n",
      "gradient norm: 0.08261089006555267, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 13860 / 20000\n",
      "gradient norm: 0.02999079025175888, minimum ratio: 2.4184210526315786\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 13861 / 20000\n",
      "gradient norm: 0.0644663691346068, minimum ratio: 2.421052631578947\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 13862 / 20000\n",
      "gradient norm: 0.042770589352585375, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 13863 / 20000\n",
      "gradient norm: 0.08946850377833471, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 13864 / 20000\n",
      "gradient norm: 0.08533010224346071, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 13865 / 20000\n",
      "gradient norm: 0.05345373903401196, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 13866 / 20000\n",
      "gradient norm: 0.07824606946087442, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 13867 / 20000\n",
      "gradient norm: 0.09046797483460978, minimum ratio: 2.4157894736842103\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 13868 / 20000\n",
      "gradient norm: 0.08274756031460129, minimum ratio: 2.423684210526316\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 13869 / 20000\n",
      "gradient norm: 0.07038381042366382, minimum ratio: 2.4078947368421053\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 13870 / 20000\n",
      "gradient norm: 0.06292623473564163, minimum ratio: 2.4289473684210523\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 13871 / 20000\n",
      "gradient norm: 0.06678970070788637, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 13872 / 20000\n",
      "gradient norm: 0.06451433081383584, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 13873 / 20000\n",
      "gradient norm: 0.0824488764628768, minimum ratio: 2.4263157894736844\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 13874 / 20000\n",
      "gradient norm: 0.04687660772469826, minimum ratio: 2.4236842105263157\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 13875 / 20000\n",
      "gradient norm: 0.060073767439462245, minimum ratio: 2.4210526315789473\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 13876 / 20000\n",
      "gradient norm: 0.08897696738131344, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 13877 / 20000\n",
      "gradient norm: 0.0341119684453588, minimum ratio: 2.4157894736842103\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 13878 / 20000\n",
      "gradient norm: 0.06340612770873122, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 13879 / 20000\n",
      "gradient norm: 0.06187615392263979, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 13880 / 20000\n",
      "gradient norm: 0.08261369614046998, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 13881 / 20000\n",
      "gradient norm: 0.10613114226725884, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 13882 / 20000\n",
      "gradient norm: 0.04454913912923075, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 13883 / 20000\n",
      "gradient norm: 0.06880586105398834, minimum ratio: 2.4236842105263157\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 13884 / 20000\n",
      "gradient norm: 0.04845851782010868, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 13885 / 20000\n",
      "gradient norm: 0.030430353872361593, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 13886 / 20000\n",
      "gradient norm: 0.03168861451558769, minimum ratio: 2.418421052631579\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 13887 / 20000\n",
      "gradient norm: 0.027674448530888185, minimum ratio: 2.421052631578947\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 13888 / 20000\n",
      "gradient norm: 0.07143529260065407, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 13889 / 20000\n",
      "gradient norm: 0.04342450149124488, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 13890 / 20000\n",
      "gradient norm: 0.061226215679198503, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 13891 / 20000\n",
      "gradient norm: 0.07319976290455088, minimum ratio: 2.421052631578947\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 13892 / 20000\n",
      "gradient norm: 0.07215156813617796, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 13893 / 20000\n",
      "gradient norm: 0.05607054304709891, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 13894 / 20000\n",
      "gradient norm: 0.08649379113921896, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 13895 / 20000\n",
      "gradient norm: 0.05901019579323474, minimum ratio: 2.4447368421052635\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 13896 / 20000\n",
      "gradient norm: 0.07739480782765895, minimum ratio: 2.426315789473684\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 13897 / 20000\n",
      "gradient norm: 0.06067091922159307, minimum ratio: 2.4184210526315786\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 13898 / 20000\n",
      "gradient norm: 0.11447467736434191, minimum ratio: 2.4263157894736844\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 13899 / 20000\n",
      "gradient norm: 0.14812866691499949, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 13900 / 20000\n",
      "gradient norm: 0.10271502676187083, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00554\n",
      "epoch 13901 / 20000\n",
      "gradient norm: 0.06337529985466972, minimum ratio: 2.4421052631578943\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 13902 / 20000\n",
      "gradient norm: 0.030120246578007936, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 13903 / 20000\n",
      "gradient norm: 0.04916254448471591, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 13904 / 20000\n",
      "gradient norm: 0.07729922258295119, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 13905 / 20000\n",
      "gradient norm: 0.060278725723037496, minimum ratio: 2.4236842105263157\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 13906 / 20000\n",
      "gradient norm: 0.08091549633536488, minimum ratio: 2.4157894736842103\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00551\n",
      "epoch 13907 / 20000\n",
      "gradient norm: 0.11125100590288639, minimum ratio: 2.4078947368421053\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 13908 / 20000\n",
      "gradient norm: 0.06779876863583922, minimum ratio: 2.4289473684210523\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 13909 / 20000\n",
      "gradient norm: 0.1432923199608922, minimum ratio: 2.4157894736842107\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 13910 / 20000\n",
      "gradient norm: 0.09064768976531923, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00551\n",
      "epoch 13911 / 20000\n",
      "gradient norm: 0.08103088414645754, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 13912 / 20000\n",
      "gradient norm: 0.06416739709675312, minimum ratio: 2.4263157894736844\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 13913 / 20000\n",
      "gradient norm: 0.08136633722460829, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 13914 / 20000\n",
      "gradient norm: 0.03789216108270921, minimum ratio: 2.4210526315789473\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 13915 / 20000\n",
      "gradient norm: 0.02342707064235583, minimum ratio: 2.4236842105263157\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 13916 / 20000\n",
      "gradient norm: 0.13085514289559796, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 13917 / 20000\n",
      "gradient norm: 0.0761960661620833, minimum ratio: 2.423684210526316\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 13918 / 20000\n",
      "gradient norm: 0.06498369120527059, minimum ratio: 2.4263157894736844\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 13919 / 20000\n",
      "gradient norm: 0.045485373892006464, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 13920 / 20000\n",
      "gradient norm: 0.05641790563822724, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 13921 / 20000\n",
      "gradient norm: 0.059829608144355007, minimum ratio: 2.4236842105263157\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 13922 / 20000\n",
      "gradient norm: 0.051934147806605324, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 13923 / 20000\n",
      "gradient norm: 0.05117776952101849, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 13924 / 20000\n",
      "gradient norm: 0.04301577201113105, minimum ratio: 2.418421052631579\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 13925 / 20000\n",
      "gradient norm: 0.1366458886768669, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00551\n",
      "epoch 13926 / 20000\n",
      "gradient norm: 0.03600771364290267, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 13927 / 20000\n",
      "gradient norm: 0.05187430081423372, minimum ratio: 2.4078947368421053\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 13928 / 20000\n",
      "gradient norm: 0.03612006838375237, minimum ratio: 2.4210526315789473\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 13929 / 20000\n",
      "gradient norm: 0.04448567845975049, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00551\n",
      "epoch 13930 / 20000\n",
      "gradient norm: 0.03414043746306561, minimum ratio: 2.4184210526315786\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 13931 / 20000\n",
      "gradient norm: 0.06018550109001808, minimum ratio: 2.4210526315789473\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 13932 / 20000\n",
      "gradient norm: 0.053257438470609486, minimum ratio: 2.4210526315789473\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00551\n",
      "epoch 13933 / 20000\n",
      "gradient norm: 0.10956153069855645, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 13934 / 20000\n",
      "gradient norm: 0.060581664758501574, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 13935 / 20000\n",
      "gradient norm: 0.10299244208727032, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 13936 / 20000\n",
      "gradient norm: 0.12881755363196135, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00571\n",
      "\tval loss: 0.00551\n",
      "epoch 13937 / 20000\n",
      "gradient norm: 0.05726358646643348, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 13938 / 20000\n",
      "gradient norm: 0.0625099798780866, minimum ratio: 2.4210526315789473\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 13939 / 20000\n",
      "gradient norm: 0.06919380859471858, minimum ratio: 2.4078947368421053\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 13940 / 20000\n",
      "gradient norm: 0.03233320111758076, minimum ratio: 2.4105263157894736\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 13941 / 20000\n",
      "gradient norm: 0.03832828113809228, minimum ratio: 2.418421052631579\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 13942 / 20000\n",
      "gradient norm: 0.07717315749323461, minimum ratio: 2.4394736842105265\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 13943 / 20000\n",
      "gradient norm: 0.0571610399056226, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 13944 / 20000\n",
      "gradient norm: 0.053180110815446824, minimum ratio: 2.4078947368421053\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 13945 / 20000\n",
      "gradient norm: 0.045867340770200826, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 13946 / 20000\n",
      "gradient norm: 0.0896023222594522, minimum ratio: 2.4184210526315786\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 13947 / 20000\n",
      "gradient norm: 0.0700261250603944, minimum ratio: 2.413157894736842\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 13948 / 20000\n",
      "gradient norm: 0.06354436342371628, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 13949 / 20000\n",
      "gradient norm: 0.08833820972358808, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 13950 / 20000\n",
      "gradient norm: 0.07582756853662431, minimum ratio: 2.4263157894736844\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 13951 / 20000\n",
      "gradient norm: 0.022902340133441612, minimum ratio: 2.4184210526315786\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 13952 / 20000\n",
      "gradient norm: 0.06830078602069989, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 13953 / 20000\n",
      "gradient norm: 0.050706195121165365, minimum ratio: 2.418421052631579\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 13954 / 20000\n",
      "gradient norm: 0.04625714595022146, minimum ratio: 2.4105263157894736\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 13955 / 20000\n",
      "gradient norm: 0.074294442019891, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 13956 / 20000\n",
      "gradient norm: 0.043149703938979656, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 13957 / 20000\n",
      "gradient norm: 0.0672959532821551, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 13958 / 20000\n",
      "gradient norm: 0.057189992628991604, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 13959 / 20000\n",
      "gradient norm: 0.028759495879057795, minimum ratio: 2.421052631578947\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 13960 / 20000\n",
      "gradient norm: 0.07599231356289238, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 13961 / 20000\n",
      "gradient norm: 0.046319990477059036, minimum ratio: 2.4105263157894736\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 13962 / 20000\n",
      "gradient norm: 0.07621027709683403, minimum ratio: 2.4157894736842107\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 13963 / 20000\n",
      "gradient norm: 0.06331291876267642, minimum ratio: 2.389473684210526\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 13964 / 20000\n",
      "gradient norm: 0.08134350110776722, minimum ratio: 2.4263157894736844\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 13965 / 20000\n",
      "gradient norm: 0.030785434326389804, minimum ratio: 2.4289473684210523\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 13966 / 20000\n",
      "gradient norm: 0.0629348924558144, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 13967 / 20000\n",
      "gradient norm: 0.033088024487369694, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 13968 / 20000\n",
      "gradient norm: 0.08506090001901612, minimum ratio: 2.4157894736842107\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 13969 / 20000\n",
      "gradient norm: 0.06325936503708363, minimum ratio: 2.4394736842105265\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 13970 / 20000\n",
      "gradient norm: 0.01997607974044513, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 13971 / 20000\n",
      "gradient norm: 0.03773914794146549, minimum ratio: 2.426315789473684\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 13972 / 20000\n",
      "gradient norm: 0.051517601998057216, minimum ratio: 2.421052631578948\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 13973 / 20000\n",
      "gradient norm: 0.106710096122697, minimum ratio: 2.4105263157894736\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 13974 / 20000\n",
      "gradient norm: 0.06499289817293175, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 13975 / 20000\n",
      "gradient norm: 0.04191089728556108, minimum ratio: 2.4210526315789473\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 13976 / 20000\n",
      "gradient norm: 0.08668137501808815, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 13977 / 20000\n",
      "gradient norm: 0.07867506431648508, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 13978 / 20000\n",
      "gradient norm: 0.08461308531695977, minimum ratio: 2.4026315789473687\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00551\n",
      "epoch 13979 / 20000\n",
      "gradient norm: 0.08825561821868178, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 13980 / 20000\n",
      "gradient norm: 0.0508278624038212, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 13981 / 20000\n",
      "gradient norm: 0.084099049505312, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 13982 / 20000\n",
      "gradient norm: 0.054379493027227, minimum ratio: 2.3973684210526316\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 13983 / 20000\n",
      "gradient norm: 0.045289817557204515, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 13984 / 20000\n",
      "gradient norm: 0.06259618722833693, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 13985 / 20000\n",
      "gradient norm: 0.029137929013813846, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00553\n",
      "epoch 13986 / 20000\n",
      "gradient norm: 0.091088748537004, minimum ratio: 2.426315789473684\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00552\n",
      "epoch 13987 / 20000\n",
      "gradient norm: 0.04932678923069034, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 13988 / 20000\n",
      "gradient norm: 0.0723924112462555, minimum ratio: 2.405263157894737\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 13989 / 20000\n",
      "gradient norm: 0.04863411322730826, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 13990 / 20000\n",
      "gradient norm: 0.11611298890784383, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 13991 / 20000\n",
      "gradient norm: 0.07713391067227349, minimum ratio: 2.4184210526315786\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 13992 / 20000\n",
      "gradient norm: 0.08321468869689852, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 13993 / 20000\n",
      "gradient norm: 0.05646688980050385, minimum ratio: 2.4105263157894736\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 13994 / 20000\n",
      "gradient norm: 0.03839557082392275, minimum ratio: 2.418421052631579\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 13995 / 20000\n",
      "gradient norm: 0.047573404663125984, minimum ratio: 2.426315789473684\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 13996 / 20000\n",
      "gradient norm: 0.09787264373153448, minimum ratio: 2.4421052631578943\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 13997 / 20000\n",
      "gradient norm: 0.07105748311732896, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00554\n",
      "epoch 13998 / 20000\n",
      "gradient norm: 0.07142745499731973, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 13999 / 20000\n",
      "gradient norm: 0.06483119650511071, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 14000 / 20000\n",
      "gradient norm: 0.03396452500601299, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 14001 / 20000\n",
      "gradient norm: 0.06400701735401526, minimum ratio: 2.4289473684210523\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 14002 / 20000\n",
      "gradient norm: 0.07900974614312872, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 14003 / 20000\n",
      "gradient norm: 0.08362345211207867, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 14004 / 20000\n",
      "gradient norm: 0.038481275565573014, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 14005 / 20000\n",
      "gradient norm: 0.07941171329002827, minimum ratio: 2.413157894736842\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00553\n",
      "epoch 14006 / 20000\n",
      "gradient norm: 0.03587248782423558, minimum ratio: 2.4210526315789473\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 14007 / 20000\n",
      "gradient norm: 0.0581909961765632, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 14008 / 20000\n",
      "gradient norm: 0.04242126477765851, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 14009 / 20000\n",
      "gradient norm: 0.09093711990863085, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 14010 / 20000\n",
      "gradient norm: 0.09499287430662662, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 14011 / 20000\n",
      "gradient norm: 0.1059636076388415, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 14012 / 20000\n",
      "gradient norm: 0.02986347145633772, minimum ratio: 2.4263157894736844\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00552\n",
      "epoch 14013 / 20000\n",
      "gradient norm: 0.04601027077296749, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 14014 / 20000\n",
      "gradient norm: 0.035170148592442274, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 14015 / 20000\n",
      "gradient norm: 0.03948272179150081, minimum ratio: 2.4184210526315786\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 14016 / 20000\n",
      "gradient norm: 0.09506044481531717, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 14017 / 20000\n",
      "gradient norm: 0.08734758419450372, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 14018 / 20000\n",
      "gradient norm: 0.044819553644629195, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 14019 / 20000\n",
      "gradient norm: 0.04236912020132877, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 14020 / 20000\n",
      "gradient norm: 0.05796810833271593, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00565\n",
      "\tval loss: 0.00551\n",
      "epoch 14021 / 20000\n",
      "gradient norm: 0.06210440717404708, minimum ratio: 2.426315789473684\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 14022 / 20000\n",
      "gradient norm: 0.0660128349554725, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00554\n",
      "epoch 14023 / 20000\n",
      "gradient norm: 0.05268887087004259, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 14024 / 20000\n",
      "gradient norm: 0.03794864198425785, minimum ratio: 2.4421052631578943\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 14025 / 20000\n",
      "gradient norm: 0.035934568441007286, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 14026 / 20000\n",
      "gradient norm: 0.08020962589944247, minimum ratio: 2.4210526315789473\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 14027 / 20000\n",
      "gradient norm: 0.058295218099374324, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 14028 / 20000\n",
      "gradient norm: 0.05686433374648914, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 14029 / 20000\n",
      "gradient norm: 0.06483099143952131, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 14030 / 20000\n",
      "gradient norm: 0.05802660017798189, minimum ratio: 2.405263157894737\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 14031 / 20000\n",
      "gradient norm: 0.06719841418089345, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00554\n",
      "epoch 14032 / 20000\n",
      "gradient norm: 0.04558532329974696, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 14033 / 20000\n",
      "gradient norm: 0.04715542265330441, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 14034 / 20000\n",
      "gradient norm: 0.04684445865859743, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 14035 / 20000\n",
      "gradient norm: 0.06542493897723034, minimum ratio: 2.4078947368421053\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 14036 / 20000\n",
      "gradient norm: 0.06152646348346025, minimum ratio: 2.4157894736842103\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 14037 / 20000\n",
      "gradient norm: 0.06610707030631602, minimum ratio: 2.418421052631579\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 14038 / 20000\n",
      "gradient norm: 0.048558411945123225, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 14039 / 20000\n",
      "gradient norm: 0.04879254277329892, minimum ratio: 2.418421052631579\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 14040 / 20000\n",
      "gradient norm: 0.09071814699564129, minimum ratio: 2.4236842105263157\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 14041 / 20000\n",
      "gradient norm: 0.051544146379455924, minimum ratio: 2.4184210526315786\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 14042 / 20000\n",
      "gradient norm: 0.08919934583536815, minimum ratio: 2.405263157894737\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00554\n",
      "epoch 14043 / 20000\n",
      "gradient norm: 0.04473402799339965, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 14044 / 20000\n",
      "gradient norm: 0.05509033799171448, minimum ratio: 2.436842105263158\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 14045 / 20000\n",
      "gradient norm: 0.06756960530765355, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 14046 / 20000\n",
      "gradient norm: 0.09051872123382054, minimum ratio: 2.4078947368421053\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 14047 / 20000\n",
      "gradient norm: 0.09197048196801916, minimum ratio: 2.4026315789473687\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 14048 / 20000\n",
      "gradient norm: 0.07619548414368182, minimum ratio: 2.4394736842105265\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 14049 / 20000\n",
      "gradient norm: 0.03705349034862593, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 14050 / 20000\n",
      "gradient norm: 0.05819382632034831, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 14051 / 20000\n",
      "gradient norm: 0.06500644759216812, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 14052 / 20000\n",
      "gradient norm: 0.06542102734965738, minimum ratio: 2.4157894736842103\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 14053 / 20000\n",
      "gradient norm: 0.0792900591623038, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 14054 / 20000\n",
      "gradient norm: 0.05912294492554793, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 14055 / 20000\n",
      "gradient norm: 0.07111643633106723, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 14056 / 20000\n",
      "gradient norm: 0.09744573419447988, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 14057 / 20000\n",
      "gradient norm: 0.05805116839474067, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 14058 / 20000\n",
      "gradient norm: 0.09229477954795584, minimum ratio: 2.4000000000000004\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 14059 / 20000\n",
      "gradient norm: 0.049502968628075905, minimum ratio: 2.423684210526316\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 14060 / 20000\n",
      "gradient norm: 0.08224302669987082, minimum ratio: 2.426315789473684\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 14061 / 20000\n",
      "gradient norm: 0.055851232493296266, minimum ratio: 2.4210526315789473\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 14062 / 20000\n",
      "gradient norm: 0.062115681561408564, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 14063 / 20000\n",
      "gradient norm: 0.06319872348103672, minimum ratio: 2.4210526315789473\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 14064 / 20000\n",
      "gradient norm: 0.06199398105673026, minimum ratio: 2.436842105263158\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 14065 / 20000\n",
      "gradient norm: 0.0988772056880407, minimum ratio: 2.4184210526315786\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 14066 / 20000\n",
      "gradient norm: 0.04997209942666814, minimum ratio: 2.4157894736842107\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 14067 / 20000\n",
      "gradient norm: 0.07633187291503418, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 14068 / 20000\n",
      "gradient norm: 0.05758124799467623, minimum ratio: 2.4236842105263157\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 14069 / 20000\n",
      "gradient norm: 0.06324825793853961, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 14070 / 20000\n",
      "gradient norm: 0.054229871195275337, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 14071 / 20000\n",
      "gradient norm: 0.03317166518536396, minimum ratio: 2.4447368421052627\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 14072 / 20000\n",
      "gradient norm: 0.0495735408476321, minimum ratio: 2.426315789473684\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 14073 / 20000\n",
      "gradient norm: 0.05936551105696708, minimum ratio: 2.413157894736842\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 14074 / 20000\n",
      "gradient norm: 0.05390848347451538, minimum ratio: 2.4184210526315786\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 14075 / 20000\n",
      "gradient norm: 0.035814817529171705, minimum ratio: 2.4289473684210523\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 14076 / 20000\n",
      "gradient norm: 0.03875080184661783, minimum ratio: 2.4236842105263157\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 14077 / 20000\n",
      "gradient norm: 0.09064681001473218, minimum ratio: 2.4131578947368424\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 14078 / 20000\n",
      "gradient norm: 0.04382686776807532, minimum ratio: 2.4263157894736844\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 14079 / 20000\n",
      "gradient norm: 0.0609717861370882, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 14080 / 20000\n",
      "gradient norm: 0.12619331205496565, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00570\n",
      "\tval loss: 0.00551\n",
      "epoch 14081 / 20000\n",
      "gradient norm: 0.09250658744713292, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 14082 / 20000\n",
      "gradient norm: 0.07291027391329408, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 14083 / 20000\n",
      "gradient norm: 0.06326413084752858, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 14084 / 20000\n",
      "gradient norm: 0.052098299594945274, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00553\n",
      "epoch 14085 / 20000\n",
      "gradient norm: 0.061395618628012016, minimum ratio: 2.4210526315789473\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 14086 / 20000\n",
      "gradient norm: 0.06404859462054446, minimum ratio: 2.4421052631578943\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 14087 / 20000\n",
      "gradient norm: 0.06759457950829528, minimum ratio: 2.4499999999999997\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 14088 / 20000\n",
      "gradient norm: 0.034023311323835514, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 14089 / 20000\n",
      "gradient norm: 0.036298377093771705, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 14090 / 20000\n",
      "gradient norm: 0.06485647588851862, minimum ratio: 2.4263157894736844\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 14091 / 20000\n",
      "gradient norm: 0.05947022984037176, minimum ratio: 2.4263157894736844\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 14092 / 20000\n",
      "gradient norm: 0.055944544961676, minimum ratio: 2.405263157894737\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 14093 / 20000\n",
      "gradient norm: 0.034088231972418725, minimum ratio: 2.405263157894737\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 14094 / 20000\n",
      "gradient norm: 0.06384201337641571, minimum ratio: 2.4210526315789473\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 14095 / 20000\n",
      "gradient norm: 0.06027849134989083, minimum ratio: 2.4210526315789473\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 14096 / 20000\n",
      "gradient norm: 0.09739251376595348, minimum ratio: 2.4105263157894736\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 14097 / 20000\n",
      "gradient norm: 0.031027706718305126, minimum ratio: 2.4210526315789473\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00551\n",
      "epoch 14098 / 20000\n",
      "gradient norm: 0.041208560403902084, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 14099 / 20000\n",
      "gradient norm: 0.08940381891443394, minimum ratio: 2.4210526315789473\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 14100 / 20000\n",
      "gradient norm: 0.04529347237985348, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 14101 / 20000\n",
      "gradient norm: 0.0163740117859561, minimum ratio: 2.4210526315789473\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 14102 / 20000\n",
      "gradient norm: 0.07695454458007589, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 14103 / 20000\n",
      "gradient norm: 0.06845511466963217, minimum ratio: 2.418421052631579\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00553\n",
      "epoch 14104 / 20000\n",
      "gradient norm: 0.03501814813353121, minimum ratio: 2.4105263157894736\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 14105 / 20000\n",
      "gradient norm: 0.04275948295253329, minimum ratio: 2.413157894736842\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 14106 / 20000\n",
      "gradient norm: 0.059257405751850456, minimum ratio: 2.4210526315789473\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 14107 / 20000\n",
      "gradient norm: 0.06402301258640364, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 14108 / 20000\n",
      "gradient norm: 0.06560198101215065, minimum ratio: 2.4263157894736844\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 14109 / 20000\n",
      "gradient norm: 0.026282628663466312, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 14110 / 20000\n",
      "gradient norm: 0.040370951901422814, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 14111 / 20000\n",
      "gradient norm: 0.05779877625172958, minimum ratio: 2.418421052631579\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 14112 / 20000\n",
      "gradient norm: 0.03658438645652495, minimum ratio: 2.4026315789473687\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 14113 / 20000\n",
      "gradient norm: 0.057704894919879735, minimum ratio: 2.4263157894736844\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00552\n",
      "epoch 14114 / 20000\n",
      "gradient norm: 0.11089545325376093, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 14115 / 20000\n",
      "gradient norm: 0.036481091898167506, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 14116 / 20000\n",
      "gradient norm: 0.05762167676584795, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 14117 / 20000\n",
      "gradient norm: 0.060562009166460484, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 14118 / 20000\n",
      "gradient norm: 0.07484773319447413, minimum ratio: 2.4263157894736844\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00552\n",
      "epoch 14119 / 20000\n",
      "gradient norm: 0.055131556902779266, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 14120 / 20000\n",
      "gradient norm: 0.06788993009831756, minimum ratio: 2.4210526315789473\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00551\n",
      "epoch 14121 / 20000\n",
      "gradient norm: 0.14200026646722108, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00554\n",
      "epoch 14122 / 20000\n",
      "gradient norm: 0.028025127219734713, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00551\n",
      "epoch 14123 / 20000\n",
      "gradient norm: 0.07630957546643913, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 14124 / 20000\n",
      "gradient norm: 0.06263898953329772, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00554\n",
      "epoch 14125 / 20000\n",
      "gradient norm: 0.07509345773723908, minimum ratio: 2.418421052631579\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00551\n",
      "epoch 14126 / 20000\n",
      "gradient norm: 0.061392313975375146, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 14127 / 20000\n",
      "gradient norm: 0.07253754045814276, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 14128 / 20000\n",
      "gradient norm: 0.0601502247445751, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 14129 / 20000\n",
      "gradient norm: 0.08490464143687859, minimum ratio: 2.4447368421052627\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00553\n",
      "epoch 14130 / 20000\n",
      "gradient norm: 0.029484877348295413, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 14131 / 20000\n",
      "gradient norm: 0.0930800085188821, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 14132 / 20000\n",
      "gradient norm: 0.03260905193747021, minimum ratio: 2.4421052631578943\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 14133 / 20000\n",
      "gradient norm: 0.04452641506213695, minimum ratio: 2.4078947368421053\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 14134 / 20000\n",
      "gradient norm: 0.07951196667272598, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 14135 / 20000\n",
      "gradient norm: 0.03646962565835565, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 14136 / 20000\n",
      "gradient norm: 0.04475783564703306, minimum ratio: 2.4421052631578943\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 14137 / 20000\n",
      "gradient norm: 0.051761397859081626, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 14138 / 20000\n",
      "gradient norm: 0.03756508795777336, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 14139 / 20000\n",
      "gradient norm: 0.12420746037969366, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00569\n",
      "\tval loss: 0.00550\n",
      "epoch 14140 / 20000\n",
      "gradient norm: 0.07991112851595972, minimum ratio: 2.4421052631578943\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 14141 / 20000\n",
      "gradient norm: 0.043983975308947265, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 14142 / 20000\n",
      "gradient norm: 0.06965653740917332, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 14143 / 20000\n",
      "gradient norm: 0.11560686398297548, minimum ratio: 2.4157894736842107\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00552\n",
      "epoch 14144 / 20000\n",
      "gradient norm: 0.030865628868923523, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00551\n",
      "epoch 14145 / 20000\n",
      "gradient norm: 0.07741238645394333, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00551\n",
      "epoch 14146 / 20000\n",
      "gradient norm: 0.04196183290332556, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 14147 / 20000\n",
      "gradient norm: 0.09529154293704778, minimum ratio: 2.426315789473684\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 14148 / 20000\n",
      "gradient norm: 0.017586369736818597, minimum ratio: 2.4394736842105265\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00551\n",
      "epoch 14149 / 20000\n",
      "gradient norm: 0.08151795284356922, minimum ratio: 2.4263157894736844\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00551\n",
      "epoch 14150 / 20000\n",
      "gradient norm: 0.049869060443597846, minimum ratio: 2.4263157894736844\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00550\n",
      "epoch 14151 / 20000\n",
      "gradient norm: 0.09093957603909075, minimum ratio: 2.4421052631578943\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00551\n",
      "epoch 14152 / 20000\n",
      "gradient norm: 0.0489517250971403, minimum ratio: 2.426315789473684\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00550\n",
      "epoch 14153 / 20000\n",
      "gradient norm: 0.12215084652416408, minimum ratio: 2.4263157894736844\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00551\n",
      "epoch 14154 / 20000\n",
      "gradient norm: 0.062241121457191184, minimum ratio: 2.4210526315789473\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00551\n",
      "epoch 14155 / 20000\n",
      "gradient norm: 0.09654506825609133, minimum ratio: 2.418421052631579\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00550\n",
      "epoch 14156 / 20000\n",
      "gradient norm: 0.05244550621137023, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 14157 / 20000\n",
      "gradient norm: 0.025144740007817745, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 14158 / 20000\n",
      "gradient norm: 0.06658794108079746, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 14159 / 20000\n",
      "gradient norm: 0.061497554706875235, minimum ratio: 2.4210526315789473\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00550\n",
      "epoch 14160 / 20000\n",
      "gradient norm: 0.09284074569586664, minimum ratio: 2.4394736842105265\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00551\n",
      "epoch 14161 / 20000\n",
      "gradient norm: 0.047128201549639925, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00551\n",
      "epoch 14162 / 20000\n",
      "gradient norm: 0.06639870384242386, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00568\n",
      "\tval loss: 0.00550\n",
      "epoch 14163 / 20000\n",
      "gradient norm: 0.10090848989784718, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 14164 / 20000\n",
      "gradient norm: 0.07538706419290975, minimum ratio: 2.4421052631578943\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00550\n",
      "epoch 14165 / 20000\n",
      "gradient norm: 0.08399257087148726, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00549\n",
      "epoch 14166 / 20000\n",
      "gradient norm: 0.05856841302011162, minimum ratio: 2.4499999999999997\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00551\n",
      "epoch 14167 / 20000\n",
      "gradient norm: 0.07236842362908646, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00550\n",
      "epoch 14168 / 20000\n",
      "gradient norm: 0.051455702443490736, minimum ratio: 2.426315789473684\n",
      "\ttrain loss: 0.00565\n",
      "\tval loss: 0.00550\n",
      "epoch 14169 / 20000\n",
      "gradient norm: 0.03341547184390947, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00565\n",
      "\tval loss: 0.00550\n",
      "epoch 14170 / 20000\n",
      "gradient norm: 0.02779477678996045, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00565\n",
      "\tval loss: 0.00550\n",
      "epoch 14171 / 20000\n",
      "gradient norm: 0.0385129048518138, minimum ratio: 2.426315789473684\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00551\n",
      "epoch 14172 / 20000\n",
      "gradient norm: 0.05531746696215123, minimum ratio: 2.4184210526315786\n",
      "\ttrain loss: 0.00564\n",
      "\tval loss: 0.00549\n",
      "epoch 14173 / 20000\n",
      "gradient norm: 0.05322563665686175, minimum ratio: 2.4263157894736844\n",
      "\ttrain loss: 0.00565\n",
      "\tval loss: 0.00549\n",
      "epoch 14174 / 20000\n",
      "gradient norm: 0.059181182223255746, minimum ratio: 2.4263157894736844\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00550\n",
      "epoch 14175 / 20000\n",
      "gradient norm: 0.10593561816494912, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00565\n",
      "\tval loss: 0.00549\n",
      "epoch 14176 / 20000\n",
      "gradient norm: 0.03793001757003367, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00564\n",
      "\tval loss: 0.00549\n",
      "epoch 14177 / 20000\n",
      "gradient norm: 0.05031890148529783, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00564\n",
      "\tval loss: 0.00550\n",
      "epoch 14178 / 20000\n",
      "gradient norm: 0.0664402037509717, minimum ratio: 2.4210526315789473\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00549\n",
      "epoch 14179 / 20000\n",
      "gradient norm: 0.07105913240229711, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00550\n",
      "epoch 14180 / 20000\n",
      "gradient norm: 0.04510524257784709, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00564\n",
      "\tval loss: 0.00549\n",
      "epoch 14181 / 20000\n",
      "gradient norm: 0.0513856083562132, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00565\n",
      "\tval loss: 0.00549\n",
      "epoch 14182 / 20000\n",
      "gradient norm: 0.07888574316166341, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00549\n",
      "epoch 14183 / 20000\n",
      "gradient norm: 0.06828303239308298, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00567\n",
      "\tval loss: 0.00552\n",
      "epoch 14184 / 20000\n",
      "gradient norm: 0.06270108104217798, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00564\n",
      "\tval loss: 0.00549\n",
      "epoch 14185 / 20000\n",
      "gradient norm: 0.09922331385314465, minimum ratio: 2.4263157894736844\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00548\n",
      "epoch 14186 / 20000\n",
      "gradient norm: 0.07652410981245339, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00565\n",
      "\tval loss: 0.00550\n",
      "epoch 14187 / 20000\n",
      "gradient norm: 0.10485185909783468, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00565\n",
      "\tval loss: 0.00552\n",
      "epoch 14188 / 20000\n",
      "gradient norm: 0.07204050911241211, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00566\n",
      "\tval loss: 0.00548\n",
      "epoch 14189 / 20000\n",
      "gradient norm: 0.07468538547982462, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00565\n",
      "\tval loss: 0.00549\n",
      "epoch 14190 / 20000\n",
      "gradient norm: 0.07072498349589296, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00564\n",
      "\tval loss: 0.00550\n",
      "epoch 14191 / 20000\n",
      "gradient norm: 0.07136511434509885, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00565\n",
      "\tval loss: 0.00549\n",
      "epoch 14192 / 20000\n",
      "gradient norm: 0.0536058807047084, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00564\n",
      "\tval loss: 0.00549\n",
      "epoch 14193 / 20000\n",
      "gradient norm: 0.0217611644329736, minimum ratio: 2.4236842105263157\n",
      "\ttrain loss: 0.00565\n",
      "\tval loss: 0.00549\n",
      "epoch 14194 / 20000\n",
      "gradient norm: 0.03681119311659131, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00563\n",
      "\tval loss: 0.00549\n",
      "epoch 14195 / 20000\n",
      "gradient norm: 0.07523698997101746, minimum ratio: 2.4210526315789473\n",
      "\ttrain loss: 0.00565\n",
      "\tval loss: 0.00549\n",
      "epoch 14196 / 20000\n",
      "gradient norm: 0.0818903719773516, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00563\n",
      "\tval loss: 0.00548\n",
      "epoch 14197 / 20000\n",
      "gradient norm: 0.06698503624647856, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00564\n",
      "\tval loss: 0.00549\n",
      "epoch 14198 / 20000\n",
      "gradient norm: 0.031112395896343514, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00564\n",
      "\tval loss: 0.00548\n",
      "epoch 14199 / 20000\n",
      "gradient norm: 0.0568311581882881, minimum ratio: 2.4157894736842103\n",
      "\ttrain loss: 0.00565\n",
      "\tval loss: 0.00547\n",
      "epoch 14200 / 20000\n",
      "gradient norm: 0.09659092035144567, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00563\n",
      "\tval loss: 0.00548\n",
      "epoch 14201 / 20000\n",
      "gradient norm: 0.040522476425394416, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00563\n",
      "\tval loss: 0.00548\n",
      "epoch 14202 / 20000\n",
      "gradient norm: 0.03309100080514327, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00563\n",
      "\tval loss: 0.00547\n",
      "epoch 14203 / 20000\n",
      "gradient norm: 0.07679126021685079, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00564\n",
      "\tval loss: 0.00547\n",
      "epoch 14204 / 20000\n",
      "gradient norm: 0.08524971932638437, minimum ratio: 2.413157894736842\n",
      "\ttrain loss: 0.00562\n",
      "\tval loss: 0.00549\n",
      "epoch 14205 / 20000\n",
      "gradient norm: 0.08882082544732839, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00563\n",
      "\tval loss: 0.00548\n",
      "epoch 14206 / 20000\n",
      "gradient norm: 0.03606891410890967, minimum ratio: 2.4263157894736844\n",
      "\ttrain loss: 0.00563\n",
      "\tval loss: 0.00547\n",
      "epoch 14207 / 20000\n",
      "gradient norm: 0.08551973575958982, minimum ratio: 2.426315789473684\n",
      "\ttrain loss: 0.00565\n",
      "\tval loss: 0.00547\n",
      "epoch 14208 / 20000\n",
      "gradient norm: 0.0886783262831159, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00564\n",
      "\tval loss: 0.00550\n",
      "epoch 14209 / 20000\n",
      "gradient norm: 0.05727529851719737, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00563\n",
      "\tval loss: 0.00547\n",
      "epoch 14210 / 20000\n",
      "gradient norm: 0.10288973164279014, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00563\n",
      "\tval loss: 0.00546\n",
      "epoch 14211 / 20000\n",
      "gradient norm: 0.06446293840417638, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00563\n",
      "\tval loss: 0.00549\n",
      "epoch 14212 / 20000\n",
      "gradient norm: 0.05728453857591376, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00563\n",
      "\tval loss: 0.00547\n",
      "epoch 14213 / 20000\n",
      "gradient norm: 0.05479495067265816, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00563\n",
      "\tval loss: 0.00546\n",
      "epoch 14214 / 20000\n",
      "gradient norm: 0.06581710663158447, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00562\n",
      "\tval loss: 0.00547\n",
      "epoch 14215 / 20000\n",
      "gradient norm: 0.08839099871693179, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00563\n",
      "\tval loss: 0.00548\n",
      "epoch 14216 / 20000\n",
      "gradient norm: 0.10338177291851025, minimum ratio: 2.4499999999999997\n",
      "\ttrain loss: 0.00564\n",
      "\tval loss: 0.00546\n",
      "epoch 14217 / 20000\n",
      "gradient norm: 0.04624983624671586, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00564\n",
      "\tval loss: 0.00547\n",
      "epoch 14218 / 20000\n",
      "gradient norm: 0.0852342960133683, minimum ratio: 2.4263157894736844\n",
      "\ttrain loss: 0.00564\n",
      "\tval loss: 0.00547\n",
      "epoch 14219 / 20000\n",
      "gradient norm: 0.10962998488685116, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00562\n",
      "\tval loss: 0.00547\n",
      "epoch 14220 / 20000\n",
      "gradient norm: 0.06265306516434066, minimum ratio: 2.4052631578947365\n",
      "\ttrain loss: 0.00562\n",
      "\tval loss: 0.00546\n",
      "epoch 14221 / 20000\n",
      "gradient norm: 0.025775202142540365, minimum ratio: 2.4447368421052627\n",
      "\ttrain loss: 0.00562\n",
      "\tval loss: 0.00547\n",
      "epoch 14222 / 20000\n",
      "gradient norm: 0.06734545936342329, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00562\n",
      "\tval loss: 0.00548\n",
      "epoch 14223 / 20000\n",
      "gradient norm: 0.06439197302097455, minimum ratio: 2.436842105263158\n",
      "\ttrain loss: 0.00561\n",
      "\tval loss: 0.00546\n",
      "epoch 14224 / 20000\n",
      "gradient norm: 0.06276768649695441, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00562\n",
      "\tval loss: 0.00545\n",
      "epoch 14225 / 20000\n",
      "gradient norm: 0.09026693366467953, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00563\n",
      "\tval loss: 0.00547\n",
      "epoch 14226 / 20000\n",
      "gradient norm: 0.06410459824837744, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00562\n",
      "\tval loss: 0.00546\n",
      "epoch 14227 / 20000\n",
      "gradient norm: 0.08710700029041618, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00562\n",
      "\tval loss: 0.00545\n",
      "epoch 14228 / 20000\n",
      "gradient norm: 0.06479846127331257, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00561\n",
      "\tval loss: 0.00547\n",
      "epoch 14229 / 20000\n",
      "gradient norm: 0.04480563182733022, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00561\n",
      "\tval loss: 0.00545\n",
      "epoch 14230 / 20000\n",
      "gradient norm: 0.044346015463816, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00562\n",
      "\tval loss: 0.00545\n",
      "epoch 14231 / 20000\n",
      "gradient norm: 0.09002330442308448, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00563\n",
      "\tval loss: 0.00545\n",
      "epoch 14232 / 20000\n",
      "gradient norm: 0.08311181783210486, minimum ratio: 2.4236842105263157\n",
      "\ttrain loss: 0.00561\n",
      "\tval loss: 0.00547\n",
      "epoch 14233 / 20000\n",
      "gradient norm: 0.04972115228883922, minimum ratio: 2.423684210526316\n",
      "\ttrain loss: 0.00560\n",
      "\tval loss: 0.00545\n",
      "epoch 14234 / 20000\n",
      "gradient norm: 0.04939851787639782, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00561\n",
      "\tval loss: 0.00545\n",
      "epoch 14235 / 20000\n",
      "gradient norm: 0.0685282772174105, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00560\n",
      "\tval loss: 0.00546\n",
      "epoch 14236 / 20000\n",
      "gradient norm: 0.07148801570292562, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00560\n",
      "\tval loss: 0.00545\n",
      "epoch 14237 / 20000\n",
      "gradient norm: 0.030021587532246485, minimum ratio: 2.4499999999999997\n",
      "\ttrain loss: 0.00562\n",
      "\tval loss: 0.00544\n",
      "epoch 14238 / 20000\n",
      "gradient norm: 0.057069200556725264, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00560\n",
      "\tval loss: 0.00545\n",
      "epoch 14239 / 20000\n",
      "gradient norm: 0.032794732484035194, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00562\n",
      "\tval loss: 0.00546\n",
      "epoch 14240 / 20000\n",
      "gradient norm: 0.0682108192704618, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00561\n",
      "\tval loss: 0.00544\n",
      "epoch 14241 / 20000\n",
      "gradient norm: 0.01692440801707562, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00561\n",
      "\tval loss: 0.00544\n",
      "epoch 14242 / 20000\n",
      "gradient norm: 0.10169221018441021, minimum ratio: 2.4263157894736844\n",
      "\ttrain loss: 0.00561\n",
      "\tval loss: 0.00545\n",
      "epoch 14243 / 20000\n",
      "gradient norm: 0.07586512097623199, minimum ratio: 2.4184210526315786\n",
      "\ttrain loss: 0.00558\n",
      "\tval loss: 0.00544\n",
      "epoch 14244 / 20000\n",
      "gradient norm: 0.07793598453281447, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00561\n",
      "\tval loss: 0.00544\n",
      "epoch 14245 / 20000\n",
      "gradient norm: 0.044273571838857606, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00561\n",
      "\tval loss: 0.00545\n",
      "epoch 14246 / 20000\n",
      "gradient norm: 0.09114359764498658, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00560\n",
      "\tval loss: 0.00544\n",
      "epoch 14247 / 20000\n",
      "gradient norm: 0.056761509040370584, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00560\n",
      "\tval loss: 0.00543\n",
      "epoch 14248 / 20000\n",
      "gradient norm: 0.12097616499522701, minimum ratio: 2.4184210526315786\n",
      "\ttrain loss: 0.00560\n",
      "\tval loss: 0.00546\n",
      "epoch 14249 / 20000\n",
      "gradient norm: 0.06046208826592192, minimum ratio: 2.4394736842105265\n",
      "\ttrain loss: 0.00560\n",
      "\tval loss: 0.00543\n",
      "epoch 14250 / 20000\n",
      "gradient norm: 0.051537834893679246, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00560\n",
      "\tval loss: 0.00543\n",
      "epoch 14251 / 20000\n",
      "gradient norm: 0.07985394273418933, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00558\n",
      "\tval loss: 0.00546\n",
      "epoch 14252 / 20000\n",
      "gradient norm: 0.03486147659714334, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00559\n",
      "\tval loss: 0.00543\n",
      "epoch 14253 / 20000\n",
      "gradient norm: 0.057580848078941926, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00560\n",
      "\tval loss: 0.00543\n",
      "epoch 14254 / 20000\n",
      "gradient norm: 0.030764364229980856, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00559\n",
      "\tval loss: 0.00544\n",
      "epoch 14255 / 20000\n",
      "gradient norm: 0.04652248456841335, minimum ratio: 2.418421052631579\n",
      "\ttrain loss: 0.00558\n",
      "\tval loss: 0.00544\n",
      "epoch 14256 / 20000\n",
      "gradient norm: 0.10334340331610292, minimum ratio: 2.4447368421052635\n",
      "\ttrain loss: 0.00559\n",
      "\tval loss: 0.00544\n",
      "epoch 14257 / 20000\n",
      "gradient norm: 0.09327474015299231, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00559\n",
      "\tval loss: 0.00542\n",
      "epoch 14258 / 20000\n",
      "gradient norm: 0.0988688666257076, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00560\n",
      "\tval loss: 0.00544\n",
      "epoch 14259 / 20000\n",
      "gradient norm: 0.0819694284000434, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00560\n",
      "\tval loss: 0.00543\n",
      "epoch 14260 / 20000\n",
      "gradient norm: 0.08507402893155813, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00558\n",
      "\tval loss: 0.00543\n",
      "epoch 14261 / 20000\n",
      "gradient norm: 0.07227771717589349, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00559\n",
      "\tval loss: 0.00544\n",
      "epoch 14262 / 20000\n",
      "gradient norm: 0.06983364911866374, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00560\n",
      "\tval loss: 0.00542\n",
      "epoch 14263 / 20000\n",
      "gradient norm: 0.06476188689703122, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00559\n",
      "\tval loss: 0.00542\n",
      "epoch 14264 / 20000\n",
      "gradient norm: 0.10576811200007796, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00559\n",
      "\tval loss: 0.00545\n",
      "epoch 14265 / 20000\n",
      "gradient norm: 0.07118442724458873, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00559\n",
      "\tval loss: 0.00542\n",
      "epoch 14266 / 20000\n",
      "gradient norm: 0.06969218014273793, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00558\n",
      "\tval loss: 0.00541\n",
      "epoch 14267 / 20000\n",
      "gradient norm: 0.07820340723264962, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00559\n",
      "\tval loss: 0.00544\n",
      "epoch 14268 / 20000\n",
      "gradient norm: 0.0868791675020475, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00559\n",
      "\tval loss: 0.00541\n",
      "epoch 14269 / 20000\n",
      "gradient norm: 0.06935454175982159, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00556\n",
      "\tval loss: 0.00542\n",
      "epoch 14270 / 20000\n",
      "gradient norm: 0.06494961207499728, minimum ratio: 2.423684210526316\n",
      "\ttrain loss: 0.00557\n",
      "\tval loss: 0.00541\n",
      "epoch 14271 / 20000\n",
      "gradient norm: 0.07847932184813544, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00557\n",
      "\tval loss: 0.00542\n",
      "epoch 14272 / 20000\n",
      "gradient norm: 0.06445638497825712, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00557\n",
      "\tval loss: 0.00541\n",
      "epoch 14273 / 20000\n",
      "gradient norm: 0.06173281473456882, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00559\n",
      "\tval loss: 0.00542\n",
      "epoch 14274 / 20000\n",
      "gradient norm: 0.0617721973976586, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00558\n",
      "\tval loss: 0.00541\n",
      "epoch 14275 / 20000\n",
      "gradient norm: 0.061824611271731555, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00556\n",
      "\tval loss: 0.00541\n",
      "epoch 14276 / 20000\n",
      "gradient norm: 0.0465015362133272, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00555\n",
      "\tval loss: 0.00541\n",
      "epoch 14277 / 20000\n",
      "gradient norm: 0.06700205930974334, minimum ratio: 2.4263157894736844\n",
      "\ttrain loss: 0.00557\n",
      "\tval loss: 0.00541\n",
      "epoch 14278 / 20000\n",
      "gradient norm: 0.06146250791789498, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00554\n",
      "\tval loss: 0.00541\n",
      "epoch 14279 / 20000\n",
      "gradient norm: 0.061403549974784255, minimum ratio: 2.4236842105263157\n",
      "\ttrain loss: 0.00556\n",
      "\tval loss: 0.00540\n",
      "epoch 14280 / 20000\n",
      "gradient norm: 0.03564785674097948, minimum ratio: 2.426315789473684\n",
      "\ttrain loss: 0.00556\n",
      "\tval loss: 0.00540\n",
      "epoch 14281 / 20000\n",
      "gradient norm: 0.042461736884433776, minimum ratio: 2.4210526315789473\n",
      "\ttrain loss: 0.00557\n",
      "\tval loss: 0.00541\n",
      "epoch 14282 / 20000\n",
      "gradient norm: 0.03853692705160938, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00557\n",
      "\tval loss: 0.00541\n",
      "epoch 14283 / 20000\n",
      "gradient norm: 0.061663186526857316, minimum ratio: 2.4289473684210523\n",
      "\ttrain loss: 0.00557\n",
      "\tval loss: 0.00540\n",
      "epoch 14284 / 20000\n",
      "gradient norm: 0.01880352760781534, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00554\n",
      "\tval loss: 0.00541\n",
      "epoch 14285 / 20000\n",
      "gradient norm: 0.09132586167834233, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00555\n",
      "\tval loss: 0.00540\n",
      "epoch 14286 / 20000\n",
      "gradient norm: 0.04298902495065704, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00555\n",
      "\tval loss: 0.00541\n",
      "epoch 14287 / 20000\n",
      "gradient norm: 0.05828038931940682, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00556\n",
      "\tval loss: 0.00540\n",
      "epoch 14288 / 20000\n",
      "gradient norm: 0.07626011845422909, minimum ratio: 2.436842105263158\n",
      "\ttrain loss: 0.00555\n",
      "\tval loss: 0.00540\n",
      "epoch 14289 / 20000\n",
      "gradient norm: 0.06717099732486531, minimum ratio: 2.4157894736842103\n",
      "\ttrain loss: 0.00556\n",
      "\tval loss: 0.00540\n",
      "epoch 14290 / 20000\n",
      "gradient norm: 0.018579086899990216, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00555\n",
      "\tval loss: 0.00539\n",
      "epoch 14291 / 20000\n",
      "gradient norm: 0.0828357752179727, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00555\n",
      "\tval loss: 0.00539\n",
      "epoch 14292 / 20000\n",
      "gradient norm: 0.13161636528093368, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00555\n",
      "\tval loss: 0.00541\n",
      "epoch 14293 / 20000\n",
      "gradient norm: 0.10571031935978681, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00555\n",
      "\tval loss: 0.00539\n",
      "epoch 14294 / 20000\n",
      "gradient norm: 0.07720978969882708, minimum ratio: 2.4263157894736844\n",
      "\ttrain loss: 0.00556\n",
      "\tval loss: 0.00539\n",
      "epoch 14295 / 20000\n",
      "gradient norm: 0.06015268771443516, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00556\n",
      "\tval loss: 0.00539\n",
      "epoch 14296 / 20000\n",
      "gradient norm: 0.021926598230493255, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00554\n",
      "\tval loss: 0.00539\n",
      "epoch 14297 / 20000\n",
      "gradient norm: 0.11885036178864539, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00555\n",
      "\tval loss: 0.00540\n",
      "epoch 14298 / 20000\n",
      "gradient norm: 0.05215828667860478, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00555\n",
      "\tval loss: 0.00538\n",
      "epoch 14299 / 20000\n",
      "gradient norm: 0.03649369435152039, minimum ratio: 2.4421052631578943\n",
      "\ttrain loss: 0.00555\n",
      "\tval loss: 0.00539\n",
      "epoch 14300 / 20000\n",
      "gradient norm: 0.04797790327575058, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00555\n",
      "\tval loss: 0.00539\n",
      "epoch 14301 / 20000\n",
      "gradient norm: 0.04048860620241612, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00553\n",
      "\tval loss: 0.00539\n",
      "epoch 14302 / 20000\n",
      "gradient norm: 0.10234226717147976, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00554\n",
      "\tval loss: 0.00538\n",
      "epoch 14303 / 20000\n",
      "gradient norm: 0.06896539346780628, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00554\n",
      "\tval loss: 0.00539\n",
      "epoch 14304 / 20000\n",
      "gradient norm: 0.029887638331274502, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00553\n",
      "\tval loss: 0.00538\n",
      "epoch 14305 / 20000\n",
      "gradient norm: 0.02104003613931127, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00552\n",
      "\tval loss: 0.00538\n",
      "epoch 14306 / 20000\n",
      "gradient norm: 0.08502779598347843, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00553\n",
      "\tval loss: 0.00538\n",
      "epoch 14307 / 20000\n",
      "gradient norm: 0.05216168111655861, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00553\n",
      "\tval loss: 0.00540\n",
      "epoch 14308 / 20000\n",
      "gradient norm: 0.053311088180635124, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00554\n",
      "\tval loss: 0.00538\n",
      "epoch 14309 / 20000\n",
      "gradient norm: 0.11525316291954368, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00555\n",
      "\tval loss: 0.00537\n",
      "epoch 14310 / 20000\n",
      "gradient norm: 0.028886680374853313, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00552\n",
      "\tval loss: 0.00539\n",
      "epoch 14311 / 20000\n",
      "gradient norm: 0.11047905904706568, minimum ratio: 2.418421052631579\n",
      "\ttrain loss: 0.00553\n",
      "\tval loss: 0.00539\n",
      "epoch 14312 / 20000\n",
      "gradient norm: 0.062728224977036, minimum ratio: 2.4157894736842103\n",
      "\ttrain loss: 0.00553\n",
      "\tval loss: 0.00537\n",
      "epoch 14313 / 20000\n",
      "gradient norm: 0.0641129867581185, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00553\n",
      "\tval loss: 0.00536\n",
      "epoch 14314 / 20000\n",
      "gradient norm: 0.06569557753391564, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00553\n",
      "\tval loss: 0.00539\n",
      "epoch 14315 / 20000\n",
      "gradient norm: 0.09191108914092183, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00553\n",
      "\tval loss: 0.00537\n",
      "epoch 14316 / 20000\n",
      "gradient norm: 0.060820668877568096, minimum ratio: 2.4157894736842103\n",
      "\ttrain loss: 0.00553\n",
      "\tval loss: 0.00537\n",
      "epoch 14317 / 20000\n",
      "gradient norm: 0.04978968479554169, minimum ratio: 2.4421052631578943\n",
      "\ttrain loss: 0.00551\n",
      "\tval loss: 0.00537\n",
      "epoch 14318 / 20000\n",
      "gradient norm: 0.06302508441149257, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00552\n",
      "\tval loss: 0.00537\n",
      "epoch 14319 / 20000\n",
      "gradient norm: 0.07768188872432802, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00552\n",
      "\tval loss: 0.00537\n",
      "epoch 14320 / 20000\n",
      "gradient norm: 0.03415521394344978, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00552\n",
      "\tval loss: 0.00536\n",
      "epoch 14321 / 20000\n",
      "gradient norm: 0.05184292112244293, minimum ratio: 2.4184210526315786\n",
      "\ttrain loss: 0.00552\n",
      "\tval loss: 0.00536\n",
      "epoch 14322 / 20000\n",
      "gradient norm: 0.021753994311438873, minimum ratio: 2.4210526315789473\n",
      "\ttrain loss: 0.00551\n",
      "\tval loss: 0.00536\n",
      "epoch 14323 / 20000\n",
      "gradient norm: 0.08022438597981818, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00551\n",
      "\tval loss: 0.00536\n",
      "epoch 14324 / 20000\n",
      "gradient norm: 0.04945231936289929, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00552\n",
      "\tval loss: 0.00536\n",
      "epoch 14325 / 20000\n",
      "gradient norm: 0.025791715481318533, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00551\n",
      "\tval loss: 0.00535\n",
      "epoch 14326 / 20000\n",
      "gradient norm: 0.03128341812407598, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00551\n",
      "\tval loss: 0.00535\n",
      "epoch 14327 / 20000\n",
      "gradient norm: 0.07375316636171192, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00551\n",
      "\tval loss: 0.00536\n",
      "epoch 14328 / 20000\n",
      "gradient norm: 0.07432308973511681, minimum ratio: 2.460526315789474\n",
      "\ttrain loss: 0.00550\n",
      "\tval loss: 0.00535\n",
      "epoch 14329 / 20000\n",
      "gradient norm: 0.08136962004937232, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00552\n",
      "\tval loss: 0.00534\n",
      "epoch 14330 / 20000\n",
      "gradient norm: 0.0534952319576405, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00551\n",
      "\tval loss: 0.00537\n",
      "epoch 14331 / 20000\n",
      "gradient norm: 0.07260928017785773, minimum ratio: 2.4210526315789473\n",
      "\ttrain loss: 0.00551\n",
      "\tval loss: 0.00535\n",
      "epoch 14332 / 20000\n",
      "gradient norm: 0.04525517323054373, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00548\n",
      "\tval loss: 0.00534\n",
      "epoch 14333 / 20000\n",
      "gradient norm: 0.06519668357213959, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00550\n",
      "\tval loss: 0.00535\n",
      "epoch 14334 / 20000\n",
      "gradient norm: 0.08076681313104928, minimum ratio: 2.4447368421052635\n",
      "\ttrain loss: 0.00549\n",
      "\tval loss: 0.00536\n",
      "epoch 14335 / 20000\n",
      "gradient norm: 0.030179113673511893, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00551\n",
      "\tval loss: 0.00534\n",
      "epoch 14336 / 20000\n",
      "gradient norm: 0.047144712996669114, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00550\n",
      "\tval loss: 0.00534\n",
      "epoch 14337 / 20000\n",
      "gradient norm: 0.04398878368374426, minimum ratio: 2.4236842105263157\n",
      "\ttrain loss: 0.00549\n",
      "\tval loss: 0.00535\n",
      "epoch 14338 / 20000\n",
      "gradient norm: 0.13488998939283192, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00552\n",
      "\tval loss: 0.00534\n",
      "epoch 14339 / 20000\n",
      "gradient norm: 0.04980810807319358, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00549\n",
      "\tval loss: 0.00535\n",
      "epoch 14340 / 20000\n",
      "gradient norm: 0.12274102494120598, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00551\n",
      "\tval loss: 0.00536\n",
      "epoch 14341 / 20000\n",
      "gradient norm: 0.03810706676449627, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00548\n",
      "\tval loss: 0.00533\n",
      "epoch 14342 / 20000\n",
      "gradient norm: 0.062128947116434574, minimum ratio: 2.423684210526316\n",
      "\ttrain loss: 0.00551\n",
      "\tval loss: 0.00533\n",
      "epoch 14343 / 20000\n",
      "gradient norm: 0.06524074269691482, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00548\n",
      "\tval loss: 0.00536\n",
      "epoch 14344 / 20000\n",
      "gradient norm: 0.10484073183033615, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00550\n",
      "\tval loss: 0.00534\n",
      "epoch 14345 / 20000\n",
      "gradient norm: 0.0781273802567739, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00549\n",
      "\tval loss: 0.00532\n",
      "epoch 14346 / 20000\n",
      "gradient norm: 0.05069057046785019, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00550\n",
      "\tval loss: 0.00534\n",
      "epoch 14347 / 20000\n",
      "gradient norm: 0.08524607674917206, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00548\n",
      "\tval loss: 0.00536\n",
      "epoch 14348 / 20000\n",
      "gradient norm: 0.08312431967351586, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00549\n",
      "\tval loss: 0.00532\n",
      "epoch 14349 / 20000\n",
      "gradient norm: 0.10522226608009078, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00550\n",
      "\tval loss: 0.00532\n",
      "epoch 14350 / 20000\n",
      "gradient norm: 0.0486509588372428, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00548\n",
      "\tval loss: 0.00535\n",
      "epoch 14351 / 20000\n",
      "gradient norm: 0.060346918588038534, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00548\n",
      "\tval loss: 0.00533\n",
      "epoch 14352 / 20000\n",
      "gradient norm: 0.07726116507546976, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00549\n",
      "\tval loss: 0.00532\n",
      "epoch 14353 / 20000\n",
      "gradient norm: 0.058343727490864694, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00549\n",
      "\tval loss: 0.00532\n",
      "epoch 14354 / 20000\n",
      "gradient norm: 0.07790276734158397, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00548\n",
      "\tval loss: 0.00535\n",
      "epoch 14355 / 20000\n",
      "gradient norm: 0.052602598967496306, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00550\n",
      "\tval loss: 0.00532\n",
      "epoch 14356 / 20000\n",
      "gradient norm: 0.06886862841201946, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00547\n",
      "\tval loss: 0.00532\n",
      "epoch 14357 / 20000\n",
      "gradient norm: 0.015900735859759152, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00548\n",
      "\tval loss: 0.00532\n",
      "epoch 14358 / 20000\n",
      "gradient norm: 0.06501001809374429, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00546\n",
      "\tval loss: 0.00532\n",
      "epoch 14359 / 20000\n",
      "gradient norm: 0.032262093358440325, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00547\n",
      "\tval loss: 0.00532\n",
      "epoch 14360 / 20000\n",
      "gradient norm: 0.049172995844855905, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00547\n",
      "\tval loss: 0.00532\n",
      "epoch 14361 / 20000\n",
      "gradient norm: 0.10690161830279976, minimum ratio: 2.4447368421052635\n",
      "\ttrain loss: 0.00547\n",
      "\tval loss: 0.00532\n",
      "epoch 14362 / 20000\n",
      "gradient norm: 0.09918356564594433, minimum ratio: 2.436842105263158\n",
      "\ttrain loss: 0.00548\n",
      "\tval loss: 0.00531\n",
      "epoch 14363 / 20000\n",
      "gradient norm: 0.04623403403093107, minimum ratio: 2.423684210526316\n",
      "\ttrain loss: 0.00546\n",
      "\tval loss: 0.00532\n",
      "epoch 14364 / 20000\n",
      "gradient norm: 0.0536976738658268, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00546\n",
      "\tval loss: 0.00532\n",
      "epoch 14365 / 20000\n",
      "gradient norm: 0.04713647055905312, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00546\n",
      "\tval loss: 0.00531\n",
      "epoch 14366 / 20000\n",
      "gradient norm: 0.04464839436695911, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00547\n",
      "\tval loss: 0.00531\n",
      "epoch 14367 / 20000\n",
      "gradient norm: 0.04195161414099857, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00547\n",
      "\tval loss: 0.00531\n",
      "epoch 14368 / 20000\n",
      "gradient norm: 0.046512608882039785, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00547\n",
      "\tval loss: 0.00531\n",
      "epoch 14369 / 20000\n",
      "gradient norm: 0.06158985536603723, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00546\n",
      "\tval loss: 0.00530\n",
      "epoch 14370 / 20000\n",
      "gradient norm: 0.020741671120049432, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00546\n",
      "\tval loss: 0.00531\n",
      "epoch 14371 / 20000\n",
      "gradient norm: 0.04522565804654732, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00545\n",
      "\tval loss: 0.00530\n",
      "epoch 14372 / 20000\n",
      "gradient norm: 0.08202101534698159, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00546\n",
      "\tval loss: 0.00530\n",
      "epoch 14373 / 20000\n",
      "gradient norm: 0.03759547744994052, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00546\n",
      "\tval loss: 0.00530\n",
      "epoch 14374 / 20000\n",
      "gradient norm: 0.04882646183250472, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00545\n",
      "\tval loss: 0.00530\n",
      "epoch 14375 / 20000\n",
      "gradient norm: 0.06218498357338831, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00545\n",
      "\tval loss: 0.00529\n",
      "epoch 14376 / 20000\n",
      "gradient norm: 0.05298738428973593, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00545\n",
      "\tval loss: 0.00530\n",
      "epoch 14377 / 20000\n",
      "gradient norm: 0.04774353373795748, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00545\n",
      "\tval loss: 0.00530\n",
      "epoch 14378 / 20000\n",
      "gradient norm: 0.012122461979743093, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00544\n",
      "\tval loss: 0.00529\n",
      "epoch 14379 / 20000\n",
      "gradient norm: 0.030034930794499815, minimum ratio: 2.46578947368421\n",
      "\ttrain loss: 0.00544\n",
      "\tval loss: 0.00529\n",
      "epoch 14380 / 20000\n",
      "gradient norm: 0.09049868513830006, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00543\n",
      "\tval loss: 0.00529\n",
      "epoch 14381 / 20000\n",
      "gradient norm: 0.035902653136872686, minimum ratio: 2.4421052631578943\n",
      "\ttrain loss: 0.00544\n",
      "\tval loss: 0.00529\n",
      "epoch 14382 / 20000\n",
      "gradient norm: 0.05204075918300077, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00543\n",
      "\tval loss: 0.00529\n",
      "epoch 14383 / 20000\n",
      "gradient norm: 0.06915495079010725, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00545\n",
      "\tval loss: 0.00528\n",
      "epoch 14384 / 20000\n",
      "gradient norm: 0.03966236926498823, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00544\n",
      "\tval loss: 0.00529\n",
      "epoch 14385 / 20000\n",
      "gradient norm: 0.07103585274307989, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00544\n",
      "\tval loss: 0.00528\n",
      "epoch 14386 / 20000\n",
      "gradient norm: 0.08630358125083148, minimum ratio: 2.4499999999999997\n",
      "\ttrain loss: 0.00545\n",
      "\tval loss: 0.00528\n",
      "epoch 14387 / 20000\n",
      "gradient norm: 0.04690385231515393, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00544\n",
      "\tval loss: 0.00530\n",
      "epoch 14388 / 20000\n",
      "gradient norm: 0.03113625544938259, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00543\n",
      "\tval loss: 0.00528\n",
      "epoch 14389 / 20000\n",
      "gradient norm: 0.04228854179382324, minimum ratio: 2.4210526315789473\n",
      "\ttrain loss: 0.00543\n",
      "\tval loss: 0.00528\n",
      "epoch 14390 / 20000\n",
      "gradient norm: 0.05350922350771725, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00542\n",
      "\tval loss: 0.00528\n",
      "epoch 14391 / 20000\n",
      "gradient norm: 0.055658855533692986, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00543\n",
      "\tval loss: 0.00528\n",
      "epoch 14392 / 20000\n",
      "gradient norm: 0.052796352363657206, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00543\n",
      "\tval loss: 0.00527\n",
      "epoch 14393 / 20000\n",
      "gradient norm: 0.07631403330015019, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00543\n",
      "\tval loss: 0.00527\n",
      "epoch 14394 / 20000\n",
      "gradient norm: 0.03998393687652424, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00543\n",
      "\tval loss: 0.00529\n",
      "epoch 14395 / 20000\n",
      "gradient norm: 0.12691657454706728, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00544\n",
      "\tval loss: 0.00527\n",
      "epoch 14396 / 20000\n",
      "gradient norm: 0.05363638780545443, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00543\n",
      "\tval loss: 0.00527\n",
      "epoch 14397 / 20000\n",
      "gradient norm: 0.04368047846946865, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00541\n",
      "\tval loss: 0.00528\n",
      "epoch 14398 / 20000\n",
      "gradient norm: 0.1141560302930884, minimum ratio: 2.4236842105263157\n",
      "\ttrain loss: 0.00544\n",
      "\tval loss: 0.00527\n",
      "epoch 14399 / 20000\n",
      "gradient norm: 0.04758764151483774, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00543\n",
      "\tval loss: 0.00527\n",
      "epoch 14400 / 20000\n",
      "gradient norm: 0.09142729097220581, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00542\n",
      "\tval loss: 0.00527\n",
      "epoch 14401 / 20000\n",
      "gradient norm: 0.039531227317638695, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00542\n",
      "\tval loss: 0.00527\n",
      "epoch 14402 / 20000\n",
      "gradient norm: 0.06739230232778937, minimum ratio: 2.4263157894736844\n",
      "\ttrain loss: 0.00542\n",
      "\tval loss: 0.00527\n",
      "epoch 14403 / 20000\n",
      "gradient norm: 0.07342984899878502, minimum ratio: 2.4210526315789473\n",
      "\ttrain loss: 0.00543\n",
      "\tval loss: 0.00526\n",
      "epoch 14404 / 20000\n",
      "gradient norm: 0.058671202743425965, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00541\n",
      "\tval loss: 0.00527\n",
      "epoch 14405 / 20000\n",
      "gradient norm: 0.12915173033252358, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00540\n",
      "\tval loss: 0.00527\n",
      "epoch 14406 / 20000\n",
      "gradient norm: 0.04804736521327868, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00541\n",
      "\tval loss: 0.00525\n",
      "epoch 14407 / 20000\n",
      "gradient norm: 0.10577993676997721, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00543\n",
      "\tval loss: 0.00526\n",
      "epoch 14408 / 20000\n",
      "gradient norm: 0.05075773305725306, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00541\n",
      "\tval loss: 0.00526\n",
      "epoch 14409 / 20000\n",
      "gradient norm: 0.08543719933368266, minimum ratio: 2.4421052631578943\n",
      "\ttrain loss: 0.00543\n",
      "\tval loss: 0.00525\n",
      "epoch 14410 / 20000\n",
      "gradient norm: 0.07400416862219572, minimum ratio: 2.4263157894736844\n",
      "\ttrain loss: 0.00541\n",
      "\tval loss: 0.00527\n",
      "epoch 14411 / 20000\n",
      "gradient norm: 0.059934637683909386, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00541\n",
      "\tval loss: 0.00526\n",
      "epoch 14412 / 20000\n",
      "gradient norm: 0.054156240745214745, minimum ratio: 2.4236842105263157\n",
      "\ttrain loss: 0.00540\n",
      "\tval loss: 0.00524\n",
      "epoch 14413 / 20000\n",
      "gradient norm: 0.0852521127089858, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00541\n",
      "\tval loss: 0.00525\n",
      "epoch 14414 / 20000\n",
      "gradient norm: 0.028234065102878958, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00539\n",
      "\tval loss: 0.00524\n",
      "epoch 14415 / 20000\n",
      "gradient norm: 0.03938751501846127, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00540\n",
      "\tval loss: 0.00525\n",
      "epoch 14416 / 20000\n",
      "gradient norm: 0.061495369795011356, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00540\n",
      "\tval loss: 0.00525\n",
      "epoch 14417 / 20000\n",
      "gradient norm: 0.07987833255901933, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00538\n",
      "\tval loss: 0.00524\n",
      "epoch 14418 / 20000\n",
      "gradient norm: 0.037775120057631284, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00541\n",
      "\tval loss: 0.00524\n",
      "epoch 14419 / 20000\n",
      "gradient norm: 0.07114228131831624, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00539\n",
      "\tval loss: 0.00524\n",
      "epoch 14420 / 20000\n",
      "gradient norm: 0.04521958710392937, minimum ratio: 2.4263157894736844\n",
      "\ttrain loss: 0.00539\n",
      "\tval loss: 0.00525\n",
      "epoch 14421 / 20000\n",
      "gradient norm: 0.0605407940747682, minimum ratio: 2.4394736842105265\n",
      "\ttrain loss: 0.00538\n",
      "\tval loss: 0.00524\n",
      "epoch 14422 / 20000\n",
      "gradient norm: 0.05325738457031548, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00540\n",
      "\tval loss: 0.00524\n",
      "epoch 14423 / 20000\n",
      "gradient norm: 0.05760472847032361, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00539\n",
      "\tval loss: 0.00524\n",
      "epoch 14424 / 20000\n",
      "gradient norm: 0.05332612030906603, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00538\n",
      "\tval loss: 0.00524\n",
      "epoch 14425 / 20000\n",
      "gradient norm: 0.04724073299439624, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00540\n",
      "\tval loss: 0.00524\n",
      "epoch 14426 / 20000\n",
      "gradient norm: 0.07287906567216851, minimum ratio: 2.4236842105263157\n",
      "\ttrain loss: 0.00538\n",
      "\tval loss: 0.00524\n",
      "epoch 14427 / 20000\n",
      "gradient norm: 0.061023598653264344, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00539\n",
      "\tval loss: 0.00522\n",
      "epoch 14428 / 20000\n",
      "gradient norm: 0.0818848191993311, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00538\n",
      "\tval loss: 0.00524\n",
      "epoch 14429 / 20000\n",
      "gradient norm: 0.060180067899636924, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00539\n",
      "\tval loss: 0.00523\n",
      "epoch 14430 / 20000\n",
      "gradient norm: 0.04836446430999786, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00538\n",
      "\tval loss: 0.00523\n",
      "epoch 14431 / 20000\n",
      "gradient norm: 0.09346134320367128, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00538\n",
      "\tval loss: 0.00523\n",
      "epoch 14432 / 20000\n",
      "gradient norm: 0.056151659693568945, minimum ratio: 2.436842105263158\n",
      "\ttrain loss: 0.00538\n",
      "\tval loss: 0.00522\n",
      "epoch 14433 / 20000\n",
      "gradient norm: 0.0814384474651888, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00537\n",
      "\tval loss: 0.00523\n",
      "epoch 14434 / 20000\n",
      "gradient norm: 0.07239032426150516, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00537\n",
      "\tval loss: 0.00523\n",
      "epoch 14435 / 20000\n",
      "gradient norm: 0.03303310365299694, minimum ratio: 2.4447368421052635\n",
      "\ttrain loss: 0.00538\n",
      "\tval loss: 0.00522\n",
      "epoch 14436 / 20000\n",
      "gradient norm: 0.04578608073643409, minimum ratio: 2.4499999999999997\n",
      "\ttrain loss: 0.00537\n",
      "\tval loss: 0.00522\n",
      "epoch 14437 / 20000\n",
      "gradient norm: 0.0451048867253121, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00538\n",
      "\tval loss: 0.00522\n",
      "epoch 14438 / 20000\n",
      "gradient norm: 0.06324886967195198, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00536\n",
      "\tval loss: 0.00521\n",
      "epoch 14439 / 20000\n",
      "gradient norm: 0.019686505402205512, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00537\n",
      "\tval loss: 0.00522\n",
      "epoch 14440 / 20000\n",
      "gradient norm: 0.09053298475919291, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00538\n",
      "\tval loss: 0.00521\n",
      "epoch 14441 / 20000\n",
      "gradient norm: 0.0317166363238357, minimum ratio: 2.4421052631578943\n",
      "\ttrain loss: 0.00537\n",
      "\tval loss: 0.00522\n",
      "epoch 14442 / 20000\n",
      "gradient norm: 0.04690553169348277, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00536\n",
      "\tval loss: 0.00521\n",
      "epoch 14443 / 20000\n",
      "gradient norm: 0.06488386762794107, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00538\n",
      "\tval loss: 0.00521\n",
      "epoch 14444 / 20000\n",
      "gradient norm: 0.04277365465532057, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00536\n",
      "\tval loss: 0.00522\n",
      "epoch 14445 / 20000\n",
      "gradient norm: 0.09586043958552182, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00535\n",
      "\tval loss: 0.00521\n",
      "epoch 14446 / 20000\n",
      "gradient norm: 0.051409424107987434, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00536\n",
      "\tval loss: 0.00521\n",
      "epoch 14447 / 20000\n",
      "gradient norm: 0.07128633331740275, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00535\n",
      "\tval loss: 0.00521\n",
      "epoch 14448 / 20000\n",
      "gradient norm: 0.04834812303306535, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00535\n",
      "\tval loss: 0.00520\n",
      "epoch 14449 / 20000\n",
      "gradient norm: 0.053165026736678556, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00536\n",
      "\tval loss: 0.00520\n",
      "epoch 14450 / 20000\n",
      "gradient norm: 0.06471908459207043, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00537\n",
      "\tval loss: 0.00521\n",
      "epoch 14451 / 20000\n",
      "gradient norm: 0.03567103872774169, minimum ratio: 2.4421052631578943\n",
      "\ttrain loss: 0.00535\n",
      "\tval loss: 0.00521\n",
      "epoch 14452 / 20000\n",
      "gradient norm: 0.05409497057553381, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00535\n",
      "\tval loss: 0.00519\n",
      "epoch 14453 / 20000\n",
      "gradient norm: 0.07993128336966038, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00535\n",
      "\tval loss: 0.00520\n",
      "epoch 14454 / 20000\n",
      "gradient norm: 0.03910310904029757, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00534\n",
      "\tval loss: 0.00521\n",
      "epoch 14455 / 20000\n",
      "gradient norm: 0.035916537133743986, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00534\n",
      "\tval loss: 0.00519\n",
      "epoch 14456 / 20000\n",
      "gradient norm: 0.040035814890870824, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00536\n",
      "\tval loss: 0.00519\n",
      "epoch 14457 / 20000\n",
      "gradient norm: 0.07748157123569399, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00534\n",
      "\tval loss: 0.00520\n",
      "epoch 14458 / 20000\n",
      "gradient norm: 0.06174423437914811, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00534\n",
      "\tval loss: 0.00519\n",
      "epoch 14459 / 20000\n",
      "gradient norm: 0.07439831749070436, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00533\n",
      "\tval loss: 0.00519\n",
      "epoch 14460 / 20000\n",
      "gradient norm: 0.039971584716113284, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00533\n",
      "\tval loss: 0.00518\n",
      "epoch 14461 / 20000\n",
      "gradient norm: 0.0519399419426918, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00533\n",
      "\tval loss: 0.00519\n",
      "epoch 14462 / 20000\n",
      "gradient norm: 0.055529856123030186, minimum ratio: 2.4289473684210523\n",
      "\ttrain loss: 0.00533\n",
      "\tval loss: 0.00519\n",
      "epoch 14463 / 20000\n",
      "gradient norm: 0.0751479108876083, minimum ratio: 2.4210526315789473\n",
      "\ttrain loss: 0.00534\n",
      "\tval loss: 0.00518\n",
      "epoch 14464 / 20000\n",
      "gradient norm: 0.11050647962838411, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00535\n",
      "\tval loss: 0.00519\n",
      "epoch 14465 / 20000\n",
      "gradient norm: 0.03233663903665729, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00533\n",
      "\tval loss: 0.00518\n",
      "epoch 14466 / 20000\n",
      "gradient norm: 0.04947498184628785, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00533\n",
      "\tval loss: 0.00518\n",
      "epoch 14467 / 20000\n",
      "gradient norm: 0.024702484952285886, minimum ratio: 2.4394736842105265\n",
      "\ttrain loss: 0.00532\n",
      "\tval loss: 0.00518\n",
      "epoch 14468 / 20000\n",
      "gradient norm: 0.04831095150439069, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00534\n",
      "\tval loss: 0.00517\n",
      "epoch 14469 / 20000\n",
      "gradient norm: 0.10861993295839056, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00533\n",
      "\tval loss: 0.00518\n",
      "epoch 14470 / 20000\n",
      "gradient norm: 0.07080503681208938, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00533\n",
      "\tval loss: 0.00517\n",
      "epoch 14471 / 20000\n",
      "gradient norm: 0.058632870262954384, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00532\n",
      "\tval loss: 0.00517\n",
      "epoch 14472 / 20000\n",
      "gradient norm: 0.031700415565865114, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00532\n",
      "\tval loss: 0.00518\n",
      "epoch 14473 / 20000\n",
      "gradient norm: 0.04864856292260811, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00532\n",
      "\tval loss: 0.00517\n",
      "epoch 14474 / 20000\n",
      "gradient norm: 0.11132437112974003, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00531\n",
      "\tval loss: 0.00517\n",
      "epoch 14475 / 20000\n",
      "gradient norm: 0.09671180401346646, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00531\n",
      "\tval loss: 0.00518\n",
      "epoch 14476 / 20000\n",
      "gradient norm: 0.048133922391571105, minimum ratio: 2.4210526315789473\n",
      "\ttrain loss: 0.00532\n",
      "\tval loss: 0.00517\n",
      "epoch 14477 / 20000\n",
      "gradient norm: 0.05211753200273961, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00532\n",
      "\tval loss: 0.00516\n",
      "epoch 14478 / 20000\n",
      "gradient norm: 0.04775060876272619, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00531\n",
      "\tval loss: 0.00517\n",
      "epoch 14479 / 20000\n",
      "gradient norm: 0.04706739174434915, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00532\n",
      "\tval loss: 0.00517\n",
      "epoch 14480 / 20000\n",
      "gradient norm: 0.06217083358205855, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00531\n",
      "\tval loss: 0.00516\n",
      "epoch 14481 / 20000\n",
      "gradient norm: 0.08961414371151477, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00531\n",
      "\tval loss: 0.00517\n",
      "epoch 14482 / 20000\n",
      "gradient norm: 0.03175133661716245, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00531\n",
      "\tval loss: 0.00515\n",
      "epoch 14483 / 20000\n",
      "gradient norm: 0.1287343790754676, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00533\n",
      "\tval loss: 0.00515\n",
      "epoch 14484 / 20000\n",
      "gradient norm: 0.06082920868357178, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00532\n",
      "\tval loss: 0.00519\n",
      "epoch 14485 / 20000\n",
      "gradient norm: 0.04572189995087683, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00532\n",
      "\tval loss: 0.00515\n",
      "epoch 14486 / 20000\n",
      "gradient norm: 0.08551761403214186, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00531\n",
      "\tval loss: 0.00515\n",
      "epoch 14487 / 20000\n",
      "gradient norm: 0.058605018188245595, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00532\n",
      "\tval loss: 0.00515\n",
      "epoch 14488 / 20000\n",
      "gradient norm: 0.052899843314662576, minimum ratio: 2.4394736842105265\n",
      "\ttrain loss: 0.00530\n",
      "\tval loss: 0.00516\n",
      "epoch 14489 / 20000\n",
      "gradient norm: 0.05930668883956969, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00529\n",
      "\tval loss: 0.00515\n",
      "epoch 14490 / 20000\n",
      "gradient norm: 0.046703485219040886, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00530\n",
      "\tval loss: 0.00515\n",
      "epoch 14491 / 20000\n",
      "gradient norm: 0.03466695931274444, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00529\n",
      "\tval loss: 0.00515\n",
      "epoch 14492 / 20000\n",
      "gradient norm: 0.042889645003015175, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00529\n",
      "\tval loss: 0.00515\n",
      "epoch 14493 / 20000\n",
      "gradient norm: 0.12235337874153629, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00532\n",
      "\tval loss: 0.00514\n",
      "epoch 14494 / 20000\n",
      "gradient norm: 0.0691645125625655, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00530\n",
      "\tval loss: 0.00516\n",
      "epoch 14495 / 20000\n",
      "gradient norm: 0.07105993787990883, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00529\n",
      "\tval loss: 0.00515\n",
      "epoch 14496 / 20000\n",
      "gradient norm: 0.08781284984434023, minimum ratio: 2.4289473684210523\n",
      "\ttrain loss: 0.00529\n",
      "\tval loss: 0.00513\n",
      "epoch 14497 / 20000\n",
      "gradient norm: 0.05450670316349715, minimum ratio: 2.4236842105263157\n",
      "\ttrain loss: 0.00529\n",
      "\tval loss: 0.00514\n",
      "epoch 14498 / 20000\n",
      "gradient norm: 0.03062851171125658, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00528\n",
      "\tval loss: 0.00514\n",
      "epoch 14499 / 20000\n",
      "gradient norm: 0.020326768804807216, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00527\n",
      "\tval loss: 0.00514\n",
      "epoch 14500 / 20000\n",
      "gradient norm: 0.06089448888087645, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00529\n",
      "\tval loss: 0.00513\n",
      "epoch 14501 / 20000\n",
      "gradient norm: 0.048772857000585645, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00529\n",
      "\tval loss: 0.00513\n",
      "epoch 14502 / 20000\n",
      "gradient norm: 0.05997537006624043, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00528\n",
      "\tval loss: 0.00514\n",
      "epoch 14503 / 20000\n",
      "gradient norm: 0.048906453303061426, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00528\n",
      "\tval loss: 0.00513\n",
      "epoch 14504 / 20000\n",
      "gradient norm: 0.03293703816598281, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00527\n",
      "\tval loss: 0.00513\n",
      "epoch 14505 / 20000\n",
      "gradient norm: 0.019755662855459377, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00527\n",
      "\tval loss: 0.00513\n",
      "epoch 14506 / 20000\n",
      "gradient norm: 0.10801673587411642, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00528\n",
      "\tval loss: 0.00513\n",
      "epoch 14507 / 20000\n",
      "gradient norm: 0.05425184723571874, minimum ratio: 2.4263157894736844\n",
      "\ttrain loss: 0.00527\n",
      "\tval loss: 0.00512\n",
      "epoch 14508 / 20000\n",
      "gradient norm: 0.05958813719917089, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00527\n",
      "\tval loss: 0.00513\n",
      "epoch 14509 / 20000\n",
      "gradient norm: 0.07876629394013435, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00527\n",
      "\tval loss: 0.00512\n",
      "epoch 14510 / 20000\n",
      "gradient norm: 0.07906944252317771, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00527\n",
      "\tval loss: 0.00512\n",
      "epoch 14511 / 20000\n",
      "gradient norm: 0.059419647965114564, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00527\n",
      "\tval loss: 0.00511\n",
      "epoch 14512 / 20000\n",
      "gradient norm: 0.03278453147504479, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00526\n",
      "\tval loss: 0.00512\n",
      "epoch 14513 / 20000\n",
      "gradient norm: 0.04554016183828935, minimum ratio: 2.4447368421052635\n",
      "\ttrain loss: 0.00526\n",
      "\tval loss: 0.00512\n",
      "epoch 14514 / 20000\n",
      "gradient norm: 0.047533013857901096, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00526\n",
      "\tval loss: 0.00511\n",
      "epoch 14515 / 20000\n",
      "gradient norm: 0.06172027008142322, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00526\n",
      "\tval loss: 0.00512\n",
      "epoch 14516 / 20000\n",
      "gradient norm: 0.06239599775290117, minimum ratio: 2.4105263157894736\n",
      "\ttrain loss: 0.00526\n",
      "\tval loss: 0.00511\n",
      "epoch 14517 / 20000\n",
      "gradient norm: 0.04791394402855076, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00525\n",
      "\tval loss: 0.00511\n",
      "epoch 14518 / 20000\n",
      "gradient norm: 0.11390943359583616, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00526\n",
      "\tval loss: 0.00511\n",
      "epoch 14519 / 20000\n",
      "gradient norm: 0.04037739022169262, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00526\n",
      "\tval loss: 0.00510\n",
      "epoch 14520 / 20000\n",
      "gradient norm: 0.047097748261876404, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00524\n",
      "\tval loss: 0.00511\n",
      "epoch 14521 / 20000\n",
      "gradient norm: 0.05529106064932421, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00526\n",
      "\tval loss: 0.00510\n",
      "epoch 14522 / 20000\n",
      "gradient norm: 0.03951529652113095, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00525\n",
      "\tval loss: 0.00510\n",
      "epoch 14523 / 20000\n",
      "gradient norm: 0.08300971175776795, minimum ratio: 2.4421052631578952\n",
      "\ttrain loss: 0.00525\n",
      "\tval loss: 0.00511\n",
      "epoch 14524 / 20000\n",
      "gradient norm: 0.0480381824017968, minimum ratio: 2.4499999999999997\n",
      "\ttrain loss: 0.00525\n",
      "\tval loss: 0.00510\n",
      "epoch 14525 / 20000\n",
      "gradient norm: 0.04290361446328461, minimum ratio: 2.426315789473684\n",
      "\ttrain loss: 0.00525\n",
      "\tval loss: 0.00509\n",
      "epoch 14526 / 20000\n",
      "gradient norm: 0.06922029424458742, minimum ratio: 2.4421052631578943\n",
      "\ttrain loss: 0.00525\n",
      "\tval loss: 0.00510\n",
      "epoch 14527 / 20000\n",
      "gradient norm: 0.09557009930722415, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00525\n",
      "\tval loss: 0.00511\n",
      "epoch 14528 / 20000\n",
      "gradient norm: 0.09451836172956973, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00523\n",
      "\tval loss: 0.00509\n",
      "epoch 14529 / 20000\n",
      "gradient norm: 0.07674671389395371, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00525\n",
      "\tval loss: 0.00508\n",
      "epoch 14530 / 20000\n",
      "gradient norm: 0.08618566149380058, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00524\n",
      "\tval loss: 0.00510\n",
      "epoch 14531 / 20000\n",
      "gradient norm: 0.06853786564897746, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00524\n",
      "\tval loss: 0.00511\n",
      "epoch 14532 / 20000\n",
      "gradient norm: 0.12151552748400718, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00527\n",
      "\tval loss: 0.00508\n",
      "epoch 14533 / 20000\n",
      "gradient norm: 0.020053328888025135, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00523\n",
      "\tval loss: 0.00510\n",
      "epoch 14534 / 20000\n",
      "gradient norm: 0.06383762566838413, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00524\n",
      "\tval loss: 0.00509\n",
      "epoch 14535 / 20000\n",
      "gradient norm: 0.07121947751147673, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00525\n",
      "\tval loss: 0.00508\n",
      "epoch 14536 / 20000\n",
      "gradient norm: 0.030406073812628165, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00524\n",
      "\tval loss: 0.00510\n",
      "epoch 14537 / 20000\n",
      "gradient norm: 0.10553085268475115, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00524\n",
      "\tval loss: 0.00508\n",
      "epoch 14538 / 20000\n",
      "gradient norm: 0.09552763041574508, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00522\n",
      "\tval loss: 0.00509\n",
      "epoch 14539 / 20000\n",
      "gradient norm: 0.08928322221618146, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00523\n",
      "\tval loss: 0.00507\n",
      "epoch 14540 / 20000\n",
      "gradient norm: 0.07753799817874096, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00522\n",
      "\tval loss: 0.00508\n",
      "epoch 14541 / 20000\n",
      "gradient norm: 0.056406864256132394, minimum ratio: 2.447368421052631\n",
      "\ttrain loss: 0.00522\n",
      "\tval loss: 0.00508\n",
      "epoch 14542 / 20000\n",
      "gradient norm: 0.0776894647278823, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00521\n",
      "\tval loss: 0.00508\n",
      "epoch 14543 / 20000\n",
      "gradient norm: 0.024541203980334103, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00522\n",
      "\tval loss: 0.00507\n",
      "epoch 14544 / 20000\n",
      "gradient norm: 0.021757910813903436, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00523\n",
      "\tval loss: 0.00507\n",
      "epoch 14545 / 20000\n",
      "gradient norm: 0.0982450392912142, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00522\n",
      "\tval loss: 0.00508\n",
      "epoch 14546 / 20000\n",
      "gradient norm: 0.11987580673303455, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00522\n",
      "\tval loss: 0.00506\n",
      "epoch 14547 / 20000\n",
      "gradient norm: 0.06238324858713895, minimum ratio: 2.4263157894736844\n",
      "\ttrain loss: 0.00522\n",
      "\tval loss: 0.00508\n",
      "epoch 14548 / 20000\n",
      "gradient norm: 0.08947622659616172, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00521\n",
      "\tval loss: 0.00507\n",
      "epoch 14549 / 20000\n",
      "gradient norm: 0.07601139484904706, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00521\n",
      "\tval loss: 0.00507\n",
      "epoch 14550 / 20000\n",
      "gradient norm: 0.0437734768493101, minimum ratio: 2.4447368421052635\n",
      "\ttrain loss: 0.00521\n",
      "\tval loss: 0.00506\n",
      "epoch 14551 / 20000\n",
      "gradient norm: 0.04944810189772397, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00520\n",
      "\tval loss: 0.00506\n",
      "epoch 14552 / 20000\n",
      "gradient norm: 0.022615967609453946, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00521\n",
      "\tval loss: 0.00506\n",
      "epoch 14553 / 20000\n",
      "gradient norm: 0.06147816026350483, minimum ratio: 2.4289473684210523\n",
      "\ttrain loss: 0.00522\n",
      "\tval loss: 0.00506\n",
      "epoch 14554 / 20000\n",
      "gradient norm: 0.0746529009193182, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00521\n",
      "\tval loss: 0.00506\n",
      "epoch 14555 / 20000\n",
      "gradient norm: 0.05999794811941683, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00519\n",
      "\tval loss: 0.00505\n",
      "epoch 14556 / 20000\n",
      "gradient norm: 0.10146668087691069, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00521\n",
      "\tval loss: 0.00505\n",
      "epoch 14557 / 20000\n",
      "gradient norm: 0.049641669960692525, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00520\n",
      "\tval loss: 0.00506\n",
      "epoch 14558 / 20000\n",
      "gradient norm: 0.0877093076123856, minimum ratio: 2.4394736842105265\n",
      "\ttrain loss: 0.00521\n",
      "\tval loss: 0.00505\n",
      "epoch 14559 / 20000\n",
      "gradient norm: 0.05431550509092631, minimum ratio: 2.413157894736842\n",
      "\ttrain loss: 0.00519\n",
      "\tval loss: 0.00505\n",
      "epoch 14560 / 20000\n",
      "gradient norm: 0.11038442060817033, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00521\n",
      "\tval loss: 0.00504\n",
      "epoch 14561 / 20000\n",
      "gradient norm: 0.045678350899834186, minimum ratio: 2.4105263157894736\n",
      "\ttrain loss: 0.00518\n",
      "\tval loss: 0.00506\n",
      "epoch 14562 / 20000\n",
      "gradient norm: 0.08243848691927269, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00520\n",
      "\tval loss: 0.00505\n",
      "epoch 14563 / 20000\n",
      "gradient norm: 0.044371217634761706, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00519\n",
      "\tval loss: 0.00504\n",
      "epoch 14564 / 20000\n",
      "gradient norm: 0.059665281674824655, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00519\n",
      "\tval loss: 0.00504\n",
      "epoch 14565 / 20000\n",
      "gradient norm: 0.0590272715780884, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00518\n",
      "\tval loss: 0.00505\n",
      "epoch 14566 / 20000\n",
      "gradient norm: 0.030914043192751706, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00519\n",
      "\tval loss: 0.00505\n",
      "epoch 14567 / 20000\n",
      "gradient norm: 0.038580851833103225, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00519\n",
      "\tval loss: 0.00504\n",
      "epoch 14568 / 20000\n",
      "gradient norm: 0.03198047316982411, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00520\n",
      "\tval loss: 0.00504\n",
      "epoch 14569 / 20000\n",
      "gradient norm: 0.10054234572453424, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00518\n",
      "\tval loss: 0.00504\n",
      "epoch 14570 / 20000\n",
      "gradient norm: 0.11897712666541338, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00519\n",
      "\tval loss: 0.00505\n",
      "epoch 14571 / 20000\n",
      "gradient norm: 0.03891762439161539, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00518\n",
      "\tval loss: 0.00503\n",
      "epoch 14572 / 20000\n",
      "gradient norm: 0.1008141910424456, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00519\n",
      "\tval loss: 0.00502\n",
      "epoch 14573 / 20000\n",
      "gradient norm: 0.05657125939615071, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00519\n",
      "\tval loss: 0.00507\n",
      "epoch 14574 / 20000\n",
      "gradient norm: 0.1104202326387167, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00520\n",
      "\tval loss: 0.00503\n",
      "epoch 14575 / 20000\n",
      "gradient norm: 0.044848977180663496, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00517\n",
      "\tval loss: 0.00502\n",
      "epoch 14576 / 20000\n",
      "gradient norm: 0.04459331824909896, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00517\n",
      "\tval loss: 0.00503\n",
      "epoch 14577 / 20000\n",
      "gradient norm: 0.07644068312947638, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00519\n",
      "\tval loss: 0.00502\n",
      "epoch 14578 / 20000\n",
      "gradient norm: 0.04540485129109584, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00516\n",
      "\tval loss: 0.00503\n",
      "epoch 14579 / 20000\n",
      "gradient norm: 0.11022587085608393, minimum ratio: 2.4236842105263157\n",
      "\ttrain loss: 0.00519\n",
      "\tval loss: 0.00502\n",
      "epoch 14580 / 20000\n",
      "gradient norm: 0.05092899440205656, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00516\n",
      "\tval loss: 0.00504\n",
      "epoch 14581 / 20000\n",
      "gradient norm: 0.04346575390081853, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00516\n",
      "\tval loss: 0.00502\n",
      "epoch 14582 / 20000\n",
      "gradient norm: 0.0328887682990171, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00517\n",
      "\tval loss: 0.00501\n",
      "epoch 14583 / 20000\n",
      "gradient norm: 0.039193041797261685, minimum ratio: 2.4499999999999997\n",
      "\ttrain loss: 0.00516\n",
      "\tval loss: 0.00502\n",
      "epoch 14584 / 20000\n",
      "gradient norm: 0.06505712767830119, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00517\n",
      "\tval loss: 0.00502\n",
      "epoch 14585 / 20000\n",
      "gradient norm: 0.08640625595580786, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00516\n",
      "\tval loss: 0.00501\n",
      "epoch 14586 / 20000\n",
      "gradient norm: 0.059317973791621625, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00515\n",
      "\tval loss: 0.00501\n",
      "epoch 14587 / 20000\n",
      "gradient norm: 0.07825443052570336, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00516\n",
      "\tval loss: 0.00501\n",
      "epoch 14588 / 20000\n",
      "gradient norm: 0.04238143336260691, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00516\n",
      "\tval loss: 0.00501\n",
      "epoch 14589 / 20000\n",
      "gradient norm: 0.0677815752569586, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00517\n",
      "\tval loss: 0.00501\n",
      "epoch 14590 / 20000\n",
      "gradient norm: 0.034466038225218654, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00515\n",
      "\tval loss: 0.00501\n",
      "epoch 14591 / 20000\n",
      "gradient norm: 0.05089420801959932, minimum ratio: 2.4447368421052627\n",
      "\ttrain loss: 0.00515\n",
      "\tval loss: 0.00501\n",
      "epoch 14592 / 20000\n",
      "gradient norm: 0.05383327370509505, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00515\n",
      "\tval loss: 0.00500\n",
      "epoch 14593 / 20000\n",
      "gradient norm: 0.05749681359156966, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00515\n",
      "\tval loss: 0.00501\n",
      "epoch 14594 / 20000\n",
      "gradient norm: 0.05010187206789851, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00515\n",
      "\tval loss: 0.00500\n",
      "epoch 14595 / 20000\n",
      "gradient norm: 0.02516360455774702, minimum ratio: 2.4447368421052635\n",
      "\ttrain loss: 0.00514\n",
      "\tval loss: 0.00500\n",
      "epoch 14596 / 20000\n",
      "gradient norm: 0.08233024430228397, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00513\n",
      "\tval loss: 0.00500\n",
      "epoch 14597 / 20000\n",
      "gradient norm: 0.05262718303129077, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00514\n",
      "\tval loss: 0.00499\n",
      "epoch 14598 / 20000\n",
      "gradient norm: 0.06739559036213905, minimum ratio: 2.4210526315789473\n",
      "\ttrain loss: 0.00514\n",
      "\tval loss: 0.00499\n",
      "epoch 14599 / 20000\n",
      "gradient norm: 0.04291169921634719, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00515\n",
      "\tval loss: 0.00499\n",
      "epoch 14600 / 20000\n",
      "gradient norm: 0.07363388301018858, minimum ratio: 2.4499999999999997\n",
      "\ttrain loss: 0.00514\n",
      "\tval loss: 0.00500\n",
      "epoch 14601 / 20000\n",
      "gradient norm: 0.07771313423290849, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00513\n",
      "\tval loss: 0.00501\n",
      "epoch 14602 / 20000\n",
      "gradient norm: 0.05086236190982163, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00513\n",
      "\tval loss: 0.00498\n",
      "epoch 14603 / 20000\n",
      "gradient norm: 0.08466354373376817, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00513\n",
      "\tval loss: 0.00498\n",
      "epoch 14604 / 20000\n",
      "gradient norm: 0.06668198702391237, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00513\n",
      "\tval loss: 0.00499\n",
      "epoch 14605 / 20000\n",
      "gradient norm: 0.09206140087917447, minimum ratio: 2.426315789473684\n",
      "\ttrain loss: 0.00514\n",
      "\tval loss: 0.00498\n",
      "epoch 14606 / 20000\n",
      "gradient norm: 0.07307492633117363, minimum ratio: 2.4236842105263157\n",
      "\ttrain loss: 0.00512\n",
      "\tval loss: 0.00499\n",
      "epoch 14607 / 20000\n",
      "gradient norm: 0.06617991713574156, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00514\n",
      "\tval loss: 0.00498\n",
      "epoch 14608 / 20000\n",
      "gradient norm: 0.05706086877034977, minimum ratio: 2.4236842105263157\n",
      "\ttrain loss: 0.00513\n",
      "\tval loss: 0.00497\n",
      "epoch 14609 / 20000\n",
      "gradient norm: 0.051157925045117736, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00513\n",
      "\tval loss: 0.00499\n",
      "epoch 14610 / 20000\n",
      "gradient norm: 0.032628720335196704, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00512\n",
      "\tval loss: 0.00498\n",
      "epoch 14611 / 20000\n",
      "gradient norm: 0.06123340339399874, minimum ratio: 2.460526315789474\n",
      "\ttrain loss: 0.00513\n",
      "\tval loss: 0.00497\n",
      "epoch 14612 / 20000\n",
      "gradient norm: 0.0841144387377426, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00512\n",
      "\tval loss: 0.00497\n",
      "epoch 14613 / 20000\n",
      "gradient norm: 0.05031484251958318, minimum ratio: 2.4263157894736844\n",
      "\ttrain loss: 0.00512\n",
      "\tval loss: 0.00498\n",
      "epoch 14614 / 20000\n",
      "gradient norm: 0.05380299099488184, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00511\n",
      "\tval loss: 0.00497\n",
      "epoch 14615 / 20000\n",
      "gradient norm: 0.05461752865812741, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00511\n",
      "\tval loss: 0.00498\n",
      "epoch 14616 / 20000\n",
      "gradient norm: 0.03260841133305803, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00512\n",
      "\tval loss: 0.00497\n",
      "epoch 14617 / 20000\n",
      "gradient norm: 0.05172589988796972, minimum ratio: 2.460526315789474\n",
      "\ttrain loss: 0.00512\n",
      "\tval loss: 0.00497\n",
      "epoch 14618 / 20000\n",
      "gradient norm: 0.04542131195194088, minimum ratio: 2.4499999999999997\n",
      "\ttrain loss: 0.00512\n",
      "\tval loss: 0.00496\n",
      "epoch 14619 / 20000\n",
      "gradient norm: 0.06377266230992973, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00510\n",
      "\tval loss: 0.00497\n",
      "epoch 14620 / 20000\n",
      "gradient norm: 0.05084941038512625, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00511\n",
      "\tval loss: 0.00496\n",
      "epoch 14621 / 20000\n",
      "gradient norm: 0.029254762557684444, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00510\n",
      "\tval loss: 0.00496\n",
      "epoch 14622 / 20000\n",
      "gradient norm: 0.07129127840744331, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00510\n",
      "\tval loss: 0.00496\n",
      "epoch 14623 / 20000\n",
      "gradient norm: 0.06324351270450279, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00510\n",
      "\tval loss: 0.00496\n",
      "epoch 14624 / 20000\n",
      "gradient norm: 0.02749092603335157, minimum ratio: 2.4157894736842103\n",
      "\ttrain loss: 0.00509\n",
      "\tval loss: 0.00495\n",
      "epoch 14625 / 20000\n",
      "gradient norm: 0.05585674272151664, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00512\n",
      "\tval loss: 0.00495\n",
      "epoch 14626 / 20000\n",
      "gradient norm: 0.0685061137919547, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00510\n",
      "\tval loss: 0.00497\n",
      "epoch 14627 / 20000\n",
      "gradient norm: 0.040069942420814186, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00509\n",
      "\tval loss: 0.00495\n",
      "epoch 14628 / 20000\n",
      "gradient norm: 0.07567158166784793, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00510\n",
      "\tval loss: 0.00495\n",
      "epoch 14629 / 20000\n",
      "gradient norm: 0.05632177571533248, minimum ratio: 2.4499999999999997\n",
      "\ttrain loss: 0.00509\n",
      "\tval loss: 0.00494\n",
      "epoch 14630 / 20000\n",
      "gradient norm: 0.04573073057690635, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00508\n",
      "\tval loss: 0.00496\n",
      "epoch 14631 / 20000\n",
      "gradient norm: 0.050890915968921036, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00509\n",
      "\tval loss: 0.00495\n",
      "epoch 14632 / 20000\n",
      "gradient norm: 0.027535046538105235, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00509\n",
      "\tval loss: 0.00494\n",
      "epoch 14633 / 20000\n",
      "gradient norm: 0.045534710690844804, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00509\n",
      "\tval loss: 0.00494\n",
      "epoch 14634 / 20000\n",
      "gradient norm: 0.03204424603609368, minimum ratio: 2.4421052631578943\n",
      "\ttrain loss: 0.00508\n",
      "\tval loss: 0.00495\n",
      "epoch 14635 / 20000\n",
      "gradient norm: 0.07939558249199763, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00509\n",
      "\tval loss: 0.00494\n",
      "epoch 14636 / 20000\n",
      "gradient norm: 0.040508867910830304, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00509\n",
      "\tval loss: 0.00494\n",
      "epoch 14637 / 20000\n",
      "gradient norm: 0.044854290492367, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00508\n",
      "\tval loss: 0.00493\n",
      "epoch 14638 / 20000\n",
      "gradient norm: 0.06463925819844007, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00509\n",
      "\tval loss: 0.00494\n",
      "epoch 14639 / 20000\n",
      "gradient norm: 0.07125278786406852, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00507\n",
      "\tval loss: 0.00494\n",
      "epoch 14640 / 20000\n",
      "gradient norm: 0.059189305757172406, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00508\n",
      "\tval loss: 0.00493\n",
      "epoch 14641 / 20000\n",
      "gradient norm: 0.04777608811855316, minimum ratio: 2.460526315789474\n",
      "\ttrain loss: 0.00507\n",
      "\tval loss: 0.00493\n",
      "epoch 14642 / 20000\n",
      "gradient norm: 0.0589738795242738, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00507\n",
      "\tval loss: 0.00493\n",
      "epoch 14643 / 20000\n",
      "gradient norm: 0.08185963693540543, minimum ratio: 2.4236842105263157\n",
      "\ttrain loss: 0.00508\n",
      "\tval loss: 0.00492\n",
      "epoch 14644 / 20000\n",
      "gradient norm: 0.056297756906133145, minimum ratio: 2.4394736842105265\n",
      "\ttrain loss: 0.00508\n",
      "\tval loss: 0.00493\n",
      "epoch 14645 / 20000\n",
      "gradient norm: 0.08275104442145675, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00507\n",
      "\tval loss: 0.00493\n",
      "epoch 14646 / 20000\n",
      "gradient norm: 0.044982162973610684, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00507\n",
      "\tval loss: 0.00492\n",
      "epoch 14647 / 20000\n",
      "gradient norm: 0.030741392518393695, minimum ratio: 2.4210526315789473\n",
      "\ttrain loss: 0.00506\n",
      "\tval loss: 0.00492\n",
      "epoch 14648 / 20000\n",
      "gradient norm: 0.03391452721552923, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00506\n",
      "\tval loss: 0.00493\n",
      "epoch 14649 / 20000\n",
      "gradient norm: 0.03729977464536205, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00506\n",
      "\tval loss: 0.00492\n",
      "epoch 14650 / 20000\n",
      "gradient norm: 0.0462060843128711, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00505\n",
      "\tval loss: 0.00492\n",
      "epoch 14651 / 20000\n",
      "gradient norm: 0.07732832169858739, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00507\n",
      "\tval loss: 0.00491\n",
      "epoch 14652 / 20000\n",
      "gradient norm: 0.09239857189822942, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00507\n",
      "\tval loss: 0.00493\n",
      "epoch 14653 / 20000\n",
      "gradient norm: 0.029365773603785783, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00505\n",
      "\tval loss: 0.00491\n",
      "epoch 14654 / 20000\n",
      "gradient norm: 0.05740894022164866, minimum ratio: 2.4421052631578943\n",
      "\ttrain loss: 0.00505\n",
      "\tval loss: 0.00491\n",
      "epoch 14655 / 20000\n",
      "gradient norm: 0.07374795794021338, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00505\n",
      "\tval loss: 0.00491\n",
      "epoch 14656 / 20000\n",
      "gradient norm: 0.05994864756939933, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00505\n",
      "\tval loss: 0.00492\n",
      "epoch 14657 / 20000\n",
      "gradient norm: 0.04526444984367117, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00504\n",
      "\tval loss: 0.00490\n",
      "epoch 14658 / 20000\n",
      "gradient norm: 0.08356215359526686, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00503\n",
      "\tval loss: 0.00491\n",
      "epoch 14659 / 20000\n",
      "gradient norm: 0.02549712746986188, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00504\n",
      "\tval loss: 0.00490\n",
      "epoch 14660 / 20000\n",
      "gradient norm: 0.03820688842097297, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00505\n",
      "\tval loss: 0.00490\n",
      "epoch 14661 / 20000\n",
      "gradient norm: 0.07272567274048924, minimum ratio: 2.46578947368421\n",
      "\ttrain loss: 0.00504\n",
      "\tval loss: 0.00491\n",
      "epoch 14662 / 20000\n",
      "gradient norm: 0.032355478208046407, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00504\n",
      "\tval loss: 0.00490\n",
      "epoch 14663 / 20000\n",
      "gradient norm: 0.0815495629212819, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00504\n",
      "\tval loss: 0.00489\n",
      "epoch 14664 / 20000\n",
      "gradient norm: 0.10047332284739241, minimum ratio: 2.436842105263158\n",
      "\ttrain loss: 0.00504\n",
      "\tval loss: 0.00491\n",
      "epoch 14665 / 20000\n",
      "gradient norm: 0.025841134251095355, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00504\n",
      "\tval loss: 0.00489\n",
      "epoch 14666 / 20000\n",
      "gradient norm: 0.03396442800294608, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00503\n",
      "\tval loss: 0.00489\n",
      "epoch 14667 / 20000\n",
      "gradient norm: 0.08832672378048301, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00504\n",
      "\tval loss: 0.00490\n",
      "epoch 14668 / 20000\n",
      "gradient norm: 0.07115011278074235, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00504\n",
      "\tval loss: 0.00488\n",
      "epoch 14669 / 20000\n",
      "gradient norm: 0.046683651773491874, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00503\n",
      "\tval loss: 0.00489\n",
      "epoch 14670 / 20000\n",
      "gradient norm: 0.029527713893912733, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00504\n",
      "\tval loss: 0.00489\n",
      "epoch 14671 / 20000\n",
      "gradient norm: 0.05347794698900543, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00502\n",
      "\tval loss: 0.00488\n",
      "epoch 14672 / 20000\n",
      "gradient norm: 0.030313033625134267, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00502\n",
      "\tval loss: 0.00489\n",
      "epoch 14673 / 20000\n",
      "gradient norm: 0.05049093411071226, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00501\n",
      "\tval loss: 0.00489\n",
      "epoch 14674 / 20000\n",
      "gradient norm: 0.035724268411286175, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00502\n",
      "\tval loss: 0.00488\n",
      "epoch 14675 / 20000\n",
      "gradient norm: 0.08454610654735006, minimum ratio: 2.4421052631578943\n",
      "\ttrain loss: 0.00502\n",
      "\tval loss: 0.00488\n",
      "epoch 14676 / 20000\n",
      "gradient norm: 0.024236606346676126, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00502\n",
      "\tval loss: 0.00489\n",
      "epoch 14677 / 20000\n",
      "gradient norm: 0.06281313486397266, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00502\n",
      "\tval loss: 0.00488\n",
      "epoch 14678 / 20000\n",
      "gradient norm: 0.04057585168629885, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00502\n",
      "\tval loss: 0.00487\n",
      "epoch 14679 / 20000\n",
      "gradient norm: 0.09020564274396747, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00502\n",
      "\tval loss: 0.00488\n",
      "epoch 14680 / 20000\n",
      "gradient norm: 0.03549185942392796, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00502\n",
      "\tval loss: 0.00487\n",
      "epoch 14681 / 20000\n",
      "gradient norm: 0.061006262665614486, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00501\n",
      "\tval loss: 0.00487\n",
      "epoch 14682 / 20000\n",
      "gradient norm: 0.060092119325418025, minimum ratio: 2.4499999999999997\n",
      "\ttrain loss: 0.00502\n",
      "\tval loss: 0.00486\n",
      "epoch 14683 / 20000\n",
      "gradient norm: 0.08644077746430412, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00500\n",
      "\tval loss: 0.00488\n",
      "epoch 14684 / 20000\n",
      "gradient norm: 0.08753605431411415, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00501\n",
      "\tval loss: 0.00486\n",
      "epoch 14685 / 20000\n",
      "gradient norm: 0.042187573097180575, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00501\n",
      "\tval loss: 0.00486\n",
      "epoch 14686 / 20000\n",
      "gradient norm: 0.02902232762426138, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00500\n",
      "\tval loss: 0.00487\n",
      "epoch 14687 / 20000\n",
      "gradient norm: 0.07378176396014169, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00500\n",
      "\tval loss: 0.00486\n",
      "epoch 14688 / 20000\n",
      "gradient norm: 0.06051296353689395, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00499\n",
      "\tval loss: 0.00486\n",
      "epoch 14689 / 20000\n",
      "gradient norm: 0.05295511847361922, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00501\n",
      "\tval loss: 0.00485\n",
      "epoch 14690 / 20000\n",
      "gradient norm: 0.06556608999380842, minimum ratio: 2.4499999999999997\n",
      "\ttrain loss: 0.00500\n",
      "\tval loss: 0.00486\n",
      "epoch 14691 / 20000\n",
      "gradient norm: 0.046996070886962116, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00499\n",
      "\tval loss: 0.00487\n",
      "epoch 14692 / 20000\n",
      "gradient norm: 0.061921954387798905, minimum ratio: 2.46578947368421\n",
      "\ttrain loss: 0.00499\n",
      "\tval loss: 0.00485\n",
      "epoch 14693 / 20000\n",
      "gradient norm: 0.0660301535972394, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00499\n",
      "\tval loss: 0.00485\n",
      "epoch 14694 / 20000\n",
      "gradient norm: 0.025317837804323062, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00499\n",
      "\tval loss: 0.00485\n",
      "epoch 14695 / 20000\n",
      "gradient norm: 0.10989309748401865, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00500\n",
      "\tval loss: 0.00485\n",
      "epoch 14696 / 20000\n",
      "gradient norm: 0.04952623424469493, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00498\n",
      "\tval loss: 0.00485\n",
      "epoch 14697 / 20000\n",
      "gradient norm: 0.09277285216376185, minimum ratio: 2.413157894736842\n",
      "\ttrain loss: 0.00500\n",
      "\tval loss: 0.00484\n",
      "epoch 14698 / 20000\n",
      "gradient norm: 0.045833829120965675, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00498\n",
      "\tval loss: 0.00485\n",
      "epoch 14699 / 20000\n",
      "gradient norm: 0.04800754916504957, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00498\n",
      "\tval loss: 0.00484\n",
      "epoch 14700 / 20000\n",
      "gradient norm: 0.027813336171675473, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00500\n",
      "\tval loss: 0.00484\n",
      "epoch 14701 / 20000\n",
      "gradient norm: 0.09230288286926225, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00500\n",
      "\tval loss: 0.00484\n",
      "epoch 14702 / 20000\n",
      "gradient norm: 0.04511810262920335, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00498\n",
      "\tval loss: 0.00484\n",
      "epoch 14703 / 20000\n",
      "gradient norm: 0.03924724683747627, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00497\n",
      "\tval loss: 0.00484\n",
      "epoch 14704 / 20000\n",
      "gradient norm: 0.06707841402385384, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00497\n",
      "\tval loss: 0.00483\n",
      "epoch 14705 / 20000\n",
      "gradient norm: 0.09446636063512415, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00497\n",
      "\tval loss: 0.00484\n",
      "epoch 14706 / 20000\n",
      "gradient norm: 0.044541484967339784, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00497\n",
      "\tval loss: 0.00483\n",
      "epoch 14707 / 20000\n",
      "gradient norm: 0.06026503929751925, minimum ratio: 2.423684210526316\n",
      "\ttrain loss: 0.00497\n",
      "\tval loss: 0.00483\n",
      "epoch 14708 / 20000\n",
      "gradient norm: 0.05195446280413307, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00498\n",
      "\tval loss: 0.00483\n",
      "epoch 14709 / 20000\n",
      "gradient norm: 0.069582577154506, minimum ratio: 2.4394736842105265\n",
      "\ttrain loss: 0.00497\n",
      "\tval loss: 0.00483\n",
      "epoch 14710 / 20000\n",
      "gradient norm: 0.051765288691967726, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00496\n",
      "\tval loss: 0.00483\n",
      "epoch 14711 / 20000\n",
      "gradient norm: 0.06947956664953381, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00497\n",
      "\tval loss: 0.00483\n",
      "epoch 14712 / 20000\n",
      "gradient norm: 0.029182617145124823, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00496\n",
      "\tval loss: 0.00482\n",
      "epoch 14713 / 20000\n",
      "gradient norm: 0.034700031334068626, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00496\n",
      "\tval loss: 0.00482\n",
      "epoch 14714 / 20000\n",
      "gradient norm: 0.08699137484654784, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00498\n",
      "\tval loss: 0.00482\n",
      "epoch 14715 / 20000\n",
      "gradient norm: 0.09302503801882267, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00496\n",
      "\tval loss: 0.00483\n",
      "epoch 14716 / 20000\n",
      "gradient norm: 0.05998768284916878, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00495\n",
      "\tval loss: 0.00481\n",
      "epoch 14717 / 20000\n",
      "gradient norm: 0.03695079847238958, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00496\n",
      "\tval loss: 0.00481\n",
      "epoch 14718 / 20000\n",
      "gradient norm: 0.049127309990581125, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00495\n",
      "\tval loss: 0.00482\n",
      "epoch 14719 / 20000\n",
      "gradient norm: 0.05487506045028567, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00497\n",
      "\tval loss: 0.00481\n",
      "epoch 14720 / 20000\n",
      "gradient norm: 0.08334798982832581, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00495\n",
      "\tval loss: 0.00480\n",
      "epoch 14721 / 20000\n",
      "gradient norm: 0.03338434858596884, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00496\n",
      "\tval loss: 0.00482\n",
      "epoch 14722 / 20000\n",
      "gradient norm: 0.0571733541728463, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00494\n",
      "\tval loss: 0.00481\n",
      "epoch 14723 / 20000\n",
      "gradient norm: 0.06733022248954512, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00495\n",
      "\tval loss: 0.00480\n",
      "epoch 14724 / 20000\n",
      "gradient norm: 0.03372734505683184, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00494\n",
      "\tval loss: 0.00480\n",
      "epoch 14725 / 20000\n",
      "gradient norm: 0.03801887066219933, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00495\n",
      "\tval loss: 0.00481\n",
      "epoch 14726 / 20000\n",
      "gradient norm: 0.043168443138711154, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00494\n",
      "\tval loss: 0.00480\n",
      "epoch 14727 / 20000\n",
      "gradient norm: 0.03992273408221081, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00494\n",
      "\tval loss: 0.00479\n",
      "epoch 14728 / 20000\n",
      "gradient norm: 0.06896444037556648, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00494\n",
      "\tval loss: 0.00480\n",
      "epoch 14729 / 20000\n",
      "gradient norm: 0.04877868917537853, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00493\n",
      "\tval loss: 0.00481\n",
      "epoch 14730 / 20000\n",
      "gradient norm: 0.05816668347688392, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00493\n",
      "\tval loss: 0.00480\n",
      "epoch 14731 / 20000\n",
      "gradient norm: 0.0381530377198942, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00492\n",
      "\tval loss: 0.00479\n",
      "epoch 14732 / 20000\n",
      "gradient norm: 0.07577487546950579, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00493\n",
      "\tval loss: 0.00479\n",
      "epoch 14733 / 20000\n",
      "gradient norm: 0.061601227323990315, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00492\n",
      "\tval loss: 0.00480\n",
      "epoch 14734 / 20000\n",
      "gradient norm: 0.04782841226551682, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00492\n",
      "\tval loss: 0.00479\n",
      "epoch 14735 / 20000\n",
      "gradient norm: 0.08646999439224601, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00492\n",
      "\tval loss: 0.00478\n",
      "epoch 14736 / 20000\n",
      "gradient norm: 0.05345290928380564, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00493\n",
      "\tval loss: 0.00479\n",
      "epoch 14737 / 20000\n",
      "gradient norm: 0.08302558853756636, minimum ratio: 2.436842105263158\n",
      "\ttrain loss: 0.00492\n",
      "\tval loss: 0.00480\n",
      "epoch 14738 / 20000\n",
      "gradient norm: 0.028025025501847267, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00493\n",
      "\tval loss: 0.00477\n",
      "epoch 14739 / 20000\n",
      "gradient norm: 0.04973547323606908, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00490\n",
      "\tval loss: 0.00478\n",
      "epoch 14740 / 20000\n",
      "gradient norm: 0.044591337093152106, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00492\n",
      "\tval loss: 0.00478\n",
      "epoch 14741 / 20000\n",
      "gradient norm: 0.05070342100225389, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00491\n",
      "\tval loss: 0.00478\n",
      "epoch 14742 / 20000\n",
      "gradient norm: 0.04400902657653205, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00491\n",
      "\tval loss: 0.00477\n",
      "epoch 14743 / 20000\n",
      "gradient norm: 0.05604268820025027, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00493\n",
      "\tval loss: 0.00477\n",
      "epoch 14744 / 20000\n",
      "gradient norm: 0.061164098035078496, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00491\n",
      "\tval loss: 0.00478\n",
      "epoch 14745 / 20000\n",
      "gradient norm: 0.03829380974639207, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00491\n",
      "\tval loss: 0.00477\n",
      "epoch 14746 / 20000\n",
      "gradient norm: 0.09860279271379113, minimum ratio: 2.4447368421052627\n",
      "\ttrain loss: 0.00491\n",
      "\tval loss: 0.00476\n",
      "epoch 14747 / 20000\n",
      "gradient norm: 0.034896657860372216, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00491\n",
      "\tval loss: 0.00478\n",
      "epoch 14748 / 20000\n",
      "gradient norm: 0.06276258654543199, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00491\n",
      "\tval loss: 0.00477\n",
      "epoch 14749 / 20000\n",
      "gradient norm: 0.05855590588180348, minimum ratio: 2.423684210526316\n",
      "\ttrain loss: 0.00491\n",
      "\tval loss: 0.00477\n",
      "epoch 14750 / 20000\n",
      "gradient norm: 0.06549025938147679, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00491\n",
      "\tval loss: 0.00476\n",
      "epoch 14751 / 20000\n",
      "gradient norm: 0.059664402273483574, minimum ratio: 2.4394736842105265\n",
      "\ttrain loss: 0.00491\n",
      "\tval loss: 0.00477\n",
      "epoch 14752 / 20000\n",
      "gradient norm: 0.11151929222978652, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00490\n",
      "\tval loss: 0.00477\n",
      "epoch 14753 / 20000\n",
      "gradient norm: 0.06543760967906564, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00489\n",
      "\tval loss: 0.00475\n",
      "epoch 14754 / 20000\n",
      "gradient norm: 0.0628590562264435, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00490\n",
      "\tval loss: 0.00475\n",
      "epoch 14755 / 20000\n",
      "gradient norm: 0.04172397457296029, minimum ratio: 2.436842105263158\n",
      "\ttrain loss: 0.00490\n",
      "\tval loss: 0.00477\n",
      "epoch 14756 / 20000\n",
      "gradient norm: 0.08183017768897116, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00490\n",
      "\tval loss: 0.00475\n",
      "epoch 14757 / 20000\n",
      "gradient norm: 0.07829390559345484, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00489\n",
      "\tval loss: 0.00474\n",
      "epoch 14758 / 20000\n",
      "gradient norm: 0.045477448613382876, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00490\n",
      "\tval loss: 0.00476\n",
      "epoch 14759 / 20000\n",
      "gradient norm: 0.03327980826725252, minimum ratio: 2.4421052631578943\n",
      "\ttrain loss: 0.00490\n",
      "\tval loss: 0.00475\n",
      "epoch 14760 / 20000\n",
      "gradient norm: 0.06117441056994721, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00488\n",
      "\tval loss: 0.00474\n",
      "epoch 14761 / 20000\n",
      "gradient norm: 0.05178183343377896, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00488\n",
      "\tval loss: 0.00476\n",
      "epoch 14762 / 20000\n",
      "gradient norm: 0.0352214845479466, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00489\n",
      "\tval loss: 0.00475\n",
      "epoch 14763 / 20000\n",
      "gradient norm: 0.024152411671821028, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00488\n",
      "\tval loss: 0.00474\n",
      "epoch 14764 / 20000\n",
      "gradient norm: 0.04160071216756478, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00488\n",
      "\tval loss: 0.00474\n",
      "epoch 14765 / 20000\n",
      "gradient norm: 0.0538246298674494, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00487\n",
      "\tval loss: 0.00474\n",
      "epoch 14766 / 20000\n",
      "gradient norm: 0.1091047270456329, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00488\n",
      "\tval loss: 0.00474\n",
      "epoch 14767 / 20000\n",
      "gradient norm: 0.0681630629405845, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00489\n",
      "\tval loss: 0.00473\n",
      "epoch 14768 / 20000\n",
      "gradient norm: 0.02774925745325163, minimum ratio: 2.4394736842105265\n",
      "\ttrain loss: 0.00487\n",
      "\tval loss: 0.00474\n",
      "epoch 14769 / 20000\n",
      "gradient norm: 0.0489336208847817, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00488\n",
      "\tval loss: 0.00473\n",
      "epoch 14770 / 20000\n",
      "gradient norm: 0.06526922126067802, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00487\n",
      "\tval loss: 0.00474\n",
      "epoch 14771 / 20000\n",
      "gradient norm: 0.054721400258131325, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00487\n",
      "\tval loss: 0.00472\n",
      "epoch 14772 / 20000\n",
      "gradient norm: 0.08085148976533674, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00487\n",
      "\tval loss: 0.00474\n",
      "epoch 14773 / 20000\n",
      "gradient norm: 0.04319497320102528, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00487\n",
      "\tval loss: 0.00472\n",
      "epoch 14774 / 20000\n",
      "gradient norm: 0.06564409023849294, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00487\n",
      "\tval loss: 0.00472\n",
      "epoch 14775 / 20000\n",
      "gradient norm: 0.06825176140409894, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00486\n",
      "\tval loss: 0.00473\n",
      "epoch 14776 / 20000\n",
      "gradient norm: 0.051132407679688185, minimum ratio: 2.4078947368421053\n",
      "\ttrain loss: 0.00485\n",
      "\tval loss: 0.00473\n",
      "epoch 14777 / 20000\n",
      "gradient norm: 0.0869439160451293, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00486\n",
      "\tval loss: 0.00472\n",
      "epoch 14778 / 20000\n",
      "gradient norm: 0.13690617750398815, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00487\n",
      "\tval loss: 0.00472\n",
      "epoch 14779 / 20000\n",
      "gradient norm: 0.06253747711889446, minimum ratio: 2.4499999999999997\n",
      "\ttrain loss: 0.00486\n",
      "\tval loss: 0.00472\n",
      "epoch 14780 / 20000\n",
      "gradient norm: 0.06695077480981126, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00485\n",
      "\tval loss: 0.00473\n",
      "epoch 14781 / 20000\n",
      "gradient norm: 0.06200925330631435, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00485\n",
      "\tval loss: 0.00471\n",
      "epoch 14782 / 20000\n",
      "gradient norm: 0.05535898148082197, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00485\n",
      "\tval loss: 0.00471\n",
      "epoch 14783 / 20000\n",
      "gradient norm: 0.042296642262954265, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00486\n",
      "\tval loss: 0.00472\n",
      "epoch 14784 / 20000\n",
      "gradient norm: 0.06846310565015301, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00485\n",
      "\tval loss: 0.00471\n",
      "epoch 14785 / 20000\n",
      "gradient norm: 0.03920852753799409, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00485\n",
      "\tval loss: 0.00471\n",
      "epoch 14786 / 20000\n",
      "gradient norm: 0.023944170796312392, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00484\n",
      "\tval loss: 0.00470\n",
      "epoch 14787 / 20000\n",
      "gradient norm: 0.09604986698832363, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00485\n",
      "\tval loss: 0.00470\n",
      "epoch 14788 / 20000\n",
      "gradient norm: 0.06427421059925109, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00483\n",
      "\tval loss: 0.00471\n",
      "epoch 14789 / 20000\n",
      "gradient norm: 0.0983955548144877, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00484\n",
      "\tval loss: 0.00469\n",
      "epoch 14790 / 20000\n",
      "gradient norm: 0.06206077494425699, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00483\n",
      "\tval loss: 0.00471\n",
      "epoch 14791 / 20000\n",
      "gradient norm: 0.05855265632271767, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00483\n",
      "\tval loss: 0.00470\n",
      "epoch 14792 / 20000\n",
      "gradient norm: 0.05962062388425693, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00484\n",
      "\tval loss: 0.00469\n",
      "epoch 14793 / 20000\n",
      "gradient norm: 0.024439645349048078, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00484\n",
      "\tval loss: 0.00470\n",
      "epoch 14794 / 20000\n",
      "gradient norm: 0.09965901158284396, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00484\n",
      "\tval loss: 0.00469\n",
      "epoch 14795 / 20000\n",
      "gradient norm: 0.038629899732768536, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00482\n",
      "\tval loss: 0.00469\n",
      "epoch 14796 / 20000\n",
      "gradient norm: 0.06906261935364455, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00483\n",
      "\tval loss: 0.00469\n",
      "epoch 14797 / 20000\n",
      "gradient norm: 0.056215819146018475, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00483\n",
      "\tval loss: 0.00469\n",
      "epoch 14798 / 20000\n",
      "gradient norm: 0.02886666706763208, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00482\n",
      "\tval loss: 0.00469\n",
      "epoch 14799 / 20000\n",
      "gradient norm: 0.05756988131906837, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00483\n",
      "\tval loss: 0.00468\n",
      "epoch 14800 / 20000\n",
      "gradient norm: 0.06574533821549267, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00483\n",
      "\tval loss: 0.00468\n",
      "epoch 14801 / 20000\n",
      "gradient norm: 0.033400657295715064, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00483\n",
      "\tval loss: 0.00469\n",
      "epoch 14802 / 20000\n",
      "gradient norm: 0.03978663979796693, minimum ratio: 2.460526315789474\n",
      "\ttrain loss: 0.00482\n",
      "\tval loss: 0.00468\n",
      "epoch 14803 / 20000\n",
      "gradient norm: 0.045078308205120265, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00482\n",
      "\tval loss: 0.00468\n",
      "epoch 14804 / 20000\n",
      "gradient norm: 0.040148267813492566, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00481\n",
      "\tval loss: 0.00468\n",
      "epoch 14805 / 20000\n",
      "gradient norm: 0.0327231161063537, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00480\n",
      "\tval loss: 0.00467\n",
      "epoch 14806 / 20000\n",
      "gradient norm: 0.07860771496780217, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00481\n",
      "\tval loss: 0.00467\n",
      "epoch 14807 / 20000\n",
      "gradient norm: 0.05189393908949569, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00481\n",
      "\tval loss: 0.00468\n",
      "epoch 14808 / 20000\n",
      "gradient norm: 0.07387486274819821, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00482\n",
      "\tval loss: 0.00468\n",
      "epoch 14809 / 20000\n",
      "gradient norm: 0.057923809508793056, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00481\n",
      "\tval loss: 0.00466\n",
      "epoch 14810 / 20000\n",
      "gradient norm: 0.06333178130444139, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00481\n",
      "\tval loss: 0.00467\n",
      "epoch 14811 / 20000\n",
      "gradient norm: 0.061058382561895996, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00479\n",
      "\tval loss: 0.00467\n",
      "epoch 14812 / 20000\n",
      "gradient norm: 0.09550335933454335, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00483\n",
      "\tval loss: 0.00466\n",
      "epoch 14813 / 20000\n",
      "gradient norm: 0.059921584208495915, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00479\n",
      "\tval loss: 0.00467\n",
      "epoch 14814 / 20000\n",
      "gradient norm: 0.0650344883906655, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00481\n",
      "\tval loss: 0.00466\n",
      "epoch 14815 / 20000\n",
      "gradient norm: 0.06824449641862884, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00480\n",
      "\tval loss: 0.00466\n",
      "epoch 14816 / 20000\n",
      "gradient norm: 0.05084235145477578, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00480\n",
      "\tval loss: 0.00465\n",
      "epoch 14817 / 20000\n",
      "gradient norm: 0.059498726681340486, minimum ratio: 2.4447368421052635\n",
      "\ttrain loss: 0.00480\n",
      "\tval loss: 0.00467\n",
      "epoch 14818 / 20000\n",
      "gradient norm: 0.04179109833785333, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00479\n",
      "\tval loss: 0.00465\n",
      "epoch 14819 / 20000\n",
      "gradient norm: 0.048793739813845605, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00479\n",
      "\tval loss: 0.00465\n",
      "epoch 14820 / 20000\n",
      "gradient norm: 0.026952447020448744, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00479\n",
      "\tval loss: 0.00466\n",
      "epoch 14821 / 20000\n",
      "gradient norm: 0.05641786352498457, minimum ratio: 2.4421052631578943\n",
      "\ttrain loss: 0.00479\n",
      "\tval loss: 0.00465\n",
      "epoch 14822 / 20000\n",
      "gradient norm: 0.09326040279120207, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00479\n",
      "\tval loss: 0.00465\n",
      "epoch 14823 / 20000\n",
      "gradient norm: 0.05336112299119122, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00479\n",
      "\tval loss: 0.00466\n",
      "epoch 14824 / 20000\n",
      "gradient norm: 0.069558376155328, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00478\n",
      "\tval loss: 0.00464\n",
      "epoch 14825 / 20000\n",
      "gradient norm: 0.08622055692831054, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00478\n",
      "\tval loss: 0.00464\n",
      "epoch 14826 / 20000\n",
      "gradient norm: 0.053127135266549885, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00478\n",
      "\tval loss: 0.00466\n",
      "epoch 14827 / 20000\n",
      "gradient norm: 0.057948429486714303, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00478\n",
      "\tval loss: 0.00465\n",
      "epoch 14828 / 20000\n",
      "gradient norm: 0.05071620020316914, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00476\n",
      "\tval loss: 0.00463\n",
      "epoch 14829 / 20000\n",
      "gradient norm: 0.06943930394481868, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00479\n",
      "\tval loss: 0.00463\n",
      "epoch 14830 / 20000\n",
      "gradient norm: 0.07623891928233206, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00478\n",
      "\tval loss: 0.00465\n",
      "epoch 14831 / 20000\n",
      "gradient norm: 0.07552924734773114, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00477\n",
      "\tval loss: 0.00463\n",
      "epoch 14832 / 20000\n",
      "gradient norm: 0.06847961654420942, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00477\n",
      "\tval loss: 0.00462\n",
      "epoch 14833 / 20000\n",
      "gradient norm: 0.019900495739420876, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00476\n",
      "\tval loss: 0.00464\n",
      "epoch 14834 / 20000\n",
      "gradient norm: 0.06810876593226567, minimum ratio: 2.4447368421052627\n",
      "\ttrain loss: 0.00476\n",
      "\tval loss: 0.00463\n",
      "epoch 14835 / 20000\n",
      "gradient norm: 0.0667785435798578, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00476\n",
      "\tval loss: 0.00463\n",
      "epoch 14836 / 20000\n",
      "gradient norm: 0.06985963039915077, minimum ratio: 2.4736842105263155\n",
      "\ttrain loss: 0.00477\n",
      "\tval loss: 0.00462\n",
      "epoch 14837 / 20000\n",
      "gradient norm: 0.0753166681388393, minimum ratio: 2.4499999999999997\n",
      "\ttrain loss: 0.00475\n",
      "\tval loss: 0.00463\n",
      "epoch 14838 / 20000\n",
      "gradient norm: 0.07328949257498607, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00476\n",
      "\tval loss: 0.00463\n",
      "epoch 14839 / 20000\n",
      "gradient norm: 0.06570047570858151, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00476\n",
      "\tval loss: 0.00462\n",
      "epoch 14840 / 20000\n",
      "gradient norm: 0.019796011212747544, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00475\n",
      "\tval loss: 0.00462\n",
      "epoch 14841 / 20000\n",
      "gradient norm: 0.04969253082526848, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00475\n",
      "\tval loss: 0.00462\n",
      "epoch 14842 / 20000\n",
      "gradient norm: 0.038063035579398274, minimum ratio: 2.460526315789474\n",
      "\ttrain loss: 0.00474\n",
      "\tval loss: 0.00462\n",
      "epoch 14843 / 20000\n",
      "gradient norm: 0.04373451563878916, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00475\n",
      "\tval loss: 0.00461\n",
      "epoch 14844 / 20000\n",
      "gradient norm: 0.0360145520826336, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00474\n",
      "\tval loss: 0.00461\n",
      "epoch 14845 / 20000\n",
      "gradient norm: 0.06126346276141703, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00474\n",
      "\tval loss: 0.00461\n",
      "epoch 14846 / 20000\n",
      "gradient norm: 0.03389996796613559, minimum ratio: 2.4447368421052627\n",
      "\ttrain loss: 0.00474\n",
      "\tval loss: 0.00462\n",
      "epoch 14847 / 20000\n",
      "gradient norm: 0.04518682393245399, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00474\n",
      "\tval loss: 0.00461\n",
      "epoch 14848 / 20000\n",
      "gradient norm: 0.05884294648421928, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00475\n",
      "\tval loss: 0.00460\n",
      "epoch 14849 / 20000\n",
      "gradient norm: 0.03674941830104217, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00473\n",
      "\tval loss: 0.00462\n",
      "epoch 14850 / 20000\n",
      "gradient norm: 0.03681146854069084, minimum ratio: 2.426315789473684\n",
      "\ttrain loss: 0.00473\n",
      "\tval loss: 0.00461\n",
      "epoch 14851 / 20000\n",
      "gradient norm: 0.056289580068551004, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00474\n",
      "\tval loss: 0.00459\n",
      "epoch 14852 / 20000\n",
      "gradient norm: 0.048360540822613984, minimum ratio: 2.4499999999999997\n",
      "\ttrain loss: 0.00473\n",
      "\tval loss: 0.00461\n",
      "epoch 14853 / 20000\n",
      "gradient norm: 0.060699071385897696, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00475\n",
      "\tval loss: 0.00460\n",
      "epoch 14854 / 20000\n",
      "gradient norm: 0.04200731927994639, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00473\n",
      "\tval loss: 0.00460\n",
      "epoch 14855 / 20000\n",
      "gradient norm: 0.04567023291019723, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00473\n",
      "\tval loss: 0.00459\n",
      "epoch 14856 / 20000\n",
      "gradient norm: 0.0660644083400257, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00472\n",
      "\tval loss: 0.00459\n",
      "epoch 14857 / 20000\n",
      "gradient norm: 0.06503374339081347, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00473\n",
      "\tval loss: 0.00459\n",
      "epoch 14858 / 20000\n",
      "gradient norm: 0.039467209251597524, minimum ratio: 2.460526315789474\n",
      "\ttrain loss: 0.00473\n",
      "\tval loss: 0.00459\n",
      "epoch 14859 / 20000\n",
      "gradient norm: 0.10505043400917202, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00474\n",
      "\tval loss: 0.00458\n",
      "epoch 14860 / 20000\n",
      "gradient norm: 0.1007568557979539, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00472\n",
      "\tval loss: 0.00461\n",
      "epoch 14861 / 20000\n",
      "gradient norm: 0.06986434705322608, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00473\n",
      "\tval loss: 0.00459\n",
      "epoch 14862 / 20000\n",
      "gradient norm: 0.052959375840146095, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00471\n",
      "\tval loss: 0.00458\n",
      "epoch 14863 / 20000\n",
      "gradient norm: 0.05525564675917849, minimum ratio: 2.4421052631578943\n",
      "\ttrain loss: 0.00472\n",
      "\tval loss: 0.00458\n",
      "epoch 14864 / 20000\n",
      "gradient norm: 0.07012967654736713, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00473\n",
      "\tval loss: 0.00459\n",
      "epoch 14865 / 20000\n",
      "gradient norm: 0.013248987932456657, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00471\n",
      "\tval loss: 0.00457\n",
      "epoch 14866 / 20000\n",
      "gradient norm: 0.04632862182916142, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00472\n",
      "\tval loss: 0.00457\n",
      "epoch 14867 / 20000\n",
      "gradient norm: 0.05908040242502466, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00470\n",
      "\tval loss: 0.00458\n",
      "epoch 14868 / 20000\n",
      "gradient norm: 0.04694900140748359, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00471\n",
      "\tval loss: 0.00457\n",
      "epoch 14869 / 20000\n",
      "gradient norm: 0.06137550639687106, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00471\n",
      "\tval loss: 0.00456\n",
      "epoch 14870 / 20000\n",
      "gradient norm: 0.03886438312474638, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00472\n",
      "\tval loss: 0.00457\n",
      "epoch 14871 / 20000\n",
      "gradient norm: 0.042381051403936, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00471\n",
      "\tval loss: 0.00458\n",
      "epoch 14872 / 20000\n",
      "gradient norm: 0.06241562869399786, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00470\n",
      "\tval loss: 0.00457\n",
      "epoch 14873 / 20000\n",
      "gradient norm: 0.06261078763054684, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00469\n",
      "\tval loss: 0.00456\n",
      "epoch 14874 / 20000\n",
      "gradient norm: 0.0685980950947851, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00469\n",
      "\tval loss: 0.00457\n",
      "epoch 14875 / 20000\n",
      "gradient norm: 0.05918039003154263, minimum ratio: 2.4499999999999997\n",
      "\ttrain loss: 0.00470\n",
      "\tval loss: 0.00457\n",
      "epoch 14876 / 20000\n",
      "gradient norm: 0.04850673096370883, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00470\n",
      "\tval loss: 0.00455\n",
      "epoch 14877 / 20000\n",
      "gradient norm: 0.060314083530101925, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00469\n",
      "\tval loss: 0.00456\n",
      "epoch 14878 / 20000\n",
      "gradient norm: 0.07647691934835166, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00469\n",
      "\tval loss: 0.00457\n",
      "epoch 14879 / 20000\n",
      "gradient norm: 0.09497723588719964, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00468\n",
      "\tval loss: 0.00455\n",
      "epoch 14880 / 20000\n",
      "gradient norm: 0.0432227497221902, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00468\n",
      "\tval loss: 0.00455\n",
      "epoch 14881 / 20000\n",
      "gradient norm: 0.05137876851949841, minimum ratio: 2.4394736842105265\n",
      "\ttrain loss: 0.00469\n",
      "\tval loss: 0.00455\n",
      "epoch 14882 / 20000\n",
      "gradient norm: 0.06353024649433792, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00468\n",
      "\tval loss: 0.00456\n",
      "epoch 14883 / 20000\n",
      "gradient norm: 0.04101175838150084, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00469\n",
      "\tval loss: 0.00455\n",
      "epoch 14884 / 20000\n",
      "gradient norm: 0.06551714360830374, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00468\n",
      "\tval loss: 0.00454\n",
      "epoch 14885 / 20000\n",
      "gradient norm: 0.059290438948664814, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00468\n",
      "\tval loss: 0.00456\n",
      "epoch 14886 / 20000\n",
      "gradient norm: 0.07542228372767568, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00469\n",
      "\tval loss: 0.00454\n",
      "epoch 14887 / 20000\n",
      "gradient norm: 0.0568621939746663, minimum ratio: 2.4263157894736844\n",
      "\ttrain loss: 0.00467\n",
      "\tval loss: 0.00454\n",
      "epoch 14888 / 20000\n",
      "gradient norm: 0.035150578420143574, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00466\n",
      "\tval loss: 0.00454\n",
      "epoch 14889 / 20000\n",
      "gradient norm: 0.03921384329441935, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00468\n",
      "\tval loss: 0.00454\n",
      "epoch 14890 / 20000\n",
      "gradient norm: 0.05839190189726651, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00466\n",
      "\tval loss: 0.00455\n",
      "epoch 14891 / 20000\n",
      "gradient norm: 0.0751688377931714, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00468\n",
      "\tval loss: 0.00454\n",
      "epoch 14892 / 20000\n",
      "gradient norm: 0.07212272559991106, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00467\n",
      "\tval loss: 0.00453\n",
      "epoch 14893 / 20000\n",
      "gradient norm: 0.05860455834772438, minimum ratio: 2.423684210526316\n",
      "\ttrain loss: 0.00466\n",
      "\tval loss: 0.00454\n",
      "epoch 14894 / 20000\n",
      "gradient norm: 0.06891967353294604, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00467\n",
      "\tval loss: 0.00453\n",
      "epoch 14895 / 20000\n",
      "gradient norm: 0.09309209289494902, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00467\n",
      "\tval loss: 0.00454\n",
      "epoch 14896 / 20000\n",
      "gradient norm: 0.050457994220778346, minimum ratio: 2.4394736842105265\n",
      "\ttrain loss: 0.00466\n",
      "\tval loss: 0.00452\n",
      "epoch 14897 / 20000\n",
      "gradient norm: 0.057915691868402064, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00468\n",
      "\tval loss: 0.00452\n",
      "epoch 14898 / 20000\n",
      "gradient norm: 0.06355098841595463, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00467\n",
      "\tval loss: 0.00455\n",
      "epoch 14899 / 20000\n",
      "gradient norm: 0.028486490773502737, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00465\n",
      "\tval loss: 0.00452\n",
      "epoch 14900 / 20000\n",
      "gradient norm: 0.07792016677558422, minimum ratio: 2.460526315789474\n",
      "\ttrain loss: 0.00466\n",
      "\tval loss: 0.00451\n",
      "epoch 14901 / 20000\n",
      "gradient norm: 0.11168600432574749, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00466\n",
      "\tval loss: 0.00454\n",
      "epoch 14902 / 20000\n",
      "gradient norm: 0.03331555152544752, minimum ratio: 2.421052631578948\n",
      "\ttrain loss: 0.00465\n",
      "\tval loss: 0.00451\n",
      "epoch 14903 / 20000\n",
      "gradient norm: 0.06349791865795851, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00465\n",
      "\tval loss: 0.00451\n",
      "epoch 14904 / 20000\n",
      "gradient norm: 0.028451699065044522, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00465\n",
      "\tval loss: 0.00452\n",
      "epoch 14905 / 20000\n",
      "gradient norm: 0.05091870506294072, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00463\n",
      "\tval loss: 0.00452\n",
      "epoch 14906 / 20000\n",
      "gradient norm: 0.051539443084038794, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00464\n",
      "\tval loss: 0.00451\n",
      "epoch 14907 / 20000\n",
      "gradient norm: 0.07447959264391102, minimum ratio: 2.460526315789474\n",
      "\ttrain loss: 0.00465\n",
      "\tval loss: 0.00450\n",
      "epoch 14908 / 20000\n",
      "gradient norm: 0.038032667711377144, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00464\n",
      "\tval loss: 0.00453\n",
      "epoch 14909 / 20000\n",
      "gradient norm: 0.04962311952840537, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00464\n",
      "\tval loss: 0.00451\n",
      "epoch 14910 / 20000\n",
      "gradient norm: 0.06429855671012774, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00464\n",
      "\tval loss: 0.00450\n",
      "epoch 14911 / 20000\n",
      "gradient norm: 0.0181925700744614, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00463\n",
      "\tval loss: 0.00451\n",
      "epoch 14912 / 20000\n",
      "gradient norm: 0.08803035237360746, minimum ratio: 2.4263157894736844\n",
      "\ttrain loss: 0.00465\n",
      "\tval loss: 0.00450\n",
      "epoch 14913 / 20000\n",
      "gradient norm: 0.04025034385267645, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00464\n",
      "\tval loss: 0.00450\n",
      "epoch 14914 / 20000\n",
      "gradient norm: 0.043889139720704406, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00462\n",
      "\tval loss: 0.00449\n",
      "epoch 14915 / 20000\n",
      "gradient norm: 0.058692265854915604, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00462\n",
      "\tval loss: 0.00451\n",
      "epoch 14916 / 20000\n",
      "gradient norm: 0.12045932083856314, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00462\n",
      "\tval loss: 0.00449\n",
      "epoch 14917 / 20000\n",
      "gradient norm: 0.023940407438203692, minimum ratio: 2.4394736842105265\n",
      "\ttrain loss: 0.00464\n",
      "\tval loss: 0.00450\n",
      "epoch 14918 / 20000\n",
      "gradient norm: 0.028524556139018387, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00462\n",
      "\tval loss: 0.00450\n",
      "epoch 14919 / 20000\n",
      "gradient norm: 0.06802397372666746, minimum ratio: 2.4421052631578943\n",
      "\ttrain loss: 0.00463\n",
      "\tval loss: 0.00449\n",
      "epoch 14920 / 20000\n",
      "gradient norm: 0.035222669306676835, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00462\n",
      "\tval loss: 0.00449\n",
      "epoch 14921 / 20000\n",
      "gradient norm: 0.07589349499903619, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00462\n",
      "\tval loss: 0.00449\n",
      "epoch 14922 / 20000\n",
      "gradient norm: 0.06980335747357458, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00462\n",
      "\tval loss: 0.00449\n",
      "epoch 14923 / 20000\n",
      "gradient norm: 0.08302395389182493, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00462\n",
      "\tval loss: 0.00448\n",
      "epoch 14924 / 20000\n",
      "gradient norm: 0.0688279444584623, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00462\n",
      "\tval loss: 0.00448\n",
      "epoch 14925 / 20000\n",
      "gradient norm: 0.05698327379650436, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00460\n",
      "\tval loss: 0.00448\n",
      "epoch 14926 / 20000\n",
      "gradient norm: 0.0522765195928514, minimum ratio: 2.418421052631579\n",
      "\ttrain loss: 0.00460\n",
      "\tval loss: 0.00448\n",
      "epoch 14927 / 20000\n",
      "gradient norm: 0.06439523206790909, minimum ratio: 2.426315789473684\n",
      "\ttrain loss: 0.00460\n",
      "\tval loss: 0.00447\n",
      "epoch 14928 / 20000\n",
      "gradient norm: 0.04275412461720407, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00461\n",
      "\tval loss: 0.00447\n",
      "epoch 14929 / 20000\n",
      "gradient norm: 0.043255115480860695, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00459\n",
      "\tval loss: 0.00448\n",
      "epoch 14930 / 20000\n",
      "gradient norm: 0.04392171947984025, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00461\n",
      "\tval loss: 0.00447\n",
      "epoch 14931 / 20000\n",
      "gradient norm: 0.07414755236823112, minimum ratio: 2.4394736842105265\n",
      "\ttrain loss: 0.00460\n",
      "\tval loss: 0.00446\n",
      "epoch 14932 / 20000\n",
      "gradient norm: 0.022869596199598163, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00460\n",
      "\tval loss: 0.00448\n",
      "epoch 14933 / 20000\n",
      "gradient norm: 0.06809805863304064, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00460\n",
      "\tval loss: 0.00447\n",
      "epoch 14934 / 20000\n",
      "gradient norm: 0.06877781730145216, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00461\n",
      "\tval loss: 0.00446\n",
      "epoch 14935 / 20000\n",
      "gradient norm: 0.03083643695572391, minimum ratio: 2.426315789473684\n",
      "\ttrain loss: 0.00459\n",
      "\tval loss: 0.00447\n",
      "epoch 14936 / 20000\n",
      "gradient norm: 0.08224467938998714, minimum ratio: 2.4421052631578943\n",
      "\ttrain loss: 0.00458\n",
      "\tval loss: 0.00446\n",
      "epoch 14937 / 20000\n",
      "gradient norm: 0.02810280624544248, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00460\n",
      "\tval loss: 0.00446\n",
      "epoch 14938 / 20000\n",
      "gradient norm: 0.03703202577889897, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00459\n",
      "\tval loss: 0.00446\n",
      "epoch 14939 / 20000\n",
      "gradient norm: 0.032624529383610934, minimum ratio: 2.4263157894736844\n",
      "\ttrain loss: 0.00458\n",
      "\tval loss: 0.00446\n",
      "epoch 14940 / 20000\n",
      "gradient norm: 0.03197822370566428, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00457\n",
      "\tval loss: 0.00445\n",
      "epoch 14941 / 20000\n",
      "gradient norm: 0.06419327005278319, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00459\n",
      "\tval loss: 0.00445\n",
      "epoch 14942 / 20000\n",
      "gradient norm: 0.04210351448273286, minimum ratio: 2.4263157894736844\n",
      "\ttrain loss: 0.00458\n",
      "\tval loss: 0.00447\n",
      "epoch 14943 / 20000\n",
      "gradient norm: 0.0965735986828804, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00459\n",
      "\tval loss: 0.00445\n",
      "epoch 14944 / 20000\n",
      "gradient norm: 0.08397709269775078, minimum ratio: 2.4421052631578943\n",
      "\ttrain loss: 0.00458\n",
      "\tval loss: 0.00446\n",
      "epoch 14945 / 20000\n",
      "gradient norm: 0.061665379093028605, minimum ratio: 2.4499999999999997\n",
      "\ttrain loss: 0.00458\n",
      "\tval loss: 0.00444\n",
      "epoch 14946 / 20000\n",
      "gradient norm: 0.045526156143750995, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00457\n",
      "\tval loss: 0.00444\n",
      "epoch 14947 / 20000\n",
      "gradient norm: 0.02638102462515235, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00457\n",
      "\tval loss: 0.00445\n",
      "epoch 14948 / 20000\n",
      "gradient norm: 0.06230046320706606, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00458\n",
      "\tval loss: 0.00444\n",
      "epoch 14949 / 20000\n",
      "gradient norm: 0.020904389792121947, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00457\n",
      "\tval loss: 0.00444\n",
      "epoch 14950 / 20000\n",
      "gradient norm: 0.06203409214504063, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00457\n",
      "\tval loss: 0.00445\n",
      "epoch 14951 / 20000\n",
      "gradient norm: 0.07398337603081018, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00456\n",
      "\tval loss: 0.00443\n",
      "epoch 14952 / 20000\n",
      "gradient norm: 0.04310345172416419, minimum ratio: 2.4263157894736844\n",
      "\ttrain loss: 0.00457\n",
      "\tval loss: 0.00443\n",
      "epoch 14953 / 20000\n",
      "gradient norm: 0.059683346131350845, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00456\n",
      "\tval loss: 0.00445\n",
      "epoch 14954 / 20000\n",
      "gradient norm: 0.05851129727670923, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00455\n",
      "\tval loss: 0.00443\n",
      "epoch 14955 / 20000\n",
      "gradient norm: 0.055843228939920664, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00456\n",
      "\tval loss: 0.00442\n",
      "epoch 14956 / 20000\n",
      "gradient norm: 0.05431340332143009, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00455\n",
      "\tval loss: 0.00443\n",
      "epoch 14957 / 20000\n",
      "gradient norm: 0.06560449383687228, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00456\n",
      "\tval loss: 0.00442\n",
      "epoch 14958 / 20000\n",
      "gradient norm: 0.06208599658566527, minimum ratio: 2.4447368421052635\n",
      "\ttrain loss: 0.00455\n",
      "\tval loss: 0.00443\n",
      "epoch 14959 / 20000\n",
      "gradient norm: 0.01982579001924023, minimum ratio: 2.413157894736842\n",
      "\ttrain loss: 0.00457\n",
      "\tval loss: 0.00442\n",
      "epoch 14960 / 20000\n",
      "gradient norm: 0.02866096788784489, minimum ratio: 2.4499999999999997\n",
      "\ttrain loss: 0.00455\n",
      "\tval loss: 0.00442\n",
      "epoch 14961 / 20000\n",
      "gradient norm: 0.04238137119682506, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00455\n",
      "\tval loss: 0.00442\n",
      "epoch 14962 / 20000\n",
      "gradient norm: 0.1130324003752321, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00455\n",
      "\tval loss: 0.00443\n",
      "epoch 14963 / 20000\n",
      "gradient norm: 0.05822527827695012, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00454\n",
      "\tval loss: 0.00441\n",
      "epoch 14964 / 20000\n",
      "gradient norm: 0.12054794485447928, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00456\n",
      "\tval loss: 0.00441\n",
      "epoch 14965 / 20000\n",
      "gradient norm: 0.09099903784226626, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00456\n",
      "\tval loss: 0.00445\n",
      "epoch 14966 / 20000\n",
      "gradient norm: 0.07013173628365621, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00456\n",
      "\tval loss: 0.00440\n",
      "epoch 14967 / 20000\n",
      "gradient norm: 0.06966842693509534, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00455\n",
      "\tval loss: 0.00440\n",
      "epoch 14968 / 20000\n",
      "gradient norm: 0.057566895557101816, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00454\n",
      "\tval loss: 0.00443\n",
      "epoch 14969 / 20000\n",
      "gradient norm: 0.05868034152081236, minimum ratio: 2.4263157894736844\n",
      "\ttrain loss: 0.00456\n",
      "\tval loss: 0.00441\n",
      "epoch 14970 / 20000\n",
      "gradient norm: 0.0804925977718085, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00454\n",
      "\tval loss: 0.00440\n",
      "epoch 14971 / 20000\n",
      "gradient norm: 0.045588157954625785, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00453\n",
      "\tval loss: 0.00441\n",
      "epoch 14972 / 20000\n",
      "gradient norm: 0.05284052679780871, minimum ratio: 2.4394736842105265\n",
      "\ttrain loss: 0.00454\n",
      "\tval loss: 0.00441\n",
      "epoch 14973 / 20000\n",
      "gradient norm: 0.038518480374477804, minimum ratio: 2.4236842105263157\n",
      "\ttrain loss: 0.00452\n",
      "\tval loss: 0.00439\n",
      "epoch 14974 / 20000\n",
      "gradient norm: 0.053021100407931954, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00453\n",
      "\tval loss: 0.00440\n",
      "epoch 14975 / 20000\n",
      "gradient norm: 0.03927689531701617, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00453\n",
      "\tval loss: 0.00440\n",
      "epoch 14976 / 20000\n",
      "gradient norm: 0.05119144159834832, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00452\n",
      "\tval loss: 0.00440\n",
      "epoch 14977 / 20000\n",
      "gradient norm: 0.05009763449197635, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00452\n",
      "\tval loss: 0.00439\n",
      "epoch 14978 / 20000\n",
      "gradient norm: 0.0799577945144847, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00452\n",
      "\tval loss: 0.00439\n",
      "epoch 14979 / 20000\n",
      "gradient norm: 0.032920424710027874, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00452\n",
      "\tval loss: 0.00439\n",
      "epoch 14980 / 20000\n",
      "gradient norm: 0.09114705221145414, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00452\n",
      "\tval loss: 0.00439\n",
      "epoch 14981 / 20000\n",
      "gradient norm: 0.015234057151246816, minimum ratio: 2.4263157894736844\n",
      "\ttrain loss: 0.00451\n",
      "\tval loss: 0.00438\n",
      "epoch 14982 / 20000\n",
      "gradient norm: 0.06869867915520445, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00452\n",
      "\tval loss: 0.00438\n",
      "epoch 14983 / 20000\n",
      "gradient norm: 0.0718153064372018, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00452\n",
      "\tval loss: 0.00440\n",
      "epoch 14984 / 20000\n",
      "gradient norm: 0.054701494285836816, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00452\n",
      "\tval loss: 0.00437\n",
      "epoch 14985 / 20000\n",
      "gradient norm: 0.04236309335101396, minimum ratio: 2.4394736842105265\n",
      "\ttrain loss: 0.00451\n",
      "\tval loss: 0.00438\n",
      "epoch 14986 / 20000\n",
      "gradient norm: 0.06309862865600735, minimum ratio: 2.405263157894737\n",
      "\ttrain loss: 0.00451\n",
      "\tval loss: 0.00438\n",
      "epoch 14987 / 20000\n",
      "gradient norm: 0.030166969227138907, minimum ratio: 2.4421052631578943\n",
      "\ttrain loss: 0.00449\n",
      "\tval loss: 0.00438\n",
      "epoch 14988 / 20000\n",
      "gradient norm: 0.0729630645364523, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00450\n",
      "\tval loss: 0.00438\n",
      "epoch 14989 / 20000\n",
      "gradient norm: 0.03798485570587218, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00450\n",
      "\tval loss: 0.00437\n",
      "epoch 14990 / 20000\n",
      "gradient norm: 0.07333603262668476, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00451\n",
      "\tval loss: 0.00437\n",
      "epoch 14991 / 20000\n",
      "gradient norm: 0.04463135957485065, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00450\n",
      "\tval loss: 0.00437\n",
      "epoch 14992 / 20000\n",
      "gradient norm: 0.09172018500976264, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00450\n",
      "\tval loss: 0.00438\n",
      "epoch 14993 / 20000\n",
      "gradient norm: 0.06952742644352838, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00450\n",
      "\tval loss: 0.00436\n",
      "epoch 14994 / 20000\n",
      "gradient norm: 0.08564807020593435, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00451\n",
      "\tval loss: 0.00436\n",
      "epoch 14995 / 20000\n",
      "gradient norm: 0.051583157386630774, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00448\n",
      "\tval loss: 0.00438\n",
      "epoch 14996 / 20000\n",
      "gradient norm: 0.048996384779457, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00449\n",
      "\tval loss: 0.00436\n",
      "epoch 14997 / 20000\n",
      "gradient norm: 0.07858132722321898, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00449\n",
      "\tval loss: 0.00435\n",
      "epoch 14998 / 20000\n",
      "gradient norm: 0.05137646239018068, minimum ratio: 2.4499999999999997\n",
      "\ttrain loss: 0.00449\n",
      "\tval loss: 0.00437\n",
      "epoch 14999 / 20000\n",
      "gradient norm: 0.04629231302533299, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00449\n",
      "\tval loss: 0.00436\n",
      "epoch 15000 / 20000\n",
      "gradient norm: 0.10072798794135451, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00448\n",
      "\tval loss: 0.00435\n",
      "epoch 15001 / 20000\n",
      "gradient norm: 0.11142708826810122, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00449\n",
      "\tval loss: 0.00435\n",
      "epoch 15002 / 20000\n",
      "gradient norm: 0.09918272687355056, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00448\n",
      "\tval loss: 0.00435\n",
      "epoch 15003 / 20000\n",
      "gradient norm: 0.05628444580361247, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00448\n",
      "\tval loss: 0.00435\n",
      "epoch 15004 / 20000\n",
      "gradient norm: 0.05793884946615435, minimum ratio: 2.4394736842105265\n",
      "\ttrain loss: 0.00447\n",
      "\tval loss: 0.00435\n",
      "epoch 15005 / 20000\n",
      "gradient norm: 0.07091202825540677, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00448\n",
      "\tval loss: 0.00434\n",
      "epoch 15006 / 20000\n",
      "gradient norm: 0.06703410024056211, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00447\n",
      "\tval loss: 0.00435\n",
      "epoch 15007 / 20000\n",
      "gradient norm: 0.06871402938850224, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00448\n",
      "\tval loss: 0.00435\n",
      "epoch 15008 / 20000\n",
      "gradient norm: 0.057196259731426835, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00447\n",
      "\tval loss: 0.00433\n",
      "epoch 15009 / 20000\n",
      "gradient norm: 0.0921218020375818, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00447\n",
      "\tval loss: 0.00434\n",
      "epoch 15010 / 20000\n",
      "gradient norm: 0.02211599299334921, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00447\n",
      "\tval loss: 0.00434\n",
      "epoch 15011 / 20000\n",
      "gradient norm: 0.03953081532381475, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00446\n",
      "\tval loss: 0.00433\n",
      "epoch 15012 / 20000\n",
      "gradient norm: 0.03993118568905629, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00446\n",
      "\tval loss: 0.00433\n",
      "epoch 15013 / 20000\n",
      "gradient norm: 0.0424449602724053, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00447\n",
      "\tval loss: 0.00433\n",
      "epoch 15014 / 20000\n",
      "gradient norm: 0.056752222299110144, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00445\n",
      "\tval loss: 0.00433\n",
      "epoch 15015 / 20000\n",
      "gradient norm: 0.0524183435481973, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00446\n",
      "\tval loss: 0.00432\n",
      "epoch 15016 / 20000\n",
      "gradient norm: 0.06482214923016727, minimum ratio: 2.436842105263158\n",
      "\ttrain loss: 0.00445\n",
      "\tval loss: 0.00433\n",
      "epoch 15017 / 20000\n",
      "gradient norm: 0.07532096293289214, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00445\n",
      "\tval loss: 0.00434\n",
      "epoch 15018 / 20000\n",
      "gradient norm: 0.02366252671345137, minimum ratio: 2.4394736842105265\n",
      "\ttrain loss: 0.00444\n",
      "\tval loss: 0.00432\n",
      "epoch 15019 / 20000\n",
      "gradient norm: 0.07129976525902748, minimum ratio: 2.418421052631579\n",
      "\ttrain loss: 0.00445\n",
      "\tval loss: 0.00431\n",
      "epoch 15020 / 20000\n",
      "gradient norm: 0.07151470112148672, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00445\n",
      "\tval loss: 0.00433\n",
      "epoch 15021 / 20000\n",
      "gradient norm: 0.07829563145060092, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00445\n",
      "\tval loss: 0.00434\n",
      "epoch 15022 / 20000\n",
      "gradient norm: 0.07865311298519373, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00446\n",
      "\tval loss: 0.00431\n",
      "epoch 15023 / 20000\n",
      "gradient norm: 0.038603054301347584, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00444\n",
      "\tval loss: 0.00432\n",
      "epoch 15024 / 20000\n",
      "gradient norm: 0.08608010341413319, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00445\n",
      "\tval loss: 0.00432\n",
      "epoch 15025 / 20000\n",
      "gradient norm: 0.055306658905465156, minimum ratio: 2.426315789473684\n",
      "\ttrain loss: 0.00444\n",
      "\tval loss: 0.00431\n",
      "epoch 15026 / 20000\n",
      "gradient norm: 0.07593168900348246, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00445\n",
      "\tval loss: 0.00431\n",
      "epoch 15027 / 20000\n",
      "gradient norm: 0.05577468691626564, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00443\n",
      "\tval loss: 0.00431\n",
      "epoch 15028 / 20000\n",
      "gradient norm: 0.085329465335235, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00444\n",
      "\tval loss: 0.00431\n",
      "epoch 15029 / 20000\n",
      "gradient norm: 0.05414791940711439, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00443\n",
      "\tval loss: 0.00430\n",
      "epoch 15030 / 20000\n",
      "gradient norm: 0.07389498222619295, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00442\n",
      "\tval loss: 0.00430\n",
      "epoch 15031 / 20000\n",
      "gradient norm: 0.05486942414427176, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00443\n",
      "\tval loss: 0.00432\n",
      "epoch 15032 / 20000\n",
      "gradient norm: 0.04051418957533315, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00443\n",
      "\tval loss: 0.00430\n",
      "epoch 15033 / 20000\n",
      "gradient norm: 0.05607888923259452, minimum ratio: 2.4210526315789473\n",
      "\ttrain loss: 0.00442\n",
      "\tval loss: 0.00429\n",
      "epoch 15034 / 20000\n",
      "gradient norm: 0.04771936050383374, minimum ratio: 2.4447368421052635\n",
      "\ttrain loss: 0.00443\n",
      "\tval loss: 0.00429\n",
      "epoch 15035 / 20000\n",
      "gradient norm: 0.03492620907491073, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00442\n",
      "\tval loss: 0.00431\n",
      "epoch 15036 / 20000\n",
      "gradient norm: 0.043657134810928255, minimum ratio: 2.4421052631578943\n",
      "\ttrain loss: 0.00442\n",
      "\tval loss: 0.00429\n",
      "epoch 15037 / 20000\n",
      "gradient norm: 0.06258757208706811, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00442\n",
      "\tval loss: 0.00428\n",
      "epoch 15038 / 20000\n",
      "gradient norm: 0.026669071841752157, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00442\n",
      "\tval loss: 0.00430\n",
      "epoch 15039 / 20000\n",
      "gradient norm: 0.06388807145413011, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00441\n",
      "\tval loss: 0.00430\n",
      "epoch 15040 / 20000\n",
      "gradient norm: 0.03307625401066616, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00441\n",
      "\tval loss: 0.00428\n",
      "epoch 15041 / 20000\n",
      "gradient norm: 0.06557858031010255, minimum ratio: 2.4394736842105265\n",
      "\ttrain loss: 0.00442\n",
      "\tval loss: 0.00428\n",
      "epoch 15042 / 20000\n",
      "gradient norm: 0.09441915707429871, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00441\n",
      "\tval loss: 0.00431\n",
      "epoch 15043 / 20000\n",
      "gradient norm: 0.07333676284179091, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00442\n",
      "\tval loss: 0.00428\n",
      "epoch 15044 / 20000\n",
      "gradient norm: 0.047160350310150534, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00441\n",
      "\tval loss: 0.00427\n",
      "epoch 15045 / 20000\n",
      "gradient norm: 0.09296018187887967, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00441\n",
      "\tval loss: 0.00428\n",
      "epoch 15046 / 20000\n",
      "gradient norm: 0.05952298565534875, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00441\n",
      "\tval loss: 0.00428\n",
      "epoch 15047 / 20000\n",
      "gradient norm: 0.039666160475462675, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00439\n",
      "\tval loss: 0.00427\n",
      "epoch 15048 / 20000\n",
      "gradient norm: 0.05921634967671707, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00441\n",
      "\tval loss: 0.00427\n",
      "epoch 15049 / 20000\n",
      "gradient norm: 0.055073793744668365, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00440\n",
      "\tval loss: 0.00428\n",
      "epoch 15050 / 20000\n",
      "gradient norm: 0.07645762909669429, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00440\n",
      "\tval loss: 0.00426\n",
      "epoch 15051 / 20000\n",
      "gradient norm: 0.03820661526697222, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00439\n",
      "\tval loss: 0.00427\n",
      "epoch 15052 / 20000\n",
      "gradient norm: 0.07626799517311156, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00440\n",
      "\tval loss: 0.00427\n",
      "epoch 15053 / 20000\n",
      "gradient norm: 0.04819230973953381, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00438\n",
      "\tval loss: 0.00426\n",
      "epoch 15054 / 20000\n",
      "gradient norm: 0.07065343216527253, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00439\n",
      "\tval loss: 0.00426\n",
      "epoch 15055 / 20000\n",
      "gradient norm: 0.046714212629012764, minimum ratio: 2.4499999999999997\n",
      "\ttrain loss: 0.00439\n",
      "\tval loss: 0.00426\n",
      "epoch 15056 / 20000\n",
      "gradient norm: 0.03359747299691662, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00438\n",
      "\tval loss: 0.00426\n",
      "epoch 15057 / 20000\n",
      "gradient norm: 0.06423312588594854, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00437\n",
      "\tval loss: 0.00426\n",
      "epoch 15058 / 20000\n",
      "gradient norm: 0.06079968874109909, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00437\n",
      "\tval loss: 0.00425\n",
      "epoch 15059 / 20000\n",
      "gradient norm: 0.08029781433288008, minimum ratio: 2.4421052631578943\n",
      "\ttrain loss: 0.00438\n",
      "\tval loss: 0.00425\n",
      "epoch 15060 / 20000\n",
      "gradient norm: 0.0313118624035269, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00439\n",
      "\tval loss: 0.00425\n",
      "epoch 15061 / 20000\n",
      "gradient norm: 0.03727654891554266, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00437\n",
      "\tval loss: 0.00425\n",
      "epoch 15062 / 20000\n",
      "gradient norm: 0.03822138247778639, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00437\n",
      "\tval loss: 0.00425\n",
      "epoch 15063 / 20000\n",
      "gradient norm: 0.05774061515694484, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00437\n",
      "\tval loss: 0.00424\n",
      "epoch 15064 / 20000\n",
      "gradient norm: 0.045372638560365885, minimum ratio: 2.421052631578947\n",
      "\ttrain loss: 0.00438\n",
      "\tval loss: 0.00424\n",
      "epoch 15065 / 20000\n",
      "gradient norm: 0.09614652604795992, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00437\n",
      "\tval loss: 0.00425\n",
      "epoch 15066 / 20000\n",
      "gradient norm: 0.05290668224915862, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00436\n",
      "\tval loss: 0.00424\n",
      "epoch 15067 / 20000\n",
      "gradient norm: 0.07498426648089662, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00438\n",
      "\tval loss: 0.00423\n",
      "epoch 15068 / 20000\n",
      "gradient norm: 0.05521576525643468, minimum ratio: 2.4499999999999997\n",
      "\ttrain loss: 0.00435\n",
      "\tval loss: 0.00426\n",
      "epoch 15069 / 20000\n",
      "gradient norm: 0.06764997728168964, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00436\n",
      "\tval loss: 0.00424\n",
      "epoch 15070 / 20000\n",
      "gradient norm: 0.09405535832047462, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00438\n",
      "\tval loss: 0.00423\n",
      "epoch 15071 / 20000\n",
      "gradient norm: 0.051661501929629594, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00435\n",
      "\tval loss: 0.00425\n",
      "epoch 15072 / 20000\n",
      "gradient norm: 0.055786770361009985, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00436\n",
      "\tval loss: 0.00424\n",
      "epoch 15073 / 20000\n",
      "gradient norm: 0.041488710790872574, minimum ratio: 2.423684210526316\n",
      "\ttrain loss: 0.00435\n",
      "\tval loss: 0.00422\n",
      "epoch 15074 / 20000\n",
      "gradient norm: 0.06964334123767912, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00436\n",
      "\tval loss: 0.00423\n",
      "epoch 15075 / 20000\n",
      "gradient norm: 0.020113295555347577, minimum ratio: 2.423684210526316\n",
      "\ttrain loss: 0.00434\n",
      "\tval loss: 0.00422\n",
      "epoch 15076 / 20000\n",
      "gradient norm: 0.11343705767649226, minimum ratio: 2.4394736842105265\n",
      "\ttrain loss: 0.00436\n",
      "\tval loss: 0.00422\n",
      "epoch 15077 / 20000\n",
      "gradient norm: 0.05675671837525442, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00434\n",
      "\tval loss: 0.00424\n",
      "epoch 15078 / 20000\n",
      "gradient norm: 0.06527180870762095, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00435\n",
      "\tval loss: 0.00422\n",
      "epoch 15079 / 20000\n",
      "gradient norm: 0.04198405452189036, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00435\n",
      "\tval loss: 0.00422\n",
      "epoch 15080 / 20000\n",
      "gradient norm: 0.06407997058704495, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00434\n",
      "\tval loss: 0.00421\n",
      "epoch 15081 / 20000\n",
      "gradient norm: 0.04535038594622165, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00434\n",
      "\tval loss: 0.00422\n",
      "epoch 15082 / 20000\n",
      "gradient norm: 0.07608840567991138, minimum ratio: 2.436842105263158\n",
      "\ttrain loss: 0.00435\n",
      "\tval loss: 0.00422\n",
      "epoch 15083 / 20000\n",
      "gradient norm: 0.07622413994977251, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00434\n",
      "\tval loss: 0.00421\n",
      "epoch 15084 / 20000\n",
      "gradient norm: 0.04076460364740342, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00434\n",
      "\tval loss: 0.00421\n",
      "epoch 15085 / 20000\n",
      "gradient norm: 0.11134047119412571, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00433\n",
      "\tval loss: 0.00422\n",
      "epoch 15086 / 20000\n",
      "gradient norm: 0.06968703243182972, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00434\n",
      "\tval loss: 0.00420\n",
      "epoch 15087 / 20000\n",
      "gradient norm: 0.07243789732456207, minimum ratio: 2.4499999999999997\n",
      "\ttrain loss: 0.00433\n",
      "\tval loss: 0.00421\n",
      "epoch 15088 / 20000\n",
      "gradient norm: 0.08980331057682633, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00434\n",
      "\tval loss: 0.00421\n",
      "epoch 15089 / 20000\n",
      "gradient norm: 0.07588620745809749, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00432\n",
      "\tval loss: 0.00420\n",
      "epoch 15090 / 20000\n",
      "gradient norm: 0.025998254772275686, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00433\n",
      "\tval loss: 0.00420\n",
      "epoch 15091 / 20000\n",
      "gradient norm: 0.05621455528307706, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00433\n",
      "\tval loss: 0.00420\n",
      "epoch 15092 / 20000\n",
      "gradient norm: 0.05268406408140436, minimum ratio: 2.4210526315789473\n",
      "\ttrain loss: 0.00433\n",
      "\tval loss: 0.00419\n",
      "epoch 15093 / 20000\n",
      "gradient norm: 0.04624178679659963, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00431\n",
      "\tval loss: 0.00420\n",
      "epoch 15094 / 20000\n",
      "gradient norm: 0.036712535831611603, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00430\n",
      "\tval loss: 0.00420\n",
      "epoch 15095 / 20000\n",
      "gradient norm: 0.03794524251134135, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00431\n",
      "\tval loss: 0.00419\n",
      "epoch 15096 / 20000\n",
      "gradient norm: 0.06534223177004606, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00432\n",
      "\tval loss: 0.00419\n",
      "epoch 15097 / 20000\n",
      "gradient norm: 0.044205343147041276, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00431\n",
      "\tval loss: 0.00419\n",
      "epoch 15098 / 20000\n",
      "gradient norm: 0.09941262428765185, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00431\n",
      "\tval loss: 0.00418\n",
      "epoch 15099 / 20000\n",
      "gradient norm: 0.04729159292764962, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00431\n",
      "\tval loss: 0.00419\n",
      "epoch 15100 / 20000\n",
      "gradient norm: 0.029302747338078916, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00431\n",
      "\tval loss: 0.00418\n",
      "epoch 15101 / 20000\n",
      "gradient norm: 0.020250967907486483, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00430\n",
      "\tval loss: 0.00418\n",
      "epoch 15102 / 20000\n",
      "gradient norm: 0.04827301169279963, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00430\n",
      "\tval loss: 0.00418\n",
      "epoch 15103 / 20000\n",
      "gradient norm: 0.052006122656166553, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00430\n",
      "\tval loss: 0.00419\n",
      "epoch 15104 / 20000\n",
      "gradient norm: 0.038543387898243964, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00430\n",
      "\tval loss: 0.00418\n",
      "epoch 15105 / 20000\n",
      "gradient norm: 0.04766628728248179, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00429\n",
      "\tval loss: 0.00417\n",
      "epoch 15106 / 20000\n",
      "gradient norm: 0.04427523474441841, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00429\n",
      "\tval loss: 0.00417\n",
      "epoch 15107 / 20000\n",
      "gradient norm: 0.03278517856961116, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00429\n",
      "\tval loss: 0.00418\n",
      "epoch 15108 / 20000\n",
      "gradient norm: 0.04538658750243485, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00429\n",
      "\tval loss: 0.00417\n",
      "epoch 15109 / 20000\n",
      "gradient norm: 0.05846716125961393, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00431\n",
      "\tval loss: 0.00417\n",
      "epoch 15110 / 20000\n",
      "gradient norm: 0.07450146565679461, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00428\n",
      "\tval loss: 0.00417\n",
      "epoch 15111 / 20000\n",
      "gradient norm: 0.037664154835511, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00430\n",
      "\tval loss: 0.00416\n",
      "epoch 15112 / 20000\n",
      "gradient norm: 0.019022542022867128, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00429\n",
      "\tval loss: 0.00417\n",
      "epoch 15113 / 20000\n",
      "gradient norm: 0.03097268013516441, minimum ratio: 2.4842105263157896\n",
      "\ttrain loss: 0.00428\n",
      "\tval loss: 0.00416\n",
      "epoch 15114 / 20000\n",
      "gradient norm: 0.03979521378641948, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00428\n",
      "\tval loss: 0.00415\n",
      "epoch 15115 / 20000\n",
      "gradient norm: 0.026511600124649704, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00428\n",
      "\tval loss: 0.00416\n",
      "epoch 15116 / 20000\n",
      "gradient norm: 0.05396692454814911, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00428\n",
      "\tval loss: 0.00416\n",
      "epoch 15117 / 20000\n",
      "gradient norm: 0.07456726563395932, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00429\n",
      "\tval loss: 0.00415\n",
      "epoch 15118 / 20000\n",
      "gradient norm: 0.04669624811504036, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00428\n",
      "\tval loss: 0.00416\n",
      "epoch 15119 / 20000\n",
      "gradient norm: 0.0666070634033531, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00427\n",
      "\tval loss: 0.00415\n",
      "epoch 15120 / 20000\n",
      "gradient norm: 0.056859374162741005, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00427\n",
      "\tval loss: 0.00414\n",
      "epoch 15121 / 20000\n",
      "gradient norm: 0.07457900950248586, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00427\n",
      "\tval loss: 0.00416\n",
      "epoch 15122 / 20000\n",
      "gradient norm: 0.05357981123961508, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00427\n",
      "\tval loss: 0.00415\n",
      "epoch 15123 / 20000\n",
      "gradient norm: 0.051761455833911896, minimum ratio: 2.4394736842105265\n",
      "\ttrain loss: 0.00427\n",
      "\tval loss: 0.00414\n",
      "epoch 15124 / 20000\n",
      "gradient norm: 0.04968509904574603, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00426\n",
      "\tval loss: 0.00414\n",
      "epoch 15125 / 20000\n",
      "gradient norm: 0.03200264705810696, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00426\n",
      "\tval loss: 0.00414\n",
      "epoch 15126 / 20000\n",
      "gradient norm: 0.02810642300755717, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00425\n",
      "\tval loss: 0.00414\n",
      "epoch 15127 / 20000\n",
      "gradient norm: 0.07268565896083601, minimum ratio: 2.4394736842105265\n",
      "\ttrain loss: 0.00426\n",
      "\tval loss: 0.00414\n",
      "epoch 15128 / 20000\n",
      "gradient norm: 0.030321742699015886, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00425\n",
      "\tval loss: 0.00413\n",
      "epoch 15129 / 20000\n",
      "gradient norm: 0.09823869878891855, minimum ratio: 2.43421052631579\n",
      "\ttrain loss: 0.00427\n",
      "\tval loss: 0.00413\n",
      "epoch 15130 / 20000\n",
      "gradient norm: 0.02558175617014058, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00425\n",
      "\tval loss: 0.00413\n",
      "epoch 15131 / 20000\n",
      "gradient norm: 0.0215574688045308, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00426\n",
      "\tval loss: 0.00413\n",
      "epoch 15132 / 20000\n",
      "gradient norm: 0.06824166851583868, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00425\n",
      "\tval loss: 0.00413\n",
      "epoch 15133 / 20000\n",
      "gradient norm: 0.032811387558467686, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00425\n",
      "\tval loss: 0.00413\n",
      "epoch 15134 / 20000\n",
      "gradient norm: 0.03857024054741487, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00424\n",
      "\tval loss: 0.00412\n",
      "epoch 15135 / 20000\n",
      "gradient norm: 0.04887127556139603, minimum ratio: 2.460526315789474\n",
      "\ttrain loss: 0.00425\n",
      "\tval loss: 0.00412\n",
      "epoch 15136 / 20000\n",
      "gradient norm: 0.06961104780202731, minimum ratio: 2.423684210526316\n",
      "\ttrain loss: 0.00424\n",
      "\tval loss: 0.00413\n",
      "epoch 15137 / 20000\n",
      "gradient norm: 0.03341877937782556, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00423\n",
      "\tval loss: 0.00412\n",
      "epoch 15138 / 20000\n",
      "gradient norm: 0.049744347226805985, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00424\n",
      "\tval loss: 0.00411\n",
      "epoch 15139 / 20000\n",
      "gradient norm: 0.030688278493471444, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00423\n",
      "\tval loss: 0.00412\n",
      "epoch 15140 / 20000\n",
      "gradient norm: 0.04351288208272308, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00423\n",
      "\tval loss: 0.00412\n",
      "epoch 15141 / 20000\n",
      "gradient norm: 0.06398281292058527, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00423\n",
      "\tval loss: 0.00411\n",
      "epoch 15142 / 20000\n",
      "gradient norm: 0.047901811718475074, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00424\n",
      "\tval loss: 0.00412\n",
      "epoch 15143 / 20000\n",
      "gradient norm: 0.05905371072003618, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00423\n",
      "\tval loss: 0.00411\n",
      "epoch 15144 / 20000\n",
      "gradient norm: 0.04856827831827104, minimum ratio: 2.4236842105263157\n",
      "\ttrain loss: 0.00423\n",
      "\tval loss: 0.00410\n",
      "epoch 15145 / 20000\n",
      "gradient norm: 0.05041920318035409, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00422\n",
      "\tval loss: 0.00412\n",
      "epoch 15146 / 20000\n",
      "gradient norm: 0.05783145752502605, minimum ratio: 2.4447368421052635\n",
      "\ttrain loss: 0.00422\n",
      "\tval loss: 0.00411\n",
      "epoch 15147 / 20000\n",
      "gradient norm: 0.05632061054348014, minimum ratio: 2.4263157894736844\n",
      "\ttrain loss: 0.00422\n",
      "\tval loss: 0.00409\n",
      "epoch 15148 / 20000\n",
      "gradient norm: 0.0334347034804523, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00422\n",
      "\tval loss: 0.00410\n",
      "epoch 15149 / 20000\n",
      "gradient norm: 0.09369457454886287, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00422\n",
      "\tval loss: 0.00411\n",
      "epoch 15150 / 20000\n",
      "gradient norm: 0.01530049421126023, minimum ratio: 2.4315789473684206\n",
      "\ttrain loss: 0.00422\n",
      "\tval loss: 0.00409\n",
      "epoch 15151 / 20000\n",
      "gradient norm: 0.09184246911900118, minimum ratio: 2.4447368421052627\n",
      "\ttrain loss: 0.00423\n",
      "\tval loss: 0.00409\n",
      "epoch 15152 / 20000\n",
      "gradient norm: 0.05544530370389111, minimum ratio: 2.4394736842105265\n",
      "\ttrain loss: 0.00421\n",
      "\tval loss: 0.00412\n",
      "epoch 15153 / 20000\n",
      "gradient norm: 0.07938387128524482, minimum ratio: 2.4421052631578943\n",
      "\ttrain loss: 0.00421\n",
      "\tval loss: 0.00409\n",
      "epoch 15154 / 20000\n",
      "gradient norm: 0.08259045775048435, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00422\n",
      "\tval loss: 0.00408\n",
      "epoch 15155 / 20000\n",
      "gradient norm: 0.11904916958883405, minimum ratio: 2.460526315789474\n",
      "\ttrain loss: 0.00422\n",
      "\tval loss: 0.00411\n",
      "epoch 15156 / 20000\n",
      "gradient norm: 0.06452092219842598, minimum ratio: 2.426315789473684\n",
      "\ttrain loss: 0.00421\n",
      "\tval loss: 0.00409\n",
      "epoch 15157 / 20000\n",
      "gradient norm: 0.04134416248416528, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00420\n",
      "\tval loss: 0.00408\n",
      "epoch 15158 / 20000\n",
      "gradient norm: 0.023981606180313975, minimum ratio: 2.46578947368421\n",
      "\ttrain loss: 0.00421\n",
      "\tval loss: 0.00409\n",
      "epoch 15159 / 20000\n",
      "gradient norm: 0.05047248431947082, minimum ratio: 2.4394736842105265\n",
      "\ttrain loss: 0.00419\n",
      "\tval loss: 0.00409\n",
      "epoch 15160 / 20000\n",
      "gradient norm: 0.08678774838335812, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00420\n",
      "\tval loss: 0.00408\n",
      "epoch 15161 / 20000\n",
      "gradient norm: 0.03953630494652316, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00420\n",
      "\tval loss: 0.00407\n",
      "epoch 15162 / 20000\n",
      "gradient norm: 0.023609827156178653, minimum ratio: 2.4447368421052635\n",
      "\ttrain loss: 0.00420\n",
      "\tval loss: 0.00408\n",
      "epoch 15163 / 20000\n",
      "gradient norm: 0.08638825197704136, minimum ratio: 2.4578947368421056\n",
      "\ttrain loss: 0.00421\n",
      "\tval loss: 0.00408\n",
      "epoch 15164 / 20000\n",
      "gradient norm: 0.07460882916348055, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00419\n",
      "\tval loss: 0.00407\n",
      "epoch 15165 / 20000\n",
      "gradient norm: 0.07779469667002559, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00419\n",
      "\tval loss: 0.00407\n",
      "epoch 15166 / 20000\n",
      "gradient norm: 0.06518141983542591, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00419\n",
      "\tval loss: 0.00407\n",
      "epoch 15167 / 20000\n",
      "gradient norm: 0.03409685584483668, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00419\n",
      "\tval loss: 0.00406\n",
      "epoch 15168 / 20000\n",
      "gradient norm: 0.0522574226197321, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00419\n",
      "\tval loss: 0.00406\n",
      "epoch 15169 / 20000\n",
      "gradient norm: 0.045891042973380536, minimum ratio: 2.4578947368421056\n",
      "\ttrain loss: 0.00418\n",
      "\tval loss: 0.00407\n",
      "epoch 15170 / 20000\n",
      "gradient norm: 0.04640692047541961, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00417\n",
      "\tval loss: 0.00406\n",
      "epoch 15171 / 20000\n",
      "gradient norm: 0.08295351435663179, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00419\n",
      "\tval loss: 0.00405\n",
      "epoch 15172 / 20000\n",
      "gradient norm: 0.03742939210496843, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00418\n",
      "\tval loss: 0.00407\n",
      "epoch 15173 / 20000\n",
      "gradient norm: 0.06313115183729678, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00417\n",
      "\tval loss: 0.00406\n",
      "epoch 15174 / 20000\n",
      "gradient norm: 0.028708494792226702, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00418\n",
      "\tval loss: 0.00405\n",
      "epoch 15175 / 20000\n",
      "gradient norm: 0.023312680365052074, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00417\n",
      "\tval loss: 0.00405\n",
      "epoch 15176 / 20000\n",
      "gradient norm: 0.07008515764027834, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00417\n",
      "\tval loss: 0.00405\n",
      "epoch 15177 / 20000\n",
      "gradient norm: 0.09247476723976433, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00417\n",
      "\tval loss: 0.00405\n",
      "epoch 15178 / 20000\n",
      "gradient norm: 0.05730130837764591, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00417\n",
      "\tval loss: 0.00406\n",
      "epoch 15179 / 20000\n",
      "gradient norm: 0.06742506293812767, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00417\n",
      "\tval loss: 0.00404\n",
      "epoch 15180 / 20000\n",
      "gradient norm: 0.02545066282618791, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00417\n",
      "\tval loss: 0.00405\n",
      "epoch 15181 / 20000\n",
      "gradient norm: 0.07200239854864776, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00417\n",
      "\tval loss: 0.00405\n",
      "epoch 15182 / 20000\n",
      "gradient norm: 0.08477277716156095, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00418\n",
      "\tval loss: 0.00403\n",
      "epoch 15183 / 20000\n",
      "gradient norm: 0.06073988671414554, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00416\n",
      "\tval loss: 0.00405\n",
      "epoch 15184 / 20000\n",
      "gradient norm: 0.04955945326946676, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00416\n",
      "\tval loss: 0.00404\n",
      "epoch 15185 / 20000\n",
      "gradient norm: 0.0473896412004251, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00416\n",
      "\tval loss: 0.00403\n",
      "epoch 15186 / 20000\n",
      "gradient norm: 0.05681500677019358, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00415\n",
      "\tval loss: 0.00404\n",
      "epoch 15187 / 20000\n",
      "gradient norm: 0.09630798816215247, minimum ratio: 2.46578947368421\n",
      "\ttrain loss: 0.00415\n",
      "\tval loss: 0.00404\n",
      "epoch 15188 / 20000\n",
      "gradient norm: 0.08115673699649051, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00415\n",
      "\tval loss: 0.00402\n",
      "epoch 15189 / 20000\n",
      "gradient norm: 0.06438614684157073, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00415\n",
      "\tval loss: 0.00403\n",
      "epoch 15190 / 20000\n",
      "gradient norm: 0.031449654314201325, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00414\n",
      "\tval loss: 0.00403\n",
      "epoch 15191 / 20000\n",
      "gradient norm: 0.09731227101292461, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00414\n",
      "\tval loss: 0.00402\n",
      "epoch 15192 / 20000\n",
      "gradient norm: 0.05958861962426454, minimum ratio: 2.4263157894736844\n",
      "\ttrain loss: 0.00414\n",
      "\tval loss: 0.00403\n",
      "epoch 15193 / 20000\n",
      "gradient norm: 0.07154247356811538, minimum ratio: 2.4499999999999997\n",
      "\ttrain loss: 0.00415\n",
      "\tval loss: 0.00402\n",
      "epoch 15194 / 20000\n",
      "gradient norm: 0.06932696071453393, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00413\n",
      "\tval loss: 0.00403\n",
      "epoch 15195 / 20000\n",
      "gradient norm: 0.035387372598052025, minimum ratio: 2.4578947368421056\n",
      "\ttrain loss: 0.00414\n",
      "\tval loss: 0.00402\n",
      "epoch 15196 / 20000\n",
      "gradient norm: 0.06017660506768152, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00414\n",
      "\tval loss: 0.00401\n",
      "epoch 15197 / 20000\n",
      "gradient norm: 0.047007537505123764, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00413\n",
      "\tval loss: 0.00403\n",
      "epoch 15198 / 20000\n",
      "gradient norm: 0.06655363168101758, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00413\n",
      "\tval loss: 0.00402\n",
      "epoch 15199 / 20000\n",
      "gradient norm: 0.04572947445558384, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00413\n",
      "\tval loss: 0.00401\n",
      "epoch 15200 / 20000\n",
      "gradient norm: 0.06482963083544746, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00413\n",
      "\tval loss: 0.00401\n",
      "epoch 15201 / 20000\n",
      "gradient norm: 0.08108347014058381, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00412\n",
      "\tval loss: 0.00401\n",
      "epoch 15202 / 20000\n",
      "gradient norm: 0.03867463511414826, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00412\n",
      "\tval loss: 0.00401\n",
      "epoch 15203 / 20000\n",
      "gradient norm: 0.05161888126167469, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00413\n",
      "\tval loss: 0.00400\n",
      "epoch 15204 / 20000\n",
      "gradient norm: 0.13227455143351108, minimum ratio: 2.426315789473684\n",
      "\ttrain loss: 0.00413\n",
      "\tval loss: 0.00402\n",
      "epoch 15205 / 20000\n",
      "gradient norm: 0.06779183266917244, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00413\n",
      "\tval loss: 0.00399\n",
      "epoch 15206 / 20000\n",
      "gradient norm: 0.0638680865522474, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00413\n",
      "\tval loss: 0.00400\n",
      "epoch 15207 / 20000\n",
      "gradient norm: 0.06932710506953299, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00411\n",
      "\tval loss: 0.00401\n",
      "epoch 15208 / 20000\n",
      "gradient norm: 0.05533939565066248, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00412\n",
      "\tval loss: 0.00399\n",
      "epoch 15209 / 20000\n",
      "gradient norm: 0.06650857179192826, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00411\n",
      "\tval loss: 0.00399\n",
      "epoch 15210 / 20000\n",
      "gradient norm: 0.08499273267807439, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00411\n",
      "\tval loss: 0.00399\n",
      "epoch 15211 / 20000\n",
      "gradient norm: 0.07375511853024364, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00412\n",
      "\tval loss: 0.00398\n",
      "epoch 15212 / 20000\n",
      "gradient norm: 0.05712654552189633, minimum ratio: 2.4394736842105265\n",
      "\ttrain loss: 0.00411\n",
      "\tval loss: 0.00399\n",
      "epoch 15213 / 20000\n",
      "gradient norm: 0.054194567346712574, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00410\n",
      "\tval loss: 0.00399\n",
      "epoch 15214 / 20000\n",
      "gradient norm: 0.07903326931409538, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00411\n",
      "\tval loss: 0.00399\n",
      "epoch 15215 / 20000\n",
      "gradient norm: 0.046008768782485276, minimum ratio: 2.4289473684210523\n",
      "\ttrain loss: 0.00410\n",
      "\tval loss: 0.00398\n",
      "epoch 15216 / 20000\n",
      "gradient norm: 0.05045596824493259, minimum ratio: 2.4421052631578943\n",
      "\ttrain loss: 0.00410\n",
      "\tval loss: 0.00398\n",
      "epoch 15217 / 20000\n",
      "gradient norm: 0.07198026176774874, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00410\n",
      "\tval loss: 0.00398\n",
      "epoch 15218 / 20000\n",
      "gradient norm: 0.07683694077422842, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00410\n",
      "\tval loss: 0.00398\n",
      "epoch 15219 / 20000\n",
      "gradient norm: 0.03754034225130454, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00409\n",
      "\tval loss: 0.00397\n",
      "epoch 15220 / 20000\n",
      "gradient norm: 0.09599380998406559, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00410\n",
      "\tval loss: 0.00398\n",
      "epoch 15221 / 20000\n",
      "gradient norm: 0.08433897874783725, minimum ratio: 2.4447368421052635\n",
      "\ttrain loss: 0.00409\n",
      "\tval loss: 0.00397\n",
      "epoch 15222 / 20000\n",
      "gradient norm: 0.060540302511071786, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00408\n",
      "\tval loss: 0.00398\n",
      "epoch 15223 / 20000\n",
      "gradient norm: 0.05740851635346189, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00409\n",
      "\tval loss: 0.00397\n",
      "epoch 15224 / 20000\n",
      "gradient norm: 0.05818785389419645, minimum ratio: 2.421052631578947\n",
      "\ttrain loss: 0.00409\n",
      "\tval loss: 0.00396\n",
      "epoch 15225 / 20000\n",
      "gradient norm: 0.0472404359607026, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00408\n",
      "\tval loss: 0.00396\n",
      "epoch 15226 / 20000\n",
      "gradient norm: 0.034357667434960604, minimum ratio: 2.4236842105263157\n",
      "\ttrain loss: 0.00408\n",
      "\tval loss: 0.00398\n",
      "epoch 15227 / 20000\n",
      "gradient norm: 0.055991816509049386, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00409\n",
      "\tval loss: 0.00396\n",
      "epoch 15228 / 20000\n",
      "gradient norm: 0.057161908625857905, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00408\n",
      "\tval loss: 0.00396\n",
      "epoch 15229 / 20000\n",
      "gradient norm: 0.05119652033317834, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00407\n",
      "\tval loss: 0.00396\n",
      "epoch 15230 / 20000\n",
      "gradient norm: 0.01836991123855114, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00407\n",
      "\tval loss: 0.00396\n",
      "epoch 15231 / 20000\n",
      "gradient norm: 0.0522258103301283, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00407\n",
      "\tval loss: 0.00396\n",
      "epoch 15232 / 20000\n",
      "gradient norm: 0.06279228086350486, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00406\n",
      "\tval loss: 0.00396\n",
      "epoch 15233 / 20000\n",
      "gradient norm: 0.04919267597142607, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00407\n",
      "\tval loss: 0.00395\n",
      "epoch 15234 / 20000\n",
      "gradient norm: 0.07149271917296574, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00408\n",
      "\tval loss: 0.00396\n",
      "epoch 15235 / 20000\n",
      "gradient norm: 0.05864790570922196, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00407\n",
      "\tval loss: 0.00395\n",
      "epoch 15236 / 20000\n",
      "gradient norm: 0.04707660054555163, minimum ratio: 2.4263157894736844\n",
      "\ttrain loss: 0.00406\n",
      "\tval loss: 0.00394\n",
      "epoch 15237 / 20000\n",
      "gradient norm: 0.11770819185767323, minimum ratio: 2.4184210526315786\n",
      "\ttrain loss: 0.00407\n",
      "\tval loss: 0.00395\n",
      "epoch 15238 / 20000\n",
      "gradient norm: 0.03400620585307479, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00405\n",
      "\tval loss: 0.00394\n",
      "epoch 15239 / 20000\n",
      "gradient norm: 0.05315506970509887, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00405\n",
      "\tval loss: 0.00393\n",
      "epoch 15240 / 20000\n",
      "gradient norm: 0.04086440248647705, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00405\n",
      "\tval loss: 0.00394\n",
      "epoch 15241 / 20000\n",
      "gradient norm: 0.04319212672999129, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00406\n",
      "\tval loss: 0.00395\n",
      "epoch 15242 / 20000\n",
      "gradient norm: 0.03502618026686832, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00405\n",
      "\tval loss: 0.00393\n",
      "epoch 15243 / 20000\n",
      "gradient norm: 0.029609302582684904, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00406\n",
      "\tval loss: 0.00393\n",
      "epoch 15244 / 20000\n",
      "gradient norm: 0.050625403120648116, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00405\n",
      "\tval loss: 0.00394\n",
      "epoch 15245 / 20000\n",
      "gradient norm: 0.09545919980155304, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00405\n",
      "\tval loss: 0.00393\n",
      "epoch 15246 / 20000\n",
      "gradient norm: 0.054612995707429945, minimum ratio: 2.4421052631578943\n",
      "\ttrain loss: 0.00404\n",
      "\tval loss: 0.00393\n",
      "epoch 15247 / 20000\n",
      "gradient norm: 0.01711014553438872, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00405\n",
      "\tval loss: 0.00393\n",
      "epoch 15248 / 20000\n",
      "gradient norm: 0.060830593400169164, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00404\n",
      "\tval loss: 0.00393\n",
      "epoch 15249 / 20000\n",
      "gradient norm: 0.045545387896709144, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00403\n",
      "\tval loss: 0.00392\n",
      "epoch 15250 / 20000\n",
      "gradient norm: 0.033437647856771946, minimum ratio: 2.4394736842105265\n",
      "\ttrain loss: 0.00404\n",
      "\tval loss: 0.00392\n",
      "epoch 15251 / 20000\n",
      "gradient norm: 0.0746450704173185, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00404\n",
      "\tval loss: 0.00392\n",
      "epoch 15252 / 20000\n",
      "gradient norm: 0.042394721298478544, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00403\n",
      "\tval loss: 0.00392\n",
      "epoch 15253 / 20000\n",
      "gradient norm: 0.06758095812983811, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00404\n",
      "\tval loss: 0.00391\n",
      "epoch 15254 / 20000\n",
      "gradient norm: 0.08056599317933433, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00403\n",
      "\tval loss: 0.00393\n",
      "epoch 15255 / 20000\n",
      "gradient norm: 0.04704552571638487, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00403\n",
      "\tval loss: 0.00391\n",
      "epoch 15256 / 20000\n",
      "gradient norm: 0.03503403015201911, minimum ratio: 2.4421052631578943\n",
      "\ttrain loss: 0.00403\n",
      "\tval loss: 0.00391\n",
      "epoch 15257 / 20000\n",
      "gradient norm: 0.07418584730476141, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00403\n",
      "\tval loss: 0.00392\n",
      "epoch 15258 / 20000\n",
      "gradient norm: 0.0925843573641032, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00403\n",
      "\tval loss: 0.00390\n",
      "epoch 15259 / 20000\n",
      "gradient norm: 0.05068176711210981, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00402\n",
      "\tval loss: 0.00392\n",
      "epoch 15260 / 20000\n",
      "gradient norm: 0.035509417997673154, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00401\n",
      "\tval loss: 0.00391\n",
      "epoch 15261 / 20000\n",
      "gradient norm: 0.036012296681292355, minimum ratio: 2.4421052631578943\n",
      "\ttrain loss: 0.00402\n",
      "\tval loss: 0.00390\n",
      "epoch 15262 / 20000\n",
      "gradient norm: 0.05526503128930926, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00401\n",
      "\tval loss: 0.00390\n",
      "epoch 15263 / 20000\n",
      "gradient norm: 0.06589156808331609, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00401\n",
      "\tval loss: 0.00390\n",
      "epoch 15264 / 20000\n",
      "gradient norm: 0.05513338220771402, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00402\n",
      "\tval loss: 0.00389\n",
      "epoch 15265 / 20000\n",
      "gradient norm: 0.03182332502910867, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00401\n",
      "\tval loss: 0.00390\n",
      "epoch 15266 / 20000\n",
      "gradient norm: 0.0730122895911336, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00401\n",
      "\tval loss: 0.00389\n",
      "epoch 15267 / 20000\n",
      "gradient norm: 0.060140343819512054, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00401\n",
      "\tval loss: 0.00390\n",
      "epoch 15268 / 20000\n",
      "gradient norm: 0.03694217960583046, minimum ratio: 2.4421052631578943\n",
      "\ttrain loss: 0.00401\n",
      "\tval loss: 0.00389\n",
      "epoch 15269 / 20000\n",
      "gradient norm: 0.02982029877603054, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00400\n",
      "\tval loss: 0.00388\n",
      "epoch 15270 / 20000\n",
      "gradient norm: 0.055307784117758274, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00400\n",
      "\tval loss: 0.00389\n",
      "epoch 15271 / 20000\n",
      "gradient norm: 0.04949742532335222, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00401\n",
      "\tval loss: 0.00390\n",
      "epoch 15272 / 20000\n",
      "gradient norm: 0.06427385559072718, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00400\n",
      "\tval loss: 0.00388\n",
      "epoch 15273 / 20000\n",
      "gradient norm: 0.036458296119235456, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00400\n",
      "\tval loss: 0.00388\n",
      "epoch 15274 / 20000\n",
      "gradient norm: 0.03775027091614902, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00399\n",
      "\tval loss: 0.00389\n",
      "epoch 15275 / 20000\n",
      "gradient norm: 0.053732545929960907, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00399\n",
      "\tval loss: 0.00388\n",
      "epoch 15276 / 20000\n",
      "gradient norm: 0.06446761847473681, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00400\n",
      "\tval loss: 0.00387\n",
      "epoch 15277 / 20000\n",
      "gradient norm: 0.045410038670524955, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00399\n",
      "\tval loss: 0.00389\n",
      "epoch 15278 / 20000\n",
      "gradient norm: 0.05845832440536469, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00399\n",
      "\tval loss: 0.00387\n",
      "epoch 15279 / 20000\n",
      "gradient norm: 0.04953972087241709, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00398\n",
      "\tval loss: 0.00387\n",
      "epoch 15280 / 20000\n",
      "gradient norm: 0.06444176472723484, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00399\n",
      "\tval loss: 0.00387\n",
      "epoch 15281 / 20000\n",
      "gradient norm: 0.08259130566148087, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00398\n",
      "\tval loss: 0.00386\n",
      "epoch 15282 / 20000\n",
      "gradient norm: 0.1053131683729589, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00397\n",
      "\tval loss: 0.00388\n",
      "epoch 15283 / 20000\n",
      "gradient norm: 0.046374010969884694, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00397\n",
      "\tval loss: 0.00387\n",
      "epoch 15284 / 20000\n",
      "gradient norm: 0.02730888605583459, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00398\n",
      "\tval loss: 0.00386\n",
      "epoch 15285 / 20000\n",
      "gradient norm: 0.06520921079209074, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00398\n",
      "\tval loss: 0.00387\n",
      "epoch 15286 / 20000\n",
      "gradient norm: 0.03561317623825744, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00397\n",
      "\tval loss: 0.00386\n",
      "epoch 15287 / 20000\n",
      "gradient norm: 0.09407551924232394, minimum ratio: 2.4499999999999997\n",
      "\ttrain loss: 0.00397\n",
      "\tval loss: 0.00386\n",
      "epoch 15288 / 20000\n",
      "gradient norm: 0.056568590458482504, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00397\n",
      "\tval loss: 0.00386\n",
      "epoch 15289 / 20000\n",
      "gradient norm: 0.054844964877702296, minimum ratio: 2.4157894736842103\n",
      "\ttrain loss: 0.00396\n",
      "\tval loss: 0.00385\n",
      "epoch 15290 / 20000\n",
      "gradient norm: 0.05123926600208506, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00397\n",
      "\tval loss: 0.00385\n",
      "epoch 15291 / 20000\n",
      "gradient norm: 0.06169478368246928, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00397\n",
      "\tval loss: 0.00385\n",
      "epoch 15292 / 20000\n",
      "gradient norm: 0.05767677316907793, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00396\n",
      "\tval loss: 0.00385\n",
      "epoch 15293 / 20000\n",
      "gradient norm: 0.04920034372480586, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00395\n",
      "\tval loss: 0.00385\n",
      "epoch 15294 / 20000\n",
      "gradient norm: 0.04630376381101087, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00396\n",
      "\tval loss: 0.00384\n",
      "epoch 15295 / 20000\n",
      "gradient norm: 0.053052947216201574, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00396\n",
      "\tval loss: 0.00384\n",
      "epoch 15296 / 20000\n",
      "gradient norm: 0.03116650035372004, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00395\n",
      "\tval loss: 0.00384\n",
      "epoch 15297 / 20000\n",
      "gradient norm: 0.030579606915125623, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00396\n",
      "\tval loss: 0.00384\n",
      "epoch 15298 / 20000\n",
      "gradient norm: 0.06455010216450319, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00394\n",
      "\tval loss: 0.00383\n",
      "epoch 15299 / 20000\n",
      "gradient norm: 0.03236541704973206, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00396\n",
      "\tval loss: 0.00384\n",
      "epoch 15300 / 20000\n",
      "gradient norm: 0.0737166439066641, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00394\n",
      "\tval loss: 0.00383\n",
      "epoch 15301 / 20000\n",
      "gradient norm: 0.05643631250131875, minimum ratio: 2.4499999999999997\n",
      "\ttrain loss: 0.00395\n",
      "\tval loss: 0.00383\n",
      "epoch 15302 / 20000\n",
      "gradient norm: 0.03875301603693515, minimum ratio: 2.4078947368421053\n",
      "\ttrain loss: 0.00394\n",
      "\tval loss: 0.00384\n",
      "epoch 15303 / 20000\n",
      "gradient norm: 0.0591038215206936, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00394\n",
      "\tval loss: 0.00383\n",
      "epoch 15304 / 20000\n",
      "gradient norm: 0.030302363447844982, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00394\n",
      "\tval loss: 0.00383\n",
      "epoch 15305 / 20000\n",
      "gradient norm: 0.08093447517603636, minimum ratio: 2.4394736842105265\n",
      "\ttrain loss: 0.00394\n",
      "\tval loss: 0.00383\n",
      "epoch 15306 / 20000\n",
      "gradient norm: 0.04915901308413595, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00393\n",
      "\tval loss: 0.00382\n",
      "epoch 15307 / 20000\n",
      "gradient norm: 0.022961841023061424, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00394\n",
      "\tval loss: 0.00383\n",
      "epoch 15308 / 20000\n",
      "gradient norm: 0.05724983580876142, minimum ratio: 2.4421052631578943\n",
      "\ttrain loss: 0.00393\n",
      "\tval loss: 0.00382\n",
      "epoch 15309 / 20000\n",
      "gradient norm: 0.04395528935128823, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00392\n",
      "\tval loss: 0.00382\n",
      "epoch 15310 / 20000\n",
      "gradient norm: 0.022648626181762666, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00393\n",
      "\tval loss: 0.00382\n",
      "epoch 15311 / 20000\n",
      "gradient norm: 0.04094841826008633, minimum ratio: 2.46578947368421\n",
      "\ttrain loss: 0.00392\n",
      "\tval loss: 0.00381\n",
      "epoch 15312 / 20000\n",
      "gradient norm: 0.0490208612754941, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00392\n",
      "\tval loss: 0.00382\n",
      "epoch 15313 / 20000\n",
      "gradient norm: 0.05310369445942342, minimum ratio: 2.4447368421052627\n",
      "\ttrain loss: 0.00391\n",
      "\tval loss: 0.00381\n",
      "epoch 15314 / 20000\n",
      "gradient norm: 0.053329218877479434, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00393\n",
      "\tval loss: 0.00381\n",
      "epoch 15315 / 20000\n",
      "gradient norm: 0.051452735206112266, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00391\n",
      "\tval loss: 0.00381\n",
      "epoch 15316 / 20000\n",
      "gradient norm: 0.10664495697710663, minimum ratio: 2.4157894736842107\n",
      "\ttrain loss: 0.00392\n",
      "\tval loss: 0.00382\n",
      "epoch 15317 / 20000\n",
      "gradient norm: 0.04265552188735455, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00391\n",
      "\tval loss: 0.00380\n",
      "epoch 15318 / 20000\n",
      "gradient norm: 0.08214977313764393, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00392\n",
      "\tval loss: 0.00380\n",
      "epoch 15319 / 20000\n",
      "gradient norm: 0.03866483288584277, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00391\n",
      "\tval loss: 0.00381\n",
      "epoch 15320 / 20000\n",
      "gradient norm: 0.057021417014766484, minimum ratio: 2.4394736842105265\n",
      "\ttrain loss: 0.00392\n",
      "\tval loss: 0.00380\n",
      "epoch 15321 / 20000\n",
      "gradient norm: 0.07813221280230209, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00391\n",
      "\tval loss: 0.00379\n",
      "epoch 15322 / 20000\n",
      "gradient norm: 0.05238792300224304, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00392\n",
      "\tval loss: 0.00381\n",
      "epoch 15323 / 20000\n",
      "gradient norm: 0.05731892213225365, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00390\n",
      "\tval loss: 0.00380\n",
      "epoch 15324 / 20000\n",
      "gradient norm: 0.04332726442953572, minimum ratio: 2.4394736842105265\n",
      "\ttrain loss: 0.00390\n",
      "\tval loss: 0.00379\n",
      "epoch 15325 / 20000\n",
      "gradient norm: 0.05148760526208207, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00390\n",
      "\tval loss: 0.00379\n",
      "epoch 15326 / 20000\n",
      "gradient norm: 0.050066118012182415, minimum ratio: 2.4394736842105265\n",
      "\ttrain loss: 0.00390\n",
      "\tval loss: 0.00380\n",
      "epoch 15327 / 20000\n",
      "gradient norm: 0.07175079709850252, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00390\n",
      "\tval loss: 0.00378\n",
      "epoch 15328 / 20000\n",
      "gradient norm: 0.07304432010278106, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00390\n",
      "\tval loss: 0.00378\n",
      "epoch 15329 / 20000\n",
      "gradient norm: 0.09646494861226529, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00389\n",
      "\tval loss: 0.00380\n",
      "epoch 15330 / 20000\n",
      "gradient norm: 0.045126391923986375, minimum ratio: 2.4052631578947365\n",
      "\ttrain loss: 0.00389\n",
      "\tval loss: 0.00378\n",
      "epoch 15331 / 20000\n",
      "gradient norm: 0.07130752521334216, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00389\n",
      "\tval loss: 0.00378\n",
      "epoch 15332 / 20000\n",
      "gradient norm: 0.056710966979153454, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00389\n",
      "\tval loss: 0.00378\n",
      "epoch 15333 / 20000\n",
      "gradient norm: 0.07971656846348196, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00388\n",
      "\tval loss: 0.00379\n",
      "epoch 15334 / 20000\n",
      "gradient norm: 0.06649665208533406, minimum ratio: 2.418421052631579\n",
      "\ttrain loss: 0.00388\n",
      "\tval loss: 0.00377\n",
      "epoch 15335 / 20000\n",
      "gradient norm: 0.07698129647178575, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00389\n",
      "\tval loss: 0.00377\n",
      "epoch 15336 / 20000\n",
      "gradient norm: 0.07492741191526875, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00388\n",
      "\tval loss: 0.00379\n",
      "epoch 15337 / 20000\n",
      "gradient norm: 0.05221650644671172, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00388\n",
      "\tval loss: 0.00377\n",
      "epoch 15338 / 20000\n",
      "gradient norm: 0.03409717552131042, minimum ratio: 2.413157894736842\n",
      "\ttrain loss: 0.00387\n",
      "\tval loss: 0.00376\n",
      "epoch 15339 / 20000\n",
      "gradient norm: 0.05819765792693943, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00388\n",
      "\tval loss: 0.00377\n",
      "epoch 15340 / 20000\n",
      "gradient norm: 0.02192436548648402, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00387\n",
      "\tval loss: 0.00377\n",
      "epoch 15341 / 20000\n",
      "gradient norm: 0.05658818857045844, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00386\n",
      "\tval loss: 0.00376\n",
      "epoch 15342 / 20000\n",
      "gradient norm: 0.059816404595039785, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00386\n",
      "\tval loss: 0.00376\n",
      "epoch 15343 / 20000\n",
      "gradient norm: 0.05938956781756133, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00387\n",
      "\tval loss: 0.00375\n",
      "epoch 15344 / 20000\n",
      "gradient norm: 0.03437643492361531, minimum ratio: 2.4210526315789473\n",
      "\ttrain loss: 0.00387\n",
      "\tval loss: 0.00376\n",
      "epoch 15345 / 20000\n",
      "gradient norm: 0.05469069129321724, minimum ratio: 2.426315789473684\n",
      "\ttrain loss: 0.00386\n",
      "\tval loss: 0.00375\n",
      "epoch 15346 / 20000\n",
      "gradient norm: 0.035078010929282755, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00387\n",
      "\tval loss: 0.00375\n",
      "epoch 15347 / 20000\n",
      "gradient norm: 0.03987885345122777, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00385\n",
      "\tval loss: 0.00375\n",
      "epoch 15348 / 20000\n",
      "gradient norm: 0.05214683886151761, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00385\n",
      "\tval loss: 0.00375\n",
      "epoch 15349 / 20000\n",
      "gradient norm: 0.05104020319413394, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00386\n",
      "\tval loss: 0.00375\n",
      "epoch 15350 / 20000\n",
      "gradient norm: 0.053242036257870495, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00385\n",
      "\tval loss: 0.00375\n",
      "epoch 15351 / 20000\n",
      "gradient norm: 0.07152575114741921, minimum ratio: 2.4447368421052627\n",
      "\ttrain loss: 0.00386\n",
      "\tval loss: 0.00374\n",
      "epoch 15352 / 20000\n",
      "gradient norm: 0.055218504334334284, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00385\n",
      "\tval loss: 0.00376\n",
      "epoch 15353 / 20000\n",
      "gradient norm: 0.02918624778976664, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00385\n",
      "\tval loss: 0.00374\n",
      "epoch 15354 / 20000\n",
      "gradient norm: 0.06010971905197948, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00385\n",
      "\tval loss: 0.00373\n",
      "epoch 15355 / 20000\n",
      "gradient norm: 0.052166355948429555, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00384\n",
      "\tval loss: 0.00375\n",
      "epoch 15356 / 20000\n",
      "gradient norm: 0.06128374231047928, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00386\n",
      "\tval loss: 0.00373\n",
      "epoch 15357 / 20000\n",
      "gradient norm: 0.0582758819218725, minimum ratio: 2.4499999999999997\n",
      "\ttrain loss: 0.00384\n",
      "\tval loss: 0.00373\n",
      "epoch 15358 / 20000\n",
      "gradient norm: 0.052214485593140125, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00383\n",
      "\tval loss: 0.00374\n",
      "epoch 15359 / 20000\n",
      "gradient norm: 0.04541917471215129, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00383\n",
      "\tval loss: 0.00373\n",
      "epoch 15360 / 20000\n",
      "gradient norm: 0.04093375941738486, minimum ratio: 2.4157894736842103\n",
      "\ttrain loss: 0.00384\n",
      "\tval loss: 0.00373\n",
      "epoch 15361 / 20000\n",
      "gradient norm: 0.033698659390211105, minimum ratio: 2.4499999999999997\n",
      "\ttrain loss: 0.00383\n",
      "\tval loss: 0.00372\n",
      "epoch 15362 / 20000\n",
      "gradient norm: 0.028956092486623675, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00383\n",
      "\tval loss: 0.00373\n",
      "epoch 15363 / 20000\n",
      "gradient norm: 0.053351030859630555, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00382\n",
      "\tval loss: 0.00373\n",
      "epoch 15364 / 20000\n",
      "gradient norm: 0.027702592662535608, minimum ratio: 2.4263157894736844\n",
      "\ttrain loss: 0.00382\n",
      "\tval loss: 0.00372\n",
      "epoch 15365 / 20000\n",
      "gradient norm: 0.07564247620757669, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00383\n",
      "\tval loss: 0.00372\n",
      "epoch 15366 / 20000\n",
      "gradient norm: 0.03992475901031867, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00383\n",
      "\tval loss: 0.00372\n",
      "epoch 15367 / 20000\n",
      "gradient norm: 0.05687429546378553, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00382\n",
      "\tval loss: 0.00371\n",
      "epoch 15368 / 20000\n",
      "gradient norm: 0.04168029804714024, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00382\n",
      "\tval loss: 0.00371\n",
      "epoch 15369 / 20000\n",
      "gradient norm: 0.07026351650711149, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00382\n",
      "\tval loss: 0.00372\n",
      "epoch 15370 / 20000\n",
      "gradient norm: 0.06726233439985663, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00382\n",
      "\tval loss: 0.00371\n",
      "epoch 15371 / 20000\n",
      "gradient norm: 0.11518401186913252, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00383\n",
      "\tval loss: 0.00370\n",
      "epoch 15372 / 20000\n",
      "gradient norm: 0.03297692473279312, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00381\n",
      "\tval loss: 0.00373\n",
      "epoch 15373 / 20000\n",
      "gradient norm: 0.06724419794045389, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00382\n",
      "\tval loss: 0.00371\n",
      "epoch 15374 / 20000\n",
      "gradient norm: 0.05238826834829524, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00381\n",
      "\tval loss: 0.00370\n",
      "epoch 15375 / 20000\n",
      "gradient norm: 0.06832455296535045, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00382\n",
      "\tval loss: 0.00370\n",
      "epoch 15376 / 20000\n",
      "gradient norm: 0.03418373939348385, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00381\n",
      "\tval loss: 0.00371\n",
      "epoch 15377 / 20000\n",
      "gradient norm: 0.06002562097273767, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00381\n",
      "\tval loss: 0.00369\n",
      "epoch 15378 / 20000\n",
      "gradient norm: 0.029154737771023065, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00380\n",
      "\tval loss: 0.00370\n",
      "epoch 15379 / 20000\n",
      "gradient norm: 0.03603367647156119, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00381\n",
      "\tval loss: 0.00369\n",
      "epoch 15380 / 20000\n",
      "gradient norm: 0.10349838808178902, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00380\n",
      "\tval loss: 0.00369\n",
      "epoch 15381 / 20000\n",
      "gradient norm: 0.06887716613709927, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00380\n",
      "\tval loss: 0.00369\n",
      "epoch 15382 / 20000\n",
      "gradient norm: 0.09304563305340707, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00379\n",
      "\tval loss: 0.00369\n",
      "epoch 15383 / 20000\n",
      "gradient norm: 0.10054498049430549, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00380\n",
      "\tval loss: 0.00370\n",
      "epoch 15384 / 20000\n",
      "gradient norm: 0.057339070714078844, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00379\n",
      "\tval loss: 0.00368\n",
      "epoch 15385 / 20000\n",
      "gradient norm: 0.047176240652333945, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00379\n",
      "\tval loss: 0.00369\n",
      "epoch 15386 / 20000\n",
      "gradient norm: 0.054618574591586366, minimum ratio: 2.4394736842105265\n",
      "\ttrain loss: 0.00379\n",
      "\tval loss: 0.00369\n",
      "epoch 15387 / 20000\n",
      "gradient norm: 0.08225816476624459, minimum ratio: 2.4447368421052627\n",
      "\ttrain loss: 0.00380\n",
      "\tval loss: 0.00368\n",
      "epoch 15388 / 20000\n",
      "gradient norm: 0.02307656459743157, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00378\n",
      "\tval loss: 0.00368\n",
      "epoch 15389 / 20000\n",
      "gradient norm: 0.045331056287977844, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00378\n",
      "\tval loss: 0.00368\n",
      "epoch 15390 / 20000\n",
      "gradient norm: 0.09832649026066065, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00379\n",
      "\tval loss: 0.00368\n",
      "epoch 15391 / 20000\n",
      "gradient norm: 0.06159368925727904, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00378\n",
      "\tval loss: 0.00367\n",
      "epoch 15392 / 20000\n",
      "gradient norm: 0.07329415180720389, minimum ratio: 2.4236842105263157\n",
      "\ttrain loss: 0.00378\n",
      "\tval loss: 0.00367\n",
      "epoch 15393 / 20000\n",
      "gradient norm: 0.058929926657583565, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00377\n",
      "\tval loss: 0.00369\n",
      "epoch 15394 / 20000\n",
      "gradient norm: 0.05272772797616199, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00377\n",
      "\tval loss: 0.00367\n",
      "epoch 15395 / 20000\n",
      "gradient norm: 0.07480608235346153, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00377\n",
      "\tval loss: 0.00366\n",
      "epoch 15396 / 20000\n",
      "gradient norm: 0.055935830518137664, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00377\n",
      "\tval loss: 0.00367\n",
      "epoch 15397 / 20000\n",
      "gradient norm: 0.051895039330702275, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00377\n",
      "\tval loss: 0.00368\n",
      "epoch 15398 / 20000\n",
      "gradient norm: 0.07781551260268316, minimum ratio: 2.4210526315789473\n",
      "\ttrain loss: 0.00378\n",
      "\tval loss: 0.00366\n",
      "epoch 15399 / 20000\n",
      "gradient norm: 0.053656396456062794, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00376\n",
      "\tval loss: 0.00366\n",
      "epoch 15400 / 20000\n",
      "gradient norm: 0.04137333310791291, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00376\n",
      "\tval loss: 0.00366\n",
      "epoch 15401 / 20000\n",
      "gradient norm: 0.046180357167031616, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00375\n",
      "\tval loss: 0.00365\n",
      "epoch 15402 / 20000\n",
      "gradient norm: 0.03595671383664012, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00377\n",
      "\tval loss: 0.00366\n",
      "epoch 15403 / 20000\n",
      "gradient norm: 0.07196277379989624, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00376\n",
      "\tval loss: 0.00365\n",
      "epoch 15404 / 20000\n",
      "gradient norm: 0.05657215905375779, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00375\n",
      "\tval loss: 0.00366\n",
      "epoch 15405 / 20000\n",
      "gradient norm: 0.05505108507350087, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00375\n",
      "\tval loss: 0.00365\n",
      "epoch 15406 / 20000\n",
      "gradient norm: 0.06403044622857124, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00375\n",
      "\tval loss: 0.00364\n",
      "epoch 15407 / 20000\n",
      "gradient norm: 0.035558918927563354, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00375\n",
      "\tval loss: 0.00365\n",
      "epoch 15408 / 20000\n",
      "gradient norm: 0.024982063099741936, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00374\n",
      "\tval loss: 0.00364\n",
      "epoch 15409 / 20000\n",
      "gradient norm: 0.06252343754749745, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00375\n",
      "\tval loss: 0.00364\n",
      "epoch 15410 / 20000\n",
      "gradient norm: 0.07735332904849201, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00374\n",
      "\tval loss: 0.00365\n",
      "epoch 15411 / 20000\n",
      "gradient norm: 0.06498991075204685, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00374\n",
      "\tval loss: 0.00364\n",
      "epoch 15412 / 20000\n",
      "gradient norm: 0.0687651140615344, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00374\n",
      "\tval loss: 0.00363\n",
      "epoch 15413 / 20000\n",
      "gradient norm: 0.05176163266878575, minimum ratio: 2.4236842105263157\n",
      "\ttrain loss: 0.00375\n",
      "\tval loss: 0.00364\n",
      "epoch 15414 / 20000\n",
      "gradient norm: 0.05319905641954392, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00374\n",
      "\tval loss: 0.00365\n",
      "epoch 15415 / 20000\n",
      "gradient norm: 0.04239945311564952, minimum ratio: 2.460526315789474\n",
      "\ttrain loss: 0.00374\n",
      "\tval loss: 0.00363\n",
      "epoch 15416 / 20000\n",
      "gradient norm: 0.08637453441042453, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00374\n",
      "\tval loss: 0.00363\n",
      "epoch 15417 / 20000\n",
      "gradient norm: 0.024385695753153414, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00373\n",
      "\tval loss: 0.00363\n",
      "epoch 15418 / 20000\n",
      "gradient norm: 0.06498141284100711, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00373\n",
      "\tval loss: 0.00364\n",
      "epoch 15419 / 20000\n",
      "gradient norm: 0.050589259481057525, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00372\n",
      "\tval loss: 0.00362\n",
      "epoch 15420 / 20000\n",
      "gradient norm: 0.054219078621827066, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00372\n",
      "\tval loss: 0.00362\n",
      "epoch 15421 / 20000\n",
      "gradient norm: 0.10750117257703096, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00373\n",
      "\tval loss: 0.00364\n",
      "epoch 15422 / 20000\n",
      "gradient norm: 0.054547282750718296, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00372\n",
      "\tval loss: 0.00361\n",
      "epoch 15423 / 20000\n",
      "gradient norm: 0.06973762076813728, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00372\n",
      "\tval loss: 0.00361\n",
      "epoch 15424 / 20000\n",
      "gradient norm: 0.0946803690167144, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00373\n",
      "\tval loss: 0.00364\n",
      "epoch 15425 / 20000\n",
      "gradient norm: 0.04522714362246916, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00371\n",
      "\tval loss: 0.00361\n",
      "epoch 15426 / 20000\n",
      "gradient norm: 0.07183508563321084, minimum ratio: 2.46578947368421\n",
      "\ttrain loss: 0.00372\n",
      "\tval loss: 0.00360\n",
      "epoch 15427 / 20000\n",
      "gradient norm: 0.06922365154605359, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00372\n",
      "\tval loss: 0.00362\n",
      "epoch 15428 / 20000\n",
      "gradient norm: 0.12797977833542973, minimum ratio: 2.46578947368421\n",
      "\ttrain loss: 0.00372\n",
      "\tval loss: 0.00361\n",
      "epoch 15429 / 20000\n",
      "gradient norm: 0.07739592011785135, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00371\n",
      "\tval loss: 0.00360\n",
      "epoch 15430 / 20000\n",
      "gradient norm: 0.07422099239192903, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00371\n",
      "\tval loss: 0.00361\n",
      "epoch 15431 / 20000\n",
      "gradient norm: 0.043341555225197226, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00370\n",
      "\tval loss: 0.00360\n",
      "epoch 15432 / 20000\n",
      "gradient norm: 0.07490480912383646, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00371\n",
      "\tval loss: 0.00360\n",
      "epoch 15433 / 20000\n",
      "gradient norm: 0.04631587129551917, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00371\n",
      "\tval loss: 0.00360\n",
      "epoch 15434 / 20000\n",
      "gradient norm: 0.050786557141691446, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00370\n",
      "\tval loss: 0.00360\n",
      "epoch 15435 / 20000\n",
      "gradient norm: 0.054561056720558554, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00369\n",
      "\tval loss: 0.00360\n",
      "epoch 15436 / 20000\n",
      "gradient norm: 0.05836324335541576, minimum ratio: 2.460526315789474\n",
      "\ttrain loss: 0.00370\n",
      "\tval loss: 0.00359\n",
      "epoch 15437 / 20000\n",
      "gradient norm: 0.0309385399450548, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00370\n",
      "\tval loss: 0.00360\n",
      "epoch 15438 / 20000\n",
      "gradient norm: 0.0385564123862423, minimum ratio: 2.4421052631578943\n",
      "\ttrain loss: 0.00369\n",
      "\tval loss: 0.00359\n",
      "epoch 15439 / 20000\n",
      "gradient norm: 0.07715667015872896, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00370\n",
      "\tval loss: 0.00358\n",
      "epoch 15440 / 20000\n",
      "gradient norm: 0.06325150770135224, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00368\n",
      "\tval loss: 0.00360\n",
      "epoch 15441 / 20000\n",
      "gradient norm: 0.06003295653499663, minimum ratio: 2.4447368421052635\n",
      "\ttrain loss: 0.00369\n",
      "\tval loss: 0.00358\n",
      "epoch 15442 / 20000\n",
      "gradient norm: 0.05652314523467794, minimum ratio: 2.46578947368421\n",
      "\ttrain loss: 0.00369\n",
      "\tval loss: 0.00358\n",
      "epoch 15443 / 20000\n",
      "gradient norm: 0.0812457445426844, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00369\n",
      "\tval loss: 0.00359\n",
      "epoch 15444 / 20000\n",
      "gradient norm: 0.056393974751699716, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00368\n",
      "\tval loss: 0.00358\n",
      "epoch 15445 / 20000\n",
      "gradient norm: 0.05068140581715852, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00368\n",
      "\tval loss: 0.00357\n",
      "epoch 15446 / 20000\n",
      "gradient norm: 0.03562669234815985, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00368\n",
      "\tval loss: 0.00358\n",
      "epoch 15447 / 20000\n",
      "gradient norm: 0.06775746715720743, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00367\n",
      "\tval loss: 0.00357\n",
      "epoch 15448 / 20000\n",
      "gradient norm: 0.0632895918097347, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00367\n",
      "\tval loss: 0.00357\n",
      "epoch 15449 / 20000\n",
      "gradient norm: 0.026663240103516728, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00367\n",
      "\tval loss: 0.00357\n",
      "epoch 15450 / 20000\n",
      "gradient norm: 0.04219282895792276, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00368\n",
      "\tval loss: 0.00357\n",
      "epoch 15451 / 20000\n",
      "gradient norm: 0.0449259431916289, minimum ratio: 2.460526315789474\n",
      "\ttrain loss: 0.00367\n",
      "\tval loss: 0.00357\n",
      "epoch 15452 / 20000\n",
      "gradient norm: 0.025895204220432788, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00366\n",
      "\tval loss: 0.00357\n",
      "epoch 15453 / 20000\n",
      "gradient norm: 0.06574445217847824, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00367\n",
      "\tval loss: 0.00356\n",
      "epoch 15454 / 20000\n",
      "gradient norm: 0.05750013887882233, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00367\n",
      "\tval loss: 0.00357\n",
      "epoch 15455 / 20000\n",
      "gradient norm: 0.01581618160707876, minimum ratio: 2.4394736842105265\n",
      "\ttrain loss: 0.00367\n",
      "\tval loss: 0.00356\n",
      "epoch 15456 / 20000\n",
      "gradient norm: 0.049560557294171304, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00366\n",
      "\tval loss: 0.00356\n",
      "epoch 15457 / 20000\n",
      "gradient norm: 0.04085796987055801, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00366\n",
      "\tval loss: 0.00355\n",
      "epoch 15458 / 20000\n",
      "gradient norm: 0.026739718101453036, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00365\n",
      "\tval loss: 0.00356\n",
      "epoch 15459 / 20000\n",
      "gradient norm: 0.040887597016990185, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00366\n",
      "\tval loss: 0.00355\n",
      "epoch 15460 / 20000\n",
      "gradient norm: 0.05486544867744669, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00365\n",
      "\tval loss: 0.00355\n",
      "epoch 15461 / 20000\n",
      "gradient norm: 0.0324921092542354, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00365\n",
      "\tval loss: 0.00356\n",
      "epoch 15462 / 20000\n",
      "gradient norm: 0.06611528791836463, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00365\n",
      "\tval loss: 0.00355\n",
      "epoch 15463 / 20000\n",
      "gradient norm: 0.08794423216022551, minimum ratio: 2.426315789473684\n",
      "\ttrain loss: 0.00364\n",
      "\tval loss: 0.00354\n",
      "epoch 15464 / 20000\n",
      "gradient norm: 0.045074440335156396, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00365\n",
      "\tval loss: 0.00355\n",
      "epoch 15465 / 20000\n",
      "gradient norm: 0.07468603609595448, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00365\n",
      "\tval loss: 0.00354\n",
      "epoch 15466 / 20000\n",
      "gradient norm: 0.04625787219265476, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00365\n",
      "\tval loss: 0.00354\n",
      "epoch 15467 / 20000\n",
      "gradient norm: 0.043392453459091485, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00365\n",
      "\tval loss: 0.00354\n",
      "epoch 15468 / 20000\n",
      "gradient norm: 0.04121568991104141, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00364\n",
      "\tval loss: 0.00354\n",
      "epoch 15469 / 20000\n",
      "gradient norm: 0.09131576144136488, minimum ratio: 2.4394736842105265\n",
      "\ttrain loss: 0.00363\n",
      "\tval loss: 0.00354\n",
      "epoch 15470 / 20000\n",
      "gradient norm: 0.07079528574831784, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00363\n",
      "\tval loss: 0.00353\n",
      "epoch 15471 / 20000\n",
      "gradient norm: 0.038730676198611036, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00363\n",
      "\tval loss: 0.00353\n",
      "epoch 15472 / 20000\n",
      "gradient norm: 0.04305818839929998, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00363\n",
      "\tval loss: 0.00353\n",
      "epoch 15473 / 20000\n",
      "gradient norm: 0.06284789799246937, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00363\n",
      "\tval loss: 0.00353\n",
      "epoch 15474 / 20000\n",
      "gradient norm: 0.0549952870933339, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00363\n",
      "\tval loss: 0.00354\n",
      "epoch 15475 / 20000\n",
      "gradient norm: 0.04079027700936422, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00362\n",
      "\tval loss: 0.00352\n",
      "epoch 15476 / 20000\n",
      "gradient norm: 0.049524670583195984, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00363\n",
      "\tval loss: 0.00352\n",
      "epoch 15477 / 20000\n",
      "gradient norm: 0.05871808686060831, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00363\n",
      "\tval loss: 0.00352\n",
      "epoch 15478 / 20000\n",
      "gradient norm: 0.06495738041121513, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00362\n",
      "\tval loss: 0.00353\n",
      "epoch 15479 / 20000\n",
      "gradient norm: 0.04108528030337766, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00361\n",
      "\tval loss: 0.00351\n",
      "epoch 15480 / 20000\n",
      "gradient norm: 0.05184942315099761, minimum ratio: 2.436842105263158\n",
      "\ttrain loss: 0.00362\n",
      "\tval loss: 0.00351\n",
      "epoch 15481 / 20000\n",
      "gradient norm: 0.057532341743353754, minimum ratio: 2.4263157894736844\n",
      "\ttrain loss: 0.00362\n",
      "\tval loss: 0.00353\n",
      "epoch 15482 / 20000\n",
      "gradient norm: 0.027015524683520198, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00360\n",
      "\tval loss: 0.00351\n",
      "epoch 15483 / 20000\n",
      "gradient norm: 0.04904313391307369, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00361\n",
      "\tval loss: 0.00350\n",
      "epoch 15484 / 20000\n",
      "gradient norm: 0.07229555526282638, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00360\n",
      "\tval loss: 0.00351\n",
      "epoch 15485 / 20000\n",
      "gradient norm: 0.07402461516903713, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00360\n",
      "\tval loss: 0.00350\n",
      "epoch 15486 / 20000\n",
      "gradient norm: 0.07351157581433654, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00359\n",
      "\tval loss: 0.00350\n",
      "epoch 15487 / 20000\n",
      "gradient norm: 0.044057618477381766, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00360\n",
      "\tval loss: 0.00350\n",
      "epoch 15488 / 20000\n",
      "gradient norm: 0.04310176277067512, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00360\n",
      "\tval loss: 0.00350\n",
      "epoch 15489 / 20000\n",
      "gradient norm: 0.06346719615976326, minimum ratio: 2.4394736842105265\n",
      "\ttrain loss: 0.00360\n",
      "\tval loss: 0.00350\n",
      "epoch 15490 / 20000\n",
      "gradient norm: 0.04530590167269111, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00359\n",
      "\tval loss: 0.00350\n",
      "epoch 15491 / 20000\n",
      "gradient norm: 0.03365148330340162, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00360\n",
      "\tval loss: 0.00349\n",
      "epoch 15492 / 20000\n",
      "gradient norm: 0.037229132489301264, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00359\n",
      "\tval loss: 0.00349\n",
      "epoch 15493 / 20000\n",
      "gradient norm: 0.07846371573396027, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00358\n",
      "\tval loss: 0.00351\n",
      "epoch 15494 / 20000\n",
      "gradient norm: 0.036010532814543694, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00359\n",
      "\tval loss: 0.00349\n",
      "epoch 15495 / 20000\n",
      "gradient norm: 0.05447209265548736, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00359\n",
      "\tval loss: 0.00348\n",
      "epoch 15496 / 20000\n",
      "gradient norm: 0.053090989822521806, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00359\n",
      "\tval loss: 0.00350\n",
      "epoch 15497 / 20000\n",
      "gradient norm: 0.04215983994072303, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00358\n",
      "\tval loss: 0.00348\n",
      "epoch 15498 / 20000\n",
      "gradient norm: 0.048346456489525735, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00358\n",
      "\tval loss: 0.00348\n",
      "epoch 15499 / 20000\n",
      "gradient norm: 0.04789066215744242, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00358\n",
      "\tval loss: 0.00348\n",
      "epoch 15500 / 20000\n",
      "gradient norm: 0.046029692399315536, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00358\n",
      "\tval loss: 0.00349\n",
      "epoch 15501 / 20000\n",
      "gradient norm: 0.021809537254739553, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00357\n",
      "\tval loss: 0.00348\n",
      "epoch 15502 / 20000\n",
      "gradient norm: 0.040633336058817804, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00356\n",
      "\tval loss: 0.00347\n",
      "epoch 15503 / 20000\n",
      "gradient norm: 0.02609834197210148, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00357\n",
      "\tval loss: 0.00348\n",
      "epoch 15504 / 20000\n",
      "gradient norm: 0.028971712687052786, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00357\n",
      "\tval loss: 0.00348\n",
      "epoch 15505 / 20000\n",
      "gradient norm: 0.04747991694603115, minimum ratio: 2.460526315789474\n",
      "\ttrain loss: 0.00356\n",
      "\tval loss: 0.00347\n",
      "epoch 15506 / 20000\n",
      "gradient norm: 0.01760826533427462, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00356\n",
      "\tval loss: 0.00347\n",
      "epoch 15507 / 20000\n",
      "gradient norm: 0.05899907770799473, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00356\n",
      "\tval loss: 0.00347\n",
      "epoch 15508 / 20000\n",
      "gradient norm: 0.024834992771502584, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00356\n",
      "\tval loss: 0.00347\n",
      "epoch 15509 / 20000\n",
      "gradient norm: 0.04010338295483962, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00357\n",
      "\tval loss: 0.00346\n",
      "epoch 15510 / 20000\n",
      "gradient norm: 0.07257912948261946, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00355\n",
      "\tval loss: 0.00347\n",
      "epoch 15511 / 20000\n",
      "gradient norm: 0.05642885767156258, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00356\n",
      "\tval loss: 0.00346\n",
      "epoch 15512 / 20000\n",
      "gradient norm: 0.045891204150393605, minimum ratio: 2.4499999999999997\n",
      "\ttrain loss: 0.00356\n",
      "\tval loss: 0.00346\n",
      "epoch 15513 / 20000\n",
      "gradient norm: 0.06297088976134546, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00355\n",
      "\tval loss: 0.00346\n",
      "epoch 15514 / 20000\n",
      "gradient norm: 0.05076083040330559, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00356\n",
      "\tval loss: 0.00346\n",
      "epoch 15515 / 20000\n",
      "gradient norm: 0.04049938847310841, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00354\n",
      "\tval loss: 0.00345\n",
      "epoch 15516 / 20000\n",
      "gradient norm: 0.07185792858945206, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00356\n",
      "\tval loss: 0.00344\n",
      "epoch 15517 / 20000\n",
      "gradient norm: 0.08776491729076952, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00356\n",
      "\tval loss: 0.00347\n",
      "epoch 15518 / 20000\n",
      "gradient norm: 0.044735221657902, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00354\n",
      "\tval loss: 0.00344\n",
      "epoch 15519 / 20000\n",
      "gradient norm: 0.07751529512461275, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00354\n",
      "\tval loss: 0.00344\n",
      "epoch 15520 / 20000\n",
      "gradient norm: 0.04130409087520093, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00354\n",
      "\tval loss: 0.00345\n",
      "epoch 15521 / 20000\n",
      "gradient norm: 0.04553531459532678, minimum ratio: 2.465789473684211\n",
      "\ttrain loss: 0.00355\n",
      "\tval loss: 0.00345\n",
      "epoch 15522 / 20000\n",
      "gradient norm: 0.049037389107979834, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00354\n",
      "\tval loss: 0.00344\n",
      "epoch 15523 / 20000\n",
      "gradient norm: 0.057419848861172795, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00354\n",
      "\tval loss: 0.00343\n",
      "epoch 15524 / 20000\n",
      "gradient norm: 0.06640008778776973, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00353\n",
      "\tval loss: 0.00345\n",
      "epoch 15525 / 20000\n",
      "gradient norm: 0.054744117078371346, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00354\n",
      "\tval loss: 0.00343\n",
      "epoch 15526 / 20000\n",
      "gradient norm: 0.08012039319146425, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00354\n",
      "\tval loss: 0.00343\n",
      "epoch 15527 / 20000\n",
      "gradient norm: 0.09221302240621299, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00353\n",
      "\tval loss: 0.00345\n",
      "epoch 15528 / 20000\n",
      "gradient norm: 0.05369624722516164, minimum ratio: 2.4447368421052627\n",
      "\ttrain loss: 0.00352\n",
      "\tval loss: 0.00342\n",
      "epoch 15529 / 20000\n",
      "gradient norm: 0.06844424386508763, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00354\n",
      "\tval loss: 0.00342\n",
      "epoch 15530 / 20000\n",
      "gradient norm: 0.06629508454352617, minimum ratio: 2.4394736842105265\n",
      "\ttrain loss: 0.00353\n",
      "\tval loss: 0.00344\n",
      "epoch 15531 / 20000\n",
      "gradient norm: 0.05936745530925691, minimum ratio: 2.4447368421052635\n",
      "\ttrain loss: 0.00352\n",
      "\tval loss: 0.00343\n",
      "epoch 15532 / 20000\n",
      "gradient norm: 0.02498570253374055, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00352\n",
      "\tval loss: 0.00342\n",
      "epoch 15533 / 20000\n",
      "gradient norm: 0.05994876904878765, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00352\n",
      "\tval loss: 0.00342\n",
      "epoch 15534 / 20000\n",
      "gradient norm: 0.046260297123808414, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00352\n",
      "\tval loss: 0.00342\n",
      "epoch 15535 / 20000\n",
      "gradient norm: 0.057321776053868234, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00351\n",
      "\tval loss: 0.00342\n",
      "epoch 15536 / 20000\n",
      "gradient norm: 0.044415420095901936, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00351\n",
      "\tval loss: 0.00341\n",
      "epoch 15537 / 20000\n",
      "gradient norm: 0.059673763113096356, minimum ratio: 2.4499999999999997\n",
      "\ttrain loss: 0.00351\n",
      "\tval loss: 0.00342\n",
      "epoch 15538 / 20000\n",
      "gradient norm: 0.03703926224261522, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00350\n",
      "\tval loss: 0.00341\n",
      "epoch 15539 / 20000\n",
      "gradient norm: 0.054629357531666756, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00351\n",
      "\tval loss: 0.00341\n",
      "epoch 15540 / 20000\n",
      "gradient norm: 0.11232416913844645, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00351\n",
      "\tval loss: 0.00342\n",
      "epoch 15541 / 20000\n",
      "gradient norm: 0.09552342531969771, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00352\n",
      "\tval loss: 0.00340\n",
      "epoch 15542 / 20000\n",
      "gradient norm: 0.04172451264457777, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00351\n",
      "\tval loss: 0.00342\n",
      "epoch 15543 / 20000\n",
      "gradient norm: 0.0923450356349349, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00351\n",
      "\tval loss: 0.00341\n",
      "epoch 15544 / 20000\n",
      "gradient norm: 0.06930332235060632, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00351\n",
      "\tval loss: 0.00340\n",
      "epoch 15545 / 20000\n",
      "gradient norm: 0.0581215547863394, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00350\n",
      "\tval loss: 0.00341\n",
      "epoch 15546 / 20000\n",
      "gradient norm: 0.06664773111697286, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00349\n",
      "\tval loss: 0.00341\n",
      "epoch 15547 / 20000\n",
      "gradient norm: 0.027665776724461466, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00349\n",
      "\tval loss: 0.00339\n",
      "epoch 15548 / 20000\n",
      "gradient norm: 0.0686216878821142, minimum ratio: 2.4394736842105265\n",
      "\ttrain loss: 0.00349\n",
      "\tval loss: 0.00339\n",
      "epoch 15549 / 20000\n",
      "gradient norm: 0.03368431847775355, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00348\n",
      "\tval loss: 0.00339\n",
      "epoch 15550 / 20000\n",
      "gradient norm: 0.028549605776788667, minimum ratio: 2.436842105263158\n",
      "\ttrain loss: 0.00348\n",
      "\tval loss: 0.00339\n",
      "epoch 15551 / 20000\n",
      "gradient norm: 0.04423882870469242, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00348\n",
      "\tval loss: 0.00339\n",
      "epoch 15552 / 20000\n",
      "gradient norm: 0.03640990721760318, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00348\n",
      "\tval loss: 0.00339\n",
      "epoch 15553 / 20000\n",
      "gradient norm: 0.04584354313556105, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00348\n",
      "\tval loss: 0.00338\n",
      "epoch 15554 / 20000\n",
      "gradient norm: 0.01358504471136257, minimum ratio: 2.423684210526316\n",
      "\ttrain loss: 0.00348\n",
      "\tval loss: 0.00339\n",
      "epoch 15555 / 20000\n",
      "gradient norm: 0.04489945256500505, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00347\n",
      "\tval loss: 0.00338\n",
      "epoch 15556 / 20000\n",
      "gradient norm: 0.034065009152982384, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00348\n",
      "\tval loss: 0.00338\n",
      "epoch 15557 / 20000\n",
      "gradient norm: 0.021293897356372327, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00348\n",
      "\tval loss: 0.00338\n",
      "epoch 15558 / 20000\n",
      "gradient norm: 0.04188007372431457, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00346\n",
      "\tval loss: 0.00338\n",
      "epoch 15559 / 20000\n",
      "gradient norm: 0.08427258301526308, minimum ratio: 2.4499999999999997\n",
      "\ttrain loss: 0.00348\n",
      "\tval loss: 0.00337\n",
      "epoch 15560 / 20000\n",
      "gradient norm: 0.08578196831513196, minimum ratio: 2.4421052631578943\n",
      "\ttrain loss: 0.00347\n",
      "\tval loss: 0.00338\n",
      "epoch 15561 / 20000\n",
      "gradient norm: 0.06988313258625567, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00347\n",
      "\tval loss: 0.00337\n",
      "epoch 15562 / 20000\n",
      "gradient norm: 0.03861941653303802, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00346\n",
      "\tval loss: 0.00336\n",
      "epoch 15563 / 20000\n",
      "gradient norm: 0.052032813779078424, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00346\n",
      "\tval loss: 0.00337\n",
      "epoch 15564 / 20000\n",
      "gradient norm: 0.04193329636473209, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00346\n",
      "\tval loss: 0.00336\n",
      "epoch 15565 / 20000\n",
      "gradient norm: 0.07713029521983117, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00346\n",
      "\tval loss: 0.00336\n",
      "epoch 15566 / 20000\n",
      "gradient norm: 0.017920840124133974, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00345\n",
      "\tval loss: 0.00337\n",
      "epoch 15567 / 20000\n",
      "gradient norm: 0.0644117527990602, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00346\n",
      "\tval loss: 0.00337\n",
      "epoch 15568 / 20000\n",
      "gradient norm: 0.09273022890556604, minimum ratio: 2.436842105263158\n",
      "\ttrain loss: 0.00346\n",
      "\tval loss: 0.00335\n",
      "epoch 15569 / 20000\n",
      "gradient norm: 0.07362265908159316, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00344\n",
      "\tval loss: 0.00337\n",
      "epoch 15570 / 20000\n",
      "gradient norm: 0.09897365921642631, minimum ratio: 2.465789473684211\n",
      "\ttrain loss: 0.00344\n",
      "\tval loss: 0.00336\n",
      "epoch 15571 / 20000\n",
      "gradient norm: 0.06808291736524552, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00345\n",
      "\tval loss: 0.00335\n",
      "epoch 15572 / 20000\n",
      "gradient norm: 0.05005007504951209, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00344\n",
      "\tval loss: 0.00336\n",
      "epoch 15573 / 20000\n",
      "gradient norm: 0.038136737304739654, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00344\n",
      "\tval loss: 0.00335\n",
      "epoch 15574 / 20000\n",
      "gradient norm: 0.05304394324775785, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00345\n",
      "\tval loss: 0.00334\n",
      "epoch 15575 / 20000\n",
      "gradient norm: 0.05533406522590667, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00344\n",
      "\tval loss: 0.00335\n",
      "epoch 15576 / 20000\n",
      "gradient norm: 0.049691541818901896, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00344\n",
      "\tval loss: 0.00334\n",
      "epoch 15577 / 20000\n",
      "gradient norm: 0.05712199315894395, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00343\n",
      "\tval loss: 0.00334\n",
      "epoch 15578 / 20000\n",
      "gradient norm: 0.05491190651082434, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00342\n",
      "\tval loss: 0.00334\n",
      "epoch 15579 / 20000\n",
      "gradient norm: 0.02181429386837408, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00342\n",
      "\tval loss: 0.00334\n",
      "epoch 15580 / 20000\n",
      "gradient norm: 0.03179771269788034, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00343\n",
      "\tval loss: 0.00333\n",
      "epoch 15581 / 20000\n",
      "gradient norm: 0.11609788553323597, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00343\n",
      "\tval loss: 0.00334\n",
      "epoch 15582 / 20000\n",
      "gradient norm: 0.05168959073489532, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00343\n",
      "\tval loss: 0.00335\n",
      "epoch 15583 / 20000\n",
      "gradient norm: 0.037074281310196966, minimum ratio: 2.4289473684210523\n",
      "\ttrain loss: 0.00343\n",
      "\tval loss: 0.00333\n",
      "epoch 15584 / 20000\n",
      "gradient norm: 0.07142959535121918, minimum ratio: 2.460526315789474\n",
      "\ttrain loss: 0.00342\n",
      "\tval loss: 0.00333\n",
      "epoch 15585 / 20000\n",
      "gradient norm: 0.09196328674443066, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00343\n",
      "\tval loss: 0.00334\n",
      "epoch 15586 / 20000\n",
      "gradient norm: 0.053120088297873735, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00342\n",
      "\tval loss: 0.00332\n",
      "epoch 15587 / 20000\n",
      "gradient norm: 0.06597129051806405, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00342\n",
      "\tval loss: 0.00332\n",
      "epoch 15588 / 20000\n",
      "gradient norm: 0.05029721319442615, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00342\n",
      "\tval loss: 0.00333\n",
      "epoch 15589 / 20000\n",
      "gradient norm: 0.06539539783261716, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00342\n",
      "\tval loss: 0.00331\n",
      "epoch 15590 / 20000\n",
      "gradient norm: 0.052523943362757564, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00341\n",
      "\tval loss: 0.00332\n",
      "epoch 15591 / 20000\n",
      "gradient norm: 0.05931315216002986, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00340\n",
      "\tval loss: 0.00332\n",
      "epoch 15592 / 20000\n",
      "gradient norm: 0.045813270029611886, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00341\n",
      "\tval loss: 0.00331\n",
      "epoch 15593 / 20000\n",
      "gradient norm: 0.039090503996703774, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00340\n",
      "\tval loss: 0.00331\n",
      "epoch 15594 / 20000\n",
      "gradient norm: 0.03692531771957874, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00340\n",
      "\tval loss: 0.00332\n",
      "epoch 15595 / 20000\n",
      "gradient norm: 0.027185398153960705, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00340\n",
      "\tval loss: 0.00331\n",
      "epoch 15596 / 20000\n",
      "gradient norm: 0.05551168310921639, minimum ratio: 2.46578947368421\n",
      "\ttrain loss: 0.00340\n",
      "\tval loss: 0.00331\n",
      "epoch 15597 / 20000\n",
      "gradient norm: 0.07302998087834567, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00340\n",
      "\tval loss: 0.00331\n",
      "epoch 15598 / 20000\n",
      "gradient norm: 0.05240442184731364, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00340\n",
      "\tval loss: 0.00330\n",
      "epoch 15599 / 20000\n",
      "gradient norm: 0.08361494349082932, minimum ratio: 2.4263157894736844\n",
      "\ttrain loss: 0.00340\n",
      "\tval loss: 0.00330\n",
      "epoch 15600 / 20000\n",
      "gradient norm: 0.05604187905555591, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00340\n",
      "\tval loss: 0.00331\n",
      "epoch 15601 / 20000\n",
      "gradient norm: 0.05932725709863007, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00339\n",
      "\tval loss: 0.00329\n",
      "epoch 15602 / 20000\n",
      "gradient norm: 0.06764701509382576, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00339\n",
      "\tval loss: 0.00330\n",
      "epoch 15603 / 20000\n",
      "gradient norm: 0.05297685164259747, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00339\n",
      "\tval loss: 0.00331\n",
      "epoch 15604 / 20000\n",
      "gradient norm: 0.08611470577307045, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00339\n",
      "\tval loss: 0.00329\n",
      "epoch 15605 / 20000\n",
      "gradient norm: 0.030958050803747028, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00338\n",
      "\tval loss: 0.00329\n",
      "epoch 15606 / 20000\n",
      "gradient norm: 0.0424330725800246, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00339\n",
      "\tval loss: 0.00329\n",
      "epoch 15607 / 20000\n",
      "gradient norm: 0.03748696844559163, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00338\n",
      "\tval loss: 0.00329\n",
      "epoch 15608 / 20000\n",
      "gradient norm: 0.0544981523999013, minimum ratio: 2.4263157894736844\n",
      "\ttrain loss: 0.00338\n",
      "\tval loss: 0.00329\n",
      "epoch 15609 / 20000\n",
      "gradient norm: 0.051241634879261255, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00338\n",
      "\tval loss: 0.00328\n",
      "epoch 15610 / 20000\n",
      "gradient norm: 0.04450996860396117, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00337\n",
      "\tval loss: 0.00329\n",
      "epoch 15611 / 20000\n",
      "gradient norm: 0.06728806311730295, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00337\n",
      "\tval loss: 0.00328\n",
      "epoch 15612 / 20000\n",
      "gradient norm: 0.09365294058807194, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00338\n",
      "\tval loss: 0.00328\n",
      "epoch 15613 / 20000\n",
      "gradient norm: 0.052765056607313454, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00338\n",
      "\tval loss: 0.00329\n",
      "epoch 15614 / 20000\n",
      "gradient norm: 0.07278959301766008, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00338\n",
      "\tval loss: 0.00327\n",
      "epoch 15615 / 20000\n",
      "gradient norm: 0.03566305176354945, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00336\n",
      "\tval loss: 0.00328\n",
      "epoch 15616 / 20000\n",
      "gradient norm: 0.06732218153774738, minimum ratio: 2.4394736842105265\n",
      "\ttrain loss: 0.00337\n",
      "\tval loss: 0.00329\n",
      "epoch 15617 / 20000\n",
      "gradient norm: 0.03723522060317919, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00335\n",
      "\tval loss: 0.00327\n",
      "epoch 15618 / 20000\n",
      "gradient norm: 0.05938747595064342, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00336\n",
      "\tval loss: 0.00327\n",
      "epoch 15619 / 20000\n",
      "gradient norm: 0.03266704443376511, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00336\n",
      "\tval loss: 0.00327\n",
      "epoch 15620 / 20000\n",
      "gradient norm: 0.04041727806907147, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00337\n",
      "\tval loss: 0.00327\n",
      "epoch 15621 / 20000\n",
      "gradient norm: 0.033318369183689356, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00337\n",
      "\tval loss: 0.00326\n",
      "epoch 15622 / 20000\n",
      "gradient norm: 0.06761003303108737, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00336\n",
      "\tval loss: 0.00326\n",
      "epoch 15623 / 20000\n",
      "gradient norm: 0.05474922666326165, minimum ratio: 2.4394736842105265\n",
      "\ttrain loss: 0.00335\n",
      "\tval loss: 0.00326\n",
      "epoch 15624 / 20000\n",
      "gradient norm: 0.01898443012032658, minimum ratio: 2.4263157894736844\n",
      "\ttrain loss: 0.00335\n",
      "\tval loss: 0.00326\n",
      "epoch 15625 / 20000\n",
      "gradient norm: 0.0811303521040827, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00335\n",
      "\tval loss: 0.00325\n",
      "epoch 15626 / 20000\n",
      "gradient norm: 0.057742806791793555, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00334\n",
      "\tval loss: 0.00327\n",
      "epoch 15627 / 20000\n",
      "gradient norm: 0.04886195779545233, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00335\n",
      "\tval loss: 0.00325\n",
      "epoch 15628 / 20000\n",
      "gradient norm: 0.07967797230230644, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00335\n",
      "\tval loss: 0.00325\n",
      "epoch 15629 / 20000\n",
      "gradient norm: 0.08356118993833661, minimum ratio: 2.4499999999999997\n",
      "\ttrain loss: 0.00335\n",
      "\tval loss: 0.00327\n",
      "epoch 15630 / 20000\n",
      "gradient norm: 0.0604081655619666, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00335\n",
      "\tval loss: 0.00324\n",
      "epoch 15631 / 20000\n",
      "gradient norm: 0.08013970742467791, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00334\n",
      "\tval loss: 0.00324\n",
      "epoch 15632 / 20000\n",
      "gradient norm: 0.03384481358807534, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00333\n",
      "\tval loss: 0.00325\n",
      "epoch 15633 / 20000\n",
      "gradient norm: 0.09081734518986195, minimum ratio: 2.4447368421052635\n",
      "\ttrain loss: 0.00334\n",
      "\tval loss: 0.00324\n",
      "epoch 15634 / 20000\n",
      "gradient norm: 0.03663689753739163, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00334\n",
      "\tval loss: 0.00324\n",
      "epoch 15635 / 20000\n",
      "gradient norm: 0.0360922243562527, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00333\n",
      "\tval loss: 0.00324\n",
      "epoch 15636 / 20000\n",
      "gradient norm: 0.06313722248887643, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00333\n",
      "\tval loss: 0.00324\n",
      "epoch 15637 / 20000\n",
      "gradient norm: 0.05448617896763608, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00333\n",
      "\tval loss: 0.00324\n",
      "epoch 15638 / 20000\n",
      "gradient norm: 0.044647056492976844, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00332\n",
      "\tval loss: 0.00323\n",
      "epoch 15639 / 20000\n",
      "gradient norm: 0.04787310212850571, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00331\n",
      "\tval loss: 0.00324\n",
      "epoch 15640 / 20000\n",
      "gradient norm: 0.03562702419003472, minimum ratio: 2.447368421052631\n",
      "\ttrain loss: 0.00332\n",
      "\tval loss: 0.00323\n",
      "epoch 15641 / 20000\n",
      "gradient norm: 0.06848482694476843, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00333\n",
      "\tval loss: 0.00323\n",
      "epoch 15642 / 20000\n",
      "gradient norm: 0.07530448981560767, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00332\n",
      "\tval loss: 0.00324\n",
      "epoch 15643 / 20000\n",
      "gradient norm: 0.06516404380090535, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00332\n",
      "\tval loss: 0.00322\n",
      "epoch 15644 / 20000\n",
      "gradient norm: 0.06757974810898304, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00331\n",
      "\tval loss: 0.00322\n",
      "epoch 15645 / 20000\n",
      "gradient norm: 0.04756516986526549, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00330\n",
      "\tval loss: 0.00324\n",
      "epoch 15646 / 20000\n",
      "gradient norm: 0.05450605374062434, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00331\n",
      "\tval loss: 0.00322\n",
      "epoch 15647 / 20000\n",
      "gradient norm: 0.08168026187922806, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00332\n",
      "\tval loss: 0.00321\n",
      "epoch 15648 / 20000\n",
      "gradient norm: 0.04213371028890833, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00331\n",
      "\tval loss: 0.00323\n",
      "epoch 15649 / 20000\n",
      "gradient norm: 0.0705957623431459, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00330\n",
      "\tval loss: 0.00323\n",
      "epoch 15650 / 20000\n",
      "gradient norm: 0.040814244537614286, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00330\n",
      "\tval loss: 0.00321\n",
      "epoch 15651 / 20000\n",
      "gradient norm: 0.08717431302648038, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00330\n",
      "\tval loss: 0.00321\n",
      "epoch 15652 / 20000\n",
      "gradient norm: 0.02635913126869127, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00329\n",
      "\tval loss: 0.00322\n",
      "epoch 15653 / 20000\n",
      "gradient norm: 0.0519486250996124, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00330\n",
      "\tval loss: 0.00321\n",
      "epoch 15654 / 20000\n",
      "gradient norm: 0.041064094635657966, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00329\n",
      "\tval loss: 0.00320\n",
      "epoch 15655 / 20000\n",
      "gradient norm: 0.07061370543669909, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00330\n",
      "\tval loss: 0.00320\n",
      "epoch 15656 / 20000\n",
      "gradient norm: 0.06934385054046288, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00329\n",
      "\tval loss: 0.00322\n",
      "epoch 15657 / 20000\n",
      "gradient norm: 0.07763828244060278, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00329\n",
      "\tval loss: 0.00319\n",
      "epoch 15658 / 20000\n",
      "gradient norm: 0.04548160475678742, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00329\n",
      "\tval loss: 0.00320\n",
      "epoch 15659 / 20000\n",
      "gradient norm: 0.040870129290851764, minimum ratio: 2.460526315789474\n",
      "\ttrain loss: 0.00328\n",
      "\tval loss: 0.00320\n",
      "epoch 15660 / 20000\n",
      "gradient norm: 0.024471720273140818, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00328\n",
      "\tval loss: 0.00319\n",
      "epoch 15661 / 20000\n",
      "gradient norm: 0.03687916212948039, minimum ratio: 2.4421052631578943\n",
      "\ttrain loss: 0.00328\n",
      "\tval loss: 0.00319\n",
      "epoch 15662 / 20000\n",
      "gradient norm: 0.05061784933786839, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00327\n",
      "\tval loss: 0.00320\n",
      "epoch 15663 / 20000\n",
      "gradient norm: 0.04532648384338245, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00328\n",
      "\tval loss: 0.00318\n",
      "epoch 15664 / 20000\n",
      "gradient norm: 0.06014568777754903, minimum ratio: 2.46578947368421\n",
      "\ttrain loss: 0.00327\n",
      "\tval loss: 0.00319\n",
      "epoch 15665 / 20000\n",
      "gradient norm: 0.07696080242749304, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00327\n",
      "\tval loss: 0.00319\n",
      "epoch 15666 / 20000\n",
      "gradient norm: 0.0726930892560631, minimum ratio: 2.4499999999999997\n",
      "\ttrain loss: 0.00329\n",
      "\tval loss: 0.00318\n",
      "epoch 15667 / 20000\n",
      "gradient norm: 0.059784419427160174, minimum ratio: 2.436842105263158\n",
      "\ttrain loss: 0.00327\n",
      "\tval loss: 0.00320\n",
      "epoch 15668 / 20000\n",
      "gradient norm: 0.0548185765510425, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00327\n",
      "\tval loss: 0.00318\n",
      "epoch 15669 / 20000\n",
      "gradient norm: 0.059655669960193336, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00326\n",
      "\tval loss: 0.00317\n",
      "epoch 15670 / 20000\n",
      "gradient norm: 0.04146472422871739, minimum ratio: 2.4394736842105265\n",
      "\ttrain loss: 0.00326\n",
      "\tval loss: 0.00318\n",
      "epoch 15671 / 20000\n",
      "gradient norm: 0.03848998004104942, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00326\n",
      "\tval loss: 0.00318\n",
      "epoch 15672 / 20000\n",
      "gradient norm: 0.033650594181381166, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00326\n",
      "\tval loss: 0.00317\n",
      "epoch 15673 / 20000\n",
      "gradient norm: 0.05713523249141872, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00327\n",
      "\tval loss: 0.00317\n",
      "epoch 15674 / 20000\n",
      "gradient norm: 0.0593935267534107, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00326\n",
      "\tval loss: 0.00318\n",
      "epoch 15675 / 20000\n",
      "gradient norm: 0.037592034379485995, minimum ratio: 2.4447368421052635\n",
      "\ttrain loss: 0.00325\n",
      "\tval loss: 0.00317\n",
      "epoch 15676 / 20000\n",
      "gradient norm: 0.05963453929871321, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00325\n",
      "\tval loss: 0.00316\n",
      "epoch 15677 / 20000\n",
      "gradient norm: 0.04759282898157835, minimum ratio: 2.4499999999999997\n",
      "\ttrain loss: 0.00326\n",
      "\tval loss: 0.00317\n",
      "epoch 15678 / 20000\n",
      "gradient norm: 0.05701139062875882, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00325\n",
      "\tval loss: 0.00317\n",
      "epoch 15679 / 20000\n",
      "gradient norm: 0.110852557932958, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00326\n",
      "\tval loss: 0.00315\n",
      "epoch 15680 / 20000\n",
      "gradient norm: 0.04913528583711013, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00325\n",
      "\tval loss: 0.00317\n",
      "epoch 15681 / 20000\n",
      "gradient norm: 0.03441761469002813, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00324\n",
      "\tval loss: 0.00316\n",
      "epoch 15682 / 20000\n",
      "gradient norm: 0.07653683982789516, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00326\n",
      "\tval loss: 0.00315\n",
      "epoch 15683 / 20000\n",
      "gradient norm: 0.07176972622983158, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00324\n",
      "\tval loss: 0.00316\n",
      "epoch 15684 / 20000\n",
      "gradient norm: 0.047420475166291, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00324\n",
      "\tval loss: 0.00315\n",
      "epoch 15685 / 20000\n",
      "gradient norm: 0.044100197323132306, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00324\n",
      "\tval loss: 0.00315\n",
      "epoch 15686 / 20000\n",
      "gradient norm: 0.0591022934531793, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00324\n",
      "\tval loss: 0.00316\n",
      "epoch 15687 / 20000\n",
      "gradient norm: 0.04224571769009344, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00322\n",
      "\tval loss: 0.00315\n",
      "epoch 15688 / 20000\n",
      "gradient norm: 0.058513623604085296, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00323\n",
      "\tval loss: 0.00314\n",
      "epoch 15689 / 20000\n",
      "gradient norm: 0.04177915852051228, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00322\n",
      "\tval loss: 0.00315\n",
      "epoch 15690 / 20000\n",
      "gradient norm: 0.06444373482372612, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00323\n",
      "\tval loss: 0.00315\n",
      "epoch 15691 / 20000\n",
      "gradient norm: 0.06509326852392405, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00323\n",
      "\tval loss: 0.00313\n",
      "epoch 15692 / 20000\n",
      "gradient norm: 0.05303998797899112, minimum ratio: 2.46578947368421\n",
      "\ttrain loss: 0.00322\n",
      "\tval loss: 0.00314\n",
      "epoch 15693 / 20000\n",
      "gradient norm: 0.05892298719845712, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00323\n",
      "\tval loss: 0.00314\n",
      "epoch 15694 / 20000\n",
      "gradient norm: 0.07450092234648764, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00321\n",
      "\tval loss: 0.00314\n",
      "epoch 15695 / 20000\n",
      "gradient norm: 0.0527806103345938, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00322\n",
      "\tval loss: 0.00313\n",
      "epoch 15696 / 20000\n",
      "gradient norm: 0.06305349885951728, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00321\n",
      "\tval loss: 0.00313\n",
      "epoch 15697 / 20000\n",
      "gradient norm: 0.03327499522129074, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00321\n",
      "\tval loss: 0.00313\n",
      "epoch 15698 / 20000\n",
      "gradient norm: 0.03956689091864973, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00322\n",
      "\tval loss: 0.00313\n",
      "epoch 15699 / 20000\n",
      "gradient norm: 0.059573356760665774, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00321\n",
      "\tval loss: 0.00312\n",
      "epoch 15700 / 20000\n",
      "gradient norm: 0.06701482529751956, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00321\n",
      "\tval loss: 0.00312\n",
      "epoch 15701 / 20000\n",
      "gradient norm: 0.03688189515378326, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00321\n",
      "\tval loss: 0.00313\n",
      "epoch 15702 / 20000\n",
      "gradient norm: 0.06692765525076538, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00321\n",
      "\tval loss: 0.00312\n",
      "epoch 15703 / 20000\n",
      "gradient norm: 0.06787366338539869, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00321\n",
      "\tval loss: 0.00312\n",
      "epoch 15704 / 20000\n",
      "gradient norm: 0.03856690489919856, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00321\n",
      "\tval loss: 0.00313\n",
      "epoch 15705 / 20000\n",
      "gradient norm: 0.04948207538109273, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00320\n",
      "\tval loss: 0.00312\n",
      "epoch 15706 / 20000\n",
      "gradient norm: 0.04064969823230058, minimum ratio: 2.4394736842105265\n",
      "\ttrain loss: 0.00320\n",
      "\tval loss: 0.00311\n",
      "epoch 15707 / 20000\n",
      "gradient norm: 0.05244519014377147, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00320\n",
      "\tval loss: 0.00312\n",
      "epoch 15708 / 20000\n",
      "gradient norm: 0.022637254267465323, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00319\n",
      "\tval loss: 0.00311\n",
      "epoch 15709 / 20000\n",
      "gradient norm: 0.03708056069444865, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00319\n",
      "\tval loss: 0.00311\n",
      "epoch 15710 / 20000\n",
      "gradient norm: 0.03823492326773703, minimum ratio: 2.4499999999999997\n",
      "\ttrain loss: 0.00319\n",
      "\tval loss: 0.00311\n",
      "epoch 15711 / 20000\n",
      "gradient norm: 0.02552895399276167, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00318\n",
      "\tval loss: 0.00310\n",
      "epoch 15712 / 20000\n",
      "gradient norm: 0.051270361291244626, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00319\n",
      "\tval loss: 0.00310\n",
      "epoch 15713 / 20000\n",
      "gradient norm: 0.05833905190229416, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00319\n",
      "\tval loss: 0.00311\n",
      "epoch 15714 / 20000\n",
      "gradient norm: 0.06910524144768715, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00319\n",
      "\tval loss: 0.00310\n",
      "epoch 15715 / 20000\n",
      "gradient norm: 0.04087820032145828, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00318\n",
      "\tval loss: 0.00310\n",
      "epoch 15716 / 20000\n",
      "gradient norm: 0.029736181546468288, minimum ratio: 2.423684210526316\n",
      "\ttrain loss: 0.00317\n",
      "\tval loss: 0.00309\n",
      "epoch 15717 / 20000\n",
      "gradient norm: 0.027133469353429973, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00318\n",
      "\tval loss: 0.00309\n",
      "epoch 15718 / 20000\n",
      "gradient norm: 0.10993421822786331, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00317\n",
      "\tval loss: 0.00309\n",
      "epoch 15719 / 20000\n",
      "gradient norm: 0.021965674008242786, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00318\n",
      "\tval loss: 0.00309\n",
      "epoch 15720 / 20000\n",
      "gradient norm: 0.08204206533264369, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00318\n",
      "\tval loss: 0.00309\n",
      "epoch 15721 / 20000\n",
      "gradient norm: 0.06013246451038867, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00317\n",
      "\tval loss: 0.00309\n",
      "epoch 15722 / 20000\n",
      "gradient norm: 0.020779495069291443, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00316\n",
      "\tval loss: 0.00308\n",
      "epoch 15723 / 20000\n",
      "gradient norm: 0.029487555206287652, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00316\n",
      "\tval loss: 0.00308\n",
      "epoch 15724 / 20000\n",
      "gradient norm: 0.05825019266922027, minimum ratio: 2.460526315789474\n",
      "\ttrain loss: 0.00316\n",
      "\tval loss: 0.00308\n",
      "epoch 15725 / 20000\n",
      "gradient norm: 0.06953380396589637, minimum ratio: 2.4499999999999997\n",
      "\ttrain loss: 0.00317\n",
      "\tval loss: 0.00308\n",
      "epoch 15726 / 20000\n",
      "gradient norm: 0.0535496526863426, minimum ratio: 2.492105263157895\n",
      "\ttrain loss: 0.00317\n",
      "\tval loss: 0.00308\n",
      "epoch 15727 / 20000\n",
      "gradient norm: 0.06016957003157586, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00316\n",
      "\tval loss: 0.00308\n",
      "epoch 15728 / 20000\n",
      "gradient norm: 0.053272622695658356, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00316\n",
      "\tval loss: 0.00307\n",
      "epoch 15729 / 20000\n",
      "gradient norm: 0.08336180995684117, minimum ratio: 2.4263157894736844\n",
      "\ttrain loss: 0.00316\n",
      "\tval loss: 0.00307\n",
      "epoch 15730 / 20000\n",
      "gradient norm: 0.042990640795324, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00315\n",
      "\tval loss: 0.00307\n",
      "epoch 15731 / 20000\n",
      "gradient norm: 0.09820358757860959, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00316\n",
      "\tval loss: 0.00307\n",
      "epoch 15732 / 20000\n",
      "gradient norm: 0.05256161914439872, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00316\n",
      "\tval loss: 0.00306\n",
      "epoch 15733 / 20000\n",
      "gradient norm: 0.07484503625892103, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00315\n",
      "\tval loss: 0.00307\n",
      "epoch 15734 / 20000\n",
      "gradient norm: 0.025774317618925124, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00315\n",
      "\tval loss: 0.00306\n",
      "epoch 15735 / 20000\n",
      "gradient norm: 0.04525416676187888, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00314\n",
      "\tval loss: 0.00306\n",
      "epoch 15736 / 20000\n",
      "gradient norm: 0.038707172439899296, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00315\n",
      "\tval loss: 0.00306\n",
      "epoch 15737 / 20000\n",
      "gradient norm: 0.06146220304071903, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00314\n",
      "\tval loss: 0.00306\n",
      "epoch 15738 / 20000\n",
      "gradient norm: 0.02710472303442657, minimum ratio: 2.436842105263158\n",
      "\ttrain loss: 0.00313\n",
      "\tval loss: 0.00306\n",
      "epoch 15739 / 20000\n",
      "gradient norm: 0.03641849587438628, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00313\n",
      "\tval loss: 0.00305\n",
      "epoch 15740 / 20000\n",
      "gradient norm: 0.03623608674388379, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00313\n",
      "\tval loss: 0.00305\n",
      "epoch 15741 / 20000\n",
      "gradient norm: 0.0617919527576305, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00314\n",
      "\tval loss: 0.00305\n",
      "epoch 15742 / 20000\n",
      "gradient norm: 0.04211131689953618, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00313\n",
      "\tval loss: 0.00305\n",
      "epoch 15743 / 20000\n",
      "gradient norm: 0.029387583024799824, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00313\n",
      "\tval loss: 0.00305\n",
      "epoch 15744 / 20000\n",
      "gradient norm: 0.026308224798412994, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00313\n",
      "\tval loss: 0.00305\n",
      "epoch 15745 / 20000\n",
      "gradient norm: 0.04017107636900619, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00312\n",
      "\tval loss: 0.00304\n",
      "epoch 15746 / 20000\n",
      "gradient norm: 0.08380244864383712, minimum ratio: 2.4447368421052627\n",
      "\ttrain loss: 0.00313\n",
      "\tval loss: 0.00304\n",
      "epoch 15747 / 20000\n",
      "gradient norm: 0.05360488162841648, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00312\n",
      "\tval loss: 0.00304\n",
      "epoch 15748 / 20000\n",
      "gradient norm: 0.03123146790312603, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00312\n",
      "\tval loss: 0.00305\n",
      "epoch 15749 / 20000\n",
      "gradient norm: 0.046957443802966736, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00312\n",
      "\tval loss: 0.00304\n",
      "epoch 15750 / 20000\n",
      "gradient norm: 0.056587693572510034, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00312\n",
      "\tval loss: 0.00303\n",
      "epoch 15751 / 20000\n",
      "gradient norm: 0.03942364342219662, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00311\n",
      "\tval loss: 0.00304\n",
      "epoch 15752 / 20000\n",
      "gradient norm: 0.033155986515339464, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00311\n",
      "\tval loss: 0.00303\n",
      "epoch 15753 / 20000\n",
      "gradient norm: 0.0490034754620865, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00311\n",
      "\tval loss: 0.00303\n",
      "epoch 15754 / 20000\n",
      "gradient norm: 0.06576454458991066, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00311\n",
      "\tval loss: 0.00303\n",
      "epoch 15755 / 20000\n",
      "gradient norm: 0.0635335044353269, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00311\n",
      "\tval loss: 0.00302\n",
      "epoch 15756 / 20000\n",
      "gradient norm: 0.03900075478304643, minimum ratio: 2.4499999999999997\n",
      "\ttrain loss: 0.00310\n",
      "\tval loss: 0.00303\n",
      "epoch 15757 / 20000\n",
      "gradient norm: 0.0402186727442313, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00310\n",
      "\tval loss: 0.00302\n",
      "epoch 15758 / 20000\n",
      "gradient norm: 0.055048075737431645, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00310\n",
      "\tval loss: 0.00302\n",
      "epoch 15759 / 20000\n",
      "gradient norm: 0.057006811315659434, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00310\n",
      "\tval loss: 0.00302\n",
      "epoch 15760 / 20000\n",
      "gradient norm: 0.023066096240654588, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00310\n",
      "\tval loss: 0.00302\n",
      "epoch 15761 / 20000\n",
      "gradient norm: 0.05688796506728977, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00309\n",
      "\tval loss: 0.00302\n",
      "epoch 15762 / 20000\n",
      "gradient norm: 0.046280151524115354, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00310\n",
      "\tval loss: 0.00301\n",
      "epoch 15763 / 20000\n",
      "gradient norm: 0.028028995380736887, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00309\n",
      "\tval loss: 0.00301\n",
      "epoch 15764 / 20000\n",
      "gradient norm: 0.04145860706921667, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00309\n",
      "\tval loss: 0.00301\n",
      "epoch 15765 / 20000\n",
      "gradient norm: 0.0416052617947571, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00309\n",
      "\tval loss: 0.00301\n",
      "epoch 15766 / 20000\n",
      "gradient norm: 0.034345436084549874, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00308\n",
      "\tval loss: 0.00301\n",
      "epoch 15767 / 20000\n",
      "gradient norm: 0.04338003904558718, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00308\n",
      "\tval loss: 0.00301\n",
      "epoch 15768 / 20000\n",
      "gradient norm: 0.05135621770750731, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00308\n",
      "\tval loss: 0.00300\n",
      "epoch 15769 / 20000\n",
      "gradient norm: 0.022026437742169946, minimum ratio: 2.4684210526315784\n",
      "\ttrain loss: 0.00307\n",
      "\tval loss: 0.00300\n",
      "epoch 15770 / 20000\n",
      "gradient norm: 0.0288093623239547, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00308\n",
      "\tval loss: 0.00300\n",
      "epoch 15771 / 20000\n",
      "gradient norm: 0.04629428335465491, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00307\n",
      "\tval loss: 0.00300\n",
      "epoch 15772 / 20000\n",
      "gradient norm: 0.020802863815333694, minimum ratio: 2.4421052631578943\n",
      "\ttrain loss: 0.00307\n",
      "\tval loss: 0.00300\n",
      "epoch 15773 / 20000\n",
      "gradient norm: 0.0250276000588201, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00308\n",
      "\tval loss: 0.00300\n",
      "epoch 15774 / 20000\n",
      "gradient norm: 0.03187917557079345, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00307\n",
      "\tval loss: 0.00299\n",
      "epoch 15775 / 20000\n",
      "gradient norm: 0.0581600631121546, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00307\n",
      "\tval loss: 0.00300\n",
      "epoch 15776 / 20000\n",
      "gradient norm: 0.026895507937297225, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00307\n",
      "\tval loss: 0.00299\n",
      "epoch 15777 / 20000\n",
      "gradient norm: 0.04900299815926701, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00307\n",
      "\tval loss: 0.00299\n",
      "epoch 15778 / 20000\n",
      "gradient norm: 0.060101128299720585, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00306\n",
      "\tval loss: 0.00299\n",
      "epoch 15779 / 20000\n",
      "gradient norm: 0.0410447739996016, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00307\n",
      "\tval loss: 0.00298\n",
      "epoch 15780 / 20000\n",
      "gradient norm: 0.014107623544987291, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00306\n",
      "\tval loss: 0.00298\n",
      "epoch 15781 / 20000\n",
      "gradient norm: 0.02833545790053904, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00306\n",
      "\tval loss: 0.00298\n",
      "epoch 15782 / 20000\n",
      "gradient norm: 0.03715555340750143, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00306\n",
      "\tval loss: 0.00298\n",
      "epoch 15783 / 20000\n",
      "gradient norm: 0.0797571613220498, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00305\n",
      "\tval loss: 0.00298\n",
      "epoch 15784 / 20000\n",
      "gradient norm: 0.07531663234112784, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00306\n",
      "\tval loss: 0.00297\n",
      "epoch 15785 / 20000\n",
      "gradient norm: 0.02838659571716562, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00305\n",
      "\tval loss: 0.00298\n",
      "epoch 15786 / 20000\n",
      "gradient norm: 0.05604800139553845, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00306\n",
      "\tval loss: 0.00297\n",
      "epoch 15787 / 20000\n",
      "gradient norm: 0.07168376742629334, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00305\n",
      "\tval loss: 0.00297\n",
      "epoch 15788 / 20000\n",
      "gradient norm: 0.07645982998656109, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00306\n",
      "\tval loss: 0.00296\n",
      "epoch 15789 / 20000\n",
      "gradient norm: 0.04416233883239329, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00304\n",
      "\tval loss: 0.00298\n",
      "epoch 15790 / 20000\n",
      "gradient norm: 0.051620688929688185, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00305\n",
      "\tval loss: 0.00296\n",
      "epoch 15791 / 20000\n",
      "gradient norm: 0.04043772263685241, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00304\n",
      "\tval loss: 0.00296\n",
      "epoch 15792 / 20000\n",
      "gradient norm: 0.034187865210697055, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00304\n",
      "\tval loss: 0.00297\n",
      "epoch 15793 / 20000\n",
      "gradient norm: 0.046417452103924006, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00304\n",
      "\tval loss: 0.00296\n",
      "epoch 15794 / 20000\n",
      "gradient norm: 0.04740199737716466, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00303\n",
      "\tval loss: 0.00295\n",
      "epoch 15795 / 20000\n",
      "gradient norm: 0.0346060314332135, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00304\n",
      "\tval loss: 0.00296\n",
      "epoch 15796 / 20000\n",
      "gradient norm: 0.03230217384407297, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00303\n",
      "\tval loss: 0.00296\n",
      "epoch 15797 / 20000\n",
      "gradient norm: 0.046258132555522025, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00303\n",
      "\tval loss: 0.00295\n",
      "epoch 15798 / 20000\n",
      "gradient norm: 0.04649042442906648, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00303\n",
      "\tval loss: 0.00295\n",
      "epoch 15799 / 20000\n",
      "gradient norm: 0.03927844495046884, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00303\n",
      "\tval loss: 0.00295\n",
      "epoch 15800 / 20000\n",
      "gradient norm: 0.03043731235084124, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00302\n",
      "\tval loss: 0.00295\n",
      "epoch 15801 / 20000\n",
      "gradient norm: 0.0747732447925955, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00303\n",
      "\tval loss: 0.00294\n",
      "epoch 15802 / 20000\n",
      "gradient norm: 0.02761175061459653, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00302\n",
      "\tval loss: 0.00295\n",
      "epoch 15803 / 20000\n",
      "gradient norm: 0.05139170802431181, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00302\n",
      "\tval loss: 0.00295\n",
      "epoch 15804 / 20000\n",
      "gradient norm: 0.061507773119956255, minimum ratio: 2.4394736842105265\n",
      "\ttrain loss: 0.00302\n",
      "\tval loss: 0.00294\n",
      "epoch 15805 / 20000\n",
      "gradient norm: 0.053560279426164925, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00301\n",
      "\tval loss: 0.00294\n",
      "epoch 15806 / 20000\n",
      "gradient norm: 0.04933199635706842, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00302\n",
      "\tval loss: 0.00295\n",
      "epoch 15807 / 20000\n",
      "gradient norm: 0.028196919651236385, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00301\n",
      "\tval loss: 0.00293\n",
      "epoch 15808 / 20000\n",
      "gradient norm: 0.03831063292454928, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00301\n",
      "\tval loss: 0.00293\n",
      "epoch 15809 / 20000\n",
      "gradient norm: 0.03399482899112627, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00300\n",
      "\tval loss: 0.00294\n",
      "epoch 15810 / 20000\n",
      "gradient norm: 0.0672223896253854, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00301\n",
      "\tval loss: 0.00293\n",
      "epoch 15811 / 20000\n",
      "gradient norm: 0.07963240204844624, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00301\n",
      "\tval loss: 0.00292\n",
      "epoch 15812 / 20000\n",
      "gradient norm: 0.08515446312958375, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00300\n",
      "\tval loss: 0.00292\n",
      "epoch 15813 / 20000\n",
      "gradient norm: 0.04049195538391359, minimum ratio: 2.4447368421052635\n",
      "\ttrain loss: 0.00300\n",
      "\tval loss: 0.00293\n",
      "epoch 15814 / 20000\n",
      "gradient norm: 0.04300827137194574, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00299\n",
      "\tval loss: 0.00293\n",
      "epoch 15815 / 20000\n",
      "gradient norm: 0.054145472357049584, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00300\n",
      "\tval loss: 0.00292\n",
      "epoch 15816 / 20000\n",
      "gradient norm: 0.03018796117976308, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00299\n",
      "\tval loss: 0.00293\n",
      "epoch 15817 / 20000\n",
      "gradient norm: 0.051865139859728515, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00300\n",
      "\tval loss: 0.00292\n",
      "epoch 15818 / 20000\n",
      "gradient norm: 0.04519522236660123, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00300\n",
      "\tval loss: 0.00292\n",
      "epoch 15819 / 20000\n",
      "gradient norm: 0.03736993024358526, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00299\n",
      "\tval loss: 0.00292\n",
      "epoch 15820 / 20000\n",
      "gradient norm: 0.053449593600817025, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00298\n",
      "\tval loss: 0.00291\n",
      "epoch 15821 / 20000\n",
      "gradient norm: 0.0635999342193827, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00299\n",
      "\tval loss: 0.00291\n",
      "epoch 15822 / 20000\n",
      "gradient norm: 0.10000450297957286, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00299\n",
      "\tval loss: 0.00290\n",
      "epoch 15823 / 20000\n",
      "gradient norm: 0.03734595165587962, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00298\n",
      "\tval loss: 0.00292\n",
      "epoch 15824 / 20000\n",
      "gradient norm: 0.04882813966833055, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00298\n",
      "\tval loss: 0.00290\n",
      "epoch 15825 / 20000\n",
      "gradient norm: 0.04357876506401226, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00298\n",
      "\tval loss: 0.00290\n",
      "epoch 15826 / 20000\n",
      "gradient norm: 0.05408917399472557, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00298\n",
      "\tval loss: 0.00291\n",
      "epoch 15827 / 20000\n",
      "gradient norm: 0.07846489310031757, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00298\n",
      "\tval loss: 0.00291\n",
      "epoch 15828 / 20000\n",
      "gradient norm: 0.035268625302705914, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00297\n",
      "\tval loss: 0.00289\n",
      "epoch 15829 / 20000\n",
      "gradient norm: 0.03994359727948904, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00297\n",
      "\tval loss: 0.00290\n",
      "epoch 15830 / 20000\n",
      "gradient norm: 0.07234967639669776, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00298\n",
      "\tval loss: 0.00290\n",
      "epoch 15831 / 20000\n",
      "gradient norm: 0.024241808016085997, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00297\n",
      "\tval loss: 0.00289\n",
      "epoch 15832 / 20000\n",
      "gradient norm: 0.066192417871207, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00297\n",
      "\tval loss: 0.00289\n",
      "epoch 15833 / 20000\n",
      "gradient norm: 0.05470197007525712, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00296\n",
      "\tval loss: 0.00289\n",
      "epoch 15834 / 20000\n",
      "gradient norm: 0.03079329535830766, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00296\n",
      "\tval loss: 0.00289\n",
      "epoch 15835 / 20000\n",
      "gradient norm: 0.07493375532794744, minimum ratio: 2.460526315789474\n",
      "\ttrain loss: 0.00296\n",
      "\tval loss: 0.00289\n",
      "epoch 15836 / 20000\n",
      "gradient norm: 0.043782178836409, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00296\n",
      "\tval loss: 0.00288\n",
      "epoch 15837 / 20000\n",
      "gradient norm: 0.049546684487722814, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00296\n",
      "\tval loss: 0.00289\n",
      "epoch 15838 / 20000\n",
      "gradient norm: 0.05556528817396611, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00296\n",
      "\tval loss: 0.00288\n",
      "epoch 15839 / 20000\n",
      "gradient norm: 0.014862175128655508, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00295\n",
      "\tval loss: 0.00288\n",
      "epoch 15840 / 20000\n",
      "gradient norm: 0.05725321383215487, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00296\n",
      "\tval loss: 0.00288\n",
      "epoch 15841 / 20000\n",
      "gradient norm: 0.04701517368084751, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00295\n",
      "\tval loss: 0.00287\n",
      "epoch 15842 / 20000\n",
      "gradient norm: 0.03622253134381026, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00295\n",
      "\tval loss: 0.00288\n",
      "epoch 15843 / 20000\n",
      "gradient norm: 0.0280607424210757, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00295\n",
      "\tval loss: 0.00287\n",
      "epoch 15844 / 20000\n",
      "gradient norm: 0.052745408029295504, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00295\n",
      "\tval loss: 0.00287\n",
      "epoch 15845 / 20000\n",
      "gradient norm: 0.030048547661863267, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00294\n",
      "\tval loss: 0.00286\n",
      "epoch 15846 / 20000\n",
      "gradient norm: 0.044654180703219026, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00294\n",
      "\tval loss: 0.00287\n",
      "epoch 15847 / 20000\n",
      "gradient norm: 0.04353176831500605, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00294\n",
      "\tval loss: 0.00287\n",
      "epoch 15848 / 20000\n",
      "gradient norm: 0.049120228679385036, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00293\n",
      "\tval loss: 0.00286\n",
      "epoch 15849 / 20000\n",
      "gradient norm: 0.044071832904592156, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00294\n",
      "\tval loss: 0.00286\n",
      "epoch 15850 / 20000\n",
      "gradient norm: 0.0319278875249438, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00294\n",
      "\tval loss: 0.00286\n",
      "epoch 15851 / 20000\n",
      "gradient norm: 0.027670827141264454, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00293\n",
      "\tval loss: 0.00286\n",
      "epoch 15852 / 20000\n",
      "gradient norm: 0.06589451571926475, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00293\n",
      "\tval loss: 0.00286\n",
      "epoch 15853 / 20000\n",
      "gradient norm: 0.10710507875774056, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00294\n",
      "\tval loss: 0.00286\n",
      "epoch 15854 / 20000\n",
      "gradient norm: 0.05720923317130655, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00293\n",
      "\tval loss: 0.00285\n",
      "epoch 15855 / 20000\n",
      "gradient norm: 0.06905321800149977, minimum ratio: 2.426315789473684\n",
      "\ttrain loss: 0.00294\n",
      "\tval loss: 0.00285\n",
      "epoch 15856 / 20000\n",
      "gradient norm: 0.06624785321764648, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00293\n",
      "\tval loss: 0.00287\n",
      "epoch 15857 / 20000\n",
      "gradient norm: 0.08265572157688439, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00293\n",
      "\tval loss: 0.00284\n",
      "epoch 15858 / 20000\n",
      "gradient norm: 0.11918084067292511, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00292\n",
      "\tval loss: 0.00285\n",
      "epoch 15859 / 20000\n",
      "gradient norm: 0.05202535801799968, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00292\n",
      "\tval loss: 0.00284\n",
      "epoch 15860 / 20000\n",
      "gradient norm: 0.08150959468912333, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00293\n",
      "\tval loss: 0.00286\n",
      "epoch 15861 / 20000\n",
      "gradient norm: 0.054821826284751296, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00291\n",
      "\tval loss: 0.00284\n",
      "epoch 15862 / 20000\n",
      "gradient norm: 0.03778701490955427, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00291\n",
      "\tval loss: 0.00284\n",
      "epoch 15863 / 20000\n",
      "gradient norm: 0.09224151156377047, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00291\n",
      "\tval loss: 0.00285\n",
      "epoch 15864 / 20000\n",
      "gradient norm: 0.032482317939866334, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00290\n",
      "\tval loss: 0.00283\n",
      "epoch 15865 / 20000\n",
      "gradient norm: 0.09053336351644248, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00292\n",
      "\tval loss: 0.00283\n",
      "epoch 15866 / 20000\n",
      "gradient norm: 0.056087684351950884, minimum ratio: 2.460526315789474\n",
      "\ttrain loss: 0.00291\n",
      "\tval loss: 0.00286\n",
      "epoch 15867 / 20000\n",
      "gradient norm: 0.0599134957883507, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00291\n",
      "\tval loss: 0.00283\n",
      "epoch 15868 / 20000\n",
      "gradient norm: 0.0750819545937702, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00292\n",
      "\tval loss: 0.00282\n",
      "epoch 15869 / 20000\n",
      "gradient norm: 0.06006987427826971, minimum ratio: 2.4499999999999997\n",
      "\ttrain loss: 0.00290\n",
      "\tval loss: 0.00285\n",
      "epoch 15870 / 20000\n",
      "gradient norm: 0.065272023959551, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00290\n",
      "\tval loss: 0.00282\n",
      "epoch 15871 / 20000\n",
      "gradient norm: 0.04089909925824031, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00290\n",
      "\tval loss: 0.00282\n",
      "epoch 15872 / 20000\n",
      "gradient norm: 0.03509357658913359, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00290\n",
      "\tval loss: 0.00283\n",
      "epoch 15873 / 20000\n",
      "gradient norm: 0.021591601020190865, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00290\n",
      "\tval loss: 0.00282\n",
      "epoch 15874 / 20000\n",
      "gradient norm: 0.03774161863839254, minimum ratio: 2.4263157894736844\n",
      "\ttrain loss: 0.00288\n",
      "\tval loss: 0.00282\n",
      "epoch 15875 / 20000\n",
      "gradient norm: 0.03937486658105627, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00289\n",
      "\tval loss: 0.00281\n",
      "epoch 15876 / 20000\n",
      "gradient norm: 0.04242681944742799, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00288\n",
      "\tval loss: 0.00282\n",
      "epoch 15877 / 20000\n",
      "gradient norm: 0.021312351571395993, minimum ratio: 2.4157894736842103\n",
      "\ttrain loss: 0.00288\n",
      "\tval loss: 0.00281\n",
      "epoch 15878 / 20000\n",
      "gradient norm: 0.06642003130400553, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00289\n",
      "\tval loss: 0.00281\n",
      "epoch 15879 / 20000\n",
      "gradient norm: 0.04370961815584451, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00288\n",
      "\tval loss: 0.00281\n",
      "epoch 15880 / 20000\n",
      "gradient norm: 0.06525038287509233, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00289\n",
      "\tval loss: 0.00280\n",
      "epoch 15881 / 20000\n",
      "gradient norm: 0.049049676570575684, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00288\n",
      "\tval loss: 0.00282\n",
      "epoch 15882 / 20000\n",
      "gradient norm: 0.08022547652944922, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00288\n",
      "\tval loss: 0.00280\n",
      "epoch 15883 / 20000\n",
      "gradient norm: 0.051688984502106905, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00287\n",
      "\tval loss: 0.00280\n",
      "epoch 15884 / 20000\n",
      "gradient norm: 0.05201426992425695, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00287\n",
      "\tval loss: 0.00281\n",
      "epoch 15885 / 20000\n",
      "gradient norm: 0.02730089786928147, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00286\n",
      "\tval loss: 0.00280\n",
      "epoch 15886 / 20000\n",
      "gradient norm: 0.03920955181820318, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00287\n",
      "\tval loss: 0.00279\n",
      "epoch 15887 / 20000\n",
      "gradient norm: 0.07971770613221452, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00287\n",
      "\tval loss: 0.00280\n",
      "epoch 15888 / 20000\n",
      "gradient norm: 0.028200929635204375, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00287\n",
      "\tval loss: 0.00279\n",
      "epoch 15889 / 20000\n",
      "gradient norm: 0.062148312106728554, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00286\n",
      "\tval loss: 0.00279\n",
      "epoch 15890 / 20000\n",
      "gradient norm: 0.029650876342202537, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00287\n",
      "\tval loss: 0.00279\n",
      "epoch 15891 / 20000\n",
      "gradient norm: 0.04320700996322557, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00286\n",
      "\tval loss: 0.00279\n",
      "epoch 15892 / 20000\n",
      "gradient norm: 0.02395755285397172, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00286\n",
      "\tval loss: 0.00278\n",
      "epoch 15893 / 20000\n",
      "gradient norm: 0.0411519244662486, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00286\n",
      "\tval loss: 0.00278\n",
      "epoch 15894 / 20000\n",
      "gradient norm: 0.03731408259773161, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00286\n",
      "\tval loss: 0.00278\n",
      "epoch 15895 / 20000\n",
      "gradient norm: 0.04738894623005763, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00284\n",
      "\tval loss: 0.00278\n",
      "epoch 15896 / 20000\n",
      "gradient norm: 0.05294733971823007, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00285\n",
      "\tval loss: 0.00278\n",
      "epoch 15897 / 20000\n",
      "gradient norm: 0.026121580856852233, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00285\n",
      "\tval loss: 0.00278\n",
      "epoch 15898 / 20000\n",
      "gradient norm: 0.04830293660052121, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00284\n",
      "\tval loss: 0.00278\n",
      "epoch 15899 / 20000\n",
      "gradient norm: 0.05440829647704959, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00285\n",
      "\tval loss: 0.00277\n",
      "epoch 15900 / 20000\n",
      "gradient norm: 0.025956021097954363, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00285\n",
      "\tval loss: 0.00277\n",
      "epoch 15901 / 20000\n",
      "gradient norm: 0.05994634982198477, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00285\n",
      "\tval loss: 0.00278\n",
      "epoch 15902 / 20000\n",
      "gradient norm: 0.027606741583440453, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00284\n",
      "\tval loss: 0.00277\n",
      "epoch 15903 / 20000\n",
      "gradient norm: 0.03903771238401532, minimum ratio: 2.4184210526315795\n",
      "\ttrain loss: 0.00284\n",
      "\tval loss: 0.00277\n",
      "epoch 15904 / 20000\n",
      "gradient norm: 0.027518932736711577, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00283\n",
      "\tval loss: 0.00276\n",
      "epoch 15905 / 20000\n",
      "gradient norm: 0.026619415380991995, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00283\n",
      "\tval loss: 0.00276\n",
      "epoch 15906 / 20000\n",
      "gradient norm: 0.03520834550727159, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00283\n",
      "\tval loss: 0.00276\n",
      "epoch 15907 / 20000\n",
      "gradient norm: 0.08697988733183593, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00284\n",
      "\tval loss: 0.00276\n",
      "epoch 15908 / 20000\n",
      "gradient norm: 0.037245530576910824, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00282\n",
      "\tval loss: 0.00277\n",
      "epoch 15909 / 20000\n",
      "gradient norm: 0.044088010559789836, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00283\n",
      "\tval loss: 0.00275\n",
      "epoch 15910 / 20000\n",
      "gradient norm: 0.06097762775607407, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00283\n",
      "\tval loss: 0.00275\n",
      "epoch 15911 / 20000\n",
      "gradient norm: 0.08203573466744274, minimum ratio: 2.4394736842105265\n",
      "\ttrain loss: 0.00284\n",
      "\tval loss: 0.00278\n",
      "epoch 15912 / 20000\n",
      "gradient norm: 0.0462604493368417, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00282\n",
      "\tval loss: 0.00275\n",
      "epoch 15913 / 20000\n",
      "gradient norm: 0.07455005601514131, minimum ratio: 2.4394736842105265\n",
      "\ttrain loss: 0.00282\n",
      "\tval loss: 0.00275\n",
      "epoch 15914 / 20000\n",
      "gradient norm: 0.07682144403224811, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00282\n",
      "\tval loss: 0.00276\n",
      "epoch 15915 / 20000\n",
      "gradient norm: 0.04302518820622936, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00282\n",
      "\tval loss: 0.00274\n",
      "epoch 15916 / 20000\n",
      "gradient norm: 0.058747937553562224, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00281\n",
      "\tval loss: 0.00274\n",
      "epoch 15917 / 20000\n",
      "gradient norm: 0.03059648966882378, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00281\n",
      "\tval loss: 0.00274\n",
      "epoch 15918 / 20000\n",
      "gradient norm: 0.04859583231154829, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00281\n",
      "\tval loss: 0.00274\n",
      "epoch 15919 / 20000\n",
      "gradient norm: 0.05414761009160429, minimum ratio: 2.4447368421052627\n",
      "\ttrain loss: 0.00281\n",
      "\tval loss: 0.00274\n",
      "epoch 15920 / 20000\n",
      "gradient norm: 0.03570502350339666, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00281\n",
      "\tval loss: 0.00274\n",
      "epoch 15921 / 20000\n",
      "gradient norm: 0.035484457621350884, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00281\n",
      "\tval loss: 0.00273\n",
      "epoch 15922 / 20000\n",
      "gradient norm: 0.07684572506695986, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00281\n",
      "\tval loss: 0.00274\n",
      "epoch 15923 / 20000\n",
      "gradient norm: 0.06896635855082422, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00280\n",
      "\tval loss: 0.00275\n",
      "epoch 15924 / 20000\n",
      "gradient norm: 0.0705180304357782, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00281\n",
      "\tval loss: 0.00273\n",
      "epoch 15925 / 20000\n",
      "gradient norm: 0.056533007067628205, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00281\n",
      "\tval loss: 0.00273\n",
      "epoch 15926 / 20000\n",
      "gradient norm: 0.031015841872431338, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00279\n",
      "\tval loss: 0.00273\n",
      "epoch 15927 / 20000\n",
      "gradient norm: 0.012901945563498884, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00280\n",
      "\tval loss: 0.00272\n",
      "epoch 15928 / 20000\n",
      "gradient norm: 0.036160586634650826, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00279\n",
      "\tval loss: 0.00272\n",
      "epoch 15929 / 20000\n",
      "gradient norm: 0.06138478883076459, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00279\n",
      "\tval loss: 0.00273\n",
      "epoch 15930 / 20000\n",
      "gradient norm: 0.05407209164695814, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00278\n",
      "\tval loss: 0.00272\n",
      "epoch 15931 / 20000\n",
      "gradient norm: 0.04919921467080712, minimum ratio: 2.4394736842105265\n",
      "\ttrain loss: 0.00279\n",
      "\tval loss: 0.00272\n",
      "epoch 15932 / 20000\n",
      "gradient norm: 0.01731947110965848, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00279\n",
      "\tval loss: 0.00272\n",
      "epoch 15933 / 20000\n",
      "gradient norm: 0.03797895851312205, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00279\n",
      "\tval loss: 0.00272\n",
      "epoch 15934 / 20000\n",
      "gradient norm: 0.08655421523144469, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00278\n",
      "\tval loss: 0.00271\n",
      "epoch 15935 / 20000\n",
      "gradient norm: 0.07261190679855645, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00279\n",
      "\tval loss: 0.00271\n",
      "epoch 15936 / 20000\n",
      "gradient norm: 0.04302190657472238, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00278\n",
      "\tval loss: 0.00271\n",
      "epoch 15937 / 20000\n",
      "gradient norm: 0.06174786016345024, minimum ratio: 2.4394736842105265\n",
      "\ttrain loss: 0.00278\n",
      "\tval loss: 0.00272\n",
      "epoch 15938 / 20000\n",
      "gradient norm: 0.023379675520118326, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00277\n",
      "\tval loss: 0.00271\n",
      "epoch 15939 / 20000\n",
      "gradient norm: 0.03964084410108626, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00277\n",
      "\tval loss: 0.00270\n",
      "epoch 15940 / 20000\n",
      "gradient norm: 0.045645100297406316, minimum ratio: 2.46578947368421\n",
      "\ttrain loss: 0.00278\n",
      "\tval loss: 0.00270\n",
      "epoch 15941 / 20000\n",
      "gradient norm: 0.06596900545991957, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00277\n",
      "\tval loss: 0.00271\n",
      "epoch 15942 / 20000\n",
      "gradient norm: 0.04032869474031031, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00278\n",
      "\tval loss: 0.00270\n",
      "epoch 15943 / 20000\n",
      "gradient norm: 0.03917306271614507, minimum ratio: 2.46578947368421\n",
      "\ttrain loss: 0.00276\n",
      "\tval loss: 0.00270\n",
      "epoch 15944 / 20000\n",
      "gradient norm: 0.053988371160812676, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00276\n",
      "\tval loss: 0.00270\n",
      "epoch 15945 / 20000\n",
      "gradient norm: 0.061186209437437356, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00276\n",
      "\tval loss: 0.00270\n",
      "epoch 15946 / 20000\n",
      "gradient norm: 0.02718066266970709, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00277\n",
      "\tval loss: 0.00269\n",
      "epoch 15947 / 20000\n",
      "gradient norm: 0.03472362452885136, minimum ratio: 2.4421052631578943\n",
      "\ttrain loss: 0.00275\n",
      "\tval loss: 0.00269\n",
      "epoch 15948 / 20000\n",
      "gradient norm: 0.03656327706994489, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00276\n",
      "\tval loss: 0.00269\n",
      "epoch 15949 / 20000\n",
      "gradient norm: 0.060309345833957195, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00276\n",
      "\tval loss: 0.00269\n",
      "epoch 15950 / 20000\n",
      "gradient norm: 0.036223948816768825, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00275\n",
      "\tval loss: 0.00268\n",
      "epoch 15951 / 20000\n",
      "gradient norm: 0.06734677270287648, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00275\n",
      "\tval loss: 0.00268\n",
      "epoch 15952 / 20000\n",
      "gradient norm: 0.07186847506090999, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00276\n",
      "\tval loss: 0.00270\n",
      "epoch 15953 / 20000\n",
      "gradient norm: 0.04843772598542273, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00276\n",
      "\tval loss: 0.00268\n",
      "epoch 15954 / 20000\n",
      "gradient norm: 0.058887948747724295, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00275\n",
      "\tval loss: 0.00268\n",
      "epoch 15955 / 20000\n",
      "gradient norm: 0.042144968057982624, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00274\n",
      "\tval loss: 0.00269\n",
      "epoch 15956 / 20000\n",
      "gradient norm: 0.04010785720311105, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00274\n",
      "\tval loss: 0.00267\n",
      "epoch 15957 / 20000\n",
      "gradient norm: 0.06343633693177253, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00274\n",
      "\tval loss: 0.00267\n",
      "epoch 15958 / 20000\n",
      "gradient norm: 0.05213292402913794, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00274\n",
      "\tval loss: 0.00268\n",
      "epoch 15959 / 20000\n",
      "gradient norm: 0.03078087724861689, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00273\n",
      "\tval loss: 0.00267\n",
      "epoch 15960 / 20000\n",
      "gradient norm: 0.04936647473368794, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00274\n",
      "\tval loss: 0.00266\n",
      "epoch 15961 / 20000\n",
      "gradient norm: 0.03217298712115735, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00273\n",
      "\tval loss: 0.00267\n",
      "epoch 15962 / 20000\n",
      "gradient norm: 0.05814294400624931, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00273\n",
      "\tval loss: 0.00267\n",
      "epoch 15963 / 20000\n",
      "gradient norm: 0.08117882715305313, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00275\n",
      "\tval loss: 0.00266\n",
      "epoch 15964 / 20000\n",
      "gradient norm: 0.05759477603714913, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00274\n",
      "\tval loss: 0.00267\n",
      "epoch 15965 / 20000\n",
      "gradient norm: 0.08203766192309558, minimum ratio: 2.46578947368421\n",
      "\ttrain loss: 0.00273\n",
      "\tval loss: 0.00266\n",
      "epoch 15966 / 20000\n",
      "gradient norm: 0.06340796675067395, minimum ratio: 2.423684210526316\n",
      "\ttrain loss: 0.00272\n",
      "\tval loss: 0.00266\n",
      "epoch 15967 / 20000\n",
      "gradient norm: 0.06711255043046549, minimum ratio: 2.4499999999999997\n",
      "\ttrain loss: 0.00273\n",
      "\tval loss: 0.00266\n",
      "epoch 15968 / 20000\n",
      "gradient norm: 0.05237768997903913, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00273\n",
      "\tval loss: 0.00267\n",
      "epoch 15969 / 20000\n",
      "gradient norm: 0.059936234552878886, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00272\n",
      "\tval loss: 0.00265\n",
      "epoch 15970 / 20000\n",
      "gradient norm: 0.027125043678097427, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00271\n",
      "\tval loss: 0.00265\n",
      "epoch 15971 / 20000\n",
      "gradient norm: 0.05539823102299124, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00272\n",
      "\tval loss: 0.00266\n",
      "epoch 15972 / 20000\n",
      "gradient norm: 0.0418413428706117, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00271\n",
      "\tval loss: 0.00265\n",
      "epoch 15973 / 20000\n",
      "gradient norm: 0.030076970462687314, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00271\n",
      "\tval loss: 0.00265\n",
      "epoch 15974 / 20000\n",
      "gradient norm: 0.03219814563635737, minimum ratio: 2.4157894736842103\n",
      "\ttrain loss: 0.00271\n",
      "\tval loss: 0.00265\n",
      "epoch 15975 / 20000\n",
      "gradient norm: 0.04674282652558759, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00271\n",
      "\tval loss: 0.00264\n",
      "epoch 15976 / 20000\n",
      "gradient norm: 0.03498735750326887, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00271\n",
      "\tval loss: 0.00265\n",
      "epoch 15977 / 20000\n",
      "gradient norm: 0.03910444036591798, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00271\n",
      "\tval loss: 0.00264\n",
      "epoch 15978 / 20000\n",
      "gradient norm: 0.05130765016656369, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00271\n",
      "\tval loss: 0.00263\n",
      "epoch 15979 / 20000\n",
      "gradient norm: 0.05298686685273424, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00270\n",
      "\tval loss: 0.00264\n",
      "epoch 15980 / 20000\n",
      "gradient norm: 0.029368922696448863, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00270\n",
      "\tval loss: 0.00263\n",
      "epoch 15981 / 20000\n",
      "gradient norm: 0.02597995856194757, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00269\n",
      "\tval loss: 0.00263\n",
      "epoch 15982 / 20000\n",
      "gradient norm: 0.07287996797822416, minimum ratio: 2.4394736842105265\n",
      "\ttrain loss: 0.00270\n",
      "\tval loss: 0.00264\n",
      "epoch 15983 / 20000\n",
      "gradient norm: 0.0450931754312478, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00270\n",
      "\tval loss: 0.00263\n",
      "epoch 15984 / 20000\n",
      "gradient norm: 0.03385957729187794, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00269\n",
      "\tval loss: 0.00263\n",
      "epoch 15985 / 20000\n",
      "gradient norm: 0.020960365771315992, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00269\n",
      "\tval loss: 0.00263\n",
      "epoch 15986 / 20000\n",
      "gradient norm: 0.043909075204283, minimum ratio: 2.426315789473684\n",
      "\ttrain loss: 0.00269\n",
      "\tval loss: 0.00262\n",
      "epoch 15987 / 20000\n",
      "gradient norm: 0.06974198669195175, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00270\n",
      "\tval loss: 0.00262\n",
      "epoch 15988 / 20000\n",
      "gradient norm: 0.038498203502967954, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00269\n",
      "\tval loss: 0.00263\n",
      "epoch 15989 / 20000\n",
      "gradient norm: 0.05613926786463708, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00269\n",
      "\tval loss: 0.00262\n",
      "epoch 15990 / 20000\n",
      "gradient norm: 0.03913049027323723, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00268\n",
      "\tval loss: 0.00262\n",
      "epoch 15991 / 20000\n",
      "gradient norm: 0.035744176944717765, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00268\n",
      "\tval loss: 0.00261\n",
      "epoch 15992 / 20000\n",
      "gradient norm: 0.04522687441203743, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00269\n",
      "\tval loss: 0.00262\n",
      "epoch 15993 / 20000\n",
      "gradient norm: 0.09170753345824778, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00269\n",
      "\tval loss: 0.00262\n",
      "epoch 15994 / 20000\n",
      "gradient norm: 0.09686324105132371, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00269\n",
      "\tval loss: 0.00261\n",
      "epoch 15995 / 20000\n",
      "gradient norm: 0.07178978540468961, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00268\n",
      "\tval loss: 0.00262\n",
      "epoch 15996 / 20000\n",
      "gradient norm: 0.03360890981275588, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00268\n",
      "\tval loss: 0.00261\n",
      "epoch 15997 / 20000\n",
      "gradient norm: 0.08672311389818788, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00268\n",
      "\tval loss: 0.00260\n",
      "epoch 15998 / 20000\n",
      "gradient norm: 0.03775483596837148, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00266\n",
      "\tval loss: 0.00262\n",
      "epoch 15999 / 20000\n",
      "gradient norm: 0.06309880688786507, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00268\n",
      "\tval loss: 0.00261\n",
      "epoch 16000 / 20000\n",
      "gradient norm: 0.08814038673881441, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00268\n",
      "\tval loss: 0.00260\n",
      "epoch 16001 / 20000\n",
      "gradient norm: 0.06634410785045475, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00267\n",
      "\tval loss: 0.00261\n",
      "epoch 16002 / 20000\n",
      "gradient norm: 0.08345828903838992, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00266\n",
      "\tval loss: 0.00260\n",
      "epoch 16003 / 20000\n",
      "gradient norm: 0.04971903772093356, minimum ratio: 2.4421052631578943\n",
      "\ttrain loss: 0.00267\n",
      "\tval loss: 0.00259\n",
      "epoch 16004 / 20000\n",
      "gradient norm: 0.04504806111799553, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00266\n",
      "\tval loss: 0.00260\n",
      "epoch 16005 / 20000\n",
      "gradient norm: 0.018964590213727206, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00266\n",
      "\tval loss: 0.00260\n",
      "epoch 16006 / 20000\n",
      "gradient norm: 0.03580859687644988, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00265\n",
      "\tval loss: 0.00259\n",
      "epoch 16007 / 20000\n",
      "gradient norm: 0.040268674201797694, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00266\n",
      "\tval loss: 0.00259\n",
      "epoch 16008 / 20000\n",
      "gradient norm: 0.060612487024627626, minimum ratio: 2.4263157894736844\n",
      "\ttrain loss: 0.00265\n",
      "\tval loss: 0.00259\n",
      "epoch 16009 / 20000\n",
      "gradient norm: 0.028465708892326802, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00265\n",
      "\tval loss: 0.00259\n",
      "epoch 16010 / 20000\n",
      "gradient norm: 0.04834691126598045, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00265\n",
      "\tval loss: 0.00258\n",
      "epoch 16011 / 20000\n",
      "gradient norm: 0.06082991778384894, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00266\n",
      "\tval loss: 0.00258\n",
      "epoch 16012 / 20000\n",
      "gradient norm: 0.02932336356025189, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00264\n",
      "\tval loss: 0.00259\n",
      "epoch 16013 / 20000\n",
      "gradient norm: 0.09430242702364922, minimum ratio: 2.4394736842105265\n",
      "\ttrain loss: 0.00265\n",
      "\tval loss: 0.00258\n",
      "epoch 16014 / 20000\n",
      "gradient norm: 0.07221763947745785, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00264\n",
      "\tval loss: 0.00257\n",
      "epoch 16015 / 20000\n",
      "gradient norm: 0.041182618675520644, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00264\n",
      "\tval loss: 0.00258\n",
      "epoch 16016 / 20000\n",
      "gradient norm: 0.029805229511111975, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00264\n",
      "\tval loss: 0.00258\n",
      "epoch 16017 / 20000\n",
      "gradient norm: 0.020498529978794977, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00263\n",
      "\tval loss: 0.00257\n",
      "epoch 16018 / 20000\n",
      "gradient norm: 0.023759062809403986, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00263\n",
      "\tval loss: 0.00257\n",
      "epoch 16019 / 20000\n",
      "gradient norm: 0.03537863533711061, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00263\n",
      "\tval loss: 0.00257\n",
      "epoch 16020 / 20000\n",
      "gradient norm: 0.036834900674875826, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00263\n",
      "\tval loss: 0.00257\n",
      "epoch 16021 / 20000\n",
      "gradient norm: 0.052062439383007586, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00263\n",
      "\tval loss: 0.00256\n",
      "epoch 16022 / 20000\n",
      "gradient norm: 0.053571159252896905, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00262\n",
      "\tval loss: 0.00256\n",
      "epoch 16023 / 20000\n",
      "gradient norm: 0.040375177457462996, minimum ratio: 2.4447368421052635\n",
      "\ttrain loss: 0.00263\n",
      "\tval loss: 0.00257\n",
      "epoch 16024 / 20000\n",
      "gradient norm: 0.06842670653713867, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00262\n",
      "\tval loss: 0.00256\n",
      "epoch 16025 / 20000\n",
      "gradient norm: 0.07341180526418611, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00263\n",
      "\tval loss: 0.00255\n",
      "epoch 16026 / 20000\n",
      "gradient norm: 0.038509920705109835, minimum ratio: 2.4421052631578943\n",
      "\ttrain loss: 0.00262\n",
      "\tval loss: 0.00257\n",
      "epoch 16027 / 20000\n",
      "gradient norm: 0.051591693714726716, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00262\n",
      "\tval loss: 0.00256\n",
      "epoch 16028 / 20000\n",
      "gradient norm: 0.06106288585579023, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00261\n",
      "\tval loss: 0.00255\n",
      "epoch 16029 / 20000\n",
      "gradient norm: 0.03519749757833779, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00262\n",
      "\tval loss: 0.00256\n",
      "epoch 16030 / 20000\n",
      "gradient norm: 0.08133123791776597, minimum ratio: 2.4394736842105265\n",
      "\ttrain loss: 0.00262\n",
      "\tval loss: 0.00255\n",
      "epoch 16031 / 20000\n",
      "gradient norm: 0.04352495667990297, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00261\n",
      "\tval loss: 0.00255\n",
      "epoch 16032 / 20000\n",
      "gradient norm: 0.0162183964275755, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00261\n",
      "\tval loss: 0.00255\n",
      "epoch 16033 / 20000\n",
      "gradient norm: 0.054922548413742334, minimum ratio: 2.4447368421052635\n",
      "\ttrain loss: 0.00261\n",
      "\tval loss: 0.00255\n",
      "epoch 16034 / 20000\n",
      "gradient norm: 0.02784149837680161, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00261\n",
      "\tval loss: 0.00254\n",
      "epoch 16035 / 20000\n",
      "gradient norm: 0.04819646297255531, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00260\n",
      "\tval loss: 0.00255\n",
      "epoch 16036 / 20000\n",
      "gradient norm: 0.032466423814184964, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00260\n",
      "\tval loss: 0.00254\n",
      "epoch 16037 / 20000\n",
      "gradient norm: 0.04794426361331716, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00260\n",
      "\tval loss: 0.00254\n",
      "epoch 16038 / 20000\n",
      "gradient norm: 0.04468591703334823, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00260\n",
      "\tval loss: 0.00255\n",
      "epoch 16039 / 20000\n",
      "gradient norm: 0.04306701093446463, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00260\n",
      "\tval loss: 0.00253\n",
      "epoch 16040 / 20000\n",
      "gradient norm: 0.024927491147536784, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00259\n",
      "\tval loss: 0.00253\n",
      "epoch 16041 / 20000\n",
      "gradient norm: 0.05518664536066353, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00260\n",
      "\tval loss: 0.00253\n",
      "epoch 16042 / 20000\n",
      "gradient norm: 0.0517491833306849, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00259\n",
      "\tval loss: 0.00253\n",
      "epoch 16043 / 20000\n",
      "gradient norm: 0.041044527490157634, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00260\n",
      "\tval loss: 0.00252\n",
      "epoch 16044 / 20000\n",
      "gradient norm: 0.02494665319682099, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00258\n",
      "\tval loss: 0.00253\n",
      "epoch 16045 / 20000\n",
      "gradient norm: 0.03391972239478491, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00259\n",
      "\tval loss: 0.00252\n",
      "epoch 16046 / 20000\n",
      "gradient norm: 0.02816171699669212, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00259\n",
      "\tval loss: 0.00252\n",
      "epoch 16047 / 20000\n",
      "gradient norm: 0.04380721540655941, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00258\n",
      "\tval loss: 0.00252\n",
      "epoch 16048 / 20000\n",
      "gradient norm: 0.05195242090849206, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00258\n",
      "\tval loss: 0.00252\n",
      "epoch 16049 / 20000\n",
      "gradient norm: 0.06502810842357576, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00258\n",
      "\tval loss: 0.00252\n",
      "epoch 16050 / 20000\n",
      "gradient norm: 0.026553977571893483, minimum ratio: 2.4394736842105265\n",
      "\ttrain loss: 0.00257\n",
      "\tval loss: 0.00252\n",
      "epoch 16051 / 20000\n",
      "gradient norm: 0.03328928811242804, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00257\n",
      "\tval loss: 0.00251\n",
      "epoch 16052 / 20000\n",
      "gradient norm: 0.03301242785528302, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00257\n",
      "\tval loss: 0.00251\n",
      "epoch 16053 / 20000\n",
      "gradient norm: 0.044166987820062786, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00257\n",
      "\tval loss: 0.00251\n",
      "epoch 16054 / 20000\n",
      "gradient norm: 0.04117869888432324, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00258\n",
      "\tval loss: 0.00251\n",
      "epoch 16055 / 20000\n",
      "gradient norm: 0.05484873661771417, minimum ratio: 2.4578947368421056\n",
      "\ttrain loss: 0.00257\n",
      "\tval loss: 0.00251\n",
      "epoch 16056 / 20000\n",
      "gradient norm: 0.05876305716810748, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00257\n",
      "\tval loss: 0.00250\n",
      "epoch 16057 / 20000\n",
      "gradient norm: 0.05736718256957829, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00257\n",
      "\tval loss: 0.00251\n",
      "epoch 16058 / 20000\n",
      "gradient norm: 0.04731869348324835, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00257\n",
      "\tval loss: 0.00251\n",
      "epoch 16059 / 20000\n",
      "gradient norm: 0.07179413025733083, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00257\n",
      "\tval loss: 0.00250\n",
      "epoch 16060 / 20000\n",
      "gradient norm: 0.06427375331986696, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00257\n",
      "\tval loss: 0.00251\n",
      "epoch 16061 / 20000\n",
      "gradient norm: 0.04085279116407037, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00257\n",
      "\tval loss: 0.00250\n",
      "epoch 16062 / 20000\n",
      "gradient norm: 0.04715367709286511, minimum ratio: 2.4447368421052635\n",
      "\ttrain loss: 0.00255\n",
      "\tval loss: 0.00249\n",
      "epoch 16063 / 20000\n",
      "gradient norm: 0.04564598051365465, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00255\n",
      "\tval loss: 0.00249\n",
      "epoch 16064 / 20000\n",
      "gradient norm: 0.03127132618101314, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00255\n",
      "\tval loss: 0.00249\n",
      "epoch 16065 / 20000\n",
      "gradient norm: 0.05317788594402373, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00255\n",
      "\tval loss: 0.00249\n",
      "epoch 16066 / 20000\n",
      "gradient norm: 0.046243174525443465, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00255\n",
      "\tval loss: 0.00249\n",
      "epoch 16067 / 20000\n",
      "gradient norm: 0.030767345044296235, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00255\n",
      "\tval loss: 0.00249\n",
      "epoch 16068 / 20000\n",
      "gradient norm: 0.03490700473776087, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00255\n",
      "\tval loss: 0.00248\n",
      "epoch 16069 / 20000\n",
      "gradient norm: 0.05473851488204673, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00254\n",
      "\tval loss: 0.00249\n",
      "epoch 16070 / 20000\n",
      "gradient norm: 0.03664152923738584, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00254\n",
      "\tval loss: 0.00248\n",
      "epoch 16071 / 20000\n",
      "gradient norm: 0.058958301262464374, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00254\n",
      "\tval loss: 0.00248\n",
      "epoch 16072 / 20000\n",
      "gradient norm: 0.022282809542957693, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00254\n",
      "\tval loss: 0.00248\n",
      "epoch 16073 / 20000\n",
      "gradient norm: 0.019817300140857697, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00254\n",
      "\tval loss: 0.00248\n",
      "epoch 16074 / 20000\n",
      "gradient norm: 0.07846827793400735, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00254\n",
      "\tval loss: 0.00248\n",
      "epoch 16075 / 20000\n",
      "gradient norm: 0.03129001474007964, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00254\n",
      "\tval loss: 0.00247\n",
      "epoch 16076 / 20000\n",
      "gradient norm: 0.05641653051134199, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00253\n",
      "\tval loss: 0.00248\n",
      "epoch 16077 / 20000\n",
      "gradient norm: 0.04459746117936447, minimum ratio: 2.4184210526315786\n",
      "\ttrain loss: 0.00253\n",
      "\tval loss: 0.00247\n",
      "epoch 16078 / 20000\n",
      "gradient norm: 0.01607972342753783, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00252\n",
      "\tval loss: 0.00247\n",
      "epoch 16079 / 20000\n",
      "gradient norm: 0.06339344408479519, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00253\n",
      "\tval loss: 0.00247\n",
      "epoch 16080 / 20000\n",
      "gradient norm: 0.024876177893020213, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00252\n",
      "\tval loss: 0.00247\n",
      "epoch 16081 / 20000\n",
      "gradient norm: 0.07374683406669647, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00253\n",
      "\tval loss: 0.00246\n",
      "epoch 16082 / 20000\n",
      "gradient norm: 0.035379941342398524, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00252\n",
      "\tval loss: 0.00246\n",
      "epoch 16083 / 20000\n",
      "gradient norm: 0.06780790531774983, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00252\n",
      "\tval loss: 0.00246\n",
      "epoch 16084 / 20000\n",
      "gradient norm: 0.02899435954168439, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00251\n",
      "\tval loss: 0.00246\n",
      "epoch 16085 / 20000\n",
      "gradient norm: 0.034747224068269134, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00252\n",
      "\tval loss: 0.00245\n",
      "epoch 16086 / 20000\n",
      "gradient norm: 0.046835742774419487, minimum ratio: 2.4421052631578943\n",
      "\ttrain loss: 0.00252\n",
      "\tval loss: 0.00246\n",
      "epoch 16087 / 20000\n",
      "gradient norm: 0.04118598805507645, minimum ratio: 2.4315789473684206\n",
      "\ttrain loss: 0.00251\n",
      "\tval loss: 0.00245\n",
      "epoch 16088 / 20000\n",
      "gradient norm: 0.08243563899304718, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00252\n",
      "\tval loss: 0.00245\n",
      "epoch 16089 / 20000\n",
      "gradient norm: 0.07514540012925863, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00252\n",
      "\tval loss: 0.00247\n",
      "epoch 16090 / 20000\n",
      "gradient norm: 0.08248456963337958, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00251\n",
      "\tval loss: 0.00245\n",
      "epoch 16091 / 20000\n",
      "gradient norm: 0.07528230349998921, minimum ratio: 2.4499999999999997\n",
      "\ttrain loss: 0.00252\n",
      "\tval loss: 0.00245\n",
      "epoch 16092 / 20000\n",
      "gradient norm: 0.042453563888557255, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00251\n",
      "\tval loss: 0.00246\n",
      "epoch 16093 / 20000\n",
      "gradient norm: 0.028679254406597465, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00250\n",
      "\tval loss: 0.00244\n",
      "epoch 16094 / 20000\n",
      "gradient norm: 0.03150538820773363, minimum ratio: 2.4447368421052635\n",
      "\ttrain loss: 0.00250\n",
      "\tval loss: 0.00244\n",
      "epoch 16095 / 20000\n",
      "gradient norm: 0.01887948630610481, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00250\n",
      "\tval loss: 0.00244\n",
      "epoch 16096 / 20000\n",
      "gradient norm: 0.0736454130965285, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00250\n",
      "\tval loss: 0.00244\n",
      "epoch 16097 / 20000\n",
      "gradient norm: 0.03125120926415548, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00249\n",
      "\tval loss: 0.00243\n",
      "epoch 16098 / 20000\n",
      "gradient norm: 0.02463016824913211, minimum ratio: 2.4263157894736844\n",
      "\ttrain loss: 0.00250\n",
      "\tval loss: 0.00244\n",
      "epoch 16099 / 20000\n",
      "gradient norm: 0.043280983984004706, minimum ratio: 2.4421052631578943\n",
      "\ttrain loss: 0.00250\n",
      "\tval loss: 0.00244\n",
      "epoch 16100 / 20000\n",
      "gradient norm: 0.02188968990230933, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00249\n",
      "\tval loss: 0.00243\n",
      "epoch 16101 / 20000\n",
      "gradient norm: 0.04539901574025862, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00249\n",
      "\tval loss: 0.00243\n",
      "epoch 16102 / 20000\n",
      "gradient norm: 0.055060419836081564, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00249\n",
      "\tval loss: 0.00243\n",
      "epoch 16103 / 20000\n",
      "gradient norm: 0.06369865004671738, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00249\n",
      "\tval loss: 0.00243\n",
      "epoch 16104 / 20000\n",
      "gradient norm: 0.06376466568326578, minimum ratio: 2.4447368421052635\n",
      "\ttrain loss: 0.00249\n",
      "\tval loss: 0.00242\n",
      "epoch 16105 / 20000\n",
      "gradient norm: 0.05744190269615501, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00248\n",
      "\tval loss: 0.00242\n",
      "epoch 16106 / 20000\n",
      "gradient norm: 0.033604133350308985, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00248\n",
      "\tval loss: 0.00243\n",
      "epoch 16107 / 20000\n",
      "gradient norm: 0.037553595029748976, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00248\n",
      "\tval loss: 0.00242\n",
      "epoch 16108 / 20000\n",
      "gradient norm: 0.03964455000823364, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00247\n",
      "\tval loss: 0.00242\n",
      "epoch 16109 / 20000\n",
      "gradient norm: 0.023657745914533734, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00248\n",
      "\tval loss: 0.00242\n",
      "epoch 16110 / 20000\n",
      "gradient norm: 0.05801287293434143, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00247\n",
      "\tval loss: 0.00242\n",
      "epoch 16111 / 20000\n",
      "gradient norm: 0.09328999186982401, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00249\n",
      "\tval loss: 0.00241\n",
      "epoch 16112 / 20000\n",
      "gradient norm: 0.04941821738611907, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00247\n",
      "\tval loss: 0.00243\n",
      "epoch 16113 / 20000\n",
      "gradient norm: 0.10707945819012821, minimum ratio: 2.4236842105263157\n",
      "\ttrain loss: 0.00248\n",
      "\tval loss: 0.00241\n",
      "epoch 16114 / 20000\n",
      "gradient norm: 0.023441928235115483, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00247\n",
      "\tval loss: 0.00241\n",
      "epoch 16115 / 20000\n",
      "gradient norm: 0.05146996001712978, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00246\n",
      "\tval loss: 0.00241\n",
      "epoch 16116 / 20000\n",
      "gradient norm: 0.03103107793140225, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00246\n",
      "\tval loss: 0.00241\n",
      "epoch 16117 / 20000\n",
      "gradient norm: 0.06628116662614048, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00247\n",
      "\tval loss: 0.00240\n",
      "epoch 16118 / 20000\n",
      "gradient norm: 0.031081091205123812, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00246\n",
      "\tval loss: 0.00241\n",
      "epoch 16119 / 20000\n",
      "gradient norm: 0.06357900018338114, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00246\n",
      "\tval loss: 0.00240\n",
      "epoch 16120 / 20000\n",
      "gradient norm: 0.05696321529103443, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00245\n",
      "\tval loss: 0.00240\n",
      "epoch 16121 / 20000\n",
      "gradient norm: 0.04782893345691264, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00246\n",
      "\tval loss: 0.00240\n",
      "epoch 16122 / 20000\n",
      "gradient norm: 0.06040635210229084, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00246\n",
      "\tval loss: 0.00241\n",
      "epoch 16123 / 20000\n",
      "gradient norm: 0.07110311364522204, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00246\n",
      "\tval loss: 0.00239\n",
      "epoch 16124 / 20000\n",
      "gradient norm: 0.05478504078928381, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00246\n",
      "\tval loss: 0.00240\n",
      "epoch 16125 / 20000\n",
      "gradient norm: 0.03440944314934313, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00245\n",
      "\tval loss: 0.00239\n",
      "epoch 16126 / 20000\n",
      "gradient norm: 0.05199378071120009, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00245\n",
      "\tval loss: 0.00239\n",
      "epoch 16127 / 20000\n",
      "gradient norm: 0.04198941675713286, minimum ratio: 2.460526315789474\n",
      "\ttrain loss: 0.00244\n",
      "\tval loss: 0.00240\n",
      "epoch 16128 / 20000\n",
      "gradient norm: 0.04983859625644982, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00245\n",
      "\tval loss: 0.00238\n",
      "epoch 16129 / 20000\n",
      "gradient norm: 0.0317194476374425, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00244\n",
      "\tval loss: 0.00238\n",
      "epoch 16130 / 20000\n",
      "gradient norm: 0.05860649223905057, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00244\n",
      "\tval loss: 0.00239\n",
      "epoch 16131 / 20000\n",
      "gradient norm: 0.06162100535584614, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00244\n",
      "\tval loss: 0.00238\n",
      "epoch 16132 / 20000\n",
      "gradient norm: 0.03989068930968642, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00244\n",
      "\tval loss: 0.00238\n",
      "epoch 16133 / 20000\n",
      "gradient norm: 0.06048583536176011, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00244\n",
      "\tval loss: 0.00239\n",
      "epoch 16134 / 20000\n",
      "gradient norm: 0.07690711319446564, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00244\n",
      "\tval loss: 0.00237\n",
      "epoch 16135 / 20000\n",
      "gradient norm: 0.0497584815020673, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00243\n",
      "\tval loss: 0.00238\n",
      "epoch 16136 / 20000\n",
      "gradient norm: 0.042110685200896114, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00242\n",
      "\tval loss: 0.00238\n",
      "epoch 16137 / 20000\n",
      "gradient norm: 0.051063517516013235, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00243\n",
      "\tval loss: 0.00237\n",
      "epoch 16138 / 20000\n",
      "gradient norm: 0.04584766662446782, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00242\n",
      "\tval loss: 0.00237\n",
      "epoch 16139 / 20000\n",
      "gradient norm: 0.03563059843145311, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00242\n",
      "\tval loss: 0.00237\n",
      "epoch 16140 / 20000\n",
      "gradient norm: 0.037424020818434656, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00243\n",
      "\tval loss: 0.00236\n",
      "epoch 16141 / 20000\n",
      "gradient norm: 0.06848398165311664, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00242\n",
      "\tval loss: 0.00238\n",
      "epoch 16142 / 20000\n",
      "gradient norm: 0.057396630640141666, minimum ratio: 2.4236842105263157\n",
      "\ttrain loss: 0.00241\n",
      "\tval loss: 0.00236\n",
      "epoch 16143 / 20000\n",
      "gradient norm: 0.04205452179303393, minimum ratio: 2.4105263157894736\n",
      "\ttrain loss: 0.00241\n",
      "\tval loss: 0.00236\n",
      "epoch 16144 / 20000\n",
      "gradient norm: 0.06134172377642244, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00242\n",
      "\tval loss: 0.00236\n",
      "epoch 16145 / 20000\n",
      "gradient norm: 0.0788857318693772, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00242\n",
      "\tval loss: 0.00236\n",
      "epoch 16146 / 20000\n",
      "gradient norm: 0.02055412411573343, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00241\n",
      "\tval loss: 0.00236\n",
      "epoch 16147 / 20000\n",
      "gradient norm: 0.025970079062972218, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00241\n",
      "\tval loss: 0.00235\n",
      "epoch 16148 / 20000\n",
      "gradient norm: 0.03866213222499937, minimum ratio: 2.4263157894736844\n",
      "\ttrain loss: 0.00241\n",
      "\tval loss: 0.00235\n",
      "epoch 16149 / 20000\n",
      "gradient norm: 0.03371935652103275, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00240\n",
      "\tval loss: 0.00235\n",
      "epoch 16150 / 20000\n",
      "gradient norm: 0.026198399835266173, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00240\n",
      "\tval loss: 0.00235\n",
      "epoch 16151 / 20000\n",
      "gradient norm: 0.05851382954278961, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00241\n",
      "\tval loss: 0.00235\n",
      "epoch 16152 / 20000\n",
      "gradient norm: 0.03377309686038643, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00240\n",
      "\tval loss: 0.00235\n",
      "epoch 16153 / 20000\n",
      "gradient norm: 0.043992128456011415, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00240\n",
      "\tval loss: 0.00234\n",
      "epoch 16154 / 20000\n",
      "gradient norm: 0.07310411240905523, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00240\n",
      "\tval loss: 0.00234\n",
      "epoch 16155 / 20000\n",
      "gradient norm: 0.06963899871334434, minimum ratio: 2.4421052631578943\n",
      "\ttrain loss: 0.00240\n",
      "\tval loss: 0.00236\n",
      "epoch 16156 / 20000\n",
      "gradient norm: 0.021515880594961345, minimum ratio: 2.4210526315789473\n",
      "\ttrain loss: 0.00239\n",
      "\tval loss: 0.00234\n",
      "epoch 16157 / 20000\n",
      "gradient norm: 0.05492033204063773, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00240\n",
      "\tval loss: 0.00234\n",
      "epoch 16158 / 20000\n",
      "gradient norm: 0.03304127507726662, minimum ratio: 2.4394736842105265\n",
      "\ttrain loss: 0.00240\n",
      "\tval loss: 0.00235\n",
      "epoch 16159 / 20000\n",
      "gradient norm: 0.03326703858328983, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00239\n",
      "\tval loss: 0.00233\n",
      "epoch 16160 / 20000\n",
      "gradient norm: 0.04205859958892688, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00238\n",
      "\tval loss: 0.00233\n",
      "epoch 16161 / 20000\n",
      "gradient norm: 0.0445060629863292, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00239\n",
      "\tval loss: 0.00234\n",
      "epoch 16162 / 20000\n",
      "gradient norm: 0.06004756945185363, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00239\n",
      "\tval loss: 0.00233\n",
      "epoch 16163 / 20000\n",
      "gradient norm: 0.02060042566154152, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00238\n",
      "\tval loss: 0.00233\n",
      "epoch 16164 / 20000\n",
      "gradient norm: 0.02794777663075365, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00238\n",
      "\tval loss: 0.00233\n",
      "epoch 16165 / 20000\n",
      "gradient norm: 0.055160090036224574, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00238\n",
      "\tval loss: 0.00232\n",
      "epoch 16166 / 20000\n",
      "gradient norm: 0.04129618010483682, minimum ratio: 2.418421052631579\n",
      "\ttrain loss: 0.00238\n",
      "\tval loss: 0.00233\n",
      "epoch 16167 / 20000\n",
      "gradient norm: 0.03527161566307768, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00238\n",
      "\tval loss: 0.00232\n",
      "epoch 16168 / 20000\n",
      "gradient norm: 0.06565958820283413, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00238\n",
      "\tval loss: 0.00232\n",
      "epoch 16169 / 20000\n",
      "gradient norm: 0.04091667471220717, minimum ratio: 2.4447368421052627\n",
      "\ttrain loss: 0.00237\n",
      "\tval loss: 0.00232\n",
      "epoch 16170 / 20000\n",
      "gradient norm: 0.038668468536343426, minimum ratio: 2.4421052631578943\n",
      "\ttrain loss: 0.00237\n",
      "\tval loss: 0.00232\n",
      "epoch 16171 / 20000\n",
      "gradient norm: 0.018296008987817913, minimum ratio: 2.4263157894736844\n",
      "\ttrain loss: 0.00237\n",
      "\tval loss: 0.00231\n",
      "epoch 16172 / 20000\n",
      "gradient norm: 0.03684405965032056, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00237\n",
      "\tval loss: 0.00231\n",
      "epoch 16173 / 20000\n",
      "gradient norm: 0.05647314578527585, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00237\n",
      "\tval loss: 0.00231\n",
      "epoch 16174 / 20000\n",
      "gradient norm: 0.04167860228335485, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00236\n",
      "\tval loss: 0.00231\n",
      "epoch 16175 / 20000\n",
      "gradient norm: 0.04769826593110338, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00236\n",
      "\tval loss: 0.00230\n",
      "epoch 16176 / 20000\n",
      "gradient norm: 0.03422495332779363, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00236\n",
      "\tval loss: 0.00231\n",
      "epoch 16177 / 20000\n",
      "gradient norm: 0.03193113760789856, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00236\n",
      "\tval loss: 0.00230\n",
      "epoch 16178 / 20000\n",
      "gradient norm: 0.029729895206401125, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00235\n",
      "\tval loss: 0.00230\n",
      "epoch 16179 / 20000\n",
      "gradient norm: 0.04597414331510663, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00235\n",
      "\tval loss: 0.00231\n",
      "epoch 16180 / 20000\n",
      "gradient norm: 0.022295996954198927, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00235\n",
      "\tval loss: 0.00230\n",
      "epoch 16181 / 20000\n",
      "gradient norm: 0.05172147729899734, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00235\n",
      "\tval loss: 0.00230\n",
      "epoch 16182 / 20000\n",
      "gradient norm: 0.0612245780066587, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00235\n",
      "\tval loss: 0.00231\n",
      "epoch 16183 / 20000\n",
      "gradient norm: 0.08630521199665964, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00235\n",
      "\tval loss: 0.00230\n",
      "epoch 16184 / 20000\n",
      "gradient norm: 0.052697546198032796, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00235\n",
      "\tval loss: 0.00229\n",
      "epoch 16185 / 20000\n",
      "gradient norm: 0.051602606021333486, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00234\n",
      "\tval loss: 0.00230\n",
      "epoch 16186 / 20000\n",
      "gradient norm: 0.029327619879040867, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00234\n",
      "\tval loss: 0.00229\n",
      "epoch 16187 / 20000\n",
      "gradient norm: 0.040979197015985847, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00234\n",
      "\tval loss: 0.00229\n",
      "epoch 16188 / 20000\n",
      "gradient norm: 0.03710208513075486, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00234\n",
      "\tval loss: 0.00229\n",
      "epoch 16189 / 20000\n",
      "gradient norm: 0.045546283246949315, minimum ratio: 2.413157894736842\n",
      "\ttrain loss: 0.00233\n",
      "\tval loss: 0.00229\n",
      "epoch 16190 / 20000\n",
      "gradient norm: 0.057756594207603484, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00234\n",
      "\tval loss: 0.00228\n",
      "epoch 16191 / 20000\n",
      "gradient norm: 0.0711934951832518, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00235\n",
      "\tval loss: 0.00229\n",
      "epoch 16192 / 20000\n",
      "gradient norm: 0.05993189907167107, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00233\n",
      "\tval loss: 0.00228\n",
      "epoch 16193 / 20000\n",
      "gradient norm: 0.059937623533187434, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00233\n",
      "\tval loss: 0.00227\n",
      "epoch 16194 / 20000\n",
      "gradient norm: 0.04041707201395184, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00233\n",
      "\tval loss: 0.00228\n",
      "epoch 16195 / 20000\n",
      "gradient norm: 0.028941648546606302, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00233\n",
      "\tval loss: 0.00228\n",
      "epoch 16196 / 20000\n",
      "gradient norm: 0.033401088148821145, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00233\n",
      "\tval loss: 0.00227\n",
      "epoch 16197 / 20000\n",
      "gradient norm: 0.05004311085212976, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00232\n",
      "\tval loss: 0.00227\n",
      "epoch 16198 / 20000\n",
      "gradient norm: 0.04336650695768185, minimum ratio: 2.4499999999999997\n",
      "\ttrain loss: 0.00232\n",
      "\tval loss: 0.00227\n",
      "epoch 16199 / 20000\n",
      "gradient norm: 0.0362064010114409, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00232\n",
      "\tval loss: 0.00227\n",
      "epoch 16200 / 20000\n",
      "gradient norm: 0.06191870442125946, minimum ratio: 2.4421052631578952\n",
      "\ttrain loss: 0.00232\n",
      "\tval loss: 0.00227\n",
      "epoch 16201 / 20000\n",
      "gradient norm: 0.07065090438118204, minimum ratio: 2.418421052631579\n",
      "\ttrain loss: 0.00231\n",
      "\tval loss: 0.00226\n",
      "epoch 16202 / 20000\n",
      "gradient norm: 0.04565053671831265, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00232\n",
      "\tval loss: 0.00226\n",
      "epoch 16203 / 20000\n",
      "gradient norm: 0.04431101132649928, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00231\n",
      "\tval loss: 0.00227\n",
      "epoch 16204 / 20000\n",
      "gradient norm: 0.06349225714802742, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00231\n",
      "\tval loss: 0.00226\n",
      "epoch 16205 / 20000\n",
      "gradient norm: 0.04148605343652889, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00231\n",
      "\tval loss: 0.00226\n",
      "epoch 16206 / 20000\n",
      "gradient norm: 0.0411015561548993, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00231\n",
      "\tval loss: 0.00226\n",
      "epoch 16207 / 20000\n",
      "gradient norm: 0.03340009198291227, minimum ratio: 2.447368421052631\n",
      "\ttrain loss: 0.00231\n",
      "\tval loss: 0.00226\n",
      "epoch 16208 / 20000\n",
      "gradient norm: 0.01938102609710768, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00230\n",
      "\tval loss: 0.00225\n",
      "epoch 16209 / 20000\n",
      "gradient norm: 0.05033664655638859, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00231\n",
      "\tval loss: 0.00226\n",
      "epoch 16210 / 20000\n",
      "gradient norm: 0.03777058352716267, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00230\n",
      "\tval loss: 0.00225\n",
      "epoch 16211 / 20000\n",
      "gradient norm: 0.03554579650517553, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00230\n",
      "\tval loss: 0.00225\n",
      "epoch 16212 / 20000\n",
      "gradient norm: 0.030224295041989535, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00230\n",
      "\tval loss: 0.00226\n",
      "epoch 16213 / 20000\n",
      "gradient norm: 0.04510165483225137, minimum ratio: 2.4499999999999997\n",
      "\ttrain loss: 0.00229\n",
      "\tval loss: 0.00225\n",
      "epoch 16214 / 20000\n",
      "gradient norm: 0.061205221398267895, minimum ratio: 2.4236842105263157\n",
      "\ttrain loss: 0.00229\n",
      "\tval loss: 0.00224\n",
      "epoch 16215 / 20000\n",
      "gradient norm: 0.017048446810804307, minimum ratio: 2.4421052631578952\n",
      "\ttrain loss: 0.00230\n",
      "\tval loss: 0.00225\n",
      "epoch 16216 / 20000\n",
      "gradient norm: 0.06626581714954227, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00230\n",
      "\tval loss: 0.00224\n",
      "epoch 16217 / 20000\n",
      "gradient norm: 0.031213210779242218, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00229\n",
      "\tval loss: 0.00224\n",
      "epoch 16218 / 20000\n",
      "gradient norm: 0.022905201243702322, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00229\n",
      "\tval loss: 0.00224\n",
      "epoch 16219 / 20000\n",
      "gradient norm: 0.03065856237662956, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00229\n",
      "\tval loss: 0.00224\n",
      "epoch 16220 / 20000\n",
      "gradient norm: 0.03720352303935215, minimum ratio: 2.4210526315789473\n",
      "\ttrain loss: 0.00228\n",
      "\tval loss: 0.00224\n",
      "epoch 16221 / 20000\n",
      "gradient norm: 0.044878146960400045, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00228\n",
      "\tval loss: 0.00223\n",
      "epoch 16222 / 20000\n",
      "gradient norm: 0.03838150529190898, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00229\n",
      "\tval loss: 0.00224\n",
      "epoch 16223 / 20000\n",
      "gradient norm: 0.06631655187811702, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00228\n",
      "\tval loss: 0.00223\n",
      "epoch 16224 / 20000\n",
      "gradient norm: 0.048566387878963724, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00227\n",
      "\tval loss: 0.00222\n",
      "epoch 16225 / 20000\n",
      "gradient norm: 0.06358217669185251, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00228\n",
      "\tval loss: 0.00223\n",
      "epoch 16226 / 20000\n",
      "gradient norm: 0.05254699703073129, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00227\n",
      "\tval loss: 0.00223\n",
      "epoch 16227 / 20000\n",
      "gradient norm: 0.01770734612364322, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00227\n",
      "\tval loss: 0.00222\n",
      "epoch 16228 / 20000\n",
      "gradient norm: 0.038090064364951104, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00227\n",
      "\tval loss: 0.00222\n",
      "epoch 16229 / 20000\n",
      "gradient norm: 0.051950324326753616, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00227\n",
      "\tval loss: 0.00223\n",
      "epoch 16230 / 20000\n",
      "gradient norm: 0.062155476422049105, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00228\n",
      "\tval loss: 0.00222\n",
      "epoch 16231 / 20000\n",
      "gradient norm: 0.031922815076541156, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00227\n",
      "\tval loss: 0.00222\n",
      "epoch 16232 / 20000\n",
      "gradient norm: 0.043571146205067635, minimum ratio: 2.465789473684211\n",
      "\ttrain loss: 0.00226\n",
      "\tval loss: 0.00222\n",
      "epoch 16233 / 20000\n",
      "gradient norm: 0.021144498692592606, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00226\n",
      "\tval loss: 0.00221\n",
      "epoch 16234 / 20000\n",
      "gradient norm: 0.029689081711694598, minimum ratio: 2.418421052631579\n",
      "\ttrain loss: 0.00226\n",
      "\tval loss: 0.00221\n",
      "epoch 16235 / 20000\n",
      "gradient norm: 0.0662234979099594, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00226\n",
      "\tval loss: 0.00221\n",
      "epoch 16236 / 20000\n",
      "gradient norm: 0.049632276059128344, minimum ratio: 2.4421052631578943\n",
      "\ttrain loss: 0.00227\n",
      "\tval loss: 0.00220\n",
      "epoch 16237 / 20000\n",
      "gradient norm: 0.05575037654489279, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00226\n",
      "\tval loss: 0.00222\n",
      "epoch 16238 / 20000\n",
      "gradient norm: 0.06817228347063065, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00227\n",
      "\tval loss: 0.00220\n",
      "epoch 16239 / 20000\n",
      "gradient norm: 0.023208482714835554, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00225\n",
      "\tval loss: 0.00221\n",
      "epoch 16240 / 20000\n",
      "gradient norm: 0.06083913694601506, minimum ratio: 2.4263157894736844\n",
      "\ttrain loss: 0.00226\n",
      "\tval loss: 0.00221\n",
      "epoch 16241 / 20000\n",
      "gradient norm: 0.05353921290952712, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00225\n",
      "\tval loss: 0.00220\n",
      "epoch 16242 / 20000\n",
      "gradient norm: 0.08774015551898628, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00226\n",
      "\tval loss: 0.00221\n",
      "epoch 16243 / 20000\n",
      "gradient norm: 0.05569781330996193, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00225\n",
      "\tval loss: 0.00219\n",
      "epoch 16244 / 20000\n",
      "gradient norm: 0.02670919307274744, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00224\n",
      "\tval loss: 0.00220\n",
      "epoch 16245 / 20000\n",
      "gradient norm: 0.03519229500670917, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00224\n",
      "\tval loss: 0.00220\n",
      "epoch 16246 / 20000\n",
      "gradient norm: 0.03440450906055048, minimum ratio: 2.4394736842105265\n",
      "\ttrain loss: 0.00224\n",
      "\tval loss: 0.00219\n",
      "epoch 16247 / 20000\n",
      "gradient norm: 0.022676026565022767, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00224\n",
      "\tval loss: 0.00220\n",
      "epoch 16248 / 20000\n",
      "gradient norm: 0.058102421811781824, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00224\n",
      "\tval loss: 0.00219\n",
      "epoch 16249 / 20000\n",
      "gradient norm: 0.06717919174116105, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00225\n",
      "\tval loss: 0.00219\n",
      "epoch 16250 / 20000\n",
      "gradient norm: 0.06478224828606471, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00224\n",
      "\tval loss: 0.00220\n",
      "epoch 16251 / 20000\n",
      "gradient norm: 0.031190140172839165, minimum ratio: 2.4394736842105265\n",
      "\ttrain loss: 0.00223\n",
      "\tval loss: 0.00218\n",
      "epoch 16252 / 20000\n",
      "gradient norm: 0.053385804465506226, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00224\n",
      "\tval loss: 0.00218\n",
      "epoch 16253 / 20000\n",
      "gradient norm: 0.0739363367902115, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00224\n",
      "\tval loss: 0.00218\n",
      "epoch 16254 / 20000\n",
      "gradient norm: 0.05309021018911153, minimum ratio: 2.4394736842105265\n",
      "\ttrain loss: 0.00223\n",
      "\tval loss: 0.00218\n",
      "epoch 16255 / 20000\n",
      "gradient norm: 0.03997625334886834, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00223\n",
      "\tval loss: 0.00218\n",
      "epoch 16256 / 20000\n",
      "gradient norm: 0.027845869393786415, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00223\n",
      "\tval loss: 0.00218\n",
      "epoch 16257 / 20000\n",
      "gradient norm: 0.057664728607051075, minimum ratio: 2.4289473684210523\n",
      "\ttrain loss: 0.00223\n",
      "\tval loss: 0.00217\n",
      "epoch 16258 / 20000\n",
      "gradient norm: 0.023446484992746264, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00222\n",
      "\tval loss: 0.00218\n",
      "epoch 16259 / 20000\n",
      "gradient norm: 0.02108532199054025, minimum ratio: 2.4499999999999997\n",
      "\ttrain loss: 0.00222\n",
      "\tval loss: 0.00217\n",
      "epoch 16260 / 20000\n",
      "gradient norm: 0.05157001595944166, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00222\n",
      "\tval loss: 0.00217\n",
      "epoch 16261 / 20000\n",
      "gradient norm: 0.03582210547756404, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00222\n",
      "\tval loss: 0.00218\n",
      "epoch 16262 / 20000\n",
      "gradient norm: 0.046470929868519306, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00222\n",
      "\tval loss: 0.00217\n",
      "epoch 16263 / 20000\n",
      "gradient norm: 0.053225280658807606, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00222\n",
      "\tval loss: 0.00216\n",
      "epoch 16264 / 20000\n",
      "gradient norm: 0.057738622825127095, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00222\n",
      "\tval loss: 0.00217\n",
      "epoch 16265 / 20000\n",
      "gradient norm: 0.04717367608100176, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00222\n",
      "\tval loss: 0.00216\n",
      "epoch 16266 / 20000\n",
      "gradient norm: 0.030692486034240574, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00221\n",
      "\tval loss: 0.00216\n",
      "epoch 16267 / 20000\n",
      "gradient norm: 0.030552460113540292, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00221\n",
      "\tval loss: 0.00217\n",
      "epoch 16268 / 20000\n",
      "gradient norm: 0.07021997636184096, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00221\n",
      "\tval loss: 0.00216\n",
      "epoch 16269 / 20000\n",
      "gradient norm: 0.03498220135224983, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00221\n",
      "\tval loss: 0.00216\n",
      "epoch 16270 / 20000\n",
      "gradient norm: 0.03312022122554481, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00220\n",
      "\tval loss: 0.00216\n",
      "epoch 16271 / 20000\n",
      "gradient norm: 0.03108985349535942, minimum ratio: 2.4394736842105265\n",
      "\ttrain loss: 0.00219\n",
      "\tval loss: 0.00215\n",
      "epoch 16272 / 20000\n",
      "gradient norm: 0.029261223040521145, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00220\n",
      "\tval loss: 0.00215\n",
      "epoch 16273 / 20000\n",
      "gradient norm: 0.05694330588448793, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00219\n",
      "\tval loss: 0.00215\n",
      "epoch 16274 / 20000\n",
      "gradient norm: 0.03481004561763257, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00219\n",
      "\tval loss: 0.00215\n",
      "epoch 16275 / 20000\n",
      "gradient norm: 0.03913479560287669, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00219\n",
      "\tval loss: 0.00214\n",
      "epoch 16276 / 20000\n",
      "gradient norm: 0.04244193696649745, minimum ratio: 2.4394736842105265\n",
      "\ttrain loss: 0.00220\n",
      "\tval loss: 0.00214\n",
      "epoch 16277 / 20000\n",
      "gradient norm: 0.03369308524997905, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00219\n",
      "\tval loss: 0.00215\n",
      "epoch 16278 / 20000\n",
      "gradient norm: 0.05233293992932886, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00219\n",
      "\tval loss: 0.00214\n",
      "epoch 16279 / 20000\n",
      "gradient norm: 0.04829153837636113, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00219\n",
      "\tval loss: 0.00214\n",
      "epoch 16280 / 20000\n",
      "gradient norm: 0.06516770558664575, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00218\n",
      "\tval loss: 0.00214\n",
      "epoch 16281 / 20000\n",
      "gradient norm: 0.049301365681458265, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00218\n",
      "\tval loss: 0.00213\n",
      "epoch 16282 / 20000\n",
      "gradient norm: 0.016976598592009395, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00218\n",
      "\tval loss: 0.00214\n",
      "epoch 16283 / 20000\n",
      "gradient norm: 0.050518383097369224, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00218\n",
      "\tval loss: 0.00213\n",
      "epoch 16284 / 20000\n",
      "gradient norm: 0.05795494816266, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00218\n",
      "\tval loss: 0.00213\n",
      "epoch 16285 / 20000\n",
      "gradient norm: 0.03310054662870243, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00218\n",
      "\tval loss: 0.00213\n",
      "epoch 16286 / 20000\n",
      "gradient norm: 0.07224822591524571, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00218\n",
      "\tval loss: 0.00214\n",
      "epoch 16287 / 20000\n",
      "gradient norm: 0.0266626380616799, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00217\n",
      "\tval loss: 0.00212\n",
      "epoch 16288 / 20000\n",
      "gradient norm: 0.03467771963914856, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00218\n",
      "\tval loss: 0.00213\n",
      "epoch 16289 / 20000\n",
      "gradient norm: 0.03984245896572247, minimum ratio: 2.4684210526315784\n",
      "\ttrain loss: 0.00217\n",
      "\tval loss: 0.00213\n",
      "epoch 16290 / 20000\n",
      "gradient norm: 0.02939293021336198, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00217\n",
      "\tval loss: 0.00212\n",
      "epoch 16291 / 20000\n",
      "gradient norm: 0.05720854247920215, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00217\n",
      "\tval loss: 0.00212\n",
      "epoch 16292 / 20000\n",
      "gradient norm: 0.060490303789265454, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00217\n",
      "\tval loss: 0.00212\n",
      "epoch 16293 / 20000\n",
      "gradient norm: 0.028674835979472846, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00216\n",
      "\tval loss: 0.00212\n",
      "epoch 16294 / 20000\n",
      "gradient norm: 0.04310887586325407, minimum ratio: 2.4263157894736844\n",
      "\ttrain loss: 0.00217\n",
      "\tval loss: 0.00212\n",
      "epoch 16295 / 20000\n",
      "gradient norm: 0.04913097666576505, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00216\n",
      "\tval loss: 0.00211\n",
      "epoch 16296 / 20000\n",
      "gradient norm: 0.021527089324081317, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00216\n",
      "\tval loss: 0.00212\n",
      "epoch 16297 / 20000\n",
      "gradient norm: 0.06273817707551643, minimum ratio: 2.46578947368421\n",
      "\ttrain loss: 0.00216\n",
      "\tval loss: 0.00211\n",
      "epoch 16298 / 20000\n",
      "gradient norm: 0.03132544306572527, minimum ratio: 2.4421052631578943\n",
      "\ttrain loss: 0.00216\n",
      "\tval loss: 0.00211\n",
      "epoch 16299 / 20000\n",
      "gradient norm: 0.03024473792174831, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00215\n",
      "\tval loss: 0.00211\n",
      "epoch 16300 / 20000\n",
      "gradient norm: 0.027604500064626336, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00215\n",
      "\tval loss: 0.00211\n",
      "epoch 16301 / 20000\n",
      "gradient norm: 0.021368078014347702, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00215\n",
      "\tval loss: 0.00211\n",
      "epoch 16302 / 20000\n",
      "gradient norm: 0.04142840311396867, minimum ratio: 2.46578947368421\n",
      "\ttrain loss: 0.00215\n",
      "\tval loss: 0.00210\n",
      "epoch 16303 / 20000\n",
      "gradient norm: 0.03068446589168161, minimum ratio: 2.4394736842105265\n",
      "\ttrain loss: 0.00215\n",
      "\tval loss: 0.00211\n",
      "epoch 16304 / 20000\n",
      "gradient norm: 0.04370950965676457, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00215\n",
      "\tval loss: 0.00210\n",
      "epoch 16305 / 20000\n",
      "gradient norm: 0.03565767372492701, minimum ratio: 2.4394736842105265\n",
      "\ttrain loss: 0.00214\n",
      "\tval loss: 0.00210\n",
      "epoch 16306 / 20000\n",
      "gradient norm: 0.023343804816249758, minimum ratio: 2.436842105263158\n",
      "\ttrain loss: 0.00214\n",
      "\tval loss: 0.00210\n",
      "epoch 16307 / 20000\n",
      "gradient norm: 0.01942969366791658, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00214\n",
      "\tval loss: 0.00210\n",
      "epoch 16308 / 20000\n",
      "gradient norm: 0.05157727497862652, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00214\n",
      "\tval loss: 0.00209\n",
      "epoch 16309 / 20000\n",
      "gradient norm: 0.029071623168420047, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00213\n",
      "\tval loss: 0.00209\n",
      "epoch 16310 / 20000\n",
      "gradient norm: 0.0588434255332686, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00214\n",
      "\tval loss: 0.00209\n",
      "epoch 16311 / 20000\n",
      "gradient norm: 0.041311985813081264, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00214\n",
      "\tval loss: 0.00209\n",
      "epoch 16312 / 20000\n",
      "gradient norm: 0.05587466340512037, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00214\n",
      "\tval loss: 0.00209\n",
      "epoch 16313 / 20000\n",
      "gradient norm: 0.02388418890768662, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00213\n",
      "\tval loss: 0.00208\n",
      "epoch 16314 / 20000\n",
      "gradient norm: 0.02400012666475959, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00213\n",
      "\tval loss: 0.00208\n",
      "epoch 16315 / 20000\n",
      "gradient norm: 0.028780961933080107, minimum ratio: 2.460526315789474\n",
      "\ttrain loss: 0.00213\n",
      "\tval loss: 0.00208\n",
      "epoch 16316 / 20000\n",
      "gradient norm: 0.02116035678773187, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00213\n",
      "\tval loss: 0.00208\n",
      "epoch 16317 / 20000\n",
      "gradient norm: 0.03098513698205352, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00213\n",
      "\tval loss: 0.00208\n",
      "epoch 16318 / 20000\n",
      "gradient norm: 0.035873235028702766, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00212\n",
      "\tval loss: 0.00208\n",
      "epoch 16319 / 20000\n",
      "gradient norm: 0.03603265428682789, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00212\n",
      "\tval loss: 0.00208\n",
      "epoch 16320 / 20000\n",
      "gradient norm: 0.04322808881988749, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00212\n",
      "\tval loss: 0.00208\n",
      "epoch 16321 / 20000\n",
      "gradient norm: 0.04954721691319719, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00211\n",
      "\tval loss: 0.00207\n",
      "epoch 16322 / 20000\n",
      "gradient norm: 0.037800265359692276, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00212\n",
      "\tval loss: 0.00207\n",
      "epoch 16323 / 20000\n",
      "gradient norm: 0.0240356934373267, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00211\n",
      "\tval loss: 0.00207\n",
      "epoch 16324 / 20000\n",
      "gradient norm: 0.06817511667031795, minimum ratio: 2.4499999999999997\n",
      "\ttrain loss: 0.00212\n",
      "\tval loss: 0.00206\n",
      "epoch 16325 / 20000\n",
      "gradient norm: 0.06638413027394563, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00212\n",
      "\tval loss: 0.00208\n",
      "epoch 16326 / 20000\n",
      "gradient norm: 0.058645000332035124, minimum ratio: 2.4421052631578943\n",
      "\ttrain loss: 0.00211\n",
      "\tval loss: 0.00206\n",
      "epoch 16327 / 20000\n",
      "gradient norm: 0.028828170150518417, minimum ratio: 2.4447368421052635\n",
      "\ttrain loss: 0.00211\n",
      "\tval loss: 0.00207\n",
      "epoch 16328 / 20000\n",
      "gradient norm: 0.09196559246629477, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00212\n",
      "\tval loss: 0.00207\n",
      "epoch 16329 / 20000\n",
      "gradient norm: 0.04941870865877718, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00211\n",
      "\tval loss: 0.00206\n",
      "epoch 16330 / 20000\n",
      "gradient norm: 0.030201632529497147, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00211\n",
      "\tval loss: 0.00206\n",
      "epoch 16331 / 20000\n",
      "gradient norm: 0.058104817115236074, minimum ratio: 2.4210526315789473\n",
      "\ttrain loss: 0.00211\n",
      "\tval loss: 0.00207\n",
      "epoch 16332 / 20000\n",
      "gradient norm: 0.05199072591494769, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00210\n",
      "\tval loss: 0.00205\n",
      "epoch 16333 / 20000\n",
      "gradient norm: 0.06208597752265632, minimum ratio: 2.423684210526316\n",
      "\ttrain loss: 0.00211\n",
      "\tval loss: 0.00205\n",
      "epoch 16334 / 20000\n",
      "gradient norm: 0.0404967371141538, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00209\n",
      "\tval loss: 0.00207\n",
      "epoch 16335 / 20000\n",
      "gradient norm: 0.051132142485585064, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00210\n",
      "\tval loss: 0.00205\n",
      "epoch 16336 / 20000\n",
      "gradient norm: 0.02747715316945687, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00209\n",
      "\tval loss: 0.00205\n",
      "epoch 16337 / 20000\n",
      "gradient norm: 0.05273595382459462, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00210\n",
      "\tval loss: 0.00205\n",
      "epoch 16338 / 20000\n",
      "gradient norm: 0.025667507608886808, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00209\n",
      "\tval loss: 0.00204\n",
      "epoch 16339 / 20000\n",
      "gradient norm: 0.030246217793319374, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00209\n",
      "\tval loss: 0.00205\n",
      "epoch 16340 / 20000\n",
      "gradient norm: 0.03865535190561786, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00209\n",
      "\tval loss: 0.00204\n",
      "epoch 16341 / 20000\n",
      "gradient norm: 0.04695424303645268, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00209\n",
      "\tval loss: 0.00204\n",
      "epoch 16342 / 20000\n",
      "gradient norm: 0.04747933614999056, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00209\n",
      "\tval loss: 0.00205\n",
      "epoch 16343 / 20000\n",
      "gradient norm: 0.03563472151290625, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00208\n",
      "\tval loss: 0.00204\n",
      "epoch 16344 / 20000\n",
      "gradient norm: 0.06113629578612745, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00209\n",
      "\tval loss: 0.00203\n",
      "epoch 16345 / 20000\n",
      "gradient norm: 0.02887539638322778, minimum ratio: 2.405263157894737\n",
      "\ttrain loss: 0.00208\n",
      "\tval loss: 0.00205\n",
      "epoch 16346 / 20000\n",
      "gradient norm: 0.03777107025962323, minimum ratio: 2.4421052631578943\n",
      "\ttrain loss: 0.00208\n",
      "\tval loss: 0.00203\n",
      "epoch 16347 / 20000\n",
      "gradient norm: 0.07135548582300544, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00209\n",
      "\tval loss: 0.00203\n",
      "epoch 16348 / 20000\n",
      "gradient norm: 0.039705918985418975, minimum ratio: 2.4157894736842103\n",
      "\ttrain loss: 0.00207\n",
      "\tval loss: 0.00205\n",
      "epoch 16349 / 20000\n",
      "gradient norm: 0.07293373218271881, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00208\n",
      "\tval loss: 0.00203\n",
      "epoch 16350 / 20000\n",
      "gradient norm: 0.02711429781629704, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00207\n",
      "\tval loss: 0.00203\n",
      "epoch 16351 / 20000\n",
      "gradient norm: 0.04173777310643345, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00207\n",
      "\tval loss: 0.00203\n",
      "epoch 16352 / 20000\n",
      "gradient norm: 0.05681177828228101, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00208\n",
      "\tval loss: 0.00202\n",
      "epoch 16353 / 20000\n",
      "gradient norm: 0.022086972545366734, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00207\n",
      "\tval loss: 0.00203\n",
      "epoch 16354 / 20000\n",
      "gradient norm: 0.0554255114402622, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00207\n",
      "\tval loss: 0.00202\n",
      "epoch 16355 / 20000\n",
      "gradient norm: 0.062207809067331254, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00207\n",
      "\tval loss: 0.00202\n",
      "epoch 16356 / 20000\n",
      "gradient norm: 0.017738543450832367, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00206\n",
      "\tval loss: 0.00203\n",
      "epoch 16357 / 20000\n",
      "gradient norm: 0.05969084182288498, minimum ratio: 2.418421052631579\n",
      "\ttrain loss: 0.00207\n",
      "\tval loss: 0.00202\n",
      "epoch 16358 / 20000\n",
      "gradient norm: 0.04566011519636959, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00205\n",
      "\tval loss: 0.00201\n",
      "epoch 16359 / 20000\n",
      "gradient norm: 0.04364816634915769, minimum ratio: 2.4236842105263157\n",
      "\ttrain loss: 0.00206\n",
      "\tval loss: 0.00202\n",
      "epoch 16360 / 20000\n",
      "gradient norm: 0.04183029766136315, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00205\n",
      "\tval loss: 0.00201\n",
      "epoch 16361 / 20000\n",
      "gradient norm: 0.04157271049916744, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00205\n",
      "\tval loss: 0.00201\n",
      "epoch 16362 / 20000\n",
      "gradient norm: 0.03137205314124003, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00205\n",
      "\tval loss: 0.00201\n",
      "epoch 16363 / 20000\n",
      "gradient norm: 0.02605157846119255, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00205\n",
      "\tval loss: 0.00201\n",
      "epoch 16364 / 20000\n",
      "gradient norm: 0.04524149437202141, minimum ratio: 2.426315789473684\n",
      "\ttrain loss: 0.00205\n",
      "\tval loss: 0.00200\n",
      "epoch 16365 / 20000\n",
      "gradient norm: 0.06552406831178814, minimum ratio: 2.4236842105263157\n",
      "\ttrain loss: 0.00205\n",
      "\tval loss: 0.00200\n",
      "epoch 16366 / 20000\n",
      "gradient norm: 0.0626021035714075, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00205\n",
      "\tval loss: 0.00201\n",
      "epoch 16367 / 20000\n",
      "gradient norm: 0.029996017401572317, minimum ratio: 2.426315789473684\n",
      "\ttrain loss: 0.00204\n",
      "\tval loss: 0.00200\n",
      "epoch 16368 / 20000\n",
      "gradient norm: 0.04591957060620189, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00204\n",
      "\tval loss: 0.00200\n",
      "epoch 16369 / 20000\n",
      "gradient norm: 0.03335316444281489, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00204\n",
      "\tval loss: 0.00201\n",
      "epoch 16370 / 20000\n",
      "gradient norm: 0.025597940606530756, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00204\n",
      "\tval loss: 0.00199\n",
      "epoch 16371 / 20000\n",
      "gradient norm: 0.0455753508140333, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00204\n",
      "\tval loss: 0.00199\n",
      "epoch 16372 / 20000\n",
      "gradient norm: 0.023259520559804514, minimum ratio: 2.4421052631578952\n",
      "\ttrain loss: 0.00203\n",
      "\tval loss: 0.00200\n",
      "epoch 16373 / 20000\n",
      "gradient norm: 0.03632430313155055, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00203\n",
      "\tval loss: 0.00199\n",
      "epoch 16374 / 20000\n",
      "gradient norm: 0.031456095282919705, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00203\n",
      "\tval loss: 0.00199\n",
      "epoch 16375 / 20000\n",
      "gradient norm: 0.040173964807763696, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00203\n",
      "\tval loss: 0.00199\n",
      "epoch 16376 / 20000\n",
      "gradient norm: 0.055684308550553396, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00203\n",
      "\tval loss: 0.00200\n",
      "epoch 16377 / 20000\n",
      "gradient norm: 0.0352267223643139, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00203\n",
      "\tval loss: 0.00198\n",
      "epoch 16378 / 20000\n",
      "gradient norm: 0.056792289833538234, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00202\n",
      "\tval loss: 0.00198\n",
      "epoch 16379 / 20000\n",
      "gradient norm: 0.034569450945127755, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00203\n",
      "\tval loss: 0.00199\n",
      "epoch 16380 / 20000\n",
      "gradient norm: 0.03615390483173542, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00202\n",
      "\tval loss: 0.00198\n",
      "epoch 16381 / 20000\n",
      "gradient norm: 0.027800749841844663, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00202\n",
      "\tval loss: 0.00198\n",
      "epoch 16382 / 20000\n",
      "gradient norm: 0.04571174317970872, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00202\n",
      "\tval loss: 0.00198\n",
      "epoch 16383 / 20000\n",
      "gradient norm: 0.051195367006585, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00201\n",
      "\tval loss: 0.00198\n",
      "epoch 16384 / 20000\n",
      "gradient norm: 0.06396280537592247, minimum ratio: 2.4263157894736844\n",
      "\ttrain loss: 0.00202\n",
      "\tval loss: 0.00197\n",
      "epoch 16385 / 20000\n",
      "gradient norm: 0.0574923173408024, minimum ratio: 2.4447368421052635\n",
      "\ttrain loss: 0.00201\n",
      "\tval loss: 0.00199\n",
      "epoch 16386 / 20000\n",
      "gradient norm: 0.03865325421793386, minimum ratio: 2.426315789473684\n",
      "\ttrain loss: 0.00201\n",
      "\tval loss: 0.00197\n",
      "epoch 16387 / 20000\n",
      "gradient norm: 0.044369929179083556, minimum ratio: 2.4210526315789473\n",
      "\ttrain loss: 0.00201\n",
      "\tval loss: 0.00197\n",
      "epoch 16388 / 20000\n",
      "gradient norm: 0.05183287209365517, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00201\n",
      "\tval loss: 0.00197\n",
      "epoch 16389 / 20000\n",
      "gradient norm: 0.04612781584728509, minimum ratio: 2.4394736842105265\n",
      "\ttrain loss: 0.00202\n",
      "\tval loss: 0.00196\n",
      "epoch 16390 / 20000\n",
      "gradient norm: 0.043104549695272, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00201\n",
      "\tval loss: 0.00197\n",
      "epoch 16391 / 20000\n",
      "gradient norm: 0.049374360183719546, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00201\n",
      "\tval loss: 0.00196\n",
      "epoch 16392 / 20000\n",
      "gradient norm: 0.06426160401315428, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00201\n",
      "\tval loss: 0.00196\n",
      "epoch 16393 / 20000\n",
      "gradient norm: 0.041866489860694855, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00200\n",
      "\tval loss: 0.00196\n",
      "epoch 16394 / 20000\n",
      "gradient norm: 0.028599044162547216, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00200\n",
      "\tval loss: 0.00196\n",
      "epoch 16395 / 20000\n",
      "gradient norm: 0.046412311028689146, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00200\n",
      "\tval loss: 0.00195\n",
      "epoch 16396 / 20000\n",
      "gradient norm: 0.06139190588146448, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00200\n",
      "\tval loss: 0.00195\n",
      "epoch 16397 / 20000\n",
      "gradient norm: 0.06018977164058015, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00200\n",
      "\tval loss: 0.00197\n",
      "epoch 16398 / 20000\n",
      "gradient norm: 0.09170519420877099, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00201\n",
      "\tval loss: 0.00195\n",
      "epoch 16399 / 20000\n",
      "gradient norm: 0.07864154246635735, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00200\n",
      "\tval loss: 0.00197\n",
      "epoch 16400 / 20000\n",
      "gradient norm: 0.034001358842942864, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00199\n",
      "\tval loss: 0.00195\n",
      "epoch 16401 / 20000\n",
      "gradient norm: 0.050751078757457435, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00199\n",
      "\tval loss: 0.00195\n",
      "epoch 16402 / 20000\n",
      "gradient norm: 0.05639938497915864, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00199\n",
      "\tval loss: 0.00196\n",
      "epoch 16403 / 20000\n",
      "gradient norm: 0.08256838959641755, minimum ratio: 2.426315789473684\n",
      "\ttrain loss: 0.00199\n",
      "\tval loss: 0.00194\n",
      "epoch 16404 / 20000\n",
      "gradient norm: 0.04475560656283051, minimum ratio: 2.4394736842105265\n",
      "\ttrain loss: 0.00199\n",
      "\tval loss: 0.00194\n",
      "epoch 16405 / 20000\n",
      "gradient norm: 0.05225919920485467, minimum ratio: 2.4499999999999997\n",
      "\ttrain loss: 0.00198\n",
      "\tval loss: 0.00195\n",
      "epoch 16406 / 20000\n",
      "gradient norm: 0.026848506124224514, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00198\n",
      "\tval loss: 0.00194\n",
      "epoch 16407 / 20000\n",
      "gradient norm: 0.05242651759181172, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00198\n",
      "\tval loss: 0.00194\n",
      "epoch 16408 / 20000\n",
      "gradient norm: 0.04195658629760146, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00198\n",
      "\tval loss: 0.00194\n",
      "epoch 16409 / 20000\n",
      "gradient norm: 0.040148031257558614, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00198\n",
      "\tval loss: 0.00194\n",
      "epoch 16410 / 20000\n",
      "gradient norm: 0.032046996464487165, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00197\n",
      "\tval loss: 0.00193\n",
      "epoch 16411 / 20000\n",
      "gradient norm: 0.01591559825465083, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00197\n",
      "\tval loss: 0.00194\n",
      "epoch 16412 / 20000\n",
      "gradient norm: 0.03210757439956069, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00197\n",
      "\tval loss: 0.00193\n",
      "epoch 16413 / 20000\n",
      "gradient norm: 0.026319030905142426, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00197\n",
      "\tval loss: 0.00193\n",
      "epoch 16414 / 20000\n",
      "gradient norm: 0.05526396352797747, minimum ratio: 2.4499999999999997\n",
      "\ttrain loss: 0.00197\n",
      "\tval loss: 0.00193\n",
      "epoch 16415 / 20000\n",
      "gradient norm: 0.06027509202249348, minimum ratio: 2.4026315789473682\n",
      "\ttrain loss: 0.00197\n",
      "\tval loss: 0.00194\n",
      "epoch 16416 / 20000\n",
      "gradient norm: 0.03553851100150496, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00197\n",
      "\tval loss: 0.00192\n",
      "epoch 16417 / 20000\n",
      "gradient norm: 0.058431834855582565, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00197\n",
      "\tval loss: 0.00192\n",
      "epoch 16418 / 20000\n",
      "gradient norm: 0.05867843120358884, minimum ratio: 2.4157894736842103\n",
      "\ttrain loss: 0.00196\n",
      "\tval loss: 0.00193\n",
      "epoch 16419 / 20000\n",
      "gradient norm: 0.06680221241549589, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00196\n",
      "\tval loss: 0.00192\n",
      "epoch 16420 / 20000\n",
      "gradient norm: 0.02673988149035722, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00196\n",
      "\tval loss: 0.00192\n",
      "epoch 16421 / 20000\n",
      "gradient norm: 0.05469077575253323, minimum ratio: 2.46578947368421\n",
      "\ttrain loss: 0.00196\n",
      "\tval loss: 0.00192\n",
      "epoch 16422 / 20000\n",
      "gradient norm: 0.03843241889262572, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00195\n",
      "\tval loss: 0.00192\n",
      "epoch 16423 / 20000\n",
      "gradient norm: 0.039825119951274246, minimum ratio: 2.4236842105263157\n",
      "\ttrain loss: 0.00195\n",
      "\tval loss: 0.00191\n",
      "epoch 16424 / 20000\n",
      "gradient norm: 0.03892267408082262, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00195\n",
      "\tval loss: 0.00191\n",
      "epoch 16425 / 20000\n",
      "gradient norm: 0.05155651021050289, minimum ratio: 2.4394736842105265\n",
      "\ttrain loss: 0.00195\n",
      "\tval loss: 0.00192\n",
      "epoch 16426 / 20000\n",
      "gradient norm: 0.04660288448212668, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00195\n",
      "\tval loss: 0.00191\n",
      "epoch 16427 / 20000\n",
      "gradient norm: 0.04298818839015439, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00195\n",
      "\tval loss: 0.00191\n",
      "epoch 16428 / 20000\n",
      "gradient norm: 0.047773457830771804, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00195\n",
      "\tval loss: 0.00190\n",
      "epoch 16429 / 20000\n",
      "gradient norm: 0.03149598545860499, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00194\n",
      "\tval loss: 0.00191\n",
      "epoch 16430 / 20000\n",
      "gradient norm: 0.030318557226564735, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00194\n",
      "\tval loss: 0.00190\n",
      "epoch 16431 / 20000\n",
      "gradient norm: 0.04144130938220769, minimum ratio: 2.4447368421052635\n",
      "\ttrain loss: 0.00194\n",
      "\tval loss: 0.00190\n",
      "epoch 16432 / 20000\n",
      "gradient norm: 0.036940259917173535, minimum ratio: 2.4289473684210523\n",
      "\ttrain loss: 0.00194\n",
      "\tval loss: 0.00190\n",
      "epoch 16433 / 20000\n",
      "gradient norm: 0.04039604222634807, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00194\n",
      "\tval loss: 0.00190\n",
      "epoch 16434 / 20000\n",
      "gradient norm: 0.050571682455483824, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00194\n",
      "\tval loss: 0.00190\n",
      "epoch 16435 / 20000\n",
      "gradient norm: 0.033283333003055304, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00193\n",
      "\tval loss: 0.00189\n",
      "epoch 16436 / 20000\n",
      "gradient norm: 0.02420094402623363, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00193\n",
      "\tval loss: 0.00190\n",
      "epoch 16437 / 20000\n",
      "gradient norm: 0.059699739096686244, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00194\n",
      "\tval loss: 0.00189\n",
      "epoch 16438 / 20000\n",
      "gradient norm: 0.05527474347036332, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00193\n",
      "\tval loss: 0.00189\n",
      "epoch 16439 / 20000\n",
      "gradient norm: 0.06463248992804438, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00194\n",
      "\tval loss: 0.00190\n",
      "epoch 16440 / 20000\n",
      "gradient norm: 0.08963354775914922, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00194\n",
      "\tval loss: 0.00188\n",
      "epoch 16441 / 20000\n",
      "gradient norm: 0.014960418513510376, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00192\n",
      "\tval loss: 0.00189\n",
      "epoch 16442 / 20000\n",
      "gradient norm: 0.05842023086734116, minimum ratio: 2.4421052631578943\n",
      "\ttrain loss: 0.00193\n",
      "\tval loss: 0.00189\n",
      "epoch 16443 / 20000\n",
      "gradient norm: 0.03662190004251897, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00192\n",
      "\tval loss: 0.00188\n",
      "epoch 16444 / 20000\n",
      "gradient norm: 0.05757758964318782, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00192\n",
      "\tval loss: 0.00189\n",
      "epoch 16445 / 20000\n",
      "gradient norm: 0.02701664000051096, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00192\n",
      "\tval loss: 0.00188\n",
      "epoch 16446 / 20000\n",
      "gradient norm: 0.03368933347519487, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00192\n",
      "\tval loss: 0.00188\n",
      "epoch 16447 / 20000\n",
      "gradient norm: 0.038425451377406716, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00192\n",
      "\tval loss: 0.00188\n",
      "epoch 16448 / 20000\n",
      "gradient norm: 0.04347729025175795, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00192\n",
      "\tval loss: 0.00188\n",
      "epoch 16449 / 20000\n",
      "gradient norm: 0.055690136447083205, minimum ratio: 2.4421052631578943\n",
      "\ttrain loss: 0.00192\n",
      "\tval loss: 0.00187\n",
      "epoch 16450 / 20000\n",
      "gradient norm: 0.028977634327020496, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00191\n",
      "\tval loss: 0.00188\n",
      "epoch 16451 / 20000\n",
      "gradient norm: 0.07905110163846985, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00191\n",
      "\tval loss: 0.00187\n",
      "epoch 16452 / 20000\n",
      "gradient norm: 0.01198990699776914, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00190\n",
      "\tval loss: 0.00187\n",
      "epoch 16453 / 20000\n",
      "gradient norm: 0.025588800926925614, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00190\n",
      "\tval loss: 0.00187\n",
      "epoch 16454 / 20000\n",
      "gradient norm: 0.040137469361070544, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00191\n",
      "\tval loss: 0.00187\n",
      "epoch 16455 / 20000\n",
      "gradient norm: 0.0553164760931395, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00191\n",
      "\tval loss: 0.00186\n",
      "epoch 16456 / 20000\n",
      "gradient norm: 0.04888162878341973, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00190\n",
      "\tval loss: 0.00187\n",
      "epoch 16457 / 20000\n",
      "gradient norm: 0.047557562473230064, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00190\n",
      "\tval loss: 0.00186\n",
      "epoch 16458 / 20000\n",
      "gradient norm: 0.041726978321094066, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00190\n",
      "\tval loss: 0.00186\n",
      "epoch 16459 / 20000\n",
      "gradient norm: 0.0453704833635129, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00189\n",
      "\tval loss: 0.00187\n",
      "epoch 16460 / 20000\n",
      "gradient norm: 0.05994683410972357, minimum ratio: 2.4263157894736844\n",
      "\ttrain loss: 0.00190\n",
      "\tval loss: 0.00186\n",
      "epoch 16461 / 20000\n",
      "gradient norm: 0.040062232699710876, minimum ratio: 2.4236842105263157\n",
      "\ttrain loss: 0.00190\n",
      "\tval loss: 0.00185\n",
      "epoch 16462 / 20000\n",
      "gradient norm: 0.04729106440208852, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00190\n",
      "\tval loss: 0.00186\n",
      "epoch 16463 / 20000\n",
      "gradient norm: 0.02846980228787288, minimum ratio: 2.4236842105263157\n",
      "\ttrain loss: 0.00189\n",
      "\tval loss: 0.00185\n",
      "epoch 16464 / 20000\n",
      "gradient norm: 0.04386022762628272, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00189\n",
      "\tval loss: 0.00185\n",
      "epoch 16465 / 20000\n",
      "gradient norm: 0.04166049126069993, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00189\n",
      "\tval loss: 0.00186\n",
      "epoch 16466 / 20000\n",
      "gradient norm: 0.035743020998779684, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00189\n",
      "\tval loss: 0.00185\n",
      "epoch 16467 / 20000\n",
      "gradient norm: 0.04378983553033322, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00189\n",
      "\tval loss: 0.00184\n",
      "epoch 16468 / 20000\n",
      "gradient norm: 0.05075972276972607, minimum ratio: 2.4421052631578943\n",
      "\ttrain loss: 0.00188\n",
      "\tval loss: 0.00186\n",
      "epoch 16469 / 20000\n",
      "gradient norm: 0.032961607445031404, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00188\n",
      "\tval loss: 0.00184\n",
      "epoch 16470 / 20000\n",
      "gradient norm: 0.04136515752179548, minimum ratio: 2.421052631578948\n",
      "\ttrain loss: 0.00188\n",
      "\tval loss: 0.00184\n",
      "epoch 16471 / 20000\n",
      "gradient norm: 0.056640463415533304, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00187\n",
      "\tval loss: 0.00184\n",
      "epoch 16472 / 20000\n",
      "gradient norm: 0.015602690516971052, minimum ratio: 2.4394736842105265\n",
      "\ttrain loss: 0.00188\n",
      "\tval loss: 0.00184\n",
      "epoch 16473 / 20000\n",
      "gradient norm: 0.028473534563090652, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00187\n",
      "\tval loss: 0.00184\n",
      "epoch 16474 / 20000\n",
      "gradient norm: 0.025719992321683094, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00187\n",
      "\tval loss: 0.00183\n",
      "epoch 16475 / 20000\n",
      "gradient norm: 0.02379604638554156, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00187\n",
      "\tval loss: 0.00184\n",
      "epoch 16476 / 20000\n",
      "gradient norm: 0.03617843799293041, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00187\n",
      "\tval loss: 0.00183\n",
      "epoch 16477 / 20000\n",
      "gradient norm: 0.038300544139929116, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00187\n",
      "\tval loss: 0.00183\n",
      "epoch 16478 / 20000\n",
      "gradient norm: 0.027201864024391398, minimum ratio: 2.4394736842105265\n",
      "\ttrain loss: 0.00187\n",
      "\tval loss: 0.00183\n",
      "epoch 16479 / 20000\n",
      "gradient norm: 0.03073824552120641, minimum ratio: 2.4447368421052627\n",
      "\ttrain loss: 0.00186\n",
      "\tval loss: 0.00183\n",
      "epoch 16480 / 20000\n",
      "gradient norm: 0.02560855046613142, minimum ratio: 2.4394736842105265\n",
      "\ttrain loss: 0.00186\n",
      "\tval loss: 0.00183\n",
      "epoch 16481 / 20000\n",
      "gradient norm: 0.027459113160148263, minimum ratio: 2.423684210526316\n",
      "\ttrain loss: 0.00186\n",
      "\tval loss: 0.00183\n",
      "epoch 16482 / 20000\n",
      "gradient norm: 0.05617590976180509, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00186\n",
      "\tval loss: 0.00182\n",
      "epoch 16483 / 20000\n",
      "gradient norm: 0.06290529598481953, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00186\n",
      "\tval loss: 0.00182\n",
      "epoch 16484 / 20000\n",
      "gradient norm: 0.03833917423617095, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00186\n",
      "\tval loss: 0.00183\n",
      "epoch 16485 / 20000\n",
      "gradient norm: 0.034243661270011216, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00185\n",
      "\tval loss: 0.00182\n",
      "epoch 16486 / 20000\n",
      "gradient norm: 0.06088206253480166, minimum ratio: 2.4447368421052635\n",
      "\ttrain loss: 0.00186\n",
      "\tval loss: 0.00182\n",
      "epoch 16487 / 20000\n",
      "gradient norm: 0.029668268616660498, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00185\n",
      "\tval loss: 0.00182\n",
      "epoch 16488 / 20000\n",
      "gradient norm: 0.04554617719259113, minimum ratio: 2.418421052631579\n",
      "\ttrain loss: 0.00185\n",
      "\tval loss: 0.00182\n",
      "epoch 16489 / 20000\n",
      "gradient norm: 0.03655498492298648, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00185\n",
      "\tval loss: 0.00181\n",
      "epoch 16490 / 20000\n",
      "gradient norm: 0.04709343780996278, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00185\n",
      "\tval loss: 0.00181\n",
      "epoch 16491 / 20000\n",
      "gradient norm: 0.03841306548565626, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00185\n",
      "\tval loss: 0.00181\n",
      "epoch 16492 / 20000\n",
      "gradient norm: 0.02345980166865047, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00184\n",
      "\tval loss: 0.00181\n",
      "epoch 16493 / 20000\n",
      "gradient norm: 0.08925207343418151, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00185\n",
      "\tval loss: 0.00181\n",
      "epoch 16494 / 20000\n",
      "gradient norm: 0.08064425026532263, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00185\n",
      "\tval loss: 0.00182\n",
      "epoch 16495 / 20000\n",
      "gradient norm: 0.08909676934126765, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00185\n",
      "\tval loss: 0.00180\n",
      "epoch 16496 / 20000\n",
      "gradient norm: 0.03302518400596455, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00184\n",
      "\tval loss: 0.00182\n",
      "epoch 16497 / 20000\n",
      "gradient norm: 0.04337711475091055, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00184\n",
      "\tval loss: 0.00180\n",
      "epoch 16498 / 20000\n",
      "gradient norm: 0.038365482119843364, minimum ratio: 2.4394736842105265\n",
      "\ttrain loss: 0.00184\n",
      "\tval loss: 0.00180\n",
      "epoch 16499 / 20000\n",
      "gradient norm: 0.08095520769711584, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00184\n",
      "\tval loss: 0.00181\n",
      "epoch 16500 / 20000\n",
      "gradient norm: 0.058617484173737466, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00184\n",
      "\tval loss: 0.00179\n",
      "epoch 16501 / 20000\n",
      "gradient norm: 0.05050396197475493, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00183\n",
      "\tval loss: 0.00180\n",
      "epoch 16502 / 20000\n",
      "gradient norm: 0.03647415549494326, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00183\n",
      "\tval loss: 0.00179\n",
      "epoch 16503 / 20000\n",
      "gradient norm: 0.053607196430675685, minimum ratio: 2.436842105263158\n",
      "\ttrain loss: 0.00183\n",
      "\tval loss: 0.00179\n",
      "epoch 16504 / 20000\n",
      "gradient norm: 0.045795738988090307, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00184\n",
      "\tval loss: 0.00179\n",
      "epoch 16505 / 20000\n",
      "gradient norm: 0.056921572249848396, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00183\n",
      "\tval loss: 0.00180\n",
      "epoch 16506 / 20000\n",
      "gradient norm: 0.05546236480586231, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00183\n",
      "\tval loss: 0.00179\n",
      "epoch 16507 / 20000\n",
      "gradient norm: 0.03018112070276402, minimum ratio: 2.4394736842105265\n",
      "\ttrain loss: 0.00182\n",
      "\tval loss: 0.00179\n",
      "epoch 16508 / 20000\n",
      "gradient norm: 0.04877945745829493, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00182\n",
      "\tval loss: 0.00179\n",
      "epoch 16509 / 20000\n",
      "gradient norm: 0.025209381594322622, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00181\n",
      "\tval loss: 0.00178\n",
      "epoch 16510 / 20000\n",
      "gradient norm: 0.0219956265646033, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00182\n",
      "\tval loss: 0.00178\n",
      "epoch 16511 / 20000\n",
      "gradient norm: 0.051064416649751365, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00182\n",
      "\tval loss: 0.00178\n",
      "epoch 16512 / 20000\n",
      "gradient norm: 0.04417772078886628, minimum ratio: 2.4263157894736844\n",
      "\ttrain loss: 0.00181\n",
      "\tval loss: 0.00178\n",
      "epoch 16513 / 20000\n",
      "gradient norm: 0.03771451994543895, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00181\n",
      "\tval loss: 0.00178\n",
      "epoch 16514 / 20000\n",
      "gradient norm: 0.053065054409671575, minimum ratio: 2.46578947368421\n",
      "\ttrain loss: 0.00181\n",
      "\tval loss: 0.00178\n",
      "epoch 16515 / 20000\n",
      "gradient norm: 0.04826996347401291, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00181\n",
      "\tval loss: 0.00177\n",
      "epoch 16516 / 20000\n",
      "gradient norm: 0.05431447993032634, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00181\n",
      "\tval loss: 0.00178\n",
      "epoch 16517 / 20000\n",
      "gradient norm: 0.025507775251753628, minimum ratio: 2.421052631578947\n",
      "\ttrain loss: 0.00181\n",
      "\tval loss: 0.00177\n",
      "epoch 16518 / 20000\n",
      "gradient norm: 0.042366719571873546, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00181\n",
      "\tval loss: 0.00177\n",
      "epoch 16519 / 20000\n",
      "gradient norm: 0.02983458078233525, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00180\n",
      "\tval loss: 0.00178\n",
      "epoch 16520 / 20000\n",
      "gradient norm: 0.05430000030901283, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00180\n",
      "\tval loss: 0.00177\n",
      "epoch 16521 / 20000\n",
      "gradient norm: 0.03096937946975231, minimum ratio: 2.4236842105263157\n",
      "\ttrain loss: 0.00180\n",
      "\tval loss: 0.00176\n",
      "epoch 16522 / 20000\n",
      "gradient norm: 0.046191240719053894, minimum ratio: 2.426315789473684\n",
      "\ttrain loss: 0.00180\n",
      "\tval loss: 0.00177\n",
      "epoch 16523 / 20000\n",
      "gradient norm: 0.027385378547478467, minimum ratio: 2.4447368421052627\n",
      "\ttrain loss: 0.00180\n",
      "\tval loss: 0.00176\n",
      "epoch 16524 / 20000\n",
      "gradient norm: 0.028392655483912677, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00179\n",
      "\tval loss: 0.00176\n",
      "epoch 16525 / 20000\n",
      "gradient norm: 0.03756818827241659, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00179\n",
      "\tval loss: 0.00176\n",
      "epoch 16526 / 20000\n",
      "gradient norm: 0.02327792189316824, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00180\n",
      "\tval loss: 0.00176\n",
      "epoch 16527 / 20000\n",
      "gradient norm: 0.03979801249806769, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00179\n",
      "\tval loss: 0.00176\n",
      "epoch 16528 / 20000\n",
      "gradient norm: 0.024172959907446057, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00179\n",
      "\tval loss: 0.00176\n",
      "epoch 16529 / 20000\n",
      "gradient norm: 0.03230830084066838, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00179\n",
      "\tval loss: 0.00176\n",
      "epoch 16530 / 20000\n",
      "gradient norm: 0.05467131099430844, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00179\n",
      "\tval loss: 0.00175\n",
      "epoch 16531 / 20000\n",
      "gradient norm: 0.04595916671678424, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00179\n",
      "\tval loss: 0.00176\n",
      "epoch 16532 / 20000\n",
      "gradient norm: 0.0368399890139699, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00179\n",
      "\tval loss: 0.00176\n",
      "epoch 16533 / 20000\n",
      "gradient norm: 0.0397137391846627, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00178\n",
      "\tval loss: 0.00175\n",
      "epoch 16534 / 20000\n",
      "gradient norm: 0.040105416846927255, minimum ratio: 2.452631578947368\n",
      "\ttrain loss: 0.00178\n",
      "\tval loss: 0.00175\n",
      "epoch 16535 / 20000\n",
      "gradient norm: 0.03904074925230816, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00178\n",
      "\tval loss: 0.00175\n",
      "epoch 16536 / 20000\n",
      "gradient norm: 0.026981066330336034, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00177\n",
      "\tval loss: 0.00174\n",
      "epoch 16537 / 20000\n",
      "gradient norm: 0.058802529820241034, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00178\n",
      "\tval loss: 0.00175\n",
      "epoch 16538 / 20000\n",
      "gradient norm: 0.02062412310624495, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00178\n",
      "\tval loss: 0.00174\n",
      "epoch 16539 / 20000\n",
      "gradient norm: 0.053587609698297456, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00178\n",
      "\tval loss: 0.00174\n",
      "epoch 16540 / 20000\n",
      "gradient norm: 0.06719576031900942, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00178\n",
      "\tval loss: 0.00175\n",
      "epoch 16541 / 20000\n",
      "gradient norm: 0.048932048259302974, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00177\n",
      "\tval loss: 0.00173\n",
      "epoch 16542 / 20000\n",
      "gradient norm: 0.035167336056474596, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00177\n",
      "\tval loss: 0.00174\n",
      "epoch 16543 / 20000\n",
      "gradient norm: 0.0478313195053488, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00177\n",
      "\tval loss: 0.00174\n",
      "epoch 16544 / 20000\n",
      "gradient norm: 0.020272522437153384, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00177\n",
      "\tval loss: 0.00173\n",
      "epoch 16545 / 20000\n",
      "gradient norm: 0.029089275747537613, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00176\n",
      "\tval loss: 0.00173\n",
      "epoch 16546 / 20000\n",
      "gradient norm: 0.018026258534519002, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00176\n",
      "\tval loss: 0.00173\n",
      "epoch 16547 / 20000\n",
      "gradient norm: 0.04980852024164051, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00176\n",
      "\tval loss: 0.00173\n",
      "epoch 16548 / 20000\n",
      "gradient norm: 0.032628541404847056, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00176\n",
      "\tval loss: 0.00172\n",
      "epoch 16549 / 20000\n",
      "gradient norm: 0.03259669980616309, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00176\n",
      "\tval loss: 0.00173\n",
      "epoch 16550 / 20000\n",
      "gradient norm: 0.019271564087830484, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00176\n",
      "\tval loss: 0.00172\n",
      "epoch 16551 / 20000\n",
      "gradient norm: 0.03409695776645094, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00175\n",
      "\tval loss: 0.00172\n",
      "epoch 16552 / 20000\n",
      "gradient norm: 0.01629904712899588, minimum ratio: 2.4210526315789473\n",
      "\ttrain loss: 0.00175\n",
      "\tval loss: 0.00172\n",
      "epoch 16553 / 20000\n",
      "gradient norm: 0.024505603651050478, minimum ratio: 2.4499999999999997\n",
      "\ttrain loss: 0.00175\n",
      "\tval loss: 0.00172\n",
      "epoch 16554 / 20000\n",
      "gradient norm: 0.03537454007891938, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00175\n",
      "\tval loss: 0.00172\n",
      "epoch 16555 / 20000\n",
      "gradient norm: 0.0467240049620159, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00175\n",
      "\tval loss: 0.00172\n",
      "epoch 16556 / 20000\n",
      "gradient norm: 0.04354050668189302, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00175\n",
      "\tval loss: 0.00172\n",
      "epoch 16557 / 20000\n",
      "gradient norm: 0.015138051239773631, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00174\n",
      "\tval loss: 0.00171\n",
      "epoch 16558 / 20000\n",
      "gradient norm: 0.028988972248043865, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00175\n",
      "\tval loss: 0.00171\n",
      "epoch 16559 / 20000\n",
      "gradient norm: 0.016085156297776848, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00174\n",
      "\tval loss: 0.00171\n",
      "epoch 16560 / 20000\n",
      "gradient norm: 0.024532098905183375, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00174\n",
      "\tval loss: 0.00171\n",
      "epoch 16561 / 20000\n",
      "gradient norm: 0.0243820309988223, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00174\n",
      "\tval loss: 0.00171\n",
      "epoch 16562 / 20000\n",
      "gradient norm: 0.023838380933739245, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00174\n",
      "\tval loss: 0.00171\n",
      "epoch 16563 / 20000\n",
      "gradient norm: 0.02912700443994254, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00174\n",
      "\tval loss: 0.00171\n",
      "epoch 16564 / 20000\n",
      "gradient norm: 0.026566543383523822, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00174\n",
      "\tval loss: 0.00170\n",
      "epoch 16565 / 20000\n",
      "gradient norm: 0.0177424376597628, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00173\n",
      "\tval loss: 0.00170\n",
      "epoch 16566 / 20000\n",
      "gradient norm: 0.023512200743425637, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00173\n",
      "\tval loss: 0.00170\n",
      "epoch 16567 / 20000\n",
      "gradient norm: 0.060236406221520156, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00173\n",
      "\tval loss: 0.00170\n",
      "epoch 16568 / 20000\n",
      "gradient norm: 0.034349411085713655, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00173\n",
      "\tval loss: 0.00170\n",
      "epoch 16569 / 20000\n",
      "gradient norm: 0.024632992106489837, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00173\n",
      "\tval loss: 0.00170\n",
      "epoch 16570 / 20000\n",
      "gradient norm: 0.024568953143898398, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00173\n",
      "\tval loss: 0.00169\n",
      "epoch 16571 / 20000\n",
      "gradient norm: 0.045031944988295436, minimum ratio: 2.4447368421052635\n",
      "\ttrain loss: 0.00173\n",
      "\tval loss: 0.00169\n",
      "epoch 16572 / 20000\n",
      "gradient norm: 0.03134152812708635, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00172\n",
      "\tval loss: 0.00170\n",
      "epoch 16573 / 20000\n",
      "gradient norm: 0.050909971934743226, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00173\n",
      "\tval loss: 0.00169\n",
      "epoch 16574 / 20000\n",
      "gradient norm: 0.01879580010427162, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00172\n",
      "\tval loss: 0.00169\n",
      "epoch 16575 / 20000\n",
      "gradient norm: 0.02000412467168644, minimum ratio: 2.4105263157894736\n",
      "\ttrain loss: 0.00172\n",
      "\tval loss: 0.00169\n",
      "epoch 16576 / 20000\n",
      "gradient norm: 0.03660211552050896, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00172\n",
      "\tval loss: 0.00168\n",
      "epoch 16577 / 20000\n",
      "gradient norm: 0.05722172115929425, minimum ratio: 2.436842105263158\n",
      "\ttrain loss: 0.00172\n",
      "\tval loss: 0.00169\n",
      "epoch 16578 / 20000\n",
      "gradient norm: 0.06401215703226626, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00172\n",
      "\tval loss: 0.00168\n",
      "epoch 16579 / 20000\n",
      "gradient norm: 0.025515141140203923, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00171\n",
      "\tval loss: 0.00169\n",
      "epoch 16580 / 20000\n",
      "gradient norm: 0.08173542044823989, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00172\n",
      "\tval loss: 0.00168\n",
      "epoch 16581 / 20000\n",
      "gradient norm: 0.042345891473814845, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00171\n",
      "\tval loss: 0.00168\n",
      "epoch 16582 / 20000\n",
      "gradient norm: 0.02765092285699211, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00171\n",
      "\tval loss: 0.00168\n",
      "epoch 16583 / 20000\n",
      "gradient norm: 0.033613745123147964, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00170\n",
      "\tval loss: 0.00168\n",
      "epoch 16584 / 20000\n",
      "gradient norm: 0.05145356190041639, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00171\n",
      "\tval loss: 0.00168\n",
      "epoch 16585 / 20000\n",
      "gradient norm: 0.023231407831190154, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00170\n",
      "\tval loss: 0.00167\n",
      "epoch 16586 / 20000\n",
      "gradient norm: 0.03511640045326203, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00170\n",
      "\tval loss: 0.00167\n",
      "epoch 16587 / 20000\n",
      "gradient norm: 0.03630067384801805, minimum ratio: 2.4421052631578943\n",
      "\ttrain loss: 0.00170\n",
      "\tval loss: 0.00167\n",
      "epoch 16588 / 20000\n",
      "gradient norm: 0.05155511113116518, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00170\n",
      "\tval loss: 0.00167\n",
      "epoch 16589 / 20000\n",
      "gradient norm: 0.07393953134305775, minimum ratio: 2.43421052631579\n",
      "\ttrain loss: 0.00171\n",
      "\tval loss: 0.00167\n",
      "epoch 16590 / 20000\n",
      "gradient norm: 0.06562962685711682, minimum ratio: 2.4421052631578943\n",
      "\ttrain loss: 0.00170\n",
      "\tval loss: 0.00168\n",
      "epoch 16591 / 20000\n",
      "gradient norm: 0.04701589449541643, minimum ratio: 2.4157894736842103\n",
      "\ttrain loss: 0.00170\n",
      "\tval loss: 0.00166\n",
      "epoch 16592 / 20000\n",
      "gradient norm: 0.06539304321631789, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00170\n",
      "\tval loss: 0.00166\n",
      "epoch 16593 / 20000\n",
      "gradient norm: 0.037772511423099786, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00169\n",
      "\tval loss: 0.00167\n",
      "epoch 16594 / 20000\n",
      "gradient norm: 0.05606443446595222, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00169\n",
      "\tval loss: 0.00166\n",
      "epoch 16595 / 20000\n",
      "gradient norm: 0.041803992236964405, minimum ratio: 2.4394736842105265\n",
      "\ttrain loss: 0.00169\n",
      "\tval loss: 0.00166\n",
      "epoch 16596 / 20000\n",
      "gradient norm: 0.03419677243800834, minimum ratio: 2.426315789473684\n",
      "\ttrain loss: 0.00169\n",
      "\tval loss: 0.00166\n",
      "epoch 16597 / 20000\n",
      "gradient norm: 0.04009385470999405, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00169\n",
      "\tval loss: 0.00166\n",
      "epoch 16598 / 20000\n",
      "gradient norm: 0.03749221537145786, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00168\n",
      "\tval loss: 0.00166\n",
      "epoch 16599 / 20000\n",
      "gradient norm: 0.018181241845013574, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00168\n",
      "\tval loss: 0.00165\n",
      "epoch 16600 / 20000\n",
      "gradient norm: 0.043647681683069095, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00168\n",
      "\tval loss: 0.00165\n",
      "epoch 16601 / 20000\n",
      "gradient norm: 0.03409123048186302, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00168\n",
      "\tval loss: 0.00165\n",
      "epoch 16602 / 20000\n",
      "gradient norm: 0.04621155862696469, minimum ratio: 2.4421052631578943\n",
      "\ttrain loss: 0.00168\n",
      "\tval loss: 0.00165\n",
      "epoch 16603 / 20000\n",
      "gradient norm: 0.033776230353396386, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00168\n",
      "\tval loss: 0.00164\n",
      "epoch 16604 / 20000\n",
      "gradient norm: 0.029598965833429247, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00167\n",
      "\tval loss: 0.00165\n",
      "epoch 16605 / 20000\n",
      "gradient norm: 0.039253806695342064, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00168\n",
      "\tval loss: 0.00165\n",
      "epoch 16606 / 20000\n",
      "gradient norm: 0.054315852583386004, minimum ratio: 2.426315789473684\n",
      "\ttrain loss: 0.00167\n",
      "\tval loss: 0.00164\n",
      "epoch 16607 / 20000\n",
      "gradient norm: 0.06748944742139429, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00168\n",
      "\tval loss: 0.00165\n",
      "epoch 16608 / 20000\n",
      "gradient norm: 0.02796242234762758, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00167\n",
      "\tval loss: 0.00164\n",
      "epoch 16609 / 20000\n",
      "gradient norm: 0.04321965132839978, minimum ratio: 2.4263157894736844\n",
      "\ttrain loss: 0.00167\n",
      "\tval loss: 0.00164\n",
      "epoch 16610 / 20000\n",
      "gradient norm: 0.04152897419407964, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00167\n",
      "\tval loss: 0.00164\n",
      "epoch 16611 / 20000\n",
      "gradient norm: 0.062307825894095004, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00167\n",
      "\tval loss: 0.00163\n",
      "epoch 16612 / 20000\n",
      "gradient norm: 0.03575660235946998, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00167\n",
      "\tval loss: 0.00164\n",
      "epoch 16613 / 20000\n",
      "gradient norm: 0.03231713242712431, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00167\n",
      "\tval loss: 0.00163\n",
      "epoch 16614 / 20000\n",
      "gradient norm: 0.044413937896024436, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00166\n",
      "\tval loss: 0.00163\n",
      "epoch 16615 / 20000\n",
      "gradient norm: 0.039421905123163015, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00167\n",
      "\tval loss: 0.00164\n",
      "epoch 16616 / 20000\n",
      "gradient norm: 0.03830570218269713, minimum ratio: 2.436842105263158\n",
      "\ttrain loss: 0.00166\n",
      "\tval loss: 0.00163\n",
      "epoch 16617 / 20000\n",
      "gradient norm: 0.04365535592660308, minimum ratio: 2.4421052631578943\n",
      "\ttrain loss: 0.00166\n",
      "\tval loss: 0.00162\n",
      "epoch 16618 / 20000\n",
      "gradient norm: 0.06127331766765565, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00166\n",
      "\tval loss: 0.00164\n",
      "epoch 16619 / 20000\n",
      "gradient norm: 0.06564852001611143, minimum ratio: 2.436842105263158\n",
      "\ttrain loss: 0.00165\n",
      "\tval loss: 0.00162\n",
      "epoch 16620 / 20000\n",
      "gradient norm: 0.03456088875827845, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00165\n",
      "\tval loss: 0.00162\n",
      "epoch 16621 / 20000\n",
      "gradient norm: 0.0263589724781923, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00165\n",
      "\tval loss: 0.00162\n",
      "epoch 16622 / 20000\n",
      "gradient norm: 0.0314388595870696, minimum ratio: 2.4263157894736844\n",
      "\ttrain loss: 0.00165\n",
      "\tval loss: 0.00162\n",
      "epoch 16623 / 20000\n",
      "gradient norm: 0.02427445279317908, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00165\n",
      "\tval loss: 0.00162\n",
      "epoch 16624 / 20000\n",
      "gradient norm: 0.04508132144110277, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00164\n",
      "\tval loss: 0.00162\n",
      "epoch 16625 / 20000\n",
      "gradient norm: 0.031840933894272894, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00164\n",
      "\tval loss: 0.00161\n",
      "epoch 16626 / 20000\n",
      "gradient norm: 0.018774552328977734, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00164\n",
      "\tval loss: 0.00161\n",
      "epoch 16627 / 20000\n",
      "gradient norm: 0.0619692481122911, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00164\n",
      "\tval loss: 0.00162\n",
      "epoch 16628 / 20000\n",
      "gradient norm: 0.048564576281933114, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00164\n",
      "\tval loss: 0.00161\n",
      "epoch 16629 / 20000\n",
      "gradient norm: 0.0445855263969861, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00164\n",
      "\tval loss: 0.00162\n",
      "epoch 16630 / 20000\n",
      "gradient norm: 0.03500968957087025, minimum ratio: 2.4236842105263157\n",
      "\ttrain loss: 0.00164\n",
      "\tval loss: 0.00161\n",
      "epoch 16631 / 20000\n",
      "gradient norm: 0.057077641831710935, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00164\n",
      "\tval loss: 0.00161\n",
      "epoch 16632 / 20000\n",
      "gradient norm: 0.06807916308753192, minimum ratio: 2.46578947368421\n",
      "\ttrain loss: 0.00164\n",
      "\tval loss: 0.00160\n",
      "epoch 16633 / 20000\n",
      "gradient norm: 0.05582656431943178, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00163\n",
      "\tval loss: 0.00162\n",
      "epoch 16634 / 20000\n",
      "gradient norm: 0.06506074889330193, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00164\n",
      "\tval loss: 0.00160\n",
      "epoch 16635 / 20000\n",
      "gradient norm: 0.042653249111026525, minimum ratio: 2.4263157894736844\n",
      "\ttrain loss: 0.00164\n",
      "\tval loss: 0.00161\n",
      "epoch 16636 / 20000\n",
      "gradient norm: 0.024897492257878184, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00162\n",
      "\tval loss: 0.00160\n",
      "epoch 16637 / 20000\n",
      "gradient norm: 0.019396847928874195, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00163\n",
      "\tval loss: 0.00160\n",
      "epoch 16638 / 20000\n",
      "gradient norm: 0.048899262852501124, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00162\n",
      "\tval loss: 0.00160\n",
      "epoch 16639 / 20000\n",
      "gradient norm: 0.03628168348222971, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00162\n",
      "\tval loss: 0.00160\n",
      "epoch 16640 / 20000\n",
      "gradient norm: 0.03327738819643855, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00162\n",
      "\tval loss: 0.00159\n",
      "epoch 16641 / 20000\n",
      "gradient norm: 0.034428105456754565, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00162\n",
      "\tval loss: 0.00159\n",
      "epoch 16642 / 20000\n",
      "gradient norm: 0.038166039681527764, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00162\n",
      "\tval loss: 0.00159\n",
      "epoch 16643 / 20000\n",
      "gradient norm: 0.0579697226639837, minimum ratio: 2.452631578947368\n",
      "\ttrain loss: 0.00162\n",
      "\tval loss: 0.00159\n",
      "epoch 16644 / 20000\n",
      "gradient norm: 0.04468059015925974, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00162\n",
      "\tval loss: 0.00159\n",
      "epoch 16645 / 20000\n",
      "gradient norm: 0.03519057872472331, minimum ratio: 2.418421052631579\n",
      "\ttrain loss: 0.00162\n",
      "\tval loss: 0.00159\n",
      "epoch 16646 / 20000\n",
      "gradient norm: 0.036148922867141664, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00161\n",
      "\tval loss: 0.00159\n",
      "epoch 16647 / 20000\n",
      "gradient norm: 0.04455588530981913, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00161\n",
      "\tval loss: 0.00158\n",
      "epoch 16648 / 20000\n",
      "gradient norm: 0.03085231001023203, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00161\n",
      "\tval loss: 0.00158\n",
      "epoch 16649 / 20000\n",
      "gradient norm: 0.03960504080168903, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00161\n",
      "\tval loss: 0.00159\n",
      "epoch 16650 / 20000\n",
      "gradient norm: 0.03574169482453726, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00160\n",
      "\tval loss: 0.00158\n",
      "epoch 16651 / 20000\n",
      "gradient norm: 0.03241862612776458, minimum ratio: 2.4447368421052635\n",
      "\ttrain loss: 0.00161\n",
      "\tval loss: 0.00158\n",
      "epoch 16652 / 20000\n",
      "gradient norm: 0.030442819392192177, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00160\n",
      "\tval loss: 0.00158\n",
      "epoch 16653 / 20000\n",
      "gradient norm: 0.032977655122522265, minimum ratio: 2.418421052631579\n",
      "\ttrain loss: 0.00160\n",
      "\tval loss: 0.00157\n",
      "epoch 16654 / 20000\n",
      "gradient norm: 0.033977894054260105, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00161\n",
      "\tval loss: 0.00157\n",
      "epoch 16655 / 20000\n",
      "gradient norm: 0.030212522542569786, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00160\n",
      "\tval loss: 0.00157\n",
      "epoch 16656 / 20000\n",
      "gradient norm: 0.02623840473825112, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00160\n",
      "\tval loss: 0.00157\n",
      "epoch 16657 / 20000\n",
      "gradient norm: 0.020006758102681488, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00160\n",
      "\tval loss: 0.00158\n",
      "epoch 16658 / 20000\n",
      "gradient norm: 0.038481588126160204, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00159\n",
      "\tval loss: 0.00157\n",
      "epoch 16659 / 20000\n",
      "gradient norm: 0.029142051993403584, minimum ratio: 2.4263157894736844\n",
      "\ttrain loss: 0.00160\n",
      "\tval loss: 0.00157\n",
      "epoch 16660 / 20000\n",
      "gradient norm: 0.03405571274925023, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00159\n",
      "\tval loss: 0.00157\n",
      "epoch 16661 / 20000\n",
      "gradient norm: 0.02513487772375811, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00159\n",
      "\tval loss: 0.00157\n",
      "epoch 16662 / 20000\n",
      "gradient norm: 0.04215205286163837, minimum ratio: 2.4447368421052635\n",
      "\ttrain loss: 0.00159\n",
      "\tval loss: 0.00157\n",
      "epoch 16663 / 20000\n",
      "gradient norm: 0.023799322021659464, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00159\n",
      "\tval loss: 0.00156\n",
      "epoch 16664 / 20000\n",
      "gradient norm: 0.02905509975971654, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00159\n",
      "\tval loss: 0.00156\n",
      "epoch 16665 / 20000\n",
      "gradient norm: 0.04545320599572733, minimum ratio: 2.4236842105263157\n",
      "\ttrain loss: 0.00159\n",
      "\tval loss: 0.00156\n",
      "epoch 16666 / 20000\n",
      "gradient norm: 0.03234482306288555, minimum ratio: 2.4184210526315786\n",
      "\ttrain loss: 0.00158\n",
      "\tval loss: 0.00156\n",
      "epoch 16667 / 20000\n",
      "gradient norm: 0.02055767990532331, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00159\n",
      "\tval loss: 0.00156\n",
      "epoch 16668 / 20000\n",
      "gradient norm: 0.03235726713319309, minimum ratio: 2.423684210526315\n",
      "\ttrain loss: 0.00158\n",
      "\tval loss: 0.00156\n",
      "epoch 16669 / 20000\n",
      "gradient norm: 0.01754368143156171, minimum ratio: 2.4447368421052635\n",
      "\ttrain loss: 0.00158\n",
      "\tval loss: 0.00156\n",
      "epoch 16670 / 20000\n",
      "gradient norm: 0.055106651270762086, minimum ratio: 2.423684210526316\n",
      "\ttrain loss: 0.00158\n",
      "\tval loss: 0.00155\n",
      "epoch 16671 / 20000\n",
      "gradient norm: 0.05004834447754547, minimum ratio: 2.4263157894736844\n",
      "\ttrain loss: 0.00158\n",
      "\tval loss: 0.00155\n",
      "epoch 16672 / 20000\n",
      "gradient norm: 0.04256555438041687, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00158\n",
      "\tval loss: 0.00155\n",
      "epoch 16673 / 20000\n",
      "gradient norm: 0.03183881437871605, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00158\n",
      "\tval loss: 0.00155\n",
      "epoch 16674 / 20000\n",
      "gradient norm: 0.023218182497657835, minimum ratio: 2.418421052631579\n",
      "\ttrain loss: 0.00157\n",
      "\tval loss: 0.00155\n",
      "epoch 16675 / 20000\n",
      "gradient norm: 0.039857384690549225, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00157\n",
      "\tval loss: 0.00155\n",
      "epoch 16676 / 20000\n",
      "gradient norm: 0.023674293828662485, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00157\n",
      "\tval loss: 0.00154\n",
      "epoch 16677 / 20000\n",
      "gradient norm: 0.036767217330634594, minimum ratio: 2.4210526315789473\n",
      "\ttrain loss: 0.00157\n",
      "\tval loss: 0.00154\n",
      "epoch 16678 / 20000\n",
      "gradient norm: 0.02327315440925304, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00157\n",
      "\tval loss: 0.00154\n",
      "epoch 16679 / 20000\n",
      "gradient norm: 0.028663136006798595, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00157\n",
      "\tval loss: 0.00154\n",
      "epoch 16680 / 20000\n",
      "gradient norm: 0.0338081342051737, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00157\n",
      "\tval loss: 0.00154\n",
      "epoch 16681 / 20000\n",
      "gradient norm: 0.02746846730588004, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00156\n",
      "\tval loss: 0.00154\n",
      "epoch 16682 / 20000\n",
      "gradient norm: 0.02892950936802663, minimum ratio: 2.4236842105263157\n",
      "\ttrain loss: 0.00156\n",
      "\tval loss: 0.00154\n",
      "epoch 16683 / 20000\n",
      "gradient norm: 0.026813283562660217, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00156\n",
      "\tval loss: 0.00154\n",
      "epoch 16684 / 20000\n",
      "gradient norm: 0.03926261427113786, minimum ratio: 2.4157894736842103\n",
      "\ttrain loss: 0.00156\n",
      "\tval loss: 0.00153\n",
      "epoch 16685 / 20000\n",
      "gradient norm: 0.028591002512257546, minimum ratio: 2.397368421052632\n",
      "\ttrain loss: 0.00156\n",
      "\tval loss: 0.00153\n",
      "epoch 16686 / 20000\n",
      "gradient norm: 0.03375023981789127, minimum ratio: 2.436842105263158\n",
      "\ttrain loss: 0.00155\n",
      "\tval loss: 0.00153\n",
      "epoch 16687 / 20000\n",
      "gradient norm: 0.049519809253979474, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00156\n",
      "\tval loss: 0.00153\n",
      "epoch 16688 / 20000\n",
      "gradient norm: 0.01603377767605707, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00155\n",
      "\tval loss: 0.00153\n",
      "epoch 16689 / 20000\n",
      "gradient norm: 0.037523799954215065, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00155\n",
      "\tval loss: 0.00153\n",
      "epoch 16690 / 20000\n",
      "gradient norm: 0.0428036228986457, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00156\n",
      "\tval loss: 0.00153\n",
      "epoch 16691 / 20000\n",
      "gradient norm: 0.020982404297683388, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00155\n",
      "\tval loss: 0.00152\n",
      "epoch 16692 / 20000\n",
      "gradient norm: 0.05251921451417729, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00155\n",
      "\tval loss: 0.00153\n",
      "epoch 16693 / 20000\n",
      "gradient norm: 0.034742029616609216, minimum ratio: 2.4236842105263157\n",
      "\ttrain loss: 0.00154\n",
      "\tval loss: 0.00152\n",
      "epoch 16694 / 20000\n",
      "gradient norm: 0.04954921652097255, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00155\n",
      "\tval loss: 0.00152\n",
      "epoch 16695 / 20000\n",
      "gradient norm: 0.0404222019133158, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00154\n",
      "\tval loss: 0.00153\n",
      "epoch 16696 / 20000\n",
      "gradient norm: 0.04453646705951542, minimum ratio: 2.46578947368421\n",
      "\ttrain loss: 0.00155\n",
      "\tval loss: 0.00151\n",
      "epoch 16697 / 20000\n",
      "gradient norm: 0.0458140765549615, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00154\n",
      "\tval loss: 0.00152\n",
      "epoch 16698 / 20000\n",
      "gradient norm: 0.023123949766159058, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00153\n",
      "\tval loss: 0.00151\n",
      "epoch 16699 / 20000\n",
      "gradient norm: 0.052015379595104605, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00154\n",
      "\tval loss: 0.00151\n",
      "epoch 16700 / 20000\n",
      "gradient norm: 0.042646657646400854, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00154\n",
      "\tval loss: 0.00151\n",
      "epoch 16701 / 20000\n",
      "gradient norm: 0.027341646899003536, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00153\n",
      "\tval loss: 0.00151\n",
      "epoch 16702 / 20000\n",
      "gradient norm: 0.03939526004251093, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00153\n",
      "\tval loss: 0.00151\n",
      "epoch 16703 / 20000\n",
      "gradient norm: 0.029986709007062018, minimum ratio: 2.423684210526316\n",
      "\ttrain loss: 0.00153\n",
      "\tval loss: 0.00151\n",
      "epoch 16704 / 20000\n",
      "gradient norm: 0.025918077386450022, minimum ratio: 2.460526315789474\n",
      "\ttrain loss: 0.00153\n",
      "\tval loss: 0.00150\n",
      "epoch 16705 / 20000\n",
      "gradient norm: 0.026144205476157367, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00153\n",
      "\tval loss: 0.00150\n",
      "epoch 16706 / 20000\n",
      "gradient norm: 0.022746521572116762, minimum ratio: 2.426315789473684\n",
      "\ttrain loss: 0.00153\n",
      "\tval loss: 0.00150\n",
      "epoch 16707 / 20000\n",
      "gradient norm: 0.031477011856622994, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00152\n",
      "\tval loss: 0.00150\n",
      "epoch 16708 / 20000\n",
      "gradient norm: 0.03658336296211928, minimum ratio: 2.4394736842105265\n",
      "\ttrain loss: 0.00152\n",
      "\tval loss: 0.00150\n",
      "epoch 16709 / 20000\n",
      "gradient norm: 0.018079235072946176, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00152\n",
      "\tval loss: 0.00150\n",
      "epoch 16710 / 20000\n",
      "gradient norm: 0.05169579159701243, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00153\n",
      "\tval loss: 0.00150\n",
      "epoch 16711 / 20000\n",
      "gradient norm: 0.04084412951488048, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00152\n",
      "\tval loss: 0.00150\n",
      "epoch 16712 / 20000\n",
      "gradient norm: 0.024454546393826604, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00152\n",
      "\tval loss: 0.00149\n",
      "epoch 16713 / 20000\n",
      "gradient norm: 0.03621410537743941, minimum ratio: 2.465789473684211\n",
      "\ttrain loss: 0.00152\n",
      "\tval loss: 0.00150\n",
      "epoch 16714 / 20000\n",
      "gradient norm: 0.013891748792957515, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00152\n",
      "\tval loss: 0.00149\n",
      "epoch 16715 / 20000\n",
      "gradient norm: 0.03548609296558425, minimum ratio: 2.423684210526316\n",
      "\ttrain loss: 0.00152\n",
      "\tval loss: 0.00149\n",
      "epoch 16716 / 20000\n",
      "gradient norm: 0.05272915540263057, minimum ratio: 2.4263157894736844\n",
      "\ttrain loss: 0.00151\n",
      "\tval loss: 0.00149\n",
      "epoch 16717 / 20000\n",
      "gradient norm: 0.06101169955218211, minimum ratio: 2.426315789473684\n",
      "\ttrain loss: 0.00152\n",
      "\tval loss: 0.00149\n",
      "epoch 16718 / 20000\n",
      "gradient norm: 0.06370759627316147, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00152\n",
      "\tval loss: 0.00148\n",
      "epoch 16719 / 20000\n",
      "gradient norm: 0.01823303135461174, minimum ratio: 2.4447368421052635\n",
      "\ttrain loss: 0.00151\n",
      "\tval loss: 0.00150\n",
      "epoch 16720 / 20000\n",
      "gradient norm: 0.05201371747534722, minimum ratio: 2.4263157894736844\n",
      "\ttrain loss: 0.00151\n",
      "\tval loss: 0.00148\n",
      "epoch 16721 / 20000\n",
      "gradient norm: 0.04540107323555276, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00151\n",
      "\tval loss: 0.00148\n",
      "epoch 16722 / 20000\n",
      "gradient norm: 0.0374836708069779, minimum ratio: 2.4421052631578943\n",
      "\ttrain loss: 0.00150\n",
      "\tval loss: 0.00149\n",
      "epoch 16723 / 20000\n",
      "gradient norm: 0.04378146107774228, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00151\n",
      "\tval loss: 0.00148\n",
      "epoch 16724 / 20000\n",
      "gradient norm: 0.040098717203363776, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00150\n",
      "\tval loss: 0.00148\n",
      "epoch 16725 / 20000\n",
      "gradient norm: 0.04576957074459642, minimum ratio: 2.4447368421052627\n",
      "\ttrain loss: 0.00150\n",
      "\tval loss: 0.00148\n",
      "epoch 16726 / 20000\n",
      "gradient norm: 0.047950029955245554, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00150\n",
      "\tval loss: 0.00148\n",
      "epoch 16727 / 20000\n",
      "gradient norm: 0.04346053907647729, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00150\n",
      "\tval loss: 0.00147\n",
      "epoch 16728 / 20000\n",
      "gradient norm: 0.016511775844264776, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00150\n",
      "\tval loss: 0.00148\n",
      "epoch 16729 / 20000\n",
      "gradient norm: 0.03540807246463373, minimum ratio: 2.46578947368421\n",
      "\ttrain loss: 0.00149\n",
      "\tval loss: 0.00147\n",
      "epoch 16730 / 20000\n",
      "gradient norm: 0.03876967990072444, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00149\n",
      "\tval loss: 0.00147\n",
      "epoch 16731 / 20000\n",
      "gradient norm: 0.027838368783704937, minimum ratio: 2.4394736842105265\n",
      "\ttrain loss: 0.00149\n",
      "\tval loss: 0.00148\n",
      "epoch 16732 / 20000\n",
      "gradient norm: 0.0307714031659998, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00149\n",
      "\tval loss: 0.00147\n",
      "epoch 16733 / 20000\n",
      "gradient norm: 0.045539733837358654, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00149\n",
      "\tval loss: 0.00146\n",
      "epoch 16734 / 20000\n",
      "gradient norm: 0.04326701338868588, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00149\n",
      "\tval loss: 0.00147\n",
      "epoch 16735 / 20000\n",
      "gradient norm: 0.035624710959382355, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00149\n",
      "\tval loss: 0.00146\n",
      "epoch 16736 / 20000\n",
      "gradient norm: 0.0436222871649079, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00149\n",
      "\tval loss: 0.00146\n",
      "epoch 16737 / 20000\n",
      "gradient norm: 0.03446709644049406, minimum ratio: 2.4447368421052635\n",
      "\ttrain loss: 0.00148\n",
      "\tval loss: 0.00147\n",
      "epoch 16738 / 20000\n",
      "gradient norm: 0.04797210532706231, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00149\n",
      "\tval loss: 0.00146\n",
      "epoch 16739 / 20000\n",
      "gradient norm: 0.033650102879619226, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00148\n",
      "\tval loss: 0.00146\n",
      "epoch 16740 / 20000\n",
      "gradient norm: 0.027493173663970083, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00148\n",
      "\tval loss: 0.00146\n",
      "epoch 16741 / 20000\n",
      "gradient norm: 0.02200396521948278, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00148\n",
      "\tval loss: 0.00146\n",
      "epoch 16742 / 20000\n",
      "gradient norm: 0.03381940070539713, minimum ratio: 2.436842105263158\n",
      "\ttrain loss: 0.00148\n",
      "\tval loss: 0.00146\n",
      "epoch 16743 / 20000\n",
      "gradient norm: 0.057724573416635394, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00148\n",
      "\tval loss: 0.00145\n",
      "epoch 16744 / 20000\n",
      "gradient norm: 0.05765482480637729, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00148\n",
      "\tval loss: 0.00145\n",
      "epoch 16745 / 20000\n",
      "gradient norm: 0.03121343208476901, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00147\n",
      "\tval loss: 0.00146\n",
      "epoch 16746 / 20000\n",
      "gradient norm: 0.036510861245915294, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00147\n",
      "\tval loss: 0.00145\n",
      "epoch 16747 / 20000\n",
      "gradient norm: 0.024191852047806606, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00147\n",
      "\tval loss: 0.00145\n",
      "epoch 16748 / 20000\n",
      "gradient norm: 0.039504312560893595, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00147\n",
      "\tval loss: 0.00145\n",
      "epoch 16749 / 20000\n",
      "gradient norm: 0.025611158285755664, minimum ratio: 2.423684210526316\n",
      "\ttrain loss: 0.00147\n",
      "\tval loss: 0.00144\n",
      "epoch 16750 / 20000\n",
      "gradient norm: 0.024512204807251692, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00147\n",
      "\tval loss: 0.00144\n",
      "epoch 16751 / 20000\n",
      "gradient norm: 0.05491791164968163, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00146\n",
      "\tval loss: 0.00145\n",
      "epoch 16752 / 20000\n",
      "gradient norm: 0.02931842318503186, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00146\n",
      "\tval loss: 0.00144\n",
      "epoch 16753 / 20000\n",
      "gradient norm: 0.04325690970290452, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00146\n",
      "\tval loss: 0.00144\n",
      "epoch 16754 / 20000\n",
      "gradient norm: 0.03758412058232352, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00146\n",
      "\tval loss: 0.00144\n",
      "epoch 16755 / 20000\n",
      "gradient norm: 0.032446180761326104, minimum ratio: 2.4184210526315786\n",
      "\ttrain loss: 0.00146\n",
      "\tval loss: 0.00143\n",
      "epoch 16756 / 20000\n",
      "gradient norm: 0.04723208420909941, minimum ratio: 2.4499999999999997\n",
      "\ttrain loss: 0.00146\n",
      "\tval loss: 0.00144\n",
      "epoch 16757 / 20000\n",
      "gradient norm: 0.018452861404512078, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00146\n",
      "\tval loss: 0.00143\n",
      "epoch 16758 / 20000\n",
      "gradient norm: 0.053938804659992456, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00146\n",
      "\tval loss: 0.00143\n",
      "epoch 16759 / 20000\n",
      "gradient norm: 0.07373005105182528, minimum ratio: 2.4210526315789473\n",
      "\ttrain loss: 0.00146\n",
      "\tval loss: 0.00143\n",
      "epoch 16760 / 20000\n",
      "gradient norm: 0.035614218621049076, minimum ratio: 2.460526315789474\n",
      "\ttrain loss: 0.00145\n",
      "\tval loss: 0.00144\n",
      "epoch 16761 / 20000\n",
      "gradient norm: 0.04352981166448444, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00145\n",
      "\tval loss: 0.00143\n",
      "epoch 16762 / 20000\n",
      "gradient norm: 0.05602100683609024, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00145\n",
      "\tval loss: 0.00143\n",
      "epoch 16763 / 20000\n",
      "gradient norm: 0.021492178842891008, minimum ratio: 2.4236842105263157\n",
      "\ttrain loss: 0.00145\n",
      "\tval loss: 0.00143\n",
      "epoch 16764 / 20000\n",
      "gradient norm: 0.03280597709817812, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00145\n",
      "\tval loss: 0.00142\n",
      "epoch 16765 / 20000\n",
      "gradient norm: 0.05530001886654645, minimum ratio: 2.418421052631579\n",
      "\ttrain loss: 0.00145\n",
      "\tval loss: 0.00142\n",
      "epoch 16766 / 20000\n",
      "gradient norm: 0.046807663165964186, minimum ratio: 2.4263157894736844\n",
      "\ttrain loss: 0.00145\n",
      "\tval loss: 0.00143\n",
      "epoch 16767 / 20000\n",
      "gradient norm: 0.05560755240730941, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00144\n",
      "\tval loss: 0.00142\n",
      "epoch 16768 / 20000\n",
      "gradient norm: 0.036312100011855364, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00144\n",
      "\tval loss: 0.00142\n",
      "epoch 16769 / 20000\n",
      "gradient norm: 0.04164159853826277, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00144\n",
      "\tval loss: 0.00142\n",
      "epoch 16770 / 20000\n",
      "gradient norm: 0.06579786556540057, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00144\n",
      "\tval loss: 0.00141\n",
      "epoch 16771 / 20000\n",
      "gradient norm: 0.019254329556133598, minimum ratio: 2.4157894736842107\n",
      "\ttrain loss: 0.00144\n",
      "\tval loss: 0.00143\n",
      "epoch 16772 / 20000\n",
      "gradient norm: 0.07225631456822157, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00144\n",
      "\tval loss: 0.00141\n",
      "epoch 16773 / 20000\n",
      "gradient norm: 0.048300782626029104, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00144\n",
      "\tval loss: 0.00141\n",
      "epoch 16774 / 20000\n",
      "gradient norm: 0.03376483713509515, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00143\n",
      "\tval loss: 0.00142\n",
      "epoch 16775 / 20000\n",
      "gradient norm: 0.029979526763781905, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00143\n",
      "\tval loss: 0.00141\n",
      "epoch 16776 / 20000\n",
      "gradient norm: 0.0636814438039437, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00143\n",
      "\tval loss: 0.00141\n",
      "epoch 16777 / 20000\n",
      "gradient norm: 0.032739636197220534, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00143\n",
      "\tval loss: 0.00141\n",
      "epoch 16778 / 20000\n",
      "gradient norm: 0.03867557959165424, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00143\n",
      "\tval loss: 0.00140\n",
      "epoch 16779 / 20000\n",
      "gradient norm: 0.02447787596611306, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00142\n",
      "\tval loss: 0.00141\n",
      "epoch 16780 / 20000\n",
      "gradient norm: 0.04153759346809238, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00143\n",
      "\tval loss: 0.00140\n",
      "epoch 16781 / 20000\n",
      "gradient norm: 0.06300801050383598, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00143\n",
      "\tval loss: 0.00140\n",
      "epoch 16782 / 20000\n",
      "gradient norm: 0.055494861444458365, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00142\n",
      "\tval loss: 0.00141\n",
      "epoch 16783 / 20000\n",
      "gradient norm: 0.05899527948349714, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00142\n",
      "\tval loss: 0.00140\n",
      "epoch 16784 / 20000\n",
      "gradient norm: 0.025860187015496194, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00142\n",
      "\tval loss: 0.00140\n",
      "epoch 16785 / 20000\n",
      "gradient norm: 0.04632550268433988, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00142\n",
      "\tval loss: 0.00140\n",
      "epoch 16786 / 20000\n",
      "gradient norm: 0.024819809070322663, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00142\n",
      "\tval loss: 0.00140\n",
      "epoch 16787 / 20000\n",
      "gradient norm: 0.020464264729525894, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00142\n",
      "\tval loss: 0.00139\n",
      "epoch 16788 / 20000\n",
      "gradient norm: 0.041173130011884496, minimum ratio: 2.426315789473684\n",
      "\ttrain loss: 0.00142\n",
      "\tval loss: 0.00140\n",
      "epoch 16789 / 20000\n",
      "gradient norm: 0.027607167794485576, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00141\n",
      "\tval loss: 0.00139\n",
      "epoch 16790 / 20000\n",
      "gradient norm: 0.038345033826772124, minimum ratio: 2.452631578947368\n",
      "\ttrain loss: 0.00141\n",
      "\tval loss: 0.00139\n",
      "epoch 16791 / 20000\n",
      "gradient norm: 0.019774042710196227, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00141\n",
      "\tval loss: 0.00139\n",
      "epoch 16792 / 20000\n",
      "gradient norm: 0.0283680540160276, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00141\n",
      "\tval loss: 0.00139\n",
      "epoch 16793 / 20000\n",
      "gradient norm: 0.029937583080027252, minimum ratio: 2.4263157894736844\n",
      "\ttrain loss: 0.00141\n",
      "\tval loss: 0.00139\n",
      "epoch 16794 / 20000\n",
      "gradient norm: 0.05250658490695059, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00141\n",
      "\tval loss: 0.00138\n",
      "epoch 16795 / 20000\n",
      "gradient norm: 0.0280428797705099, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00140\n",
      "\tval loss: 0.00138\n",
      "epoch 16796 / 20000\n",
      "gradient norm: 0.01719452120596543, minimum ratio: 2.426315789473684\n",
      "\ttrain loss: 0.00140\n",
      "\tval loss: 0.00138\n",
      "epoch 16797 / 20000\n",
      "gradient norm: 0.04571037960704416, minimum ratio: 2.4236842105263157\n",
      "\ttrain loss: 0.00140\n",
      "\tval loss: 0.00138\n",
      "epoch 16798 / 20000\n",
      "gradient norm: 0.023534692882094532, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00140\n",
      "\tval loss: 0.00138\n",
      "epoch 16799 / 20000\n",
      "gradient norm: 0.04983078083023429, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00140\n",
      "\tval loss: 0.00138\n",
      "epoch 16800 / 20000\n",
      "gradient norm: 0.08144110208377242, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00141\n",
      "\tval loss: 0.00138\n",
      "epoch 16801 / 20000\n",
      "gradient norm: 0.056894227920565754, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00140\n",
      "\tval loss: 0.00137\n",
      "epoch 16802 / 20000\n",
      "gradient norm: 0.05056683765724301, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00140\n",
      "\tval loss: 0.00139\n",
      "epoch 16803 / 20000\n",
      "gradient norm: 0.03830248233862221, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00140\n",
      "\tval loss: 0.00137\n",
      "epoch 16804 / 20000\n",
      "gradient norm: 0.04632650830899365, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00140\n",
      "\tval loss: 0.00137\n",
      "epoch 16805 / 20000\n",
      "gradient norm: 0.03099109197501093, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00139\n",
      "\tval loss: 0.00137\n",
      "epoch 16806 / 20000\n",
      "gradient norm: 0.04964435868896544, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00139\n",
      "\tval loss: 0.00137\n",
      "epoch 16807 / 20000\n",
      "gradient norm: 0.02594673604471609, minimum ratio: 2.4499999999999997\n",
      "\ttrain loss: 0.00139\n",
      "\tval loss: 0.00137\n",
      "epoch 16808 / 20000\n",
      "gradient norm: 0.031664707174059004, minimum ratio: 2.4394736842105265\n",
      "\ttrain loss: 0.00139\n",
      "\tval loss: 0.00137\n",
      "epoch 16809 / 20000\n",
      "gradient norm: 0.03906277456553653, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00139\n",
      "\tval loss: 0.00136\n",
      "epoch 16810 / 20000\n",
      "gradient norm: 0.03555207257159054, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00139\n",
      "\tval loss: 0.00137\n",
      "epoch 16811 / 20000\n",
      "gradient norm: 0.05150181753560901, minimum ratio: 2.4447368421052627\n",
      "\ttrain loss: 0.00139\n",
      "\tval loss: 0.00136\n",
      "epoch 16812 / 20000\n",
      "gradient norm: 0.07274269277695566, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00139\n",
      "\tval loss: 0.00137\n",
      "epoch 16813 / 20000\n",
      "gradient norm: 0.06048174714669585, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00138\n",
      "\tval loss: 0.00136\n",
      "epoch 16814 / 20000\n",
      "gradient norm: 0.02874024090124294, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00138\n",
      "\tval loss: 0.00136\n",
      "epoch 16815 / 20000\n",
      "gradient norm: 0.03494265356857795, minimum ratio: 2.4447368421052635\n",
      "\ttrain loss: 0.00138\n",
      "\tval loss: 0.00136\n",
      "epoch 16816 / 20000\n",
      "gradient norm: 0.05377879983279854, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00138\n",
      "\tval loss: 0.00135\n",
      "epoch 16817 / 20000\n",
      "gradient norm: 0.07438359124353155, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00138\n",
      "\tval loss: 0.00136\n",
      "epoch 16818 / 20000\n",
      "gradient norm: 0.023095751355867833, minimum ratio: 2.426315789473684\n",
      "\ttrain loss: 0.00137\n",
      "\tval loss: 0.00135\n",
      "epoch 16819 / 20000\n",
      "gradient norm: 0.04671391908777878, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00138\n",
      "\tval loss: 0.00135\n",
      "epoch 16820 / 20000\n",
      "gradient norm: 0.03191614110255614, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00137\n",
      "\tval loss: 0.00135\n",
      "epoch 16821 / 20000\n",
      "gradient norm: 0.02917280769906938, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00137\n",
      "\tval loss: 0.00135\n",
      "epoch 16822 / 20000\n",
      "gradient norm: 0.040084431078867055, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00137\n",
      "\tval loss: 0.00135\n",
      "epoch 16823 / 20000\n",
      "gradient norm: 0.016007790865842253, minimum ratio: 2.436842105263158\n",
      "\ttrain loss: 0.00137\n",
      "\tval loss: 0.00135\n",
      "epoch 16824 / 20000\n",
      "gradient norm: 0.05750643811188638, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00137\n",
      "\tval loss: 0.00134\n",
      "epoch 16825 / 20000\n",
      "gradient norm: 0.02891327510587871, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00136\n",
      "\tval loss: 0.00134\n",
      "epoch 16826 / 20000\n",
      "gradient norm: 0.043334919784683734, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00137\n",
      "\tval loss: 0.00135\n",
      "epoch 16827 / 20000\n",
      "gradient norm: 0.04061828349949792, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00136\n",
      "\tval loss: 0.00134\n",
      "epoch 16828 / 20000\n",
      "gradient norm: 0.08586885186377913, minimum ratio: 2.46578947368421\n",
      "\ttrain loss: 0.00137\n",
      "\tval loss: 0.00135\n",
      "epoch 16829 / 20000\n",
      "gradient norm: 0.05689815804362297, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00136\n",
      "\tval loss: 0.00134\n",
      "epoch 16830 / 20000\n",
      "gradient norm: 0.05867353465873748, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00136\n",
      "\tval loss: 0.00135\n",
      "epoch 16831 / 20000\n",
      "gradient norm: 0.05780645820777863, minimum ratio: 2.4421052631578943\n",
      "\ttrain loss: 0.00136\n",
      "\tval loss: 0.00133\n",
      "epoch 16832 / 20000\n",
      "gradient norm: 0.057817521097604185, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00136\n",
      "\tval loss: 0.00134\n",
      "epoch 16833 / 20000\n",
      "gradient norm: 0.040883551933802664, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00136\n",
      "\tval loss: 0.00133\n",
      "epoch 16834 / 20000\n",
      "gradient norm: 0.018806226551532745, minimum ratio: 2.423684210526316\n",
      "\ttrain loss: 0.00135\n",
      "\tval loss: 0.00133\n",
      "epoch 16835 / 20000\n",
      "gradient norm: 0.0373024275759235, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00136\n",
      "\tval loss: 0.00134\n",
      "epoch 16836 / 20000\n",
      "gradient norm: 0.050455708522349596, minimum ratio: 2.4289473684210523\n",
      "\ttrain loss: 0.00135\n",
      "\tval loss: 0.00133\n",
      "epoch 16837 / 20000\n",
      "gradient norm: 0.0646604192443192, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00135\n",
      "\tval loss: 0.00134\n",
      "epoch 16838 / 20000\n",
      "gradient norm: 0.06343344104243442, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00135\n",
      "\tval loss: 0.00133\n",
      "epoch 16839 / 20000\n",
      "gradient norm: 0.023932061449158937, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00135\n",
      "\tval loss: 0.00133\n",
      "epoch 16840 / 20000\n",
      "gradient norm: 0.042568975972244516, minimum ratio: 2.418421052631579\n",
      "\ttrain loss: 0.00135\n",
      "\tval loss: 0.00133\n",
      "epoch 16841 / 20000\n",
      "gradient norm: 0.053200098394881934, minimum ratio: 2.436842105263158\n",
      "\ttrain loss: 0.00134\n",
      "\tval loss: 0.00132\n",
      "epoch 16842 / 20000\n",
      "gradient norm: 0.01840705401264131, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00135\n",
      "\tval loss: 0.00133\n",
      "epoch 16843 / 20000\n",
      "gradient norm: 0.03634307807078585, minimum ratio: 2.4421052631578952\n",
      "\ttrain loss: 0.00135\n",
      "\tval loss: 0.00132\n",
      "epoch 16844 / 20000\n",
      "gradient norm: 0.054852476285304874, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00134\n",
      "\tval loss: 0.00132\n",
      "epoch 16845 / 20000\n",
      "gradient norm: 0.021397799195256084, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00134\n",
      "\tval loss: 0.00132\n",
      "epoch 16846 / 20000\n",
      "gradient norm: 0.03444589374703355, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00134\n",
      "\tval loss: 0.00132\n",
      "epoch 16847 / 20000\n",
      "gradient norm: 0.03217478416627273, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00133\n",
      "\tval loss: 0.00132\n",
      "epoch 16848 / 20000\n",
      "gradient norm: 0.03169801279727835, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00134\n",
      "\tval loss: 0.00131\n",
      "epoch 16849 / 20000\n",
      "gradient norm: 0.03831538348458707, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00133\n",
      "\tval loss: 0.00132\n",
      "epoch 16850 / 20000\n",
      "gradient norm: 0.04189059423515573, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00133\n",
      "\tval loss: 0.00131\n",
      "epoch 16851 / 20000\n",
      "gradient norm: 0.05006021645385772, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00133\n",
      "\tval loss: 0.00132\n",
      "epoch 16852 / 20000\n",
      "gradient norm: 0.017823057831265032, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00132\n",
      "\tval loss: 0.00131\n",
      "epoch 16853 / 20000\n",
      "gradient norm: 0.02575817407341674, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00133\n",
      "\tval loss: 0.00131\n",
      "epoch 16854 / 20000\n",
      "gradient norm: 0.04058610845822841, minimum ratio: 2.426315789473684\n",
      "\ttrain loss: 0.00133\n",
      "\tval loss: 0.00131\n",
      "epoch 16855 / 20000\n",
      "gradient norm: 0.03998595580924302, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00133\n",
      "\tval loss: 0.00130\n",
      "epoch 16856 / 20000\n",
      "gradient norm: 0.026329945190809667, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00133\n",
      "\tval loss: 0.00131\n",
      "epoch 16857 / 20000\n",
      "gradient norm: 0.022910577157745138, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00132\n",
      "\tval loss: 0.00131\n",
      "epoch 16858 / 20000\n",
      "gradient norm: 0.033884708769619465, minimum ratio: 2.4236842105263157\n",
      "\ttrain loss: 0.00132\n",
      "\tval loss: 0.00130\n",
      "epoch 16859 / 20000\n",
      "gradient norm: 0.03253954107640311, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00132\n",
      "\tval loss: 0.00130\n",
      "epoch 16860 / 20000\n",
      "gradient norm: 0.02300302407820709, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00132\n",
      "\tval loss: 0.00130\n",
      "epoch 16861 / 20000\n",
      "gradient norm: 0.03911471599712968, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00132\n",
      "\tval loss: 0.00130\n",
      "epoch 16862 / 20000\n",
      "gradient norm: 0.0233026712667197, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00131\n",
      "\tval loss: 0.00130\n",
      "epoch 16863 / 20000\n",
      "gradient norm: 0.0273860776796937, minimum ratio: 2.4236842105263157\n",
      "\ttrain loss: 0.00131\n",
      "\tval loss: 0.00130\n",
      "epoch 16864 / 20000\n",
      "gradient norm: 0.04117732192389667, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00131\n",
      "\tval loss: 0.00129\n",
      "epoch 16865 / 20000\n",
      "gradient norm: 0.0390977279166691, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00132\n",
      "\tval loss: 0.00129\n",
      "epoch 16866 / 20000\n",
      "gradient norm: 0.025202215125318617, minimum ratio: 2.4210526315789473\n",
      "\ttrain loss: 0.00131\n",
      "\tval loss: 0.00130\n",
      "epoch 16867 / 20000\n",
      "gradient norm: 0.04834168474189937, minimum ratio: 2.4157894736842103\n",
      "\ttrain loss: 0.00131\n",
      "\tval loss: 0.00129\n",
      "epoch 16868 / 20000\n",
      "gradient norm: 0.054587639519013464, minimum ratio: 2.4447368421052635\n",
      "\ttrain loss: 0.00131\n",
      "\tval loss: 0.00129\n",
      "epoch 16869 / 20000\n",
      "gradient norm: 0.037439647247083485, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00131\n",
      "\tval loss: 0.00130\n",
      "epoch 16870 / 20000\n",
      "gradient norm: 0.05731568159535527, minimum ratio: 2.4421052631578943\n",
      "\ttrain loss: 0.00131\n",
      "\tval loss: 0.00129\n",
      "epoch 16871 / 20000\n",
      "gradient norm: 0.03762631508288905, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00130\n",
      "\tval loss: 0.00129\n",
      "epoch 16872 / 20000\n",
      "gradient norm: 0.03163030149880797, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00130\n",
      "\tval loss: 0.00129\n",
      "epoch 16873 / 20000\n",
      "gradient norm: 0.04988359031267464, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00131\n",
      "\tval loss: 0.00128\n",
      "epoch 16874 / 20000\n",
      "gradient norm: 0.06286114209797233, minimum ratio: 2.4394736842105265\n",
      "\ttrain loss: 0.00131\n",
      "\tval loss: 0.00128\n",
      "epoch 16875 / 20000\n",
      "gradient norm: 0.06128830136731267, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00131\n",
      "\tval loss: 0.00129\n",
      "epoch 16876 / 20000\n",
      "gradient norm: 0.05394846393028274, minimum ratio: 2.4736842105263155\n",
      "\ttrain loss: 0.00130\n",
      "\tval loss: 0.00128\n",
      "epoch 16877 / 20000\n",
      "gradient norm: 0.044867766031529754, minimum ratio: 2.4236842105263157\n",
      "\ttrain loss: 0.00130\n",
      "\tval loss: 0.00129\n",
      "epoch 16878 / 20000\n",
      "gradient norm: 0.0380386165343225, minimum ratio: 2.423684210526316\n",
      "\ttrain loss: 0.00130\n",
      "\tval loss: 0.00128\n",
      "epoch 16879 / 20000\n",
      "gradient norm: 0.03749887764570303, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00129\n",
      "\tval loss: 0.00127\n",
      "epoch 16880 / 20000\n",
      "gradient norm: 0.04429270728724077, minimum ratio: 2.4447368421052635\n",
      "\ttrain loss: 0.00129\n",
      "\tval loss: 0.00128\n",
      "epoch 16881 / 20000\n",
      "gradient norm: 0.04839232575614005, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00129\n",
      "\tval loss: 0.00127\n",
      "epoch 16882 / 20000\n",
      "gradient norm: 0.018889382510678843, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00129\n",
      "\tval loss: 0.00128\n",
      "epoch 16883 / 20000\n",
      "gradient norm: 0.04932661005295813, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00129\n",
      "\tval loss: 0.00127\n",
      "epoch 16884 / 20000\n",
      "gradient norm: 0.052360794274136424, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00129\n",
      "\tval loss: 0.00127\n",
      "epoch 16885 / 20000\n",
      "gradient norm: 0.047452584374696016, minimum ratio: 2.4236842105263157\n",
      "\ttrain loss: 0.00129\n",
      "\tval loss: 0.00128\n",
      "epoch 16886 / 20000\n",
      "gradient norm: 0.028595704294275492, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00128\n",
      "\tval loss: 0.00127\n",
      "epoch 16887 / 20000\n",
      "gradient norm: 0.03931279061362147, minimum ratio: 2.4263157894736844\n",
      "\ttrain loss: 0.00129\n",
      "\tval loss: 0.00127\n",
      "epoch 16888 / 20000\n",
      "gradient norm: 0.042035496851895005, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00128\n",
      "\tval loss: 0.00127\n",
      "epoch 16889 / 20000\n",
      "gradient norm: 0.02849948056973517, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00128\n",
      "\tval loss: 0.00126\n",
      "epoch 16890 / 20000\n",
      "gradient norm: 0.07416105642914772, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00129\n",
      "\tval loss: 0.00126\n",
      "epoch 16891 / 20000\n",
      "gradient norm: 0.08461412315955386, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00129\n",
      "\tval loss: 0.00128\n",
      "epoch 16892 / 20000\n",
      "gradient norm: 0.0554806919535622, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00128\n",
      "\tval loss: 0.00126\n",
      "epoch 16893 / 20000\n",
      "gradient norm: 0.05694125150330365, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00129\n",
      "\tval loss: 0.00126\n",
      "epoch 16894 / 20000\n",
      "gradient norm: 0.08287392964120954, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00129\n",
      "\tval loss: 0.00127\n",
      "epoch 16895 / 20000\n",
      "gradient norm: 0.02912177296821028, minimum ratio: 2.4236842105263157\n",
      "\ttrain loss: 0.00127\n",
      "\tval loss: 0.00126\n",
      "epoch 16896 / 20000\n",
      "gradient norm: 0.05859201482962817, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00128\n",
      "\tval loss: 0.00126\n",
      "epoch 16897 / 20000\n",
      "gradient norm: 0.07314349384978414, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00127\n",
      "\tval loss: 0.00127\n",
      "epoch 16898 / 20000\n",
      "gradient norm: 0.024394766747718677, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00127\n",
      "\tval loss: 0.00125\n",
      "epoch 16899 / 20000\n",
      "gradient norm: 0.05294417351251468, minimum ratio: 2.4394736842105265\n",
      "\ttrain loss: 0.00127\n",
      "\tval loss: 0.00125\n",
      "epoch 16900 / 20000\n",
      "gradient norm: 0.06562199431937188, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00127\n",
      "\tval loss: 0.00125\n",
      "epoch 16901 / 20000\n",
      "gradient norm: 0.0190627122647129, minimum ratio: 2.46578947368421\n",
      "\ttrain loss: 0.00127\n",
      "\tval loss: 0.00125\n",
      "epoch 16902 / 20000\n",
      "gradient norm: 0.04264111275551841, minimum ratio: 2.460526315789474\n",
      "\ttrain loss: 0.00127\n",
      "\tval loss: 0.00125\n",
      "epoch 16903 / 20000\n",
      "gradient norm: 0.06846388359554112, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00127\n",
      "\tval loss: 0.00125\n",
      "epoch 16904 / 20000\n",
      "gradient norm: 0.04738390422426164, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00126\n",
      "\tval loss: 0.00124\n",
      "epoch 16905 / 20000\n",
      "gradient norm: 0.041808925627265126, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00126\n",
      "\tval loss: 0.00125\n",
      "epoch 16906 / 20000\n",
      "gradient norm: 0.033026044693542644, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00126\n",
      "\tval loss: 0.00124\n",
      "epoch 16907 / 20000\n",
      "gradient norm: 0.046135667245835066, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00126\n",
      "\tval loss: 0.00124\n",
      "epoch 16908 / 20000\n",
      "gradient norm: 0.02571345615433529, minimum ratio: 2.4236842105263157\n",
      "\ttrain loss: 0.00126\n",
      "\tval loss: 0.00124\n",
      "epoch 16909 / 20000\n",
      "gradient norm: 0.017348939058138058, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00126\n",
      "\tval loss: 0.00124\n",
      "epoch 16910 / 20000\n",
      "gradient norm: 0.044600375986192375, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00126\n",
      "\tval loss: 0.00124\n",
      "epoch 16911 / 20000\n",
      "gradient norm: 0.016697672836016864, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00125\n",
      "\tval loss: 0.00124\n",
      "epoch 16912 / 20000\n",
      "gradient norm: 0.029358719533775002, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00125\n",
      "\tval loss: 0.00124\n",
      "epoch 16913 / 20000\n",
      "gradient norm: 0.04100281506543979, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00125\n",
      "\tval loss: 0.00123\n",
      "epoch 16914 / 20000\n",
      "gradient norm: 0.02126337366644293, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00125\n",
      "\tval loss: 0.00124\n",
      "epoch 16915 / 20000\n",
      "gradient norm: 0.01950697199208662, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00125\n",
      "\tval loss: 0.00123\n",
      "epoch 16916 / 20000\n",
      "gradient norm: 0.028162594768218696, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00125\n",
      "\tval loss: 0.00123\n",
      "epoch 16917 / 20000\n",
      "gradient norm: 0.025314321683254093, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00125\n",
      "\tval loss: 0.00123\n",
      "epoch 16918 / 20000\n",
      "gradient norm: 0.04052294633584097, minimum ratio: 2.460526315789474\n",
      "\ttrain loss: 0.00124\n",
      "\tval loss: 0.00123\n",
      "epoch 16919 / 20000\n",
      "gradient norm: 0.05784188094548881, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00124\n",
      "\tval loss: 0.00123\n",
      "epoch 16920 / 20000\n",
      "gradient norm: 0.042295371647924185, minimum ratio: 2.421052631578947\n",
      "\ttrain loss: 0.00124\n",
      "\tval loss: 0.00123\n",
      "epoch 16921 / 20000\n",
      "gradient norm: 0.04589643329381943, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00124\n",
      "\tval loss: 0.00122\n",
      "epoch 16922 / 20000\n",
      "gradient norm: 0.016797581571154296, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00124\n",
      "\tval loss: 0.00123\n",
      "epoch 16923 / 20000\n",
      "gradient norm: 0.029134603217244148, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00124\n",
      "\tval loss: 0.00122\n",
      "epoch 16924 / 20000\n",
      "gradient norm: 0.057861655426677316, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00124\n",
      "\tval loss: 0.00122\n",
      "epoch 16925 / 20000\n",
      "gradient norm: 0.05802902590949088, minimum ratio: 2.4263157894736844\n",
      "\ttrain loss: 0.00124\n",
      "\tval loss: 0.00123\n",
      "epoch 16926 / 20000\n",
      "gradient norm: 0.038171007530763745, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00124\n",
      "\tval loss: 0.00122\n",
      "epoch 16927 / 20000\n",
      "gradient norm: 0.06012513191672042, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00124\n",
      "\tval loss: 0.00122\n",
      "epoch 16928 / 20000\n",
      "gradient norm: 0.040845604497008026, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00123\n",
      "\tval loss: 0.00122\n",
      "epoch 16929 / 20000\n",
      "gradient norm: 0.045498499006498605, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00124\n",
      "\tval loss: 0.00121\n",
      "epoch 16930 / 20000\n",
      "gradient norm: 0.027830760751385242, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00123\n",
      "\tval loss: 0.00122\n",
      "epoch 16931 / 20000\n",
      "gradient norm: 0.03410683240508661, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00123\n",
      "\tval loss: 0.00121\n",
      "epoch 16932 / 20000\n",
      "gradient norm: 0.03283721680054441, minimum ratio: 2.413157894736842\n",
      "\ttrain loss: 0.00123\n",
      "\tval loss: 0.00121\n",
      "epoch 16933 / 20000\n",
      "gradient norm: 0.05161980778211728, minimum ratio: 2.447368421052631\n",
      "\ttrain loss: 0.00123\n",
      "\tval loss: 0.00122\n",
      "epoch 16934 / 20000\n",
      "gradient norm: 0.05857688025571406, minimum ratio: 2.4236842105263157\n",
      "\ttrain loss: 0.00122\n",
      "\tval loss: 0.00121\n",
      "epoch 16935 / 20000\n",
      "gradient norm: 0.037913771855528466, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00122\n",
      "\tval loss: 0.00121\n",
      "epoch 16936 / 20000\n",
      "gradient norm: 0.05132641602540389, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00123\n",
      "\tval loss: 0.00121\n",
      "epoch 16937 / 20000\n",
      "gradient norm: 0.03655984066426754, minimum ratio: 2.436842105263158\n",
      "\ttrain loss: 0.00122\n",
      "\tval loss: 0.00120\n",
      "epoch 16938 / 20000\n",
      "gradient norm: 0.03655303578125313, minimum ratio: 2.4105263157894736\n",
      "\ttrain loss: 0.00122\n",
      "\tval loss: 0.00121\n",
      "epoch 16939 / 20000\n",
      "gradient norm: 0.036120622244197875, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00122\n",
      "\tval loss: 0.00120\n",
      "epoch 16940 / 20000\n",
      "gradient norm: 0.034626143227797, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00122\n",
      "\tval loss: 0.00120\n",
      "epoch 16941 / 20000\n",
      "gradient norm: 0.03267604252323508, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00122\n",
      "\tval loss: 0.00120\n",
      "epoch 16942 / 20000\n",
      "gradient norm: 0.016874037217348814, minimum ratio: 2.4447368421052627\n",
      "\ttrain loss: 0.00122\n",
      "\tval loss: 0.00120\n",
      "epoch 16943 / 20000\n",
      "gradient norm: 0.0325669075245969, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00121\n",
      "\tval loss: 0.00120\n",
      "epoch 16944 / 20000\n",
      "gradient norm: 0.016963473259238526, minimum ratio: 2.405263157894737\n",
      "\ttrain loss: 0.00121\n",
      "\tval loss: 0.00120\n",
      "epoch 16945 / 20000\n",
      "gradient norm: 0.03562288348621223, minimum ratio: 2.4210526315789473\n",
      "\ttrain loss: 0.00121\n",
      "\tval loss: 0.00120\n",
      "epoch 16946 / 20000\n",
      "gradient norm: 0.022833693423308432, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00121\n",
      "\tval loss: 0.00119\n",
      "epoch 16947 / 20000\n",
      "gradient norm: 0.03180377744138241, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00121\n",
      "\tval loss: 0.00119\n",
      "epoch 16948 / 20000\n",
      "gradient norm: 0.04161392361856997, minimum ratio: 2.4289473684210523\n",
      "\ttrain loss: 0.00121\n",
      "\tval loss: 0.00119\n",
      "epoch 16949 / 20000\n",
      "gradient norm: 0.043717011460103095, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00120\n",
      "\tval loss: 0.00119\n",
      "epoch 16950 / 20000\n",
      "gradient norm: 0.028930952888913453, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00120\n",
      "\tval loss: 0.00119\n",
      "epoch 16951 / 20000\n",
      "gradient norm: 0.030904225423000753, minimum ratio: 2.413157894736842\n",
      "\ttrain loss: 0.00120\n",
      "\tval loss: 0.00119\n",
      "epoch 16952 / 20000\n",
      "gradient norm: 0.03095394343836233, minimum ratio: 2.4210526315789473\n",
      "\ttrain loss: 0.00120\n",
      "\tval loss: 0.00119\n",
      "epoch 16953 / 20000\n",
      "gradient norm: 0.037610068276990205, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00120\n",
      "\tval loss: 0.00118\n",
      "epoch 16954 / 20000\n",
      "gradient norm: 0.025187542021740228, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00120\n",
      "\tval loss: 0.00119\n",
      "epoch 16955 / 20000\n",
      "gradient norm: 0.024200841784477234, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00120\n",
      "\tval loss: 0.00118\n",
      "epoch 16956 / 20000\n",
      "gradient norm: 0.02279635239392519, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00120\n",
      "\tval loss: 0.00118\n",
      "epoch 16957 / 20000\n",
      "gradient norm: 0.02422290510730818, minimum ratio: 2.423684210526316\n",
      "\ttrain loss: 0.00119\n",
      "\tval loss: 0.00118\n",
      "epoch 16958 / 20000\n",
      "gradient norm: 0.015424855591845699, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00119\n",
      "\tval loss: 0.00118\n",
      "epoch 16959 / 20000\n",
      "gradient norm: 0.03748483693925664, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00119\n",
      "\tval loss: 0.00118\n",
      "epoch 16960 / 20000\n",
      "gradient norm: 0.028674999543000013, minimum ratio: 2.465789473684211\n",
      "\ttrain loss: 0.00119\n",
      "\tval loss: 0.00118\n",
      "epoch 16961 / 20000\n",
      "gradient norm: 0.031520632677711546, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00119\n",
      "\tval loss: 0.00117\n",
      "epoch 16962 / 20000\n",
      "gradient norm: 0.036898810241837054, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00119\n",
      "\tval loss: 0.00118\n",
      "epoch 16963 / 20000\n",
      "gradient norm: 0.05801110924221575, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00120\n",
      "\tval loss: 0.00118\n",
      "epoch 16964 / 20000\n",
      "gradient norm: 0.048606266384013, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00119\n",
      "\tval loss: 0.00117\n",
      "epoch 16965 / 20000\n",
      "gradient norm: 0.05199155234731734, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00119\n",
      "\tval loss: 0.00118\n",
      "epoch 16966 / 20000\n",
      "gradient norm: 0.02371373266214505, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00119\n",
      "\tval loss: 0.00117\n",
      "epoch 16967 / 20000\n",
      "gradient norm: 0.03528280640603043, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00118\n",
      "\tval loss: 0.00117\n",
      "epoch 16968 / 20000\n",
      "gradient norm: 0.02564371912740171, minimum ratio: 2.4394736842105265\n",
      "\ttrain loss: 0.00118\n",
      "\tval loss: 0.00117\n",
      "epoch 16969 / 20000\n",
      "gradient norm: 0.04354608035646379, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00118\n",
      "\tval loss: 0.00116\n",
      "epoch 16970 / 20000\n",
      "gradient norm: 0.03202971693826839, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00118\n",
      "\tval loss: 0.00117\n",
      "epoch 16971 / 20000\n",
      "gradient norm: 0.016426730959210545, minimum ratio: 2.4394736842105265\n",
      "\ttrain loss: 0.00118\n",
      "\tval loss: 0.00116\n",
      "epoch 16972 / 20000\n",
      "gradient norm: 0.028781674918718636, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00118\n",
      "\tval loss: 0.00116\n",
      "epoch 16973 / 20000\n",
      "gradient norm: 0.029086293274303898, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00117\n",
      "\tval loss: 0.00116\n",
      "epoch 16974 / 20000\n",
      "gradient norm: 0.0518281701952219, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00118\n",
      "\tval loss: 0.00116\n",
      "epoch 16975 / 20000\n",
      "gradient norm: 0.06613918318180367, minimum ratio: 2.436842105263158\n",
      "\ttrain loss: 0.00118\n",
      "\tval loss: 0.00116\n",
      "epoch 16976 / 20000\n",
      "gradient norm: 0.06584060157183558, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00118\n",
      "\tval loss: 0.00117\n",
      "epoch 16977 / 20000\n",
      "gradient norm: 0.01072641386417672, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00117\n",
      "\tval loss: 0.00116\n",
      "epoch 16978 / 20000\n",
      "gradient norm: 0.05103603680618107, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00117\n",
      "\tval loss: 0.00115\n",
      "epoch 16979 / 20000\n",
      "gradient norm: 0.03426979767391458, minimum ratio: 2.413157894736842\n",
      "\ttrain loss: 0.00117\n",
      "\tval loss: 0.00116\n",
      "epoch 16980 / 20000\n",
      "gradient norm: 0.04821659892331809, minimum ratio: 2.4236842105263157\n",
      "\ttrain loss: 0.00117\n",
      "\tval loss: 0.00115\n",
      "epoch 16981 / 20000\n",
      "gradient norm: 0.030570580129278824, minimum ratio: 2.413157894736842\n",
      "\ttrain loss: 0.00117\n",
      "\tval loss: 0.00116\n",
      "epoch 16982 / 20000\n",
      "gradient norm: 0.03497359459288418, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00117\n",
      "\tval loss: 0.00115\n",
      "epoch 16983 / 20000\n",
      "gradient norm: 0.03205215069465339, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00116\n",
      "\tval loss: 0.00115\n",
      "epoch 16984 / 20000\n",
      "gradient norm: 0.017475466680480167, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00116\n",
      "\tval loss: 0.00115\n",
      "epoch 16985 / 20000\n",
      "gradient norm: 0.026813460513949394, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00116\n",
      "\tval loss: 0.00115\n",
      "epoch 16986 / 20000\n",
      "gradient norm: 0.03135138898505829, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00116\n",
      "\tval loss: 0.00115\n",
      "epoch 16987 / 20000\n",
      "gradient norm: 0.038537626853212714, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00116\n",
      "\tval loss: 0.00115\n",
      "epoch 16988 / 20000\n",
      "gradient norm: 0.03423613519407809, minimum ratio: 2.4394736842105265\n",
      "\ttrain loss: 0.00116\n",
      "\tval loss: 0.00114\n",
      "epoch 16989 / 20000\n",
      "gradient norm: 0.03849820623872802, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00115\n",
      "\tval loss: 0.00115\n",
      "epoch 16990 / 20000\n",
      "gradient norm: 0.030686251702718437, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00116\n",
      "\tval loss: 0.00114\n",
      "epoch 16991 / 20000\n",
      "gradient norm: 0.02068259730003774, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00115\n",
      "\tval loss: 0.00114\n",
      "epoch 16992 / 20000\n",
      "gradient norm: 0.03814468247583136, minimum ratio: 2.4447368421052635\n",
      "\ttrain loss: 0.00115\n",
      "\tval loss: 0.00114\n",
      "epoch 16993 / 20000\n",
      "gradient norm: 0.06155724613927305, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00116\n",
      "\tval loss: 0.00115\n",
      "epoch 16994 / 20000\n",
      "gradient norm: 0.055964379105716944, minimum ratio: 2.4447368421052627\n",
      "\ttrain loss: 0.00116\n",
      "\tval loss: 0.00114\n",
      "epoch 16995 / 20000\n",
      "gradient norm: 0.038742753327824175, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00116\n",
      "\tval loss: 0.00115\n",
      "epoch 16996 / 20000\n",
      "gradient norm: 0.04442731314338744, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00115\n",
      "\tval loss: 0.00114\n",
      "epoch 16997 / 20000\n",
      "gradient norm: 0.05593784124357626, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00115\n",
      "\tval loss: 0.00113\n",
      "epoch 16998 / 20000\n",
      "gradient norm: 0.026724215829744935, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00114\n",
      "\tval loss: 0.00114\n",
      "epoch 16999 / 20000\n",
      "gradient norm: 0.03606227831915021, minimum ratio: 2.4236842105263157\n",
      "\ttrain loss: 0.00115\n",
      "\tval loss: 0.00113\n",
      "epoch 17000 / 20000\n",
      "gradient norm: 0.03181585838319734, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00114\n",
      "\tval loss: 0.00113\n",
      "epoch 17001 / 20000\n",
      "gradient norm: 0.022565686784218997, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00114\n",
      "\tval loss: 0.00113\n",
      "epoch 17002 / 20000\n",
      "gradient norm: 0.03896018836530857, minimum ratio: 2.4394736842105265\n",
      "\ttrain loss: 0.00114\n",
      "\tval loss: 0.00113\n",
      "epoch 17003 / 20000\n",
      "gradient norm: 0.03234356880420819, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00114\n",
      "\tval loss: 0.00113\n",
      "epoch 17004 / 20000\n",
      "gradient norm: 0.01485677104210481, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00114\n",
      "\tval loss: 0.00113\n",
      "epoch 17005 / 20000\n",
      "gradient norm: 0.015320504899136722, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00114\n",
      "\tval loss: 0.00112\n",
      "epoch 17006 / 20000\n",
      "gradient norm: 0.024814733624225482, minimum ratio: 2.4421052631578943\n",
      "\ttrain loss: 0.00114\n",
      "\tval loss: 0.00112\n",
      "epoch 17007 / 20000\n",
      "gradient norm: 0.04164295963710174, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00113\n",
      "\tval loss: 0.00112\n",
      "epoch 17008 / 20000\n",
      "gradient norm: 0.028089053463190794, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00113\n",
      "\tval loss: 0.00112\n",
      "epoch 17009 / 20000\n",
      "gradient norm: 0.05637514538830146, minimum ratio: 2.4210526315789473\n",
      "\ttrain loss: 0.00113\n",
      "\tval loss: 0.00112\n",
      "epoch 17010 / 20000\n",
      "gradient norm: 0.03169429610716179, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00113\n",
      "\tval loss: 0.00112\n",
      "epoch 17011 / 20000\n",
      "gradient norm: 0.03933621049509384, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00113\n",
      "\tval loss: 0.00112\n",
      "epoch 17012 / 20000\n",
      "gradient norm: 0.03502228099387139, minimum ratio: 2.4394736842105265\n",
      "\ttrain loss: 0.00113\n",
      "\tval loss: 0.00112\n",
      "epoch 17013 / 20000\n",
      "gradient norm: 0.03133550920756534, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00113\n",
      "\tval loss: 0.00111\n",
      "epoch 17014 / 20000\n",
      "gradient norm: 0.02377749653533101, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00113\n",
      "\tval loss: 0.00112\n",
      "epoch 17015 / 20000\n",
      "gradient norm: 0.015911734983092174, minimum ratio: 2.4394736842105265\n",
      "\ttrain loss: 0.00112\n",
      "\tval loss: 0.00111\n",
      "epoch 17016 / 20000\n",
      "gradient norm: 0.036673684197012335, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00112\n",
      "\tval loss: 0.00111\n",
      "epoch 17017 / 20000\n",
      "gradient norm: 0.057572201592847705, minimum ratio: 2.4210526315789473\n",
      "\ttrain loss: 0.00113\n",
      "\tval loss: 0.00112\n",
      "epoch 17018 / 20000\n",
      "gradient norm: 0.05708465137286112, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00113\n",
      "\tval loss: 0.00111\n",
      "epoch 17019 / 20000\n",
      "gradient norm: 0.032203784154262394, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00112\n",
      "\tval loss: 0.00112\n",
      "epoch 17020 / 20000\n",
      "gradient norm: 0.03661588387330994, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00112\n",
      "\tval loss: 0.00111\n",
      "epoch 17021 / 20000\n",
      "gradient norm: 0.03673824272118509, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00112\n",
      "\tval loss: 0.00110\n",
      "epoch 17022 / 20000\n",
      "gradient norm: 0.05047485255636275, minimum ratio: 2.46578947368421\n",
      "\ttrain loss: 0.00112\n",
      "\tval loss: 0.00111\n",
      "epoch 17023 / 20000\n",
      "gradient norm: 0.035037366789765656, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00111\n",
      "\tval loss: 0.00110\n",
      "epoch 17024 / 20000\n",
      "gradient norm: 0.038121014600619674, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00112\n",
      "\tval loss: 0.00110\n",
      "epoch 17025 / 20000\n",
      "gradient norm: 0.03338921023532748, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00111\n",
      "\tval loss: 0.00110\n",
      "epoch 17026 / 20000\n",
      "gradient norm: 0.02702825580490753, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00112\n",
      "\tval loss: 0.00110\n",
      "epoch 17027 / 20000\n",
      "gradient norm: 0.028579819583683275, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00111\n",
      "\tval loss: 0.00110\n",
      "epoch 17028 / 20000\n",
      "gradient norm: 0.030474092753138393, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00111\n",
      "\tval loss: 0.00110\n",
      "epoch 17029 / 20000\n",
      "gradient norm: 0.042411405011080205, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00111\n",
      "\tval loss: 0.00110\n",
      "epoch 17030 / 20000\n",
      "gradient norm: 0.019545469695003703, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00111\n",
      "\tval loss: 0.00110\n",
      "epoch 17031 / 20000\n",
      "gradient norm: 0.013345860701519996, minimum ratio: 2.4236842105263157\n",
      "\ttrain loss: 0.00111\n",
      "\tval loss: 0.00109\n",
      "epoch 17032 / 20000\n",
      "gradient norm: 0.02700439450563863, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00110\n",
      "\tval loss: 0.00109\n",
      "epoch 17033 / 20000\n",
      "gradient norm: 0.020948286139173433, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00110\n",
      "\tval loss: 0.00109\n",
      "epoch 17034 / 20000\n",
      "gradient norm: 0.03339511825470254, minimum ratio: 2.4394736842105265\n",
      "\ttrain loss: 0.00110\n",
      "\tval loss: 0.00109\n",
      "epoch 17035 / 20000\n",
      "gradient norm: 0.029015759122557938, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00110\n",
      "\tval loss: 0.00109\n",
      "epoch 17036 / 20000\n",
      "gradient norm: 0.02999847591854632, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00110\n",
      "\tval loss: 0.00109\n",
      "epoch 17037 / 20000\n",
      "gradient norm: 0.024286425847094506, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00110\n",
      "\tval loss: 0.00109\n",
      "epoch 17038 / 20000\n",
      "gradient norm: 0.03871811804128811, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00110\n",
      "\tval loss: 0.00109\n",
      "epoch 17039 / 20000\n",
      "gradient norm: 0.03226156294113025, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00110\n",
      "\tval loss: 0.00109\n",
      "epoch 17040 / 20000\n",
      "gradient norm: 0.02655179295106791, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00109\n",
      "\tval loss: 0.00108\n",
      "epoch 17041 / 20000\n",
      "gradient norm: 0.044889663346111774, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00110\n",
      "\tval loss: 0.00108\n",
      "epoch 17042 / 20000\n",
      "gradient norm: 0.021417657611891627, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00109\n",
      "\tval loss: 0.00109\n",
      "epoch 17043 / 20000\n",
      "gradient norm: 0.04498549771960825, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00110\n",
      "\tval loss: 0.00108\n",
      "epoch 17044 / 20000\n",
      "gradient norm: 0.05956305586732924, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00109\n",
      "\tval loss: 0.00108\n",
      "epoch 17045 / 20000\n",
      "gradient norm: 0.07267282507382333, minimum ratio: 2.4210526315789473\n",
      "\ttrain loss: 0.00110\n",
      "\tval loss: 0.00109\n",
      "epoch 17046 / 20000\n",
      "gradient norm: 0.04135972337098792, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00109\n",
      "\tval loss: 0.00108\n",
      "epoch 17047 / 20000\n",
      "gradient norm: 0.05487909307703376, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00109\n",
      "\tval loss: 0.00108\n",
      "epoch 17048 / 20000\n",
      "gradient norm: 0.06355234025977552, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00109\n",
      "\tval loss: 0.00108\n",
      "epoch 17049 / 20000\n",
      "gradient norm: 0.04824667505454272, minimum ratio: 2.436842105263158\n",
      "\ttrain loss: 0.00109\n",
      "\tval loss: 0.00107\n",
      "epoch 17050 / 20000\n",
      "gradient norm: 0.04964741802541539, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00109\n",
      "\tval loss: 0.00108\n",
      "epoch 17051 / 20000\n",
      "gradient norm: 0.02538158617244335, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00108\n",
      "\tval loss: 0.00107\n",
      "epoch 17052 / 20000\n",
      "gradient norm: 0.033949233329622075, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00108\n",
      "\tval loss: 0.00107\n",
      "epoch 17053 / 20000\n",
      "gradient norm: 0.020178165344987065, minimum ratio: 2.4210526315789473\n",
      "\ttrain loss: 0.00108\n",
      "\tval loss: 0.00107\n",
      "epoch 17054 / 20000\n",
      "gradient norm: 0.04517321885214187, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00108\n",
      "\tval loss: 0.00107\n",
      "epoch 17055 / 20000\n",
      "gradient norm: 0.038770050392486155, minimum ratio: 2.4236842105263157\n",
      "\ttrain loss: 0.00108\n",
      "\tval loss: 0.00106\n",
      "epoch 17056 / 20000\n",
      "gradient norm: 0.03256197724840604, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00108\n",
      "\tval loss: 0.00107\n",
      "epoch 17057 / 20000\n",
      "gradient norm: 0.028539397259010002, minimum ratio: 2.4394736842105265\n",
      "\ttrain loss: 0.00108\n",
      "\tval loss: 0.00106\n",
      "epoch 17058 / 20000\n",
      "gradient norm: 0.024935940396972, minimum ratio: 2.426315789473684\n",
      "\ttrain loss: 0.00108\n",
      "\tval loss: 0.00106\n",
      "epoch 17059 / 20000\n",
      "gradient norm: 0.028811121999751776, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00108\n",
      "\tval loss: 0.00106\n",
      "epoch 17060 / 20000\n",
      "gradient norm: 0.050818585557863116, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00107\n",
      "\tval loss: 0.00106\n",
      "epoch 17061 / 20000\n",
      "gradient norm: 0.028924052166985348, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00107\n",
      "\tval loss: 0.00106\n",
      "epoch 17062 / 20000\n",
      "gradient norm: 0.08647671691142023, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00108\n",
      "\tval loss: 0.00107\n",
      "epoch 17063 / 20000\n",
      "gradient norm: 0.04157349345041439, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00107\n",
      "\tval loss: 0.00106\n",
      "epoch 17064 / 20000\n",
      "gradient norm: 0.047356217983178794, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00107\n",
      "\tval loss: 0.00105\n",
      "epoch 17065 / 20000\n",
      "gradient norm: 0.04475860408274457, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00107\n",
      "\tval loss: 0.00107\n",
      "epoch 17066 / 20000\n",
      "gradient norm: 0.03400414902716875, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00107\n",
      "\tval loss: 0.00105\n",
      "epoch 17067 / 20000\n",
      "gradient norm: 0.05681788956280798, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00106\n",
      "\tval loss: 0.00106\n",
      "epoch 17068 / 20000\n",
      "gradient norm: 0.030807311355601996, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00107\n",
      "\tval loss: 0.00105\n",
      "epoch 17069 / 20000\n",
      "gradient norm: 0.040173752582632005, minimum ratio: 2.4210526315789473\n",
      "\ttrain loss: 0.00106\n",
      "\tval loss: 0.00105\n",
      "epoch 17070 / 20000\n",
      "gradient norm: 0.03159346187021583, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00106\n",
      "\tval loss: 0.00106\n",
      "epoch 17071 / 20000\n",
      "gradient norm: 0.04274857381824404, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00106\n",
      "\tval loss: 0.00105\n",
      "epoch 17072 / 20000\n",
      "gradient norm: 0.037649511417839676, minimum ratio: 2.4263157894736844\n",
      "\ttrain loss: 0.00106\n",
      "\tval loss: 0.00105\n",
      "epoch 17073 / 20000\n",
      "gradient norm: 0.02475971406965982, minimum ratio: 2.4421052631578943\n",
      "\ttrain loss: 0.00106\n",
      "\tval loss: 0.00105\n",
      "epoch 17074 / 20000\n",
      "gradient norm: 0.037410724558867514, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00106\n",
      "\tval loss: 0.00104\n",
      "epoch 17075 / 20000\n",
      "gradient norm: 0.025508153368718922, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00105\n",
      "\tval loss: 0.00105\n",
      "epoch 17076 / 20000\n",
      "gradient norm: 0.03103661589557305, minimum ratio: 2.436842105263158\n",
      "\ttrain loss: 0.00105\n",
      "\tval loss: 0.00104\n",
      "epoch 17077 / 20000\n",
      "gradient norm: 0.02969860180746764, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00105\n",
      "\tval loss: 0.00104\n",
      "epoch 17078 / 20000\n",
      "gradient norm: 0.016597128531429917, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00105\n",
      "\tval loss: 0.00104\n",
      "epoch 17079 / 20000\n",
      "gradient norm: 0.027733029972296208, minimum ratio: 2.426315789473684\n",
      "\ttrain loss: 0.00105\n",
      "\tval loss: 0.00104\n",
      "epoch 17080 / 20000\n",
      "gradient norm: 0.03147522441577166, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00105\n",
      "\tval loss: 0.00104\n",
      "epoch 17081 / 20000\n",
      "gradient norm: 0.0491943767410703, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00105\n",
      "\tval loss: 0.00104\n",
      "epoch 17082 / 20000\n",
      "gradient norm: 0.03427323515643366, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00105\n",
      "\tval loss: 0.00103\n",
      "epoch 17083 / 20000\n",
      "gradient norm: 0.0421726816566661, minimum ratio: 2.4236842105263157\n",
      "\ttrain loss: 0.00105\n",
      "\tval loss: 0.00104\n",
      "epoch 17084 / 20000\n",
      "gradient norm: 0.027581970061874017, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00105\n",
      "\tval loss: 0.00103\n",
      "epoch 17085 / 20000\n",
      "gradient norm: 0.04585433576721698, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00104\n",
      "\tval loss: 0.00103\n",
      "epoch 17086 / 20000\n",
      "gradient norm: 0.02183468354633078, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00104\n",
      "\tval loss: 0.00103\n",
      "epoch 17087 / 20000\n",
      "gradient norm: 0.03180976107250899, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00104\n",
      "\tval loss: 0.00103\n",
      "epoch 17088 / 20000\n",
      "gradient norm: 0.05739395855925977, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00104\n",
      "\tval loss: 0.00103\n",
      "epoch 17089 / 20000\n",
      "gradient norm: 0.023479500436224043, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00104\n",
      "\tval loss: 0.00103\n",
      "epoch 17090 / 20000\n",
      "gradient norm: 0.02624441619263962, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00104\n",
      "\tval loss: 0.00103\n",
      "epoch 17091 / 20000\n",
      "gradient norm: 0.023348900285782292, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00104\n",
      "\tval loss: 0.00103\n",
      "epoch 17092 / 20000\n",
      "gradient norm: 0.025816700654104352, minimum ratio: 2.4499999999999997\n",
      "\ttrain loss: 0.00104\n",
      "\tval loss: 0.00103\n",
      "epoch 17093 / 20000\n",
      "gradient norm: 0.03431692917365581, minimum ratio: 2.4421052631578943\n",
      "\ttrain loss: 0.00104\n",
      "\tval loss: 0.00103\n",
      "epoch 17094 / 20000\n",
      "gradient norm: 0.02368776948424056, minimum ratio: 2.4578947368421056\n",
      "\ttrain loss: 0.00103\n",
      "\tval loss: 0.00102\n",
      "epoch 17095 / 20000\n",
      "gradient norm: 0.031270002480596304, minimum ratio: 2.4236842105263157\n",
      "\ttrain loss: 0.00103\n",
      "\tval loss: 0.00103\n",
      "epoch 17096 / 20000\n",
      "gradient norm: 0.04580753808841109, minimum ratio: 2.4394736842105265\n",
      "\ttrain loss: 0.00103\n",
      "\tval loss: 0.00102\n",
      "epoch 17097 / 20000\n",
      "gradient norm: 0.02837968140374869, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00103\n",
      "\tval loss: 0.00102\n",
      "epoch 17098 / 20000\n",
      "gradient norm: 0.04791523187304847, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00103\n",
      "\tval loss: 0.00102\n",
      "epoch 17099 / 20000\n",
      "gradient norm: 0.03970047563780099, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00103\n",
      "\tval loss: 0.00102\n",
      "epoch 17100 / 20000\n",
      "gradient norm: 0.057695827330462635, minimum ratio: 2.4421052631578943\n",
      "\ttrain loss: 0.00103\n",
      "\tval loss: 0.00101\n",
      "epoch 17101 / 20000\n",
      "gradient norm: 0.036264861293602735, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00103\n",
      "\tval loss: 0.00102\n",
      "epoch 17102 / 20000\n",
      "gradient norm: 0.048862540046684444, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00103\n",
      "\tval loss: 0.00101\n",
      "epoch 17103 / 20000\n",
      "gradient norm: 0.02006397265358828, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00102\n",
      "\tval loss: 0.00101\n",
      "epoch 17104 / 20000\n",
      "gradient norm: 0.02335920080076903, minimum ratio: 2.4236842105263157\n",
      "\ttrain loss: 0.00102\n",
      "\tval loss: 0.00101\n",
      "epoch 17105 / 20000\n",
      "gradient norm: 0.028372804925311357, minimum ratio: 2.413157894736842\n",
      "\ttrain loss: 0.00102\n",
      "\tval loss: 0.00101\n",
      "epoch 17106 / 20000\n",
      "gradient norm: 0.01426209436613135, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00102\n",
      "\tval loss: 0.00101\n",
      "epoch 17107 / 20000\n",
      "gradient norm: 0.017102664685808122, minimum ratio: 2.4394736842105265\n",
      "\ttrain loss: 0.00102\n",
      "\tval loss: 0.00101\n",
      "epoch 17108 / 20000\n",
      "gradient norm: 0.032074641436338425, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00102\n",
      "\tval loss: 0.00101\n",
      "epoch 17109 / 20000\n",
      "gradient norm: 0.01322223010356538, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00102\n",
      "\tval loss: 0.00101\n",
      "epoch 17110 / 20000\n",
      "gradient norm: 0.044360909407259896, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00102\n",
      "\tval loss: 0.00101\n",
      "epoch 17111 / 20000\n",
      "gradient norm: 0.03341794037260115, minimum ratio: 2.4263157894736844\n",
      "\ttrain loss: 0.00102\n",
      "\tval loss: 0.00100\n",
      "epoch 17112 / 20000\n",
      "gradient norm: 0.019951318521634676, minimum ratio: 2.418421052631579\n",
      "\ttrain loss: 0.00101\n",
      "\tval loss: 0.00101\n",
      "epoch 17113 / 20000\n",
      "gradient norm: 0.021530453261220828, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00101\n",
      "\tval loss: 0.00100\n",
      "epoch 17114 / 20000\n",
      "gradient norm: 0.022407585027394816, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00101\n",
      "\tval loss: 0.00100\n",
      "epoch 17115 / 20000\n",
      "gradient norm: 0.024088816600851715, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00101\n",
      "\tval loss: 0.00100\n",
      "epoch 17116 / 20000\n",
      "gradient norm: 0.021697640739148483, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00101\n",
      "\tval loss: 0.00100\n",
      "epoch 17117 / 20000\n",
      "gradient norm: 0.047132992767728865, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00101\n",
      "\tval loss: 0.00100\n",
      "epoch 17118 / 20000\n",
      "gradient norm: 0.05081353976856917, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00101\n",
      "\tval loss: 0.00100\n",
      "epoch 17119 / 20000\n",
      "gradient norm: 0.03000276058446616, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00100\n",
      "\tval loss: 0.00100\n",
      "epoch 17120 / 20000\n",
      "gradient norm: 0.02629926535882987, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00100\n",
      "\tval loss: 0.00099\n",
      "epoch 17121 / 20000\n",
      "gradient norm: 0.034933052433189005, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00100\n",
      "\tval loss: 0.00099\n",
      "epoch 17122 / 20000\n",
      "gradient norm: 0.042347049340605736, minimum ratio: 2.4289473684210523\n",
      "\ttrain loss: 0.00100\n",
      "\tval loss: 0.00100\n",
      "epoch 17123 / 20000\n",
      "gradient norm: 0.059782351832836866, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00101\n",
      "\tval loss: 0.00099\n",
      "epoch 17124 / 20000\n",
      "gradient norm: 0.032985837548039854, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00100\n",
      "\tval loss: 0.00100\n",
      "epoch 17125 / 20000\n",
      "gradient norm: 0.041696927859447896, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00100\n",
      "\tval loss: 0.00099\n",
      "epoch 17126 / 20000\n",
      "gradient norm: 0.013881445018341765, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00100\n",
      "\tval loss: 0.00099\n",
      "epoch 17127 / 20000\n",
      "gradient norm: 0.033447659050580114, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00100\n",
      "\tval loss: 0.00099\n",
      "epoch 17128 / 20000\n",
      "gradient norm: 0.024212278658524156, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00099\n",
      "\tval loss: 0.00099\n",
      "epoch 17129 / 20000\n",
      "gradient norm: 0.05626042385119945, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00100\n",
      "\tval loss: 0.00098\n",
      "epoch 17130 / 20000\n",
      "gradient norm: 0.028290481626754627, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00099\n",
      "\tval loss: 0.00098\n",
      "epoch 17131 / 20000\n",
      "gradient norm: 0.022230982867768034, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00099\n",
      "\tval loss: 0.00099\n",
      "epoch 17132 / 20000\n",
      "gradient norm: 0.022909870458533987, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00099\n",
      "\tval loss: 0.00098\n",
      "epoch 17133 / 20000\n",
      "gradient norm: 0.012767957960022613, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00099\n",
      "\tval loss: 0.00098\n",
      "epoch 17134 / 20000\n",
      "gradient norm: 0.0300275251356652, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00099\n",
      "\tval loss: 0.00098\n",
      "epoch 17135 / 20000\n",
      "gradient norm: 0.020699042594060302, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00099\n",
      "\tval loss: 0.00098\n",
      "epoch 17136 / 20000\n",
      "gradient norm: 0.02690612099831924, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00099\n",
      "\tval loss: 0.00098\n",
      "epoch 17137 / 20000\n",
      "gradient norm: 0.0175860722665675, minimum ratio: 2.423684210526316\n",
      "\ttrain loss: 0.00099\n",
      "\tval loss: 0.00098\n",
      "epoch 17138 / 20000\n",
      "gradient norm: 0.02876268874388188, minimum ratio: 2.436842105263158\n",
      "\ttrain loss: 0.00098\n",
      "\tval loss: 0.00098\n",
      "epoch 17139 / 20000\n",
      "gradient norm: 0.02870999905280769, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00098\n",
      "\tval loss: 0.00097\n",
      "epoch 17140 / 20000\n",
      "gradient norm: 0.02456487703602761, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00098\n",
      "\tval loss: 0.00097\n",
      "epoch 17141 / 20000\n",
      "gradient norm: 0.03679698274936527, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00098\n",
      "\tval loss: 0.00097\n",
      "epoch 17142 / 20000\n",
      "gradient norm: 0.027356082922779024, minimum ratio: 2.4157894736842103\n",
      "\ttrain loss: 0.00098\n",
      "\tval loss: 0.00097\n",
      "epoch 17143 / 20000\n",
      "gradient norm: 0.028661944554187357, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00098\n",
      "\tval loss: 0.00097\n",
      "epoch 17144 / 20000\n",
      "gradient norm: 0.01869724877178669, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00098\n",
      "\tval loss: 0.00097\n",
      "epoch 17145 / 20000\n",
      "gradient norm: 0.028976422967389226, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00098\n",
      "\tval loss: 0.00097\n",
      "epoch 17146 / 20000\n",
      "gradient norm: 0.027408572263084352, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00097\n",
      "\tval loss: 0.00097\n",
      "epoch 17147 / 20000\n",
      "gradient norm: 0.015679726318921894, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00098\n",
      "\tval loss: 0.00097\n",
      "epoch 17148 / 20000\n",
      "gradient norm: 0.022684888128424063, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00098\n",
      "\tval loss: 0.00097\n",
      "epoch 17149 / 20000\n",
      "gradient norm: 0.015966688137268648, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00097\n",
      "\tval loss: 0.00096\n",
      "epoch 17150 / 20000\n",
      "gradient norm: 0.041076435591094196, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00097\n",
      "\tval loss: 0.00096\n",
      "epoch 17151 / 20000\n",
      "gradient norm: 0.009912223147694021, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00097\n",
      "\tval loss: 0.00096\n",
      "epoch 17152 / 20000\n",
      "gradient norm: 0.027466514729894698, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00097\n",
      "\tval loss: 0.00096\n",
      "epoch 17153 / 20000\n",
      "gradient norm: 0.01814762322464958, minimum ratio: 2.4394736842105265\n",
      "\ttrain loss: 0.00097\n",
      "\tval loss: 0.00096\n",
      "epoch 17154 / 20000\n",
      "gradient norm: 0.020627085083106067, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00097\n",
      "\tval loss: 0.00096\n",
      "epoch 17155 / 20000\n",
      "gradient norm: 0.02335806260816753, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00097\n",
      "\tval loss: 0.00096\n",
      "epoch 17156 / 20000\n",
      "gradient norm: 0.02766465288004838, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00096\n",
      "\tval loss: 0.00096\n",
      "epoch 17157 / 20000\n",
      "gradient norm: 0.02546860818983987, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00096\n",
      "\tval loss: 0.00096\n",
      "epoch 17158 / 20000\n",
      "gradient norm: 0.01893044708413072, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00096\n",
      "\tval loss: 0.00095\n",
      "epoch 17159 / 20000\n",
      "gradient norm: 0.020753596123540774, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00096\n",
      "\tval loss: 0.00095\n",
      "epoch 17160 / 20000\n",
      "gradient norm: 0.029731092683505267, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00096\n",
      "\tval loss: 0.00095\n",
      "epoch 17161 / 20000\n",
      "gradient norm: 0.018689188407734036, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00096\n",
      "\tval loss: 0.00095\n",
      "epoch 17162 / 20000\n",
      "gradient norm: 0.022967064520344138, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00096\n",
      "\tval loss: 0.00095\n",
      "epoch 17163 / 20000\n",
      "gradient norm: 0.02192260412266478, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00096\n",
      "\tval loss: 0.00095\n",
      "epoch 17164 / 20000\n",
      "gradient norm: 0.028784721216652542, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00096\n",
      "\tval loss: 0.00095\n",
      "epoch 17165 / 20000\n",
      "gradient norm: 0.03476671242970042, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00096\n",
      "\tval loss: 0.00095\n",
      "epoch 17166 / 20000\n",
      "gradient norm: 0.03131423535523936, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00095\n",
      "\tval loss: 0.00095\n",
      "epoch 17167 / 20000\n",
      "gradient norm: 0.019670376961585134, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00095\n",
      "\tval loss: 0.00094\n",
      "epoch 17168 / 20000\n",
      "gradient norm: 0.026501645799726248, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00095\n",
      "\tval loss: 0.00095\n",
      "epoch 17169 / 20000\n",
      "gradient norm: 0.020732065255288035, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00095\n",
      "\tval loss: 0.00094\n",
      "epoch 17170 / 20000\n",
      "gradient norm: 0.039175310055725276, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00095\n",
      "\tval loss: 0.00094\n",
      "epoch 17171 / 20000\n",
      "gradient norm: 0.03452713054139167, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00095\n",
      "\tval loss: 0.00094\n",
      "epoch 17172 / 20000\n",
      "gradient norm: 0.02346212591510266, minimum ratio: 2.4236842105263157\n",
      "\ttrain loss: 0.00095\n",
      "\tval loss: 0.00094\n",
      "epoch 17173 / 20000\n",
      "gradient norm: 0.025717594078741968, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00095\n",
      "\tval loss: 0.00094\n",
      "epoch 17174 / 20000\n",
      "gradient norm: 0.016795525705674663, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00095\n",
      "\tval loss: 0.00094\n",
      "epoch 17175 / 20000\n",
      "gradient norm: 0.031610324047505856, minimum ratio: 2.4210526315789473\n",
      "\ttrain loss: 0.00095\n",
      "\tval loss: 0.00094\n",
      "epoch 17176 / 20000\n",
      "gradient norm: 0.04788681713398546, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00095\n",
      "\tval loss: 0.00094\n",
      "epoch 17177 / 20000\n",
      "gradient norm: 0.04239674611017108, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00094\n",
      "\tval loss: 0.00093\n",
      "epoch 17178 / 20000\n",
      "gradient norm: 0.0517432545311749, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00095\n",
      "\tval loss: 0.00094\n",
      "epoch 17179 / 20000\n",
      "gradient norm: 0.04129434970673174, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00094\n",
      "\tval loss: 0.00093\n",
      "epoch 17180 / 20000\n",
      "gradient norm: 0.027915591548662633, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00094\n",
      "\tval loss: 0.00093\n",
      "epoch 17181 / 20000\n",
      "gradient norm: 0.05114499799674377, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00094\n",
      "\tval loss: 0.00093\n",
      "epoch 17182 / 20000\n",
      "gradient norm: 0.041364905482623726, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00093\n",
      "\tval loss: 0.00093\n",
      "epoch 17183 / 20000\n",
      "gradient norm: 0.04222266230499372, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00094\n",
      "\tval loss: 0.00093\n",
      "epoch 17184 / 20000\n",
      "gradient norm: 0.048642881913110614, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00093\n",
      "\tval loss: 0.00093\n",
      "epoch 17185 / 20000\n",
      "gradient norm: 0.020198368933051825, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00093\n",
      "\tval loss: 0.00092\n",
      "epoch 17186 / 20000\n",
      "gradient norm: 0.04092578258132562, minimum ratio: 2.4394736842105265\n",
      "\ttrain loss: 0.00094\n",
      "\tval loss: 0.00093\n",
      "epoch 17187 / 20000\n",
      "gradient norm: 0.04956500750267878, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00094\n",
      "\tval loss: 0.00092\n",
      "epoch 17188 / 20000\n",
      "gradient norm: 0.03678793978178874, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00093\n",
      "\tval loss: 0.00092\n",
      "epoch 17189 / 20000\n",
      "gradient norm: 0.04844327352475375, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00093\n",
      "\tval loss: 0.00092\n",
      "epoch 17190 / 20000\n",
      "gradient norm: 0.03463222488062456, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00093\n",
      "\tval loss: 0.00092\n",
      "epoch 17191 / 20000\n",
      "gradient norm: 0.018695295555517077, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00093\n",
      "\tval loss: 0.00092\n",
      "epoch 17192 / 20000\n",
      "gradient norm: 0.027080828964244574, minimum ratio: 2.4157894736842103\n",
      "\ttrain loss: 0.00093\n",
      "\tval loss: 0.00092\n",
      "epoch 17193 / 20000\n",
      "gradient norm: 0.0405031411210075, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00093\n",
      "\tval loss: 0.00092\n",
      "epoch 17194 / 20000\n",
      "gradient norm: 0.021614027325995266, minimum ratio: 2.426315789473684\n",
      "\ttrain loss: 0.00092\n",
      "\tval loss: 0.00091\n",
      "epoch 17195 / 20000\n",
      "gradient norm: 0.023832870472688228, minimum ratio: 2.423684210526316\n",
      "\ttrain loss: 0.00093\n",
      "\tval loss: 0.00092\n",
      "epoch 17196 / 20000\n",
      "gradient norm: 0.03578235948225483, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00092\n",
      "\tval loss: 0.00092\n",
      "epoch 17197 / 20000\n",
      "gradient norm: 0.03725326099083759, minimum ratio: 2.4236842105263157\n",
      "\ttrain loss: 0.00092\n",
      "\tval loss: 0.00091\n",
      "epoch 17198 / 20000\n",
      "gradient norm: 0.0315937465056777, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00092\n",
      "\tval loss: 0.00091\n",
      "epoch 17199 / 20000\n",
      "gradient norm: 0.03685154335107654, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00092\n",
      "\tval loss: 0.00091\n",
      "epoch 17200 / 20000\n",
      "gradient norm: 0.04132175026461482, minimum ratio: 2.4236842105263157\n",
      "\ttrain loss: 0.00092\n",
      "\tval loss: 0.00091\n",
      "epoch 17201 / 20000\n",
      "gradient norm: 0.01376213357434608, minimum ratio: 2.4289473684210523\n",
      "\ttrain loss: 0.00092\n",
      "\tval loss: 0.00091\n",
      "epoch 17202 / 20000\n",
      "gradient norm: 0.041360855277162045, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00091\n",
      "\tval loss: 0.00091\n",
      "epoch 17203 / 20000\n",
      "gradient norm: 0.029424445994663984, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00092\n",
      "\tval loss: 0.00091\n",
      "epoch 17204 / 20000\n",
      "gradient norm: 0.03647105523850769, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00092\n",
      "\tval loss: 0.00090\n",
      "epoch 17205 / 20000\n",
      "gradient norm: 0.033955144230276346, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00091\n",
      "\tval loss: 0.00091\n",
      "epoch 17206 / 20000\n",
      "gradient norm: 0.042215406661853194, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00091\n",
      "\tval loss: 0.00090\n",
      "epoch 17207 / 20000\n",
      "gradient norm: 0.023182823322713375, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00091\n",
      "\tval loss: 0.00091\n",
      "epoch 17208 / 20000\n",
      "gradient norm: 0.05738188802934019, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00091\n",
      "\tval loss: 0.00090\n",
      "epoch 17209 / 20000\n",
      "gradient norm: 0.02649363683303818, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00091\n",
      "\tval loss: 0.00090\n",
      "epoch 17210 / 20000\n",
      "gradient norm: 0.038600673142354935, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00091\n",
      "\tval loss: 0.00090\n",
      "epoch 17211 / 20000\n",
      "gradient norm: 0.008523954078555107, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00091\n",
      "\tval loss: 0.00090\n",
      "epoch 17212 / 20000\n",
      "gradient norm: 0.043731290788855404, minimum ratio: 2.426315789473684\n",
      "\ttrain loss: 0.00091\n",
      "\tval loss: 0.00090\n",
      "epoch 17213 / 20000\n",
      "gradient norm: 0.03415740706259385, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00091\n",
      "\tval loss: 0.00090\n",
      "epoch 17214 / 20000\n",
      "gradient norm: 0.04108188766986132, minimum ratio: 2.4263157894736844\n",
      "\ttrain loss: 0.00091\n",
      "\tval loss: 0.00089\n",
      "epoch 17215 / 20000\n",
      "gradient norm: 0.03109508316265419, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00090\n",
      "\tval loss: 0.00090\n",
      "epoch 17216 / 20000\n",
      "gradient norm: 0.031664638489019126, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00090\n",
      "\tval loss: 0.00089\n",
      "epoch 17217 / 20000\n",
      "gradient norm: 0.03363282111240551, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00090\n",
      "\tval loss: 0.00089\n",
      "epoch 17218 / 20000\n",
      "gradient norm: 0.019824605755275115, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00090\n",
      "\tval loss: 0.00089\n",
      "epoch 17219 / 20000\n",
      "gradient norm: 0.02331549726659432, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00090\n",
      "\tval loss: 0.00089\n",
      "epoch 17220 / 20000\n",
      "gradient norm: 0.02710376220056787, minimum ratio: 2.4421052631578943\n",
      "\ttrain loss: 0.00090\n",
      "\tval loss: 0.00089\n",
      "epoch 17221 / 20000\n",
      "gradient norm: 0.03732613567262888, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00090\n",
      "\tval loss: 0.00089\n",
      "epoch 17222 / 20000\n",
      "gradient norm: 0.02939115950721316, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00090\n",
      "\tval loss: 0.00089\n",
      "epoch 17223 / 20000\n",
      "gradient norm: 0.014065210067201406, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00089\n",
      "\tval loss: 0.00089\n",
      "epoch 17224 / 20000\n",
      "gradient norm: 0.03310292452806607, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00089\n",
      "\tval loss: 0.00089\n",
      "epoch 17225 / 20000\n",
      "gradient norm: 0.03756371501367539, minimum ratio: 2.4394736842105265\n",
      "\ttrain loss: 0.00089\n",
      "\tval loss: 0.00088\n",
      "epoch 17226 / 20000\n",
      "gradient norm: 0.027428268193034455, minimum ratio: 2.4394736842105265\n",
      "\ttrain loss: 0.00089\n",
      "\tval loss: 0.00089\n",
      "epoch 17227 / 20000\n",
      "gradient norm: 0.014778106764424592, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00089\n",
      "\tval loss: 0.00088\n",
      "epoch 17228 / 20000\n",
      "gradient norm: 0.03339075989788398, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00089\n",
      "\tval loss: 0.00088\n",
      "epoch 17229 / 20000\n",
      "gradient norm: 0.03573608014266938, minimum ratio: 2.4263157894736844\n",
      "\ttrain loss: 0.00089\n",
      "\tval loss: 0.00088\n",
      "epoch 17230 / 20000\n",
      "gradient norm: 0.04558817460201681, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00089\n",
      "\tval loss: 0.00088\n",
      "epoch 17231 / 20000\n",
      "gradient norm: 0.031309291982324794, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00089\n",
      "\tval loss: 0.00089\n",
      "epoch 17232 / 20000\n",
      "gradient norm: 0.029824400000507012, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00089\n",
      "\tval loss: 0.00087\n",
      "epoch 17233 / 20000\n",
      "gradient norm: 0.031522650620900095, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00088\n",
      "\tval loss: 0.00088\n",
      "epoch 17234 / 20000\n",
      "gradient norm: 0.04441477556247264, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00088\n",
      "\tval loss: 0.00088\n",
      "epoch 17235 / 20000\n",
      "gradient norm: 0.027892472688108683, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00088\n",
      "\tval loss: 0.00087\n",
      "epoch 17236 / 20000\n",
      "gradient norm: 0.023194096109364182, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00088\n",
      "\tval loss: 0.00088\n",
      "epoch 17237 / 20000\n",
      "gradient norm: 0.019366445543710142, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00088\n",
      "\tval loss: 0.00087\n",
      "epoch 17238 / 20000\n",
      "gradient norm: 0.041894275113008916, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00088\n",
      "\tval loss: 0.00087\n",
      "epoch 17239 / 20000\n",
      "gradient norm: 0.028162380738649517, minimum ratio: 2.423684210526316\n",
      "\ttrain loss: 0.00088\n",
      "\tval loss: 0.00087\n",
      "epoch 17240 / 20000\n",
      "gradient norm: 0.03149686602409929, minimum ratio: 2.4210526315789473\n",
      "\ttrain loss: 0.00088\n",
      "\tval loss: 0.00087\n",
      "epoch 17241 / 20000\n",
      "gradient norm: 0.03484035760629922, minimum ratio: 2.4263157894736844\n",
      "\ttrain loss: 0.00087\n",
      "\tval loss: 0.00087\n",
      "epoch 17242 / 20000\n",
      "gradient norm: 0.03396205141325481, minimum ratio: 2.436842105263158\n",
      "\ttrain loss: 0.00087\n",
      "\tval loss: 0.00087\n",
      "epoch 17243 / 20000\n",
      "gradient norm: 0.048554895212873816, minimum ratio: 2.4578947368421056\n",
      "\ttrain loss: 0.00088\n",
      "\tval loss: 0.00086\n",
      "epoch 17244 / 20000\n",
      "gradient norm: 0.02648695686366409, minimum ratio: 2.436842105263158\n",
      "\ttrain loss: 0.00087\n",
      "\tval loss: 0.00087\n",
      "epoch 17245 / 20000\n",
      "gradient norm: 0.03742651373613626, minimum ratio: 2.4447368421052627\n",
      "\ttrain loss: 0.00087\n",
      "\tval loss: 0.00086\n",
      "epoch 17246 / 20000\n",
      "gradient norm: 0.025335073834867217, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00087\n",
      "\tval loss: 0.00086\n",
      "epoch 17247 / 20000\n",
      "gradient norm: 0.044528295926284045, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00087\n",
      "\tval loss: 0.00086\n",
      "epoch 17248 / 20000\n",
      "gradient norm: 0.04091346845962107, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00087\n",
      "\tval loss: 0.00086\n",
      "epoch 17249 / 20000\n",
      "gradient norm: 0.04711902583949268, minimum ratio: 2.421052631578947\n",
      "\ttrain loss: 0.00087\n",
      "\tval loss: 0.00086\n",
      "epoch 17250 / 20000\n",
      "gradient norm: 0.02756442324607633, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00086\n",
      "\tval loss: 0.00086\n",
      "epoch 17251 / 20000\n",
      "gradient norm: 0.04170938627794385, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00087\n",
      "\tval loss: 0.00086\n",
      "epoch 17252 / 20000\n",
      "gradient norm: 0.018328118545468897, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00086\n",
      "\tval loss: 0.00085\n",
      "epoch 17253 / 20000\n",
      "gradient norm: 0.0257530985691119, minimum ratio: 2.423684210526316\n",
      "\ttrain loss: 0.00086\n",
      "\tval loss: 0.00085\n",
      "epoch 17254 / 20000\n",
      "gradient norm: 0.028721596114337444, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00086\n",
      "\tval loss: 0.00086\n",
      "epoch 17255 / 20000\n",
      "gradient norm: 0.027632909012027085, minimum ratio: 2.426315789473684\n",
      "\ttrain loss: 0.00086\n",
      "\tval loss: 0.00085\n",
      "epoch 17256 / 20000\n",
      "gradient norm: 0.023983260267414153, minimum ratio: 2.4421052631578943\n",
      "\ttrain loss: 0.00086\n",
      "\tval loss: 0.00085\n",
      "epoch 17257 / 20000\n",
      "gradient norm: 0.020653964253142476, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00086\n",
      "\tval loss: 0.00085\n",
      "epoch 17258 / 20000\n",
      "gradient norm: 0.012028862838633358, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00085\n",
      "\tval loss: 0.00085\n",
      "epoch 17259 / 20000\n",
      "gradient norm: 0.02740194895886816, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00086\n",
      "\tval loss: 0.00085\n",
      "epoch 17260 / 20000\n",
      "gradient norm: 0.03230962809175253, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00086\n",
      "\tval loss: 0.00085\n",
      "epoch 17261 / 20000\n",
      "gradient norm: 0.034680956159718335, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00085\n",
      "\tval loss: 0.00085\n",
      "epoch 17262 / 20000\n",
      "gradient norm: 0.03146458533592522, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00085\n",
      "\tval loss: 0.00084\n",
      "epoch 17263 / 20000\n",
      "gradient norm: 0.032005115470383316, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00085\n",
      "\tval loss: 0.00085\n",
      "epoch 17264 / 20000\n",
      "gradient norm: 0.023149220447521657, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00085\n",
      "\tval loss: 0.00084\n",
      "epoch 17265 / 20000\n",
      "gradient norm: 0.03726080112392083, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00085\n",
      "\tval loss: 0.00084\n",
      "epoch 17266 / 20000\n",
      "gradient norm: 0.0413805246935226, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00085\n",
      "\tval loss: 0.00085\n",
      "epoch 17267 / 20000\n",
      "gradient norm: 0.047834074473939836, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00085\n",
      "\tval loss: 0.00084\n",
      "epoch 17268 / 20000\n",
      "gradient norm: 0.025046590657439083, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00085\n",
      "\tval loss: 0.00084\n",
      "epoch 17269 / 20000\n",
      "gradient norm: 0.032331121095921844, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00085\n",
      "\tval loss: 0.00084\n",
      "epoch 17270 / 20000\n",
      "gradient norm: 0.04008531279396266, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00085\n",
      "\tval loss: 0.00084\n",
      "epoch 17271 / 20000\n",
      "gradient norm: 0.0445051058777608, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00084\n",
      "\tval loss: 0.00085\n",
      "epoch 17272 / 20000\n",
      "gradient norm: 0.032263204688206315, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00084\n",
      "\tval loss: 0.00084\n",
      "epoch 17273 / 20000\n",
      "gradient norm: 0.04306360724149272, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00084\n",
      "\tval loss: 0.00083\n",
      "epoch 17274 / 20000\n",
      "gradient norm: 0.022877252486068755, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00084\n",
      "\tval loss: 0.00084\n",
      "epoch 17275 / 20000\n",
      "gradient norm: 0.03278316353680566, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00084\n",
      "\tval loss: 0.00083\n",
      "epoch 17276 / 20000\n",
      "gradient norm: 0.029191713081672788, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00084\n",
      "\tval loss: 0.00083\n",
      "epoch 17277 / 20000\n",
      "gradient norm: 0.036757964408025146, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00084\n",
      "\tval loss: 0.00084\n",
      "epoch 17278 / 20000\n",
      "gradient norm: 0.04011452232953161, minimum ratio: 2.4210526315789473\n",
      "\ttrain loss: 0.00084\n",
      "\tval loss: 0.00083\n",
      "epoch 17279 / 20000\n",
      "gradient norm: 0.04583172738784924, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00084\n",
      "\tval loss: 0.00083\n",
      "epoch 17280 / 20000\n",
      "gradient norm: 0.02659207972465083, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00083\n",
      "\tval loss: 0.00083\n",
      "epoch 17281 / 20000\n",
      "gradient norm: 0.0376964132883586, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00084\n",
      "\tval loss: 0.00083\n",
      "epoch 17282 / 20000\n",
      "gradient norm: 0.029617829364724457, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00083\n",
      "\tval loss: 0.00083\n",
      "epoch 17283 / 20000\n",
      "gradient norm: 0.04716208635363728, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00083\n",
      "\tval loss: 0.00082\n",
      "epoch 17284 / 20000\n",
      "gradient norm: 0.020548091939417645, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00083\n",
      "\tval loss: 0.00083\n",
      "epoch 17285 / 20000\n",
      "gradient norm: 0.01850304362596944, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00083\n",
      "\tval loss: 0.00082\n",
      "epoch 17286 / 20000\n",
      "gradient norm: 0.028148240235168487, minimum ratio: 2.4421052631578943\n",
      "\ttrain loss: 0.00083\n",
      "\tval loss: 0.00082\n",
      "epoch 17287 / 20000\n",
      "gradient norm: 0.03719712214660831, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00083\n",
      "\tval loss: 0.00082\n",
      "epoch 17288 / 20000\n",
      "gradient norm: 0.022107197786681354, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00082\n",
      "\tval loss: 0.00082\n",
      "epoch 17289 / 20000\n",
      "gradient norm: 0.027821656898595393, minimum ratio: 2.4499999999999997\n",
      "\ttrain loss: 0.00083\n",
      "\tval loss: 0.00082\n",
      "epoch 17290 / 20000\n",
      "gradient norm: 0.023459949996322393, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00083\n",
      "\tval loss: 0.00082\n",
      "epoch 17291 / 20000\n",
      "gradient norm: 0.025312814803328365, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00082\n",
      "\tval loss: 0.00082\n",
      "epoch 17292 / 20000\n",
      "gradient norm: 0.032440603332361206, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00082\n",
      "\tval loss: 0.00082\n",
      "epoch 17293 / 20000\n",
      "gradient norm: 0.06527836853638291, minimum ratio: 2.405263157894737\n",
      "\ttrain loss: 0.00083\n",
      "\tval loss: 0.00082\n",
      "epoch 17294 / 20000\n",
      "gradient norm: 0.056044377270154655, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00082\n",
      "\tval loss: 0.00081\n",
      "epoch 17295 / 20000\n",
      "gradient norm: 0.04235465335659683, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00082\n",
      "\tval loss: 0.00082\n",
      "epoch 17296 / 20000\n",
      "gradient norm: 0.03082825493765995, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00082\n",
      "\tval loss: 0.00081\n",
      "epoch 17297 / 20000\n",
      "gradient norm: 0.05958243802888319, minimum ratio: 2.4236842105263157\n",
      "\ttrain loss: 0.00082\n",
      "\tval loss: 0.00081\n",
      "epoch 17298 / 20000\n",
      "gradient norm: 0.026257443358190358, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00082\n",
      "\tval loss: 0.00081\n",
      "epoch 17299 / 20000\n",
      "gradient norm: 0.04006099316757172, minimum ratio: 2.4210526315789473\n",
      "\ttrain loss: 0.00082\n",
      "\tval loss: 0.00081\n",
      "epoch 17300 / 20000\n",
      "gradient norm: 0.023231754603330046, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00082\n",
      "\tval loss: 0.00081\n",
      "epoch 17301 / 20000\n",
      "gradient norm: 0.026232250791508704, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00082\n",
      "\tval loss: 0.00081\n",
      "epoch 17302 / 20000\n",
      "gradient norm: 0.03919633926125243, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00081\n",
      "\tval loss: 0.00081\n",
      "epoch 17303 / 20000\n",
      "gradient norm: 0.03537363186478615, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00081\n",
      "\tval loss: 0.00081\n",
      "epoch 17304 / 20000\n",
      "gradient norm: 0.055787612684071064, minimum ratio: 2.4210526315789473\n",
      "\ttrain loss: 0.00081\n",
      "\tval loss: 0.00080\n",
      "epoch 17305 / 20000\n",
      "gradient norm: 0.027298606204567477, minimum ratio: 2.4421052631578943\n",
      "\ttrain loss: 0.00081\n",
      "\tval loss: 0.00081\n",
      "epoch 17306 / 20000\n",
      "gradient norm: 0.033521608798764646, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00081\n",
      "\tval loss: 0.00080\n",
      "epoch 17307 / 20000\n",
      "gradient norm: 0.03284138371236622, minimum ratio: 2.418421052631579\n",
      "\ttrain loss: 0.00081\n",
      "\tval loss: 0.00080\n",
      "epoch 17308 / 20000\n",
      "gradient norm: 0.010716600896557793, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00081\n",
      "\tval loss: 0.00080\n",
      "epoch 17309 / 20000\n",
      "gradient norm: 0.03768687596311793, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00081\n",
      "\tval loss: 0.00080\n",
      "epoch 17310 / 20000\n",
      "gradient norm: 0.03785231534857303, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00081\n",
      "\tval loss: 0.00080\n",
      "epoch 17311 / 20000\n",
      "gradient norm: 0.028214427991770208, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00080\n",
      "\tval loss: 0.00080\n",
      "epoch 17312 / 20000\n",
      "gradient norm: 0.031690627249190584, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00080\n",
      "\tval loss: 0.00080\n",
      "epoch 17313 / 20000\n",
      "gradient norm: 0.022174282930791378, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00080\n",
      "\tval loss: 0.00079\n",
      "epoch 17314 / 20000\n",
      "gradient norm: 0.018106503237504512, minimum ratio: 2.4210526315789473\n",
      "\ttrain loss: 0.00080\n",
      "\tval loss: 0.00080\n",
      "epoch 17315 / 20000\n",
      "gradient norm: 0.028195859340485185, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00080\n",
      "\tval loss: 0.00079\n",
      "epoch 17316 / 20000\n",
      "gradient norm: 0.031013562227599323, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00080\n",
      "\tval loss: 0.00079\n",
      "epoch 17317 / 20000\n",
      "gradient norm: 0.053049883543280885, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00080\n",
      "\tval loss: 0.00079\n",
      "epoch 17318 / 20000\n",
      "gradient norm: 0.03143169864779338, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00080\n",
      "\tval loss: 0.00079\n",
      "epoch 17319 / 20000\n",
      "gradient norm: 0.0284536182298325, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00080\n",
      "\tval loss: 0.00079\n",
      "epoch 17320 / 20000\n",
      "gradient norm: 0.052929107390809804, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00080\n",
      "\tval loss: 0.00079\n",
      "epoch 17321 / 20000\n",
      "gradient norm: 0.035800065990770236, minimum ratio: 2.4236842105263157\n",
      "\ttrain loss: 0.00079\n",
      "\tval loss: 0.00079\n",
      "epoch 17322 / 20000\n",
      "gradient norm: 0.01765136292669922, minimum ratio: 2.418421052631579\n",
      "\ttrain loss: 0.00079\n",
      "\tval loss: 0.00079\n",
      "epoch 17323 / 20000\n",
      "gradient norm: 0.018347581702983007, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00079\n",
      "\tval loss: 0.00079\n",
      "epoch 17324 / 20000\n",
      "gradient norm: 0.03092733328230679, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00079\n",
      "\tval loss: 0.00079\n",
      "epoch 17325 / 20000\n",
      "gradient norm: 0.028018902812618762, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00079\n",
      "\tval loss: 0.00078\n",
      "epoch 17326 / 20000\n",
      "gradient norm: 0.020985961018595845, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00079\n",
      "\tval loss: 0.00079\n",
      "epoch 17327 / 20000\n",
      "gradient norm: 0.036689658532850444, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00079\n",
      "\tval loss: 0.00078\n",
      "epoch 17328 / 20000\n",
      "gradient norm: 0.033449870825279504, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00079\n",
      "\tval loss: 0.00078\n",
      "epoch 17329 / 20000\n",
      "gradient norm: 0.03380928409751505, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00079\n",
      "\tval loss: 0.00078\n",
      "epoch 17330 / 20000\n",
      "gradient norm: 0.021579191670753062, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00078\n",
      "\tval loss: 0.00078\n",
      "epoch 17331 / 20000\n",
      "gradient norm: 0.013345875369850546, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00079\n",
      "\tval loss: 0.00078\n",
      "epoch 17332 / 20000\n",
      "gradient norm: 0.034837145882193, minimum ratio: 2.46578947368421\n",
      "\ttrain loss: 0.00078\n",
      "\tval loss: 0.00078\n",
      "epoch 17333 / 20000\n",
      "gradient norm: 0.029005563410464674, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00078\n",
      "\tval loss: 0.00078\n",
      "epoch 17334 / 20000\n",
      "gradient norm: 0.03261380404001102, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00078\n",
      "\tval loss: 0.00078\n",
      "epoch 17335 / 20000\n",
      "gradient norm: 0.01656854889006354, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00078\n",
      "\tval loss: 0.00077\n",
      "epoch 17336 / 20000\n",
      "gradient norm: 0.049562055559363216, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00078\n",
      "\tval loss: 0.00078\n",
      "epoch 17337 / 20000\n",
      "gradient norm: 0.024671450082678348, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00078\n",
      "\tval loss: 0.00077\n",
      "epoch 17338 / 20000\n",
      "gradient norm: 0.03309143673686776, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00078\n",
      "\tval loss: 0.00077\n",
      "epoch 17339 / 20000\n",
      "gradient norm: 0.01767383120022714, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00078\n",
      "\tval loss: 0.00077\n",
      "epoch 17340 / 20000\n",
      "gradient norm: 0.02373689503292553, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00078\n",
      "\tval loss: 0.00077\n",
      "epoch 17341 / 20000\n",
      "gradient norm: 0.019186566583812237, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00078\n",
      "\tval loss: 0.00077\n",
      "epoch 17342 / 20000\n",
      "gradient norm: 0.03412942215800285, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00077\n",
      "\tval loss: 0.00077\n",
      "epoch 17343 / 20000\n",
      "gradient norm: 0.03759611095301807, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00078\n",
      "\tval loss: 0.00077\n",
      "epoch 17344 / 20000\n",
      "gradient norm: 0.04851203435100615, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00077\n",
      "\tval loss: 0.00077\n",
      "epoch 17345 / 20000\n",
      "gradient norm: 0.022709664539434016, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00077\n",
      "\tval loss: 0.00077\n",
      "epoch 17346 / 20000\n",
      "gradient norm: 0.029944782552774996, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00077\n",
      "\tval loss: 0.00077\n",
      "epoch 17347 / 20000\n",
      "gradient norm: 0.04055705096106976, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00077\n",
      "\tval loss: 0.00076\n",
      "epoch 17348 / 20000\n",
      "gradient norm: 0.032328835455700755, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00077\n",
      "\tval loss: 0.00076\n",
      "epoch 17349 / 20000\n",
      "gradient norm: 0.03486482863081619, minimum ratio: 2.4236842105263157\n",
      "\ttrain loss: 0.00077\n",
      "\tval loss: 0.00076\n",
      "epoch 17350 / 20000\n",
      "gradient norm: 0.023303416994167492, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00077\n",
      "\tval loss: 0.00076\n",
      "epoch 17351 / 20000\n",
      "gradient norm: 0.020494778058491647, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00077\n",
      "\tval loss: 0.00076\n",
      "epoch 17352 / 20000\n",
      "gradient norm: 0.01818965029087849, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00077\n",
      "\tval loss: 0.00076\n",
      "epoch 17353 / 20000\n",
      "gradient norm: 0.03201283176895231, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00077\n",
      "\tval loss: 0.00076\n",
      "epoch 17354 / 20000\n",
      "gradient norm: 0.02891371102305129, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00076\n",
      "\tval loss: 0.00076\n",
      "epoch 17355 / 20000\n",
      "gradient norm: 0.022339916322380304, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00076\n",
      "\tval loss: 0.00076\n",
      "epoch 17356 / 20000\n",
      "gradient norm: 0.0376977190899197, minimum ratio: 2.4421052631578943\n",
      "\ttrain loss: 0.00076\n",
      "\tval loss: 0.00076\n",
      "epoch 17357 / 20000\n",
      "gradient norm: 0.030354654067195952, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00076\n",
      "\tval loss: 0.00075\n",
      "epoch 17358 / 20000\n",
      "gradient norm: 0.025233933120034635, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00076\n",
      "\tval loss: 0.00076\n",
      "epoch 17359 / 20000\n",
      "gradient norm: 0.01965756554272957, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00076\n",
      "\tval loss: 0.00075\n",
      "epoch 17360 / 20000\n",
      "gradient norm: 0.04390692582819611, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00076\n",
      "\tval loss: 0.00075\n",
      "epoch 17361 / 20000\n",
      "gradient norm: 0.04174619709374383, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00076\n",
      "\tval loss: 0.00076\n",
      "epoch 17362 / 20000\n",
      "gradient norm: 0.02554725849768147, minimum ratio: 2.4210526315789473\n",
      "\ttrain loss: 0.00076\n",
      "\tval loss: 0.00075\n",
      "epoch 17363 / 20000\n",
      "gradient norm: 0.026758407009765506, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00076\n",
      "\tval loss: 0.00075\n",
      "epoch 17364 / 20000\n",
      "gradient norm: 0.025566240889020264, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00075\n",
      "\tval loss: 0.00075\n",
      "epoch 17365 / 20000\n",
      "gradient norm: 0.024094124921248294, minimum ratio: 2.4289473684210523\n",
      "\ttrain loss: 0.00075\n",
      "\tval loss: 0.00075\n",
      "epoch 17366 / 20000\n",
      "gradient norm: 0.027753569651395082, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00075\n",
      "\tval loss: 0.00075\n",
      "epoch 17367 / 20000\n",
      "gradient norm: 0.03166521468665451, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00075\n",
      "\tval loss: 0.00074\n",
      "epoch 17368 / 20000\n",
      "gradient norm: 0.029316985688637942, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00075\n",
      "\tval loss: 0.00075\n",
      "epoch 17369 / 20000\n",
      "gradient norm: 0.033575982379261404, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00075\n",
      "\tval loss: 0.00075\n",
      "epoch 17370 / 20000\n",
      "gradient norm: 0.030103312426945195, minimum ratio: 2.4447368421052635\n",
      "\ttrain loss: 0.00075\n",
      "\tval loss: 0.00074\n",
      "epoch 17371 / 20000\n",
      "gradient norm: 0.03616507336846553, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00075\n",
      "\tval loss: 0.00075\n",
      "epoch 17372 / 20000\n",
      "gradient norm: 0.02154962212080136, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00075\n",
      "\tval loss: 0.00074\n",
      "epoch 17373 / 20000\n",
      "gradient norm: 0.029844454780686647, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00074\n",
      "\tval loss: 0.00074\n",
      "epoch 17374 / 20000\n",
      "gradient norm: 0.01724785743863322, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00075\n",
      "\tval loss: 0.00074\n",
      "epoch 17375 / 20000\n",
      "gradient norm: 0.029909234144724905, minimum ratio: 2.4210526315789473\n",
      "\ttrain loss: 0.00075\n",
      "\tval loss: 0.00074\n",
      "epoch 17376 / 20000\n",
      "gradient norm: 0.029105345136485994, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00074\n",
      "\tval loss: 0.00074\n",
      "epoch 17377 / 20000\n",
      "gradient norm: 0.020686893025413156, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00074\n",
      "\tval loss: 0.00074\n",
      "epoch 17378 / 20000\n",
      "gradient norm: 0.013011646893573925, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00074\n",
      "\tval loss: 0.00074\n",
      "epoch 17379 / 20000\n",
      "gradient norm: 0.013890123431337997, minimum ratio: 2.4421052631578943\n",
      "\ttrain loss: 0.00074\n",
      "\tval loss: 0.00073\n",
      "epoch 17380 / 20000\n",
      "gradient norm: 0.014636712789069861, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00074\n",
      "\tval loss: 0.00073\n",
      "epoch 17381 / 20000\n",
      "gradient norm: 0.04024659525020979, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00074\n",
      "\tval loss: 0.00073\n",
      "epoch 17382 / 20000\n",
      "gradient norm: 0.027473078458569944, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00074\n",
      "\tval loss: 0.00073\n",
      "epoch 17383 / 20000\n",
      "gradient norm: 0.039447485643904656, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00074\n",
      "\tval loss: 0.00073\n",
      "epoch 17384 / 20000\n",
      "gradient norm: 0.05045186454663053, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00074\n",
      "\tval loss: 0.00073\n",
      "epoch 17385 / 20000\n",
      "gradient norm: 0.03828218922717497, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00073\n",
      "\tval loss: 0.00074\n",
      "epoch 17386 / 20000\n",
      "gradient norm: 0.019857654435327277, minimum ratio: 2.423684210526316\n",
      "\ttrain loss: 0.00073\n",
      "\tval loss: 0.00073\n",
      "epoch 17387 / 20000\n",
      "gradient norm: 0.023530895414296538, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00073\n",
      "\tval loss: 0.00073\n",
      "epoch 17388 / 20000\n",
      "gradient norm: 0.034791411890182644, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00073\n",
      "\tval loss: 0.00073\n",
      "epoch 17389 / 20000\n",
      "gradient norm: 0.02792327932547778, minimum ratio: 2.4263157894736844\n",
      "\ttrain loss: 0.00073\n",
      "\tval loss: 0.00073\n",
      "epoch 17390 / 20000\n",
      "gradient norm: 0.02147217621677555, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00073\n",
      "\tval loss: 0.00073\n",
      "epoch 17391 / 20000\n",
      "gradient norm: 0.020421083958353847, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00073\n",
      "\tval loss: 0.00073\n",
      "epoch 17392 / 20000\n",
      "gradient norm: 0.029964371206006035, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00073\n",
      "\tval loss: 0.00072\n",
      "epoch 17393 / 20000\n",
      "gradient norm: 0.022038923954823986, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00073\n",
      "\tval loss: 0.00072\n",
      "epoch 17394 / 20000\n",
      "gradient norm: 0.024237599835032597, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00073\n",
      "\tval loss: 0.00072\n",
      "epoch 17395 / 20000\n",
      "gradient norm: 0.04704390815459192, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00073\n",
      "\tval loss: 0.00072\n",
      "epoch 17396 / 20000\n",
      "gradient norm: 0.04053633083822206, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00073\n",
      "\tval loss: 0.00072\n",
      "epoch 17397 / 20000\n",
      "gradient norm: 0.01457829907303676, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00072\n",
      "\tval loss: 0.00072\n",
      "epoch 17398 / 20000\n",
      "gradient norm: 0.03390283085172996, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00072\n",
      "\tval loss: 0.00072\n",
      "epoch 17399 / 20000\n",
      "gradient norm: 0.026668287231586874, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00072\n",
      "\tval loss: 0.00072\n",
      "epoch 17400 / 20000\n",
      "gradient norm: 0.017019715131027624, minimum ratio: 2.4236842105263157\n",
      "\ttrain loss: 0.00072\n",
      "\tval loss: 0.00071\n",
      "epoch 17401 / 20000\n",
      "gradient norm: 0.03021837427513674, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00072\n",
      "\tval loss: 0.00072\n",
      "epoch 17402 / 20000\n",
      "gradient norm: 0.038695763621944934, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00072\n",
      "\tval loss: 0.00071\n",
      "epoch 17403 / 20000\n",
      "gradient norm: 0.029913082980783656, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00072\n",
      "\tval loss: 0.00072\n",
      "epoch 17404 / 20000\n",
      "gradient norm: 0.035384934511967, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00072\n",
      "\tval loss: 0.00071\n",
      "epoch 17405 / 20000\n",
      "gradient norm: 0.028657916467636824, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00072\n",
      "\tval loss: 0.00071\n",
      "epoch 17406 / 20000\n",
      "gradient norm: 0.01707513994188048, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00071\n",
      "\tval loss: 0.00071\n",
      "epoch 17407 / 20000\n",
      "gradient norm: 0.028848324320279062, minimum ratio: 2.4289473684210523\n",
      "\ttrain loss: 0.00071\n",
      "\tval loss: 0.00071\n",
      "epoch 17408 / 20000\n",
      "gradient norm: 0.026351650536525995, minimum ratio: 2.4447368421052627\n",
      "\ttrain loss: 0.00071\n",
      "\tval loss: 0.00071\n",
      "epoch 17409 / 20000\n",
      "gradient norm: 0.04297116887755692, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00071\n",
      "\tval loss: 0.00071\n",
      "epoch 17410 / 20000\n",
      "gradient norm: 0.04772102186689153, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00071\n",
      "\tval loss: 0.00071\n",
      "epoch 17411 / 20000\n",
      "gradient norm: 0.035594611952546984, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00071\n",
      "\tval loss: 0.00071\n",
      "epoch 17412 / 20000\n",
      "gradient norm: 0.029658839048352093, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00071\n",
      "\tval loss: 0.00071\n",
      "epoch 17413 / 20000\n",
      "gradient norm: 0.02724791833315976, minimum ratio: 2.4421052631578943\n",
      "\ttrain loss: 0.00071\n",
      "\tval loss: 0.00070\n",
      "epoch 17414 / 20000\n",
      "gradient norm: 0.01693407242419198, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00071\n",
      "\tval loss: 0.00070\n",
      "epoch 17415 / 20000\n",
      "gradient norm: 0.014833974477369338, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00071\n",
      "\tval loss: 0.00070\n",
      "epoch 17416 / 20000\n",
      "gradient norm: 0.023453283676644787, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00071\n",
      "\tval loss: 0.00070\n",
      "epoch 17417 / 20000\n",
      "gradient norm: 0.01651121536269784, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00070\n",
      "\tval loss: 0.00070\n",
      "epoch 17418 / 20000\n",
      "gradient norm: 0.027690283488482237, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00070\n",
      "\tval loss: 0.00070\n",
      "epoch 17419 / 20000\n",
      "gradient norm: 0.028148789191618562, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00070\n",
      "\tval loss: 0.00070\n",
      "epoch 17420 / 20000\n",
      "gradient norm: 0.04142972099361941, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00071\n",
      "\tval loss: 0.00070\n",
      "epoch 17421 / 20000\n",
      "gradient norm: 0.03447052286355756, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00070\n",
      "\tval loss: 0.00070\n",
      "epoch 17422 / 20000\n",
      "gradient norm: 0.043144180555827916, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00070\n",
      "\tval loss: 0.00070\n",
      "epoch 17423 / 20000\n",
      "gradient norm: 0.03483608382521197, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00070\n",
      "\tval loss: 0.00070\n",
      "epoch 17424 / 20000\n",
      "gradient norm: 0.01582618974498473, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00070\n",
      "\tval loss: 0.00069\n",
      "epoch 17425 / 20000\n",
      "gradient norm: 0.01621880910533946, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00070\n",
      "\tval loss: 0.00069\n",
      "epoch 17426 / 20000\n",
      "gradient norm: 0.023365800792817026, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00070\n",
      "\tval loss: 0.00069\n",
      "epoch 17427 / 20000\n",
      "gradient norm: 0.019793204322922975, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00070\n",
      "\tval loss: 0.00069\n",
      "epoch 17428 / 20000\n",
      "gradient norm: 0.03532906511100009, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00069\n",
      "\tval loss: 0.00069\n",
      "epoch 17429 / 20000\n",
      "gradient norm: 0.02024680096656084, minimum ratio: 2.452631578947368\n",
      "\ttrain loss: 0.00069\n",
      "\tval loss: 0.00069\n",
      "epoch 17430 / 20000\n",
      "gradient norm: 0.011921896395506337, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00069\n",
      "\tval loss: 0.00069\n",
      "epoch 17431 / 20000\n",
      "gradient norm: 0.012744081555865705, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00069\n",
      "\tval loss: 0.00069\n",
      "epoch 17432 / 20000\n",
      "gradient norm: 0.023770982690621167, minimum ratio: 2.46578947368421\n",
      "\ttrain loss: 0.00069\n",
      "\tval loss: 0.00069\n",
      "epoch 17433 / 20000\n",
      "gradient norm: 0.018311494612134993, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00069\n",
      "\tval loss: 0.00069\n",
      "epoch 17434 / 20000\n",
      "gradient norm: 0.01944578487018589, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00069\n",
      "\tval loss: 0.00069\n",
      "epoch 17435 / 20000\n",
      "gradient norm: 0.023170742788352072, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00069\n",
      "\tval loss: 0.00069\n",
      "epoch 17436 / 20000\n",
      "gradient norm: 0.02870464662555605, minimum ratio: 2.4499999999999997\n",
      "\ttrain loss: 0.00069\n",
      "\tval loss: 0.00068\n",
      "epoch 17437 / 20000\n",
      "gradient norm: 0.027110623486805707, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00069\n",
      "\tval loss: 0.00068\n",
      "epoch 17438 / 20000\n",
      "gradient norm: 0.04680462524993345, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00069\n",
      "\tval loss: 0.00068\n",
      "epoch 17439 / 20000\n",
      "gradient norm: 0.03779795247828588, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00068\n",
      "\tval loss: 0.00068\n",
      "epoch 17440 / 20000\n",
      "gradient norm: 0.014997948543168604, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00068\n",
      "\tval loss: 0.00069\n",
      "epoch 17441 / 20000\n",
      "gradient norm: 0.01981642874306999, minimum ratio: 2.421052631578948\n",
      "\ttrain loss: 0.00068\n",
      "\tval loss: 0.00068\n",
      "epoch 17442 / 20000\n",
      "gradient norm: 0.033182752144057304, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00068\n",
      "\tval loss: 0.00068\n",
      "epoch 17443 / 20000\n",
      "gradient norm: 0.03612404566956684, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00069\n",
      "\tval loss: 0.00068\n",
      "epoch 17444 / 20000\n",
      "gradient norm: 0.033031109313014895, minimum ratio: 2.4421052631578943\n",
      "\ttrain loss: 0.00068\n",
      "\tval loss: 0.00068\n",
      "epoch 17445 / 20000\n",
      "gradient norm: 0.017928968998603523, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00068\n",
      "\tval loss: 0.00068\n",
      "epoch 17446 / 20000\n",
      "gradient norm: 0.02805471362080425, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00068\n",
      "\tval loss: 0.00067\n",
      "epoch 17447 / 20000\n",
      "gradient norm: 0.042758555558975786, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00068\n",
      "\tval loss: 0.00067\n",
      "epoch 17448 / 20000\n",
      "gradient norm: 0.019293351244414225, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00068\n",
      "\tval loss: 0.00067\n",
      "epoch 17449 / 20000\n",
      "gradient norm: 0.02163634728640318, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00068\n",
      "\tval loss: 0.00067\n",
      "epoch 17450 / 20000\n",
      "gradient norm: 0.01941055155475624, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00068\n",
      "\tval loss: 0.00067\n",
      "epoch 17451 / 20000\n",
      "gradient norm: 0.02655657529248856, minimum ratio: 2.4263157894736844\n",
      "\ttrain loss: 0.00068\n",
      "\tval loss: 0.00067\n",
      "epoch 17452 / 20000\n",
      "gradient norm: 0.014162870371364988, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00067\n",
      "\tval loss: 0.00067\n",
      "epoch 17453 / 20000\n",
      "gradient norm: 0.017303152359090745, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00067\n",
      "\tval loss: 0.00067\n",
      "epoch 17454 / 20000\n",
      "gradient norm: 0.02599879735498689, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00067\n",
      "\tval loss: 0.00067\n",
      "epoch 17455 / 20000\n",
      "gradient norm: 0.040244238974992186, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00067\n",
      "\tval loss: 0.00067\n",
      "epoch 17456 / 20000\n",
      "gradient norm: 0.026901854464085773, minimum ratio: 2.4499999999999997\n",
      "\ttrain loss: 0.00067\n",
      "\tval loss: 0.00067\n",
      "epoch 17457 / 20000\n",
      "gradient norm: 0.033636567153735086, minimum ratio: 2.4421052631578943\n",
      "\ttrain loss: 0.00067\n",
      "\tval loss: 0.00066\n",
      "epoch 17458 / 20000\n",
      "gradient norm: 0.020623720425646752, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00067\n",
      "\tval loss: 0.00067\n",
      "epoch 17459 / 20000\n",
      "gradient norm: 0.032056584721431136, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00067\n",
      "\tval loss: 0.00066\n",
      "epoch 17460 / 20000\n",
      "gradient norm: 0.02057520765811205, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00067\n",
      "\tval loss: 0.00066\n",
      "epoch 17461 / 20000\n",
      "gradient norm: 0.03165744183934294, minimum ratio: 2.4263157894736844\n",
      "\ttrain loss: 0.00066\n",
      "\tval loss: 0.00066\n",
      "epoch 17462 / 20000\n",
      "gradient norm: 0.015079154632985592, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00066\n",
      "\tval loss: 0.00066\n",
      "epoch 17463 / 20000\n",
      "gradient norm: 0.015786551346536726, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00067\n",
      "\tval loss: 0.00066\n",
      "epoch 17464 / 20000\n",
      "gradient norm: 0.02668669749982655, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00066\n",
      "\tval loss: 0.00066\n",
      "epoch 17465 / 20000\n",
      "gradient norm: 0.03927036852110177, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00066\n",
      "\tval loss: 0.00066\n",
      "epoch 17466 / 20000\n",
      "gradient norm: 0.024604149512015283, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00066\n",
      "\tval loss: 0.00066\n",
      "epoch 17467 / 20000\n",
      "gradient norm: 0.03264920352376066, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00066\n",
      "\tval loss: 0.00066\n",
      "epoch 17468 / 20000\n",
      "gradient norm: 0.018960487926960923, minimum ratio: 2.4157894736842107\n",
      "\ttrain loss: 0.00066\n",
      "\tval loss: 0.00066\n",
      "epoch 17469 / 20000\n",
      "gradient norm: 0.01938610697106924, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00066\n",
      "\tval loss: 0.00066\n",
      "epoch 17470 / 20000\n",
      "gradient norm: 0.02287076215725392, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00066\n",
      "\tval loss: 0.00066\n",
      "epoch 17471 / 20000\n",
      "gradient norm: 0.035407343704719096, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00066\n",
      "\tval loss: 0.00065\n",
      "epoch 17472 / 20000\n",
      "gradient norm: 0.03218655049568042, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00066\n",
      "\tval loss: 0.00066\n",
      "epoch 17473 / 20000\n",
      "gradient norm: 0.026413784187752753, minimum ratio: 2.4263157894736844\n",
      "\ttrain loss: 0.00066\n",
      "\tval loss: 0.00065\n",
      "epoch 17474 / 20000\n",
      "gradient norm: 0.029910029319580644, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00065\n",
      "\tval loss: 0.00065\n",
      "epoch 17475 / 20000\n",
      "gradient norm: 0.033306327648460865, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00066\n",
      "\tval loss: 0.00065\n",
      "epoch 17476 / 20000\n",
      "gradient norm: 0.0243068840354681, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00065\n",
      "\tval loss: 0.00065\n",
      "epoch 17477 / 20000\n",
      "gradient norm: 0.02482289823819883, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00065\n",
      "\tval loss: 0.00065\n",
      "epoch 17478 / 20000\n",
      "gradient norm: 0.011993847583653405, minimum ratio: 2.4263157894736844\n",
      "\ttrain loss: 0.00065\n",
      "\tval loss: 0.00065\n",
      "epoch 17479 / 20000\n",
      "gradient norm: 0.023267467870027758, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00065\n",
      "\tval loss: 0.00065\n",
      "epoch 17480 / 20000\n",
      "gradient norm: 0.030111033644061536, minimum ratio: 2.4394736842105265\n",
      "\ttrain loss: 0.00065\n",
      "\tval loss: 0.00065\n",
      "epoch 17481 / 20000\n",
      "gradient norm: 0.04598693212028593, minimum ratio: 2.4421052631578943\n",
      "\ttrain loss: 0.00065\n",
      "\tval loss: 0.00065\n",
      "epoch 17482 / 20000\n",
      "gradient norm: 0.010543378361035138, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00065\n",
      "\tval loss: 0.00065\n",
      "epoch 17483 / 20000\n",
      "gradient norm: 0.02085480763344094, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00065\n",
      "\tval loss: 0.00065\n",
      "epoch 17484 / 20000\n",
      "gradient norm: 0.024740812223171815, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00064\n",
      "\tval loss: 0.00064\n",
      "epoch 17485 / 20000\n",
      "gradient norm: 0.02126219414640218, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00065\n",
      "\tval loss: 0.00064\n",
      "epoch 17486 / 20000\n",
      "gradient norm: 0.02232389390701428, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00064\n",
      "\tval loss: 0.00064\n",
      "epoch 17487 / 20000\n",
      "gradient norm: 0.01387887613964267, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00064\n",
      "\tval loss: 0.00064\n",
      "epoch 17488 / 20000\n",
      "gradient norm: 0.017833127712947316, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00064\n",
      "\tval loss: 0.00064\n",
      "epoch 17489 / 20000\n",
      "gradient norm: 0.0204763570218347, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00064\n",
      "\tval loss: 0.00064\n",
      "epoch 17490 / 20000\n",
      "gradient norm: 0.02703202297561802, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00064\n",
      "\tval loss: 0.00064\n",
      "epoch 17491 / 20000\n",
      "gradient norm: 0.02987455765833147, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00064\n",
      "\tval loss: 0.00064\n",
      "epoch 17492 / 20000\n",
      "gradient norm: 0.020326837082393467, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00064\n",
      "\tval loss: 0.00064\n",
      "epoch 17493 / 20000\n",
      "gradient norm: 0.018775208794977516, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00064\n",
      "\tval loss: 0.00063\n",
      "epoch 17494 / 20000\n",
      "gradient norm: 0.04399259388446808, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00064\n",
      "\tval loss: 0.00064\n",
      "epoch 17495 / 20000\n",
      "gradient norm: 0.013355265517020598, minimum ratio: 2.460526315789474\n",
      "\ttrain loss: 0.00063\n",
      "\tval loss: 0.00063\n",
      "epoch 17496 / 20000\n",
      "gradient norm: 0.021321523177903146, minimum ratio: 2.460526315789474\n",
      "\ttrain loss: 0.00063\n",
      "\tval loss: 0.00063\n",
      "epoch 17497 / 20000\n",
      "gradient norm: 0.018366029747994617, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00063\n",
      "\tval loss: 0.00063\n",
      "epoch 17498 / 20000\n",
      "gradient norm: 0.021634707285556942, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00063\n",
      "\tval loss: 0.00063\n",
      "epoch 17499 / 20000\n",
      "gradient norm: 0.02471282308397349, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00063\n",
      "\tval loss: 0.00063\n",
      "epoch 17500 / 20000\n",
      "gradient norm: 0.033133729244582355, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00063\n",
      "\tval loss: 0.00063\n",
      "epoch 17501 / 20000\n",
      "gradient norm: 0.0240280659054406, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00063\n",
      "\tval loss: 0.00063\n",
      "epoch 17502 / 20000\n",
      "gradient norm: 0.014338484354084358, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00063\n",
      "\tval loss: 0.00063\n",
      "epoch 17503 / 20000\n",
      "gradient norm: 0.014249021944124252, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00063\n",
      "\tval loss: 0.00063\n",
      "epoch 17504 / 20000\n",
      "gradient norm: 0.030181413399986923, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00063\n",
      "\tval loss: 0.00063\n",
      "epoch 17505 / 20000\n",
      "gradient norm: 0.029873932246118784, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00063\n",
      "\tval loss: 0.00063\n",
      "epoch 17506 / 20000\n",
      "gradient norm: 0.02072972507448867, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00063\n",
      "\tval loss: 0.00063\n",
      "epoch 17507 / 20000\n",
      "gradient norm: 0.02444667788222432, minimum ratio: 2.426315789473684\n",
      "\ttrain loss: 0.00063\n",
      "\tval loss: 0.00062\n",
      "epoch 17508 / 20000\n",
      "gradient norm: 0.015015140801551752, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00063\n",
      "\tval loss: 0.00063\n",
      "epoch 17509 / 20000\n",
      "gradient norm: 0.017800740897655487, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00062\n",
      "\tval loss: 0.00062\n",
      "epoch 17510 / 20000\n",
      "gradient norm: 0.034207989810965955, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00062\n",
      "\tval loss: 0.00062\n",
      "epoch 17511 / 20000\n",
      "gradient norm: 0.015730921470094472, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00062\n",
      "\tval loss: 0.00062\n",
      "epoch 17512 / 20000\n",
      "gradient norm: 0.017038938793120906, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00062\n",
      "\tval loss: 0.00062\n",
      "epoch 17513 / 20000\n",
      "gradient norm: 0.02933000202756375, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00062\n",
      "\tval loss: 0.00062\n",
      "epoch 17514 / 20000\n",
      "gradient norm: 0.017283901557675563, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00062\n",
      "\tval loss: 0.00062\n",
      "epoch 17515 / 20000\n",
      "gradient norm: 0.022211068077012897, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00062\n",
      "\tval loss: 0.00062\n",
      "epoch 17516 / 20000\n",
      "gradient norm: 0.024777523474767804, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00062\n",
      "\tval loss: 0.00062\n",
      "epoch 17517 / 20000\n",
      "gradient norm: 0.016753551026340574, minimum ratio: 2.4499999999999997\n",
      "\ttrain loss: 0.00062\n",
      "\tval loss: 0.00062\n",
      "epoch 17518 / 20000\n",
      "gradient norm: 0.028474318329244852, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00062\n",
      "\tval loss: 0.00061\n",
      "epoch 17519 / 20000\n",
      "gradient norm: 0.012752327515045181, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00062\n",
      "\tval loss: 0.00061\n",
      "epoch 17520 / 20000\n",
      "gradient norm: 0.021119425509823486, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00062\n",
      "\tval loss: 0.00062\n",
      "epoch 17521 / 20000\n",
      "gradient norm: 0.015758530469611287, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00061\n",
      "\tval loss: 0.00061\n",
      "epoch 17522 / 20000\n",
      "gradient norm: 0.01454202069726307, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00061\n",
      "\tval loss: 0.00061\n",
      "epoch 17523 / 20000\n",
      "gradient norm: 0.01655305027088616, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00061\n",
      "\tval loss: 0.00061\n",
      "epoch 17524 / 20000\n",
      "gradient norm: 0.022941202216316015, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00061\n",
      "\tval loss: 0.00061\n",
      "epoch 17525 / 20000\n",
      "gradient norm: 0.01396267008385621, minimum ratio: 2.4394736842105265\n",
      "\ttrain loss: 0.00061\n",
      "\tval loss: 0.00061\n",
      "epoch 17526 / 20000\n",
      "gradient norm: 0.021971230700728483, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00061\n",
      "\tval loss: 0.00061\n",
      "epoch 17527 / 20000\n",
      "gradient norm: 0.021857201645616442, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00061\n",
      "\tval loss: 0.00061\n",
      "epoch 17528 / 20000\n",
      "gradient norm: 0.007772127020871267, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00061\n",
      "\tval loss: 0.00061\n",
      "epoch 17529 / 20000\n",
      "gradient norm: 0.025553042476531118, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00061\n",
      "\tval loss: 0.00061\n",
      "epoch 17530 / 20000\n",
      "gradient norm: 0.026399127760669217, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00061\n",
      "\tval loss: 0.00061\n",
      "epoch 17531 / 20000\n",
      "gradient norm: 0.039152143290266395, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00061\n",
      "\tval loss: 0.00060\n",
      "epoch 17532 / 20000\n",
      "gradient norm: 0.03128140935586998, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00061\n",
      "\tval loss: 0.00061\n",
      "epoch 17533 / 20000\n",
      "gradient norm: 0.04427586239762604, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00061\n",
      "\tval loss: 0.00060\n",
      "epoch 17534 / 20000\n",
      "gradient norm: 0.035874897192115895, minimum ratio: 2.413157894736842\n",
      "\ttrain loss: 0.00060\n",
      "\tval loss: 0.00061\n",
      "epoch 17535 / 20000\n",
      "gradient norm: 0.028706963057629764, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00060\n",
      "\tval loss: 0.00060\n",
      "epoch 17536 / 20000\n",
      "gradient norm: 0.023662127583520487, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00060\n",
      "\tval loss: 0.00060\n",
      "epoch 17537 / 20000\n",
      "gradient norm: 0.021688699664082378, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00060\n",
      "\tval loss: 0.00060\n",
      "epoch 17538 / 20000\n",
      "gradient norm: 0.01746607554377988, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00060\n",
      "\tval loss: 0.00060\n",
      "epoch 17539 / 20000\n",
      "gradient norm: 0.02415477839531377, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00060\n",
      "\tval loss: 0.00060\n",
      "epoch 17540 / 20000\n",
      "gradient norm: 0.03121032298076898, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00060\n",
      "\tval loss: 0.00060\n",
      "epoch 17541 / 20000\n",
      "gradient norm: 0.01744239282561466, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00060\n",
      "\tval loss: 0.00060\n",
      "epoch 17542 / 20000\n",
      "gradient norm: 0.02593694644747302, minimum ratio: 2.4499999999999997\n",
      "\ttrain loss: 0.00060\n",
      "\tval loss: 0.00060\n",
      "epoch 17543 / 20000\n",
      "gradient norm: 0.026360816380474716, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00060\n",
      "\tval loss: 0.00060\n",
      "epoch 17544 / 20000\n",
      "gradient norm: 0.028891543770441785, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00060\n",
      "\tval loss: 0.00059\n",
      "epoch 17545 / 20000\n",
      "gradient norm: 0.019584564201068133, minimum ratio: 2.4394736842105265\n",
      "\ttrain loss: 0.00059\n",
      "\tval loss: 0.00059\n",
      "epoch 17546 / 20000\n",
      "gradient norm: 0.021848275151569396, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00059\n",
      "\tval loss: 0.00059\n",
      "epoch 17547 / 20000\n",
      "gradient norm: 0.014050360332475975, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00059\n",
      "\tval loss: 0.00059\n",
      "epoch 17548 / 20000\n",
      "gradient norm: 0.022761366795748472, minimum ratio: 2.4394736842105265\n",
      "\ttrain loss: 0.00059\n",
      "\tval loss: 0.00059\n",
      "epoch 17549 / 20000\n",
      "gradient norm: 0.023816557542886585, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00059\n",
      "\tval loss: 0.00059\n",
      "epoch 17550 / 20000\n",
      "gradient norm: 0.03042808035388589, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00059\n",
      "\tval loss: 0.00059\n",
      "epoch 17551 / 20000\n",
      "gradient norm: 0.018779818521579728, minimum ratio: 2.465789473684211\n",
      "\ttrain loss: 0.00059\n",
      "\tval loss: 0.00059\n",
      "epoch 17552 / 20000\n",
      "gradient norm: 0.012744321778882295, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00059\n",
      "\tval loss: 0.00059\n",
      "epoch 17553 / 20000\n",
      "gradient norm: 0.012879356509074569, minimum ratio: 2.46578947368421\n",
      "\ttrain loss: 0.00059\n",
      "\tval loss: 0.00059\n",
      "epoch 17554 / 20000\n",
      "gradient norm: 0.02595174836460501, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00059\n",
      "\tval loss: 0.00059\n",
      "epoch 17555 / 20000\n",
      "gradient norm: 0.016361404850613326, minimum ratio: 2.4263157894736844\n",
      "\ttrain loss: 0.00059\n",
      "\tval loss: 0.00059\n",
      "epoch 17556 / 20000\n",
      "gradient norm: 0.017830789438448846, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00058\n",
      "\tval loss: 0.00059\n",
      "epoch 17557 / 20000\n",
      "gradient norm: 0.013003196974750608, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00059\n",
      "\tval loss: 0.00058\n",
      "epoch 17558 / 20000\n",
      "gradient norm: 0.025777411181479692, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00058\n",
      "\tval loss: 0.00058\n",
      "epoch 17559 / 20000\n",
      "gradient norm: 0.02149466541595757, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00058\n",
      "\tval loss: 0.00058\n",
      "epoch 17560 / 20000\n",
      "gradient norm: 0.029444772022543475, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00058\n",
      "\tval loss: 0.00058\n",
      "epoch 17561 / 20000\n",
      "gradient norm: 0.041017651034053415, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00058\n",
      "\tval loss: 0.00058\n",
      "epoch 17562 / 20000\n",
      "gradient norm: 0.017979269905481488, minimum ratio: 2.4394736842105265\n",
      "\ttrain loss: 0.00058\n",
      "\tval loss: 0.00058\n",
      "epoch 17563 / 20000\n",
      "gradient norm: 0.032272848882712424, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00058\n",
      "\tval loss: 0.00058\n",
      "epoch 17564 / 20000\n",
      "gradient norm: 0.0312706386030186, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00058\n",
      "\tval loss: 0.00058\n",
      "epoch 17565 / 20000\n",
      "gradient norm: 0.02082178561249748, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00058\n",
      "\tval loss: 0.00058\n",
      "epoch 17566 / 20000\n",
      "gradient norm: 0.022930903403903358, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00058\n",
      "\tval loss: 0.00058\n",
      "epoch 17567 / 20000\n",
      "gradient norm: 0.031682534026913345, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00058\n",
      "\tval loss: 0.00058\n",
      "epoch 17568 / 20000\n",
      "gradient norm: 0.028187390067614615, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00058\n",
      "\tval loss: 0.00057\n",
      "epoch 17569 / 20000\n",
      "gradient norm: 0.017567636532476172, minimum ratio: 2.460526315789474\n",
      "\ttrain loss: 0.00058\n",
      "\tval loss: 0.00058\n",
      "epoch 17570 / 20000\n",
      "gradient norm: 0.025333166457130574, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00057\n",
      "\tval loss: 0.00057\n",
      "epoch 17571 / 20000\n",
      "gradient norm: 0.015407626051455736, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00057\n",
      "\tval loss: 0.00057\n",
      "epoch 17572 / 20000\n",
      "gradient norm: 0.01593268057331443, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00057\n",
      "\tval loss: 0.00057\n",
      "epoch 17573 / 20000\n",
      "gradient norm: 0.022757975064450875, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00057\n",
      "\tval loss: 0.00057\n",
      "epoch 17574 / 20000\n",
      "gradient norm: 0.029420676597510464, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00057\n",
      "\tval loss: 0.00057\n",
      "epoch 17575 / 20000\n",
      "gradient norm: 0.021464456105604768, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00057\n",
      "\tval loss: 0.00057\n",
      "epoch 17576 / 20000\n",
      "gradient norm: 0.0209353951504454, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00057\n",
      "\tval loss: 0.00057\n",
      "epoch 17577 / 20000\n",
      "gradient norm: 0.030050045053940266, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00057\n",
      "\tval loss: 0.00057\n",
      "epoch 17578 / 20000\n",
      "gradient norm: 0.034057540411595255, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00057\n",
      "\tval loss: 0.00057\n",
      "epoch 17579 / 20000\n",
      "gradient norm: 0.042696086049545556, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00057\n",
      "\tval loss: 0.00057\n",
      "epoch 17580 / 20000\n",
      "gradient norm: 0.03965904560755007, minimum ratio: 2.460526315789474\n",
      "\ttrain loss: 0.00057\n",
      "\tval loss: 0.00056\n",
      "epoch 17581 / 20000\n",
      "gradient norm: 0.025658353930339217, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00057\n",
      "\tval loss: 0.00057\n",
      "epoch 17582 / 20000\n",
      "gradient norm: 0.037111632351297885, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00057\n",
      "\tval loss: 0.00056\n",
      "epoch 17583 / 20000\n",
      "gradient norm: 0.038094064220786095, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00057\n",
      "\tval loss: 0.00057\n",
      "epoch 17584 / 20000\n",
      "gradient norm: 0.03030356828821823, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00056\n",
      "\tval loss: 0.00056\n",
      "epoch 17585 / 20000\n",
      "gradient norm: 0.035541520395781845, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00056\n",
      "\tval loss: 0.00056\n",
      "epoch 17586 / 20000\n",
      "gradient norm: 0.031632035272195935, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00056\n",
      "\tval loss: 0.00056\n",
      "epoch 17587 / 20000\n",
      "gradient norm: 0.0374644914700184, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00056\n",
      "\tval loss: 0.00056\n",
      "epoch 17588 / 20000\n",
      "gradient norm: 0.04158189822919667, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00056\n",
      "\tval loss: 0.00057\n",
      "epoch 17589 / 20000\n",
      "gradient norm: 0.02944944877526723, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00056\n",
      "\tval loss: 0.00056\n",
      "epoch 17590 / 20000\n",
      "gradient norm: 0.05112532706698403, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00056\n",
      "\tval loss: 0.00056\n",
      "epoch 17591 / 20000\n",
      "gradient norm: 0.02675308653851971, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00056\n",
      "\tval loss: 0.00056\n",
      "epoch 17592 / 20000\n",
      "gradient norm: 0.02792119127116166, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00056\n",
      "\tval loss: 0.00056\n",
      "epoch 17593 / 20000\n",
      "gradient norm: 0.021022571221692488, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00056\n",
      "\tval loss: 0.00056\n",
      "epoch 17594 / 20000\n",
      "gradient norm: 0.016654768522130325, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00056\n",
      "\tval loss: 0.00056\n",
      "epoch 17595 / 20000\n",
      "gradient norm: 0.016633858205750585, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00055\n",
      "\tval loss: 0.00056\n",
      "epoch 17596 / 20000\n",
      "gradient norm: 0.02682312609977089, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00055\n",
      "\tval loss: 0.00055\n",
      "epoch 17597 / 20000\n",
      "gradient norm: 0.024321170116309077, minimum ratio: 2.436842105263158\n",
      "\ttrain loss: 0.00055\n",
      "\tval loss: 0.00055\n",
      "epoch 17598 / 20000\n",
      "gradient norm: 0.017307795817032456, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00055\n",
      "\tval loss: 0.00055\n",
      "epoch 17599 / 20000\n",
      "gradient norm: 0.028664343582931906, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00055\n",
      "\tval loss: 0.00055\n",
      "epoch 17600 / 20000\n",
      "gradient norm: 0.015035767952213064, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00055\n",
      "\tval loss: 0.00055\n",
      "epoch 17601 / 20000\n",
      "gradient norm: 0.02994361170567572, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00055\n",
      "\tval loss: 0.00055\n",
      "epoch 17602 / 20000\n",
      "gradient norm: 0.02472714043688029, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00055\n",
      "\tval loss: 0.00055\n",
      "epoch 17603 / 20000\n",
      "gradient norm: 0.01742953000939451, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00055\n",
      "\tval loss: 0.00055\n",
      "epoch 17604 / 20000\n",
      "gradient norm: 0.022740187821909785, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00055\n",
      "\tval loss: 0.00055\n",
      "epoch 17605 / 20000\n",
      "gradient norm: 0.015947631502058357, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00055\n",
      "\tval loss: 0.00055\n",
      "epoch 17606 / 20000\n",
      "gradient norm: 0.025747771316673607, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00055\n",
      "\tval loss: 0.00055\n",
      "epoch 17607 / 20000\n",
      "gradient norm: 0.03687035193433985, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00055\n",
      "\tval loss: 0.00055\n",
      "epoch 17608 / 20000\n",
      "gradient norm: 0.028267276764381677, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00055\n",
      "\tval loss: 0.00055\n",
      "epoch 17609 / 20000\n",
      "gradient norm: 0.041602983517805114, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00055\n",
      "\tval loss: 0.00054\n",
      "epoch 17610 / 20000\n",
      "gradient norm: 0.04055932495975867, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00055\n",
      "\tval loss: 0.00055\n",
      "epoch 17611 / 20000\n",
      "gradient norm: 0.0504933595075272, minimum ratio: 2.4499999999999997\n",
      "\ttrain loss: 0.00055\n",
      "\tval loss: 0.00054\n",
      "epoch 17612 / 20000\n",
      "gradient norm: 0.030195258412277326, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00054\n",
      "\tval loss: 0.00055\n",
      "epoch 17613 / 20000\n",
      "gradient norm: 0.03879779326962307, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00054\n",
      "\tval loss: 0.00054\n",
      "epoch 17614 / 20000\n",
      "gradient norm: 0.027212370419874787, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00054\n",
      "\tval loss: 0.00054\n",
      "epoch 17615 / 20000\n",
      "gradient norm: 0.027931279022595845, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00054\n",
      "\tval loss: 0.00054\n",
      "epoch 17616 / 20000\n",
      "gradient norm: 0.0181484428467229, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00054\n",
      "\tval loss: 0.00054\n",
      "epoch 17617 / 20000\n",
      "gradient norm: 0.027574524632655084, minimum ratio: 2.4394736842105265\n",
      "\ttrain loss: 0.00054\n",
      "\tval loss: 0.00054\n",
      "epoch 17618 / 20000\n",
      "gradient norm: 0.014110162417637184, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00054\n",
      "\tval loss: 0.00054\n",
      "epoch 17619 / 20000\n",
      "gradient norm: 0.01972458339878358, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00054\n",
      "\tval loss: 0.00054\n",
      "epoch 17620 / 20000\n",
      "gradient norm: 0.013609959598397836, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00054\n",
      "\tval loss: 0.00054\n",
      "epoch 17621 / 20000\n",
      "gradient norm: 0.02659372560447082, minimum ratio: 2.4499999999999997\n",
      "\ttrain loss: 0.00054\n",
      "\tval loss: 0.00054\n",
      "epoch 17622 / 20000\n",
      "gradient norm: 0.018522919504903257, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00053\n",
      "\tval loss: 0.00053\n",
      "epoch 17623 / 20000\n",
      "gradient norm: 0.020657583023421466, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00053\n",
      "\tval loss: 0.00054\n",
      "epoch 17624 / 20000\n",
      "gradient norm: 0.029252391774207354, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00053\n",
      "\tval loss: 0.00053\n",
      "epoch 17625 / 20000\n",
      "gradient norm: 0.03728865855373442, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00053\n",
      "\tval loss: 0.00053\n",
      "epoch 17626 / 20000\n",
      "gradient norm: 0.04122285210178234, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00053\n",
      "\tval loss: 0.00053\n",
      "epoch 17627 / 20000\n",
      "gradient norm: 0.02451087610097602, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00053\n",
      "\tval loss: 0.00054\n",
      "epoch 17628 / 20000\n",
      "gradient norm: 0.03733047976857051, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00053\n",
      "\tval loss: 0.00053\n",
      "epoch 17629 / 20000\n",
      "gradient norm: 0.02652849181322381, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00053\n",
      "\tval loss: 0.00053\n",
      "epoch 17630 / 20000\n",
      "gradient norm: 0.01861642688163556, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00053\n",
      "\tval loss: 0.00053\n",
      "epoch 17631 / 20000\n",
      "gradient norm: 0.012728592002531514, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00053\n",
      "\tval loss: 0.00053\n",
      "epoch 17632 / 20000\n",
      "gradient norm: 0.022179104998940602, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00053\n",
      "\tval loss: 0.00053\n",
      "epoch 17633 / 20000\n",
      "gradient norm: 0.013969642022857442, minimum ratio: 2.4499999999999997\n",
      "\ttrain loss: 0.00053\n",
      "\tval loss: 0.00053\n",
      "epoch 17634 / 20000\n",
      "gradient norm: 0.02019856071274262, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00053\n",
      "\tval loss: 0.00053\n",
      "epoch 17635 / 20000\n",
      "gradient norm: 0.022910096013220027, minimum ratio: 2.460526315789474\n",
      "\ttrain loss: 0.00052\n",
      "\tval loss: 0.00053\n",
      "epoch 17636 / 20000\n",
      "gradient norm: 0.01749672755249776, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00052\n",
      "\tval loss: 0.00052\n",
      "epoch 17637 / 20000\n",
      "gradient norm: 0.03463290227227844, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00052\n",
      "\tval loss: 0.00052\n",
      "epoch 17638 / 20000\n",
      "gradient norm: 0.04563944292021915, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00053\n",
      "\tval loss: 0.00052\n",
      "epoch 17639 / 20000\n",
      "gradient norm: 0.04021887050475925, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00052\n",
      "\tval loss: 0.00052\n",
      "epoch 17640 / 20000\n",
      "gradient norm: 0.03296718536876142, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00052\n",
      "\tval loss: 0.00052\n",
      "epoch 17641 / 20000\n",
      "gradient norm: 0.012984702654648572, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00052\n",
      "\tval loss: 0.00052\n",
      "epoch 17642 / 20000\n",
      "gradient norm: 0.020856544288108125, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00052\n",
      "\tval loss: 0.00052\n",
      "epoch 17643 / 20000\n",
      "gradient norm: 0.03283325408119708, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00052\n",
      "\tval loss: 0.00052\n",
      "epoch 17644 / 20000\n",
      "gradient norm: 0.02915304915222805, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00052\n",
      "\tval loss: 0.00052\n",
      "epoch 17645 / 20000\n",
      "gradient norm: 0.023495343164540827, minimum ratio: 2.4421052631578943\n",
      "\ttrain loss: 0.00052\n",
      "\tval loss: 0.00052\n",
      "epoch 17646 / 20000\n",
      "gradient norm: 0.02091928932350129, minimum ratio: 2.4421052631578943\n",
      "\ttrain loss: 0.00051\n",
      "\tval loss: 0.00052\n",
      "epoch 17647 / 20000\n",
      "gradient norm: 0.019242511538323015, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00052\n",
      "\tval loss: 0.00052\n",
      "epoch 17648 / 20000\n",
      "gradient norm: 0.024919688468798995, minimum ratio: 2.4684210526315784\n",
      "\ttrain loss: 0.00052\n",
      "\tval loss: 0.00052\n",
      "epoch 17649 / 20000\n",
      "gradient norm: 0.02900275232968852, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00051\n",
      "\tval loss: 0.00052\n",
      "epoch 17650 / 20000\n",
      "gradient norm: 0.023606458446010947, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00051\n",
      "\tval loss: 0.00051\n",
      "epoch 17651 / 20000\n",
      "gradient norm: 0.017333181982394308, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00051\n",
      "\tval loss: 0.00051\n",
      "epoch 17652 / 20000\n",
      "gradient norm: 0.028034418413881212, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00051\n",
      "\tval loss: 0.00051\n",
      "epoch 17653 / 20000\n",
      "gradient norm: 0.02521827002055943, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00051\n",
      "\tval loss: 0.00051\n",
      "epoch 17654 / 20000\n",
      "gradient norm: 0.023829004785511643, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00051\n",
      "\tval loss: 0.00051\n",
      "epoch 17655 / 20000\n",
      "gradient norm: 0.02658594789681956, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00051\n",
      "\tval loss: 0.00051\n",
      "epoch 17656 / 20000\n",
      "gradient norm: 0.015261621738318354, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00051\n",
      "\tval loss: 0.00051\n",
      "epoch 17657 / 20000\n",
      "gradient norm: 0.016022799885831773, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00051\n",
      "\tval loss: 0.00051\n",
      "epoch 17658 / 20000\n",
      "gradient norm: 0.011290370661299676, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00051\n",
      "\tval loss: 0.00051\n",
      "epoch 17659 / 20000\n",
      "gradient norm: 0.016543578560231254, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00051\n",
      "\tval loss: 0.00051\n",
      "epoch 17660 / 20000\n",
      "gradient norm: 0.019754715933231637, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00051\n",
      "\tval loss: 0.00051\n",
      "epoch 17661 / 20000\n",
      "gradient norm: 0.02460188014083542, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00050\n",
      "\tval loss: 0.00051\n",
      "epoch 17662 / 20000\n",
      "gradient norm: 0.029835520952474326, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00050\n",
      "\tval loss: 0.00051\n",
      "epoch 17663 / 20000\n",
      "gradient norm: 0.034920721605885774, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00050\n",
      "\tval loss: 0.00051\n",
      "epoch 17664 / 20000\n",
      "gradient norm: 0.019898643251508474, minimum ratio: 2.465789473684211\n",
      "\ttrain loss: 0.00050\n",
      "\tval loss: 0.00050\n",
      "epoch 17665 / 20000\n",
      "gradient norm: 0.017843280074885115, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00050\n",
      "\tval loss: 0.00051\n",
      "epoch 17666 / 20000\n",
      "gradient norm: 0.008500291325617582, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00050\n",
      "\tval loss: 0.00050\n",
      "epoch 17667 / 20000\n",
      "gradient norm: 0.02546071750111878, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00050\n",
      "\tval loss: 0.00050\n",
      "epoch 17668 / 20000\n",
      "gradient norm: 0.015985509613528848, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00050\n",
      "\tval loss: 0.00050\n",
      "epoch 17669 / 20000\n",
      "gradient norm: 0.0181456383143086, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00050\n",
      "\tval loss: 0.00050\n",
      "epoch 17670 / 20000\n",
      "gradient norm: 0.014292269013822079, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00050\n",
      "\tval loss: 0.00050\n",
      "epoch 17671 / 20000\n",
      "gradient norm: 0.017737400979967788, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00050\n",
      "\tval loss: 0.00050\n",
      "epoch 17672 / 20000\n",
      "gradient norm: 0.011281264538411051, minimum ratio: 2.43421052631579\n",
      "\ttrain loss: 0.00050\n",
      "\tval loss: 0.00050\n",
      "epoch 17673 / 20000\n",
      "gradient norm: 0.02544737554853782, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00050\n",
      "\tval loss: 0.00050\n",
      "epoch 17674 / 20000\n",
      "gradient norm: 0.04250232281628996, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00050\n",
      "\tval loss: 0.00050\n",
      "epoch 17675 / 20000\n",
      "gradient norm: 0.024291180016007274, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00049\n",
      "\tval loss: 0.00050\n",
      "epoch 17676 / 20000\n",
      "gradient norm: 0.023775857232976705, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00049\n",
      "\tval loss: 0.00050\n",
      "epoch 17677 / 20000\n",
      "gradient norm: 0.04056522125029005, minimum ratio: 2.4447368421052635\n",
      "\ttrain loss: 0.00050\n",
      "\tval loss: 0.00049\n",
      "epoch 17678 / 20000\n",
      "gradient norm: 0.032944493810646236, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00049\n",
      "\tval loss: 0.00049\n",
      "epoch 17679 / 20000\n",
      "gradient norm: 0.021733068046160042, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00049\n",
      "\tval loss: 0.00050\n",
      "epoch 17680 / 20000\n",
      "gradient norm: 0.023117097647627816, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00049\n",
      "\tval loss: 0.00049\n",
      "epoch 17681 / 20000\n",
      "gradient norm: 0.02926556667080149, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00049\n",
      "\tval loss: 0.00049\n",
      "epoch 17682 / 20000\n",
      "gradient norm: 0.0381600228138268, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00049\n",
      "\tval loss: 0.00049\n",
      "epoch 17683 / 20000\n",
      "gradient norm: 0.01818930421723053, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00049\n",
      "\tval loss: 0.00050\n",
      "epoch 17684 / 20000\n",
      "gradient norm: 0.018723333021625876, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00049\n",
      "\tval loss: 0.00049\n",
      "epoch 17685 / 20000\n",
      "gradient norm: 0.04206589807290584, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00049\n",
      "\tval loss: 0.00049\n",
      "epoch 17686 / 20000\n",
      "gradient norm: 0.04787450283765793, minimum ratio: 2.4447368421052635\n",
      "\ttrain loss: 0.00049\n",
      "\tval loss: 0.00049\n",
      "epoch 17687 / 20000\n",
      "gradient norm: 0.027167062973603606, minimum ratio: 2.4499999999999997\n",
      "\ttrain loss: 0.00049\n",
      "\tval loss: 0.00049\n",
      "epoch 17688 / 20000\n",
      "gradient norm: 0.009990984806790948, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00049\n",
      "\tval loss: 0.00049\n",
      "epoch 17689 / 20000\n",
      "gradient norm: 0.03066748514538631, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00049\n",
      "\tval loss: 0.00049\n",
      "epoch 17690 / 20000\n",
      "gradient norm: 0.017826804367359728, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00048\n",
      "\tval loss: 0.00049\n",
      "epoch 17691 / 20000\n",
      "gradient norm: 0.017184507043566555, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00048\n",
      "\tval loss: 0.00049\n",
      "epoch 17692 / 20000\n",
      "gradient norm: 0.02360707544721663, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00048\n",
      "\tval loss: 0.00048\n",
      "epoch 17693 / 20000\n",
      "gradient norm: 0.02773904093191959, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00048\n",
      "\tval loss: 0.00049\n",
      "epoch 17694 / 20000\n",
      "gradient norm: 0.015464287804206833, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00048\n",
      "\tval loss: 0.00048\n",
      "epoch 17695 / 20000\n",
      "gradient norm: 0.02599126982386224, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00048\n",
      "\tval loss: 0.00048\n",
      "epoch 17696 / 20000\n",
      "gradient norm: 0.021294583741109818, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00048\n",
      "\tval loss: 0.00048\n",
      "epoch 17697 / 20000\n",
      "gradient norm: 0.03457546967547387, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00048\n",
      "\tval loss: 0.00048\n",
      "epoch 17698 / 20000\n",
      "gradient norm: 0.0267205240088515, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00048\n",
      "\tval loss: 0.00048\n",
      "epoch 17699 / 20000\n",
      "gradient norm: 0.03491499653318897, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00048\n",
      "\tval loss: 0.00048\n",
      "epoch 17700 / 20000\n",
      "gradient norm: 0.032131590123753995, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00048\n",
      "\tval loss: 0.00048\n",
      "epoch 17701 / 20000\n",
      "gradient norm: 0.01290509061072953, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00048\n",
      "\tval loss: 0.00048\n",
      "epoch 17702 / 20000\n",
      "gradient norm: 0.02834551694104448, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00048\n",
      "\tval loss: 0.00048\n",
      "epoch 17703 / 20000\n",
      "gradient norm: 0.027575018350034952, minimum ratio: 2.4499999999999997\n",
      "\ttrain loss: 0.00048\n",
      "\tval loss: 0.00048\n",
      "epoch 17704 / 20000\n",
      "gradient norm: 0.0387891111895442, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00048\n",
      "\tval loss: 0.00048\n",
      "epoch 17705 / 20000\n",
      "gradient norm: 0.03171172708971426, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00047\n",
      "\tval loss: 0.00048\n",
      "epoch 17706 / 20000\n",
      "gradient norm: 0.02324278565356508, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00047\n",
      "\tval loss: 0.00047\n",
      "epoch 17707 / 20000\n",
      "gradient norm: 0.012593694787938148, minimum ratio: 2.4421052631578943\n",
      "\ttrain loss: 0.00047\n",
      "\tval loss: 0.00048\n",
      "epoch 17708 / 20000\n",
      "gradient norm: 0.04110872407909483, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00047\n",
      "\tval loss: 0.00047\n",
      "epoch 17709 / 20000\n",
      "gradient norm: 0.020874647627351806, minimum ratio: 2.4447368421052635\n",
      "\ttrain loss: 0.00047\n",
      "\tval loss: 0.00047\n",
      "epoch 17710 / 20000\n",
      "gradient norm: 0.01516755172633566, minimum ratio: 2.4842105263157896\n",
      "\ttrain loss: 0.00047\n",
      "\tval loss: 0.00047\n",
      "epoch 17711 / 20000\n",
      "gradient norm: 0.019910821385565214, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00047\n",
      "\tval loss: 0.00047\n",
      "epoch 17712 / 20000\n",
      "gradient norm: 0.028012191149173304, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00047\n",
      "\tval loss: 0.00047\n",
      "epoch 17713 / 20000\n",
      "gradient norm: 0.021950630994979292, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00047\n",
      "\tval loss: 0.00047\n",
      "epoch 17714 / 20000\n",
      "gradient norm: 0.02363066707039252, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00047\n",
      "\tval loss: 0.00047\n",
      "epoch 17715 / 20000\n",
      "gradient norm: 0.02066950561129488, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00047\n",
      "\tval loss: 0.00047\n",
      "epoch 17716 / 20000\n",
      "gradient norm: 0.029474389972165227, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00047\n",
      "\tval loss: 0.00047\n",
      "epoch 17717 / 20000\n",
      "gradient norm: 0.01174606209679041, minimum ratio: 2.460526315789474\n",
      "\ttrain loss: 0.00046\n",
      "\tval loss: 0.00047\n",
      "epoch 17718 / 20000\n",
      "gradient norm: 0.01300101020024158, minimum ratio: 2.46578947368421\n",
      "\ttrain loss: 0.00046\n",
      "\tval loss: 0.00047\n",
      "epoch 17719 / 20000\n",
      "gradient norm: 0.017445632664021105, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00046\n",
      "\tval loss: 0.00047\n",
      "epoch 17720 / 20000\n",
      "gradient norm: 0.020892203378025442, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00046\n",
      "\tval loss: 0.00047\n",
      "epoch 17721 / 20000\n",
      "gradient norm: 0.03384204889880493, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00046\n",
      "\tval loss: 0.00047\n",
      "epoch 17722 / 20000\n",
      "gradient norm: 0.018747067195363343, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00046\n",
      "\tval loss: 0.00046\n",
      "epoch 17723 / 20000\n",
      "gradient norm: 0.036593389115296304, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00046\n",
      "\tval loss: 0.00047\n",
      "epoch 17724 / 20000\n",
      "gradient norm: 0.02070195588748902, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00046\n",
      "\tval loss: 0.00046\n",
      "epoch 17725 / 20000\n",
      "gradient norm: 0.0432888520299457, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00046\n",
      "\tval loss: 0.00046\n",
      "epoch 17726 / 20000\n",
      "gradient norm: 0.03316886042011902, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00046\n",
      "\tval loss: 0.00046\n",
      "epoch 17727 / 20000\n",
      "gradient norm: 0.03851454850519076, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00046\n",
      "\tval loss: 0.00046\n",
      "epoch 17728 / 20000\n",
      "gradient norm: 0.026197136496193707, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00046\n",
      "\tval loss: 0.00047\n",
      "epoch 17729 / 20000\n",
      "gradient norm: 0.017367608641507104, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00046\n",
      "\tval loss: 0.00046\n",
      "epoch 17730 / 20000\n",
      "gradient norm: 0.015388219690066762, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00046\n",
      "\tval loss: 0.00046\n",
      "epoch 17731 / 20000\n",
      "gradient norm: 0.04044319619424641, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00046\n",
      "\tval loss: 0.00046\n",
      "epoch 17732 / 20000\n",
      "gradient norm: 0.053123385325307027, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00046\n",
      "\tval loss: 0.00046\n",
      "epoch 17733 / 20000\n",
      "gradient norm: 0.042993590293917805, minimum ratio: 2.4499999999999997\n",
      "\ttrain loss: 0.00046\n",
      "\tval loss: 0.00046\n",
      "epoch 17734 / 20000\n",
      "gradient norm: 0.03154920961242169, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00045\n",
      "\tval loss: 0.00046\n",
      "epoch 17735 / 20000\n",
      "gradient norm: 0.02927687345072627, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00045\n",
      "\tval loss: 0.00046\n",
      "epoch 17736 / 20000\n",
      "gradient norm: 0.03189407067839056, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00045\n",
      "\tval loss: 0.00045\n",
      "epoch 17737 / 20000\n",
      "gradient norm: 0.0307644015410915, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00045\n",
      "\tval loss: 0.00046\n",
      "epoch 17738 / 20000\n",
      "gradient norm: 0.03152099807630293, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00045\n",
      "\tval loss: 0.00045\n",
      "epoch 17739 / 20000\n",
      "gradient norm: 0.013602176681160927, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00045\n",
      "\tval loss: 0.00045\n",
      "epoch 17740 / 20000\n",
      "gradient norm: 0.0131615591380978, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00045\n",
      "\tval loss: 0.00046\n",
      "epoch 17741 / 20000\n",
      "gradient norm: 0.02214776395703666, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00045\n",
      "\tval loss: 0.00045\n",
      "epoch 17742 / 20000\n",
      "gradient norm: 0.015712674794485793, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00045\n",
      "\tval loss: 0.00045\n",
      "epoch 17743 / 20000\n",
      "gradient norm: 0.012572342238854617, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00045\n",
      "\tval loss: 0.00045\n",
      "epoch 17744 / 20000\n",
      "gradient norm: 0.017825646180426702, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00045\n",
      "\tval loss: 0.00045\n",
      "epoch 17745 / 20000\n",
      "gradient norm: 0.020516893855528906, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00045\n",
      "\tval loss: 0.00045\n",
      "epoch 17746 / 20000\n",
      "gradient norm: 0.014983085740823299, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00045\n",
      "\tval loss: 0.00045\n",
      "epoch 17747 / 20000\n",
      "gradient norm: 0.009562147330143489, minimum ratio: 2.4289473684210523\n",
      "\ttrain loss: 0.00045\n",
      "\tval loss: 0.00045\n",
      "epoch 17748 / 20000\n",
      "gradient norm: 0.015360138851974625, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00044\n",
      "\tval loss: 0.00045\n",
      "epoch 17749 / 20000\n",
      "gradient norm: 0.017695856891805306, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00045\n",
      "\tval loss: 0.00045\n",
      "epoch 17750 / 20000\n",
      "gradient norm: 0.01736751673161052, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00044\n",
      "\tval loss: 0.00045\n",
      "epoch 17751 / 20000\n",
      "gradient norm: 0.013075280701741576, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00044\n",
      "\tval loss: 0.00045\n",
      "epoch 17752 / 20000\n",
      "gradient norm: 0.027195383881917223, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00044\n",
      "\tval loss: 0.00045\n",
      "epoch 17753 / 20000\n",
      "gradient norm: 0.024394357344135642, minimum ratio: 2.452631578947368\n",
      "\ttrain loss: 0.00044\n",
      "\tval loss: 0.00044\n",
      "epoch 17754 / 20000\n",
      "gradient norm: 0.020656996872276068, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00044\n",
      "\tval loss: 0.00045\n",
      "epoch 17755 / 20000\n",
      "gradient norm: 0.014653157442808151, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00044\n",
      "\tval loss: 0.00044\n",
      "epoch 17756 / 20000\n",
      "gradient norm: 0.019173613662132993, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00044\n",
      "\tval loss: 0.00045\n",
      "epoch 17757 / 20000\n",
      "gradient norm: 0.030564223183318973, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00044\n",
      "\tval loss: 0.00044\n",
      "epoch 17758 / 20000\n",
      "gradient norm: 0.030478499887976795, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00044\n",
      "\tval loss: 0.00044\n",
      "epoch 17759 / 20000\n",
      "gradient norm: 0.024535197822842747, minimum ratio: 2.4210526315789473\n",
      "\ttrain loss: 0.00044\n",
      "\tval loss: 0.00044\n",
      "epoch 17760 / 20000\n",
      "gradient norm: 0.029935605576611124, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00044\n",
      "\tval loss: 0.00044\n",
      "epoch 17761 / 20000\n",
      "gradient norm: 0.014917279637302272, minimum ratio: 2.4499999999999997\n",
      "\ttrain loss: 0.00044\n",
      "\tval loss: 0.00044\n",
      "epoch 17762 / 20000\n",
      "gradient norm: 0.01657160185277462, minimum ratio: 2.4289473684210523\n",
      "\ttrain loss: 0.00044\n",
      "\tval loss: 0.00044\n",
      "epoch 17763 / 20000\n",
      "gradient norm: 0.023345041932770982, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00044\n",
      "\tval loss: 0.00044\n",
      "epoch 17764 / 20000\n",
      "gradient norm: 0.024132943741278723, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00044\n",
      "\tval loss: 0.00044\n",
      "epoch 17765 / 20000\n",
      "gradient norm: 0.02825568977277726, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00043\n",
      "\tval loss: 0.00044\n",
      "epoch 17766 / 20000\n",
      "gradient norm: 0.021194989210925996, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00043\n",
      "\tval loss: 0.00044\n",
      "epoch 17767 / 20000\n",
      "gradient norm: 0.022955939901294187, minimum ratio: 2.4499999999999997\n",
      "\ttrain loss: 0.00043\n",
      "\tval loss: 0.00043\n",
      "epoch 17768 / 20000\n",
      "gradient norm: 0.0245966034126468, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00043\n",
      "\tval loss: 0.00044\n",
      "epoch 17769 / 20000\n",
      "gradient norm: 0.01158122843480669, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00043\n",
      "\tval loss: 0.00043\n",
      "epoch 17770 / 20000\n",
      "gradient norm: 0.02753849924192764, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00043\n",
      "\tval loss: 0.00043\n",
      "epoch 17771 / 20000\n",
      "gradient norm: 0.0222889119759202, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00043\n",
      "\tval loss: 0.00043\n",
      "epoch 17772 / 20000\n",
      "gradient norm: 0.010360751504777, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00043\n",
      "\tval loss: 0.00043\n",
      "epoch 17773 / 20000\n",
      "gradient norm: 0.021159337949939072, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00043\n",
      "\tval loss: 0.00043\n",
      "epoch 17774 / 20000\n",
      "gradient norm: 0.027992547547910362, minimum ratio: 2.460526315789474\n",
      "\ttrain loss: 0.00043\n",
      "\tval loss: 0.00043\n",
      "epoch 17775 / 20000\n",
      "gradient norm: 0.0333982456359081, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00043\n",
      "\tval loss: 0.00043\n",
      "epoch 17776 / 20000\n",
      "gradient norm: 0.025860783018288203, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00043\n",
      "\tval loss: 0.00043\n",
      "epoch 17777 / 20000\n",
      "gradient norm: 0.023215795255964622, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00043\n",
      "\tval loss: 0.00043\n",
      "epoch 17778 / 20000\n",
      "gradient norm: 0.028615356437512673, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00043\n",
      "\tval loss: 0.00043\n",
      "epoch 17779 / 20000\n",
      "gradient norm: 0.018829465378075838, minimum ratio: 2.4447368421052635\n",
      "\ttrain loss: 0.00042\n",
      "\tval loss: 0.00043\n",
      "epoch 17780 / 20000\n",
      "gradient norm: 0.026180085231317207, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00043\n",
      "\tval loss: 0.00043\n",
      "epoch 17781 / 20000\n",
      "gradient norm: 0.027178583957720548, minimum ratio: 2.4499999999999997\n",
      "\ttrain loss: 0.00042\n",
      "\tval loss: 0.00043\n",
      "epoch 17782 / 20000\n",
      "gradient norm: 0.027846791257616132, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00042\n",
      "\tval loss: 0.00043\n",
      "epoch 17783 / 20000\n",
      "gradient norm: 0.022564206272363663, minimum ratio: 2.4210526315789473\n",
      "\ttrain loss: 0.00042\n",
      "\tval loss: 0.00043\n",
      "epoch 17784 / 20000\n",
      "gradient norm: 0.013526683440431952, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00042\n",
      "\tval loss: 0.00042\n",
      "epoch 17785 / 20000\n",
      "gradient norm: 0.034117623581551015, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00042\n",
      "\tval loss: 0.00043\n",
      "epoch 17786 / 20000\n",
      "gradient norm: 0.029897895408794284, minimum ratio: 2.4499999999999997\n",
      "\ttrain loss: 0.00042\n",
      "\tval loss: 0.00042\n",
      "epoch 17787 / 20000\n",
      "gradient norm: 0.020137199491728097, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00042\n",
      "\tval loss: 0.00042\n",
      "epoch 17788 / 20000\n",
      "gradient norm: 0.016969441319815814, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00042\n",
      "\tval loss: 0.00042\n",
      "epoch 17789 / 20000\n",
      "gradient norm: 0.031198412441881374, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00042\n",
      "\tval loss: 0.00042\n",
      "epoch 17790 / 20000\n",
      "gradient norm: 0.015889053378487006, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00042\n",
      "\tval loss: 0.00042\n",
      "epoch 17791 / 20000\n",
      "gradient norm: 0.03062092637992464, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00042\n",
      "\tval loss: 0.00042\n",
      "epoch 17792 / 20000\n",
      "gradient norm: 0.024504922068445012, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00042\n",
      "\tval loss: 0.00042\n",
      "epoch 17793 / 20000\n",
      "gradient norm: 0.011340530443703756, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00042\n",
      "\tval loss: 0.00042\n",
      "epoch 17794 / 20000\n",
      "gradient norm: 0.01596680804505013, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00041\n",
      "\tval loss: 0.00042\n",
      "epoch 17795 / 20000\n",
      "gradient norm: 0.030507142597343773, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00041\n",
      "\tval loss: 0.00042\n",
      "epoch 17796 / 20000\n",
      "gradient norm: 0.01957471745845396, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00041\n",
      "\tval loss: 0.00042\n",
      "epoch 17797 / 20000\n",
      "gradient norm: 0.025309618649771437, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00041\n",
      "\tval loss: 0.00042\n",
      "epoch 17798 / 20000\n",
      "gradient norm: 0.020000216783955693, minimum ratio: 2.436842105263158\n",
      "\ttrain loss: 0.00041\n",
      "\tval loss: 0.00042\n",
      "epoch 17799 / 20000\n",
      "gradient norm: 0.02503323685959913, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00041\n",
      "\tval loss: 0.00042\n",
      "epoch 17800 / 20000\n",
      "gradient norm: 0.029578861605841666, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00041\n",
      "\tval loss: 0.00041\n",
      "epoch 17801 / 20000\n",
      "gradient norm: 0.03193392331013456, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00041\n",
      "\tval loss: 0.00042\n",
      "epoch 17802 / 20000\n",
      "gradient norm: 0.03389976313337684, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00041\n",
      "\tval loss: 0.00041\n",
      "epoch 17803 / 20000\n",
      "gradient norm: 0.016184954889467917, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00041\n",
      "\tval loss: 0.00042\n",
      "epoch 17804 / 20000\n",
      "gradient norm: 0.01232806796906516, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00041\n",
      "\tval loss: 0.00041\n",
      "epoch 17805 / 20000\n",
      "gradient norm: 0.011595829710131511, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00041\n",
      "\tval loss: 0.00041\n",
      "epoch 17806 / 20000\n",
      "gradient norm: 0.020919571921695024, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00041\n",
      "\tval loss: 0.00041\n",
      "epoch 17807 / 20000\n",
      "gradient norm: 0.019516520376782864, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00041\n",
      "\tval loss: 0.00041\n",
      "epoch 17808 / 20000\n",
      "gradient norm: 0.015401888900669292, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00041\n",
      "\tval loss: 0.00041\n",
      "epoch 17809 / 20000\n",
      "gradient norm: 0.019604511704528704, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00041\n",
      "\tval loss: 0.00041\n",
      "epoch 17810 / 20000\n",
      "gradient norm: 0.009633533627493307, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00040\n",
      "\tval loss: 0.00041\n",
      "epoch 17811 / 20000\n",
      "gradient norm: 0.02489459974458441, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00040\n",
      "\tval loss: 0.00041\n",
      "epoch 17812 / 20000\n",
      "gradient norm: 0.012723188730888069, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00040\n",
      "\tval loss: 0.00041\n",
      "epoch 17813 / 20000\n",
      "gradient norm: 0.023880494642071426, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00040\n",
      "\tval loss: 0.00041\n",
      "epoch 17814 / 20000\n",
      "gradient norm: 0.01517473443527706, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00040\n",
      "\tval loss: 0.00041\n",
      "epoch 17815 / 20000\n",
      "gradient norm: 0.014348087133839726, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00040\n",
      "\tval loss: 0.00041\n",
      "epoch 17816 / 20000\n",
      "gradient norm: 0.01870680772117339, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00040\n",
      "\tval loss: 0.00041\n",
      "epoch 17817 / 20000\n",
      "gradient norm: 0.03489823354175314, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00040\n",
      "\tval loss: 0.00041\n",
      "epoch 17818 / 20000\n",
      "gradient norm: 0.029557195550296456, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00040\n",
      "\tval loss: 0.00041\n",
      "epoch 17819 / 20000\n",
      "gradient norm: 0.02710533869685605, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00040\n",
      "\tval loss: 0.00040\n",
      "epoch 17820 / 20000\n",
      "gradient norm: 0.016332037863321602, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00040\n",
      "\tval loss: 0.00040\n",
      "epoch 17821 / 20000\n",
      "gradient norm: 0.022405696043279022, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00040\n",
      "\tval loss: 0.00040\n",
      "epoch 17822 / 20000\n",
      "gradient norm: 0.01743154347059317, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00040\n",
      "\tval loss: 0.00040\n",
      "epoch 17823 / 20000\n",
      "gradient norm: 0.026377274363767356, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00040\n",
      "\tval loss: 0.00040\n",
      "epoch 17824 / 20000\n",
      "gradient norm: 0.04249314853223041, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00040\n",
      "\tval loss: 0.00040\n",
      "epoch 17825 / 20000\n",
      "gradient norm: 0.04568191588623449, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00040\n",
      "\tval loss: 0.00040\n",
      "epoch 17826 / 20000\n",
      "gradient norm: 0.04273429251043126, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00040\n",
      "\tval loss: 0.00040\n",
      "epoch 17827 / 20000\n",
      "gradient norm: 0.034391138586215675, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00040\n",
      "\tval loss: 0.00041\n",
      "epoch 17828 / 20000\n",
      "gradient norm: 0.032378279545810074, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00039\n",
      "\tval loss: 0.00040\n",
      "epoch 17829 / 20000\n",
      "gradient norm: 0.011867156616062857, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00039\n",
      "\tval loss: 0.00040\n",
      "epoch 17830 / 20000\n",
      "gradient norm: 0.028630780521780252, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00039\n",
      "\tval loss: 0.00040\n",
      "epoch 17831 / 20000\n",
      "gradient norm: 0.04148118550074287, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00040\n",
      "\tval loss: 0.00040\n",
      "epoch 17832 / 20000\n",
      "gradient norm: 0.03705401666229591, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00039\n",
      "\tval loss: 0.00040\n",
      "epoch 17833 / 20000\n",
      "gradient norm: 0.03509638935793191, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00039\n",
      "\tval loss: 0.00039\n",
      "epoch 17834 / 20000\n",
      "gradient norm: 0.028415902343112975, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00039\n",
      "\tval loss: 0.00040\n",
      "epoch 17835 / 20000\n",
      "gradient norm: 0.024495076795574278, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00039\n",
      "\tval loss: 0.00039\n",
      "epoch 17836 / 20000\n",
      "gradient norm: 0.04202341957716271, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00039\n",
      "\tval loss: 0.00039\n",
      "epoch 17837 / 20000\n",
      "gradient norm: 0.020934942149324343, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00039\n",
      "\tval loss: 0.00039\n",
      "epoch 17838 / 20000\n",
      "gradient norm: 0.02530457021202892, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00039\n",
      "\tval loss: 0.00039\n",
      "epoch 17839 / 20000\n",
      "gradient norm: 0.01510541103198193, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00039\n",
      "\tval loss: 0.00039\n",
      "epoch 17840 / 20000\n",
      "gradient norm: 0.03134580791811459, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00039\n",
      "\tval loss: 0.00039\n",
      "epoch 17841 / 20000\n",
      "gradient norm: 0.03874959304812364, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00039\n",
      "\tval loss: 0.00039\n",
      "epoch 17842 / 20000\n",
      "gradient norm: 0.029705299763008952, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00039\n",
      "\tval loss: 0.00039\n",
      "epoch 17843 / 20000\n",
      "gradient norm: 0.028493835183326155, minimum ratio: 2.4894736842105267\n",
      "\ttrain loss: 0.00039\n",
      "\tval loss: 0.00039\n",
      "epoch 17844 / 20000\n",
      "gradient norm: 0.02821268799016252, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00038\n",
      "\tval loss: 0.00039\n",
      "epoch 17845 / 20000\n",
      "gradient norm: 0.024976725573651493, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00038\n",
      "\tval loss: 0.00039\n",
      "epoch 17846 / 20000\n",
      "gradient norm: 0.01601196959381923, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00038\n",
      "\tval loss: 0.00039\n",
      "epoch 17847 / 20000\n",
      "gradient norm: 0.021248054457828403, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00038\n",
      "\tval loss: 0.00039\n",
      "epoch 17848 / 20000\n",
      "gradient norm: 0.02466836264648009, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00038\n",
      "\tval loss: 0.00039\n",
      "epoch 17849 / 20000\n",
      "gradient norm: 0.030340521421749145, minimum ratio: 2.46578947368421\n",
      "\ttrain loss: 0.00038\n",
      "\tval loss: 0.00039\n",
      "epoch 17850 / 20000\n",
      "gradient norm: 0.01799670883337967, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00038\n",
      "\tval loss: 0.00039\n",
      "epoch 17851 / 20000\n",
      "gradient norm: 0.014197189011611044, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00038\n",
      "\tval loss: 0.00038\n",
      "epoch 17852 / 20000\n",
      "gradient norm: 0.02220973261864856, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00038\n",
      "\tval loss: 0.00039\n",
      "epoch 17853 / 20000\n",
      "gradient norm: 0.031101896427571774, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00038\n",
      "\tval loss: 0.00038\n",
      "epoch 17854 / 20000\n",
      "gradient norm: 0.018631051148986444, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00038\n",
      "\tval loss: 0.00038\n",
      "epoch 17855 / 20000\n",
      "gradient norm: 0.015671957458835095, minimum ratio: 2.436842105263158\n",
      "\ttrain loss: 0.00038\n",
      "\tval loss: 0.00038\n",
      "epoch 17856 / 20000\n",
      "gradient norm: 0.018883363081840798, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00038\n",
      "\tval loss: 0.00038\n",
      "epoch 17857 / 20000\n",
      "gradient norm: 0.014053372637135908, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00038\n",
      "\tval loss: 0.00038\n",
      "epoch 17858 / 20000\n",
      "gradient norm: 0.015927474189084023, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00038\n",
      "\tval loss: 0.00038\n",
      "epoch 17859 / 20000\n",
      "gradient norm: 0.017879998980788514, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00038\n",
      "\tval loss: 0.00038\n",
      "epoch 17860 / 20000\n",
      "gradient norm: 0.01329313512542285, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00037\n",
      "\tval loss: 0.00038\n",
      "epoch 17861 / 20000\n",
      "gradient norm: 0.013820367836160585, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00037\n",
      "\tval loss: 0.00038\n",
      "epoch 17862 / 20000\n",
      "gradient norm: 0.018259052594657987, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00037\n",
      "\tval loss: 0.00038\n",
      "epoch 17863 / 20000\n",
      "gradient norm: 0.021505902346689254, minimum ratio: 2.492105263157895\n",
      "\ttrain loss: 0.00037\n",
      "\tval loss: 0.00038\n",
      "epoch 17864 / 20000\n",
      "gradient norm: 0.02272262898623012, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00037\n",
      "\tval loss: 0.00038\n",
      "epoch 17865 / 20000\n",
      "gradient norm: 0.024509880342520773, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00037\n",
      "\tval loss: 0.00038\n",
      "epoch 17866 / 20000\n",
      "gradient norm: 0.0253479492967017, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00037\n",
      "\tval loss: 0.00038\n",
      "epoch 17867 / 20000\n",
      "gradient norm: 0.011727235556463711, minimum ratio: 2.465789473684211\n",
      "\ttrain loss: 0.00037\n",
      "\tval loss: 0.00038\n",
      "epoch 17868 / 20000\n",
      "gradient norm: 0.011171931109856814, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00037\n",
      "\tval loss: 0.00038\n",
      "epoch 17869 / 20000\n",
      "gradient norm: 0.024405935924733058, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00037\n",
      "\tval loss: 0.00038\n",
      "epoch 17870 / 20000\n",
      "gradient norm: 0.01368640101281926, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00037\n",
      "\tval loss: 0.00037\n",
      "epoch 17871 / 20000\n",
      "gradient norm: 0.01098365655343514, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00037\n",
      "\tval loss: 0.00037\n",
      "epoch 17872 / 20000\n",
      "gradient norm: 0.010372437609476037, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00037\n",
      "\tval loss: 0.00037\n",
      "epoch 17873 / 20000\n",
      "gradient norm: 0.012415382792823948, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00037\n",
      "\tval loss: 0.00037\n",
      "epoch 17874 / 20000\n",
      "gradient norm: 0.018457403144566342, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00037\n",
      "\tval loss: 0.00037\n",
      "epoch 17875 / 20000\n",
      "gradient norm: 0.022037460759747773, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00037\n",
      "\tval loss: 0.00037\n",
      "epoch 17876 / 20000\n",
      "gradient norm: 0.017326904024230316, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00037\n",
      "\tval loss: 0.00037\n",
      "epoch 17877 / 20000\n",
      "gradient norm: 0.01854169851867482, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00036\n",
      "\tval loss: 0.00037\n",
      "epoch 17878 / 20000\n",
      "gradient norm: 0.012764180661179125, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00036\n",
      "\tval loss: 0.00037\n",
      "epoch 17879 / 20000\n",
      "gradient norm: 0.04180975625058636, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00037\n",
      "\tval loss: 0.00037\n",
      "epoch 17880 / 20000\n",
      "gradient norm: 0.039727635215967894, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00037\n",
      "\tval loss: 0.00037\n",
      "epoch 17881 / 20000\n",
      "gradient norm: 0.0328921313630417, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00036\n",
      "\tval loss: 0.00037\n",
      "epoch 17882 / 20000\n",
      "gradient norm: 0.020981338864658028, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00036\n",
      "\tval loss: 0.00037\n",
      "epoch 17883 / 20000\n",
      "gradient norm: 0.017173469183035195, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00036\n",
      "\tval loss: 0.00037\n",
      "epoch 17884 / 20000\n",
      "gradient norm: 0.022916555404663086, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00036\n",
      "\tval loss: 0.00037\n",
      "epoch 17885 / 20000\n",
      "gradient norm: 0.04845320573076606, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00036\n",
      "\tval loss: 0.00037\n",
      "epoch 17886 / 20000\n",
      "gradient norm: 0.027667196933180094, minimum ratio: 2.4394736842105265\n",
      "\ttrain loss: 0.00036\n",
      "\tval loss: 0.00036\n",
      "epoch 17887 / 20000\n",
      "gradient norm: 0.026223901222692803, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00036\n",
      "\tval loss: 0.00037\n",
      "epoch 17888 / 20000\n",
      "gradient norm: 0.026168234064243734, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00036\n",
      "\tval loss: 0.00036\n",
      "epoch 17889 / 20000\n",
      "gradient norm: 0.01557623062399216, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00036\n",
      "\tval loss: 0.00037\n",
      "epoch 17890 / 20000\n",
      "gradient norm: 0.007977126617333852, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00036\n",
      "\tval loss: 0.00036\n",
      "epoch 17891 / 20000\n",
      "gradient norm: 0.024122957256622612, minimum ratio: 2.452631578947368\n",
      "\ttrain loss: 0.00036\n",
      "\tval loss: 0.00036\n",
      "epoch 17892 / 20000\n",
      "gradient norm: 0.026225449779303744, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00036\n",
      "\tval loss: 0.00036\n",
      "epoch 17893 / 20000\n",
      "gradient norm: 0.017859446787042543, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00036\n",
      "\tval loss: 0.00036\n",
      "epoch 17894 / 20000\n",
      "gradient norm: 0.017662484373431653, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00036\n",
      "\tval loss: 0.00036\n",
      "epoch 17895 / 20000\n",
      "gradient norm: 0.030470216821413487, minimum ratio: 2.4421052631578943\n",
      "\ttrain loss: 0.00036\n",
      "\tval loss: 0.00036\n",
      "epoch 17896 / 20000\n",
      "gradient norm: 0.03834334679413587, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00036\n",
      "\tval loss: 0.00036\n",
      "epoch 17897 / 20000\n",
      "gradient norm: 0.030758136068470776, minimum ratio: 2.46578947368421\n",
      "\ttrain loss: 0.00035\n",
      "\tval loss: 0.00036\n",
      "epoch 17898 / 20000\n",
      "gradient norm: 0.013879083940992132, minimum ratio: 2.4447368421052627\n",
      "\ttrain loss: 0.00035\n",
      "\tval loss: 0.00036\n",
      "epoch 17899 / 20000\n",
      "gradient norm: 0.02703405646025203, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00035\n",
      "\tval loss: 0.00036\n",
      "epoch 17900 / 20000\n",
      "gradient norm: 0.019480572402244434, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00035\n",
      "\tval loss: 0.00036\n",
      "epoch 17901 / 20000\n",
      "gradient norm: 0.013922927842941135, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00035\n",
      "\tval loss: 0.00036\n",
      "epoch 17902 / 20000\n",
      "gradient norm: 0.02078486609389074, minimum ratio: 2.4447368421052635\n",
      "\ttrain loss: 0.00035\n",
      "\tval loss: 0.00036\n",
      "epoch 17903 / 20000\n",
      "gradient norm: 0.015582112973788753, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00035\n",
      "\tval loss: 0.00036\n",
      "epoch 17904 / 20000\n",
      "gradient norm: 0.013346986786928028, minimum ratio: 2.492105263157895\n",
      "\ttrain loss: 0.00035\n",
      "\tval loss: 0.00036\n",
      "epoch 17905 / 20000\n",
      "gradient norm: 0.013168632387532853, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00035\n",
      "\tval loss: 0.00036\n",
      "epoch 17906 / 20000\n",
      "gradient norm: 0.012704569089692086, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00035\n",
      "\tval loss: 0.00035\n",
      "epoch 17907 / 20000\n",
      "gradient norm: 0.018175817327573895, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00035\n",
      "\tval loss: 0.00035\n",
      "epoch 17908 / 20000\n",
      "gradient norm: 0.021907523449044675, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00035\n",
      "\tval loss: 0.00035\n",
      "epoch 17909 / 20000\n",
      "gradient norm: 0.03916602930985391, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00035\n",
      "\tval loss: 0.00035\n",
      "epoch 17910 / 20000\n",
      "gradient norm: 0.02149272960377857, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00035\n",
      "\tval loss: 0.00035\n",
      "epoch 17911 / 20000\n",
      "gradient norm: 0.023520068381913006, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00035\n",
      "\tval loss: 0.00035\n",
      "epoch 17912 / 20000\n",
      "gradient norm: 0.015736272558569908, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00035\n",
      "\tval loss: 0.00035\n",
      "epoch 17913 / 20000\n",
      "gradient norm: 0.03119751496706158, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00035\n",
      "\tval loss: 0.00035\n",
      "epoch 17914 / 20000\n",
      "gradient norm: 0.0353173651965335, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00035\n",
      "\tval loss: 0.00035\n",
      "epoch 17915 / 20000\n",
      "gradient norm: 0.042901889071799815, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00035\n",
      "\tval loss: 0.00035\n",
      "epoch 17916 / 20000\n",
      "gradient norm: 0.022799786878749728, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00034\n",
      "\tval loss: 0.00035\n",
      "epoch 17917 / 20000\n",
      "gradient norm: 0.020876789450994693, minimum ratio: 2.4842105263157896\n",
      "\ttrain loss: 0.00034\n",
      "\tval loss: 0.00035\n",
      "epoch 17918 / 20000\n",
      "gradient norm: 0.02678300515981391, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00034\n",
      "\tval loss: 0.00035\n",
      "epoch 17919 / 20000\n",
      "gradient norm: 0.03227806807262823, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00034\n",
      "\tval loss: 0.00035\n",
      "epoch 17920 / 20000\n",
      "gradient norm: 0.01724504191952292, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00034\n",
      "\tval loss: 0.00035\n",
      "epoch 17921 / 20000\n",
      "gradient norm: 0.022020673553925008, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00034\n",
      "\tval loss: 0.00035\n",
      "epoch 17922 / 20000\n",
      "gradient norm: 0.024516510602552444, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00034\n",
      "\tval loss: 0.00035\n",
      "epoch 17923 / 20000\n",
      "gradient norm: 0.012901195586891845, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00034\n",
      "\tval loss: 0.00035\n",
      "epoch 17924 / 20000\n",
      "gradient norm: 0.019238278415286914, minimum ratio: 2.4447368421052627\n",
      "\ttrain loss: 0.00034\n",
      "\tval loss: 0.00034\n",
      "epoch 17925 / 20000\n",
      "gradient norm: 0.027687161084031686, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00034\n",
      "\tval loss: 0.00034\n",
      "epoch 17926 / 20000\n",
      "gradient norm: 0.018254541733767837, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00034\n",
      "\tval loss: 0.00035\n",
      "epoch 17927 / 20000\n",
      "gradient norm: 0.018355884356424212, minimum ratio: 2.465789473684211\n",
      "\ttrain loss: 0.00034\n",
      "\tval loss: 0.00034\n",
      "epoch 17928 / 20000\n",
      "gradient norm: 0.013920202050940134, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00034\n",
      "\tval loss: 0.00034\n",
      "epoch 17929 / 20000\n",
      "gradient norm: 0.02174232160905376, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00034\n",
      "\tval loss: 0.00034\n",
      "epoch 17930 / 20000\n",
      "gradient norm: 0.013364745653234422, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00034\n",
      "\tval loss: 0.00034\n",
      "epoch 17931 / 20000\n",
      "gradient norm: 0.015966073755407706, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00034\n",
      "\tval loss: 0.00034\n",
      "epoch 17932 / 20000\n",
      "gradient norm: 0.02152192557696253, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00034\n",
      "\tval loss: 0.00034\n",
      "epoch 17933 / 20000\n",
      "gradient norm: 0.010543082724325359, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00033\n",
      "\tval loss: 0.00034\n",
      "epoch 17934 / 20000\n",
      "gradient norm: 0.017983864614507183, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00033\n",
      "\tval loss: 0.00034\n",
      "epoch 17935 / 20000\n",
      "gradient norm: 0.01730927321477793, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00033\n",
      "\tval loss: 0.00034\n",
      "epoch 17936 / 20000\n",
      "gradient norm: 0.018668647826416418, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00033\n",
      "\tval loss: 0.00034\n",
      "epoch 17937 / 20000\n",
      "gradient norm: 0.012464368424843997, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00033\n",
      "\tval loss: 0.00034\n",
      "epoch 17938 / 20000\n",
      "gradient norm: 0.01976497209398076, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00033\n",
      "\tval loss: 0.00034\n",
      "epoch 17939 / 20000\n",
      "gradient norm: 0.014240218661143444, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00033\n",
      "\tval loss: 0.00034\n",
      "epoch 17940 / 20000\n",
      "gradient norm: 0.01961585006210953, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00033\n",
      "\tval loss: 0.00034\n",
      "epoch 17941 / 20000\n",
      "gradient norm: 0.022233927680645138, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00033\n",
      "\tval loss: 0.00034\n",
      "epoch 17942 / 20000\n",
      "gradient norm: 0.014609064848627895, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00033\n",
      "\tval loss: 0.00033\n",
      "epoch 17943 / 20000\n",
      "gradient norm: 0.019440969394054264, minimum ratio: 2.4499999999999997\n",
      "\ttrain loss: 0.00033\n",
      "\tval loss: 0.00034\n",
      "epoch 17944 / 20000\n",
      "gradient norm: 0.023435642768163234, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00033\n",
      "\tval loss: 0.00033\n",
      "epoch 17945 / 20000\n",
      "gradient norm: 0.01939075460541062, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00033\n",
      "\tval loss: 0.00033\n",
      "epoch 17946 / 20000\n",
      "gradient norm: 0.015509791352087632, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00033\n",
      "\tval loss: 0.00033\n",
      "epoch 17947 / 20000\n",
      "gradient norm: 0.010286646254826337, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00033\n",
      "\tval loss: 0.00033\n",
      "epoch 17948 / 20000\n",
      "gradient norm: 0.010593891696771607, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00033\n",
      "\tval loss: 0.00033\n",
      "epoch 17949 / 20000\n",
      "gradient norm: 0.022573365597054362, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00033\n",
      "\tval loss: 0.00033\n",
      "epoch 17950 / 20000\n",
      "gradient norm: 0.010117734156665392, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00032\n",
      "\tval loss: 0.00033\n",
      "epoch 17951 / 20000\n",
      "gradient norm: 0.009402050971402787, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00032\n",
      "\tval loss: 0.00033\n",
      "epoch 17952 / 20000\n",
      "gradient norm: 0.014490000685327686, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00032\n",
      "\tval loss: 0.00033\n",
      "epoch 17953 / 20000\n",
      "gradient norm: 0.016958613181486726, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00032\n",
      "\tval loss: 0.00033\n",
      "epoch 17954 / 20000\n",
      "gradient norm: 0.02901867136824876, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00033\n",
      "\tval loss: 0.00033\n",
      "epoch 17955 / 20000\n",
      "gradient norm: 0.03710948018124327, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00032\n",
      "\tval loss: 0.00033\n",
      "epoch 17956 / 20000\n",
      "gradient norm: 0.04606641491409391, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00033\n",
      "\tval loss: 0.00033\n",
      "epoch 17957 / 20000\n",
      "gradient norm: 0.04614275658968836, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00033\n",
      "\tval loss: 0.00033\n",
      "epoch 17958 / 20000\n",
      "gradient norm: 0.038650421891361475, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00032\n",
      "\tval loss: 0.00033\n",
      "epoch 17959 / 20000\n",
      "gradient norm: 0.026547854766249657, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00032\n",
      "\tval loss: 0.00033\n",
      "epoch 17960 / 20000\n",
      "gradient norm: 0.022473899167380296, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00032\n",
      "\tval loss: 0.00033\n",
      "epoch 17961 / 20000\n",
      "gradient norm: 0.014591514875064604, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00032\n",
      "\tval loss: 0.00033\n",
      "epoch 17962 / 20000\n",
      "gradient norm: 0.014357298787217587, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00032\n",
      "\tval loss: 0.00032\n",
      "epoch 17963 / 20000\n",
      "gradient norm: 0.020078609668416902, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00032\n",
      "\tval loss: 0.00033\n",
      "epoch 17964 / 20000\n",
      "gradient norm: 0.03751521388767287, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00032\n",
      "\tval loss: 0.00032\n",
      "epoch 17965 / 20000\n",
      "gradient norm: 0.015035686257760972, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00032\n",
      "\tval loss: 0.00032\n",
      "epoch 17966 / 20000\n",
      "gradient norm: 0.015448518824996427, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00032\n",
      "\tval loss: 0.00033\n",
      "epoch 17967 / 20000\n",
      "gradient norm: 0.019565432652598247, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00032\n",
      "\tval loss: 0.00032\n",
      "epoch 17968 / 20000\n",
      "gradient norm: 0.0395022522425279, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00032\n",
      "\tval loss: 0.00032\n",
      "epoch 17969 / 20000\n",
      "gradient norm: 0.049039242236176506, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00032\n",
      "\tval loss: 0.00032\n",
      "epoch 17970 / 20000\n",
      "gradient norm: 0.015608046349370852, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00032\n",
      "\tval loss: 0.00032\n",
      "epoch 17971 / 20000\n",
      "gradient norm: 0.02232544604339637, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00031\n",
      "\tval loss: 0.00032\n",
      "epoch 17972 / 20000\n",
      "gradient norm: 0.026054529000248294, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00031\n",
      "\tval loss: 0.00032\n",
      "epoch 17973 / 20000\n",
      "gradient norm: 0.027298622531816363, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00031\n",
      "\tval loss: 0.00032\n",
      "epoch 17974 / 20000\n",
      "gradient norm: 0.026496520353248343, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00031\n",
      "\tval loss: 0.00032\n",
      "epoch 17975 / 20000\n",
      "gradient norm: 0.03582439533784054, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00032\n",
      "\tval loss: 0.00032\n",
      "epoch 17976 / 20000\n",
      "gradient norm: 0.0347292608639691, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00032\n",
      "\tval loss: 0.00032\n",
      "epoch 17977 / 20000\n",
      "gradient norm: 0.027623204397968948, minimum ratio: 2.46578947368421\n",
      "\ttrain loss: 0.00031\n",
      "\tval loss: 0.00032\n",
      "epoch 17978 / 20000\n",
      "gradient norm: 0.018869256629841402, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00031\n",
      "\tval loss: 0.00032\n",
      "epoch 17979 / 20000\n",
      "gradient norm: 0.0221580199431628, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00031\n",
      "\tval loss: 0.00032\n",
      "epoch 17980 / 20000\n",
      "gradient norm: 0.011510864685988054, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00031\n",
      "\tval loss: 0.00032\n",
      "epoch 17981 / 20000\n",
      "gradient norm: 0.02923339416156523, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00031\n",
      "\tval loss: 0.00031\n",
      "epoch 17982 / 20000\n",
      "gradient norm: 0.04261270398274064, minimum ratio: 2.460526315789474\n",
      "\ttrain loss: 0.00031\n",
      "\tval loss: 0.00032\n",
      "epoch 17983 / 20000\n",
      "gradient norm: 0.02527375367935747, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00031\n",
      "\tval loss: 0.00031\n",
      "epoch 17984 / 20000\n",
      "gradient norm: 0.02354476705659181, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00031\n",
      "\tval loss: 0.00031\n",
      "epoch 17985 / 20000\n",
      "gradient norm: 0.015018770296592265, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00031\n",
      "\tval loss: 0.00031\n",
      "epoch 17986 / 20000\n",
      "gradient norm: 0.01418263473897241, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00031\n",
      "\tval loss: 0.00031\n",
      "epoch 17987 / 20000\n",
      "gradient norm: 0.01582792538101785, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00031\n",
      "\tval loss: 0.00031\n",
      "epoch 17988 / 20000\n",
      "gradient norm: 0.019598966639023274, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00031\n",
      "\tval loss: 0.00031\n",
      "epoch 17989 / 20000\n",
      "gradient norm: 0.023285171133466065, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00030\n",
      "\tval loss: 0.00031\n",
      "epoch 17990 / 20000\n",
      "gradient norm: 0.01042677513032686, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00030\n",
      "\tval loss: 0.00031\n",
      "epoch 17991 / 20000\n",
      "gradient norm: 0.008848735655192286, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00030\n",
      "\tval loss: 0.00031\n",
      "epoch 17992 / 20000\n",
      "gradient norm: 0.021395931515144184, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00031\n",
      "\tval loss: 0.00031\n",
      "epoch 17993 / 20000\n",
      "gradient norm: 0.02824097336269915, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00030\n",
      "\tval loss: 0.00031\n",
      "epoch 17994 / 20000\n",
      "gradient norm: 0.026643687451723963, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00030\n",
      "\tval loss: 0.00031\n",
      "epoch 17995 / 20000\n",
      "gradient norm: 0.01972099070553668, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00030\n",
      "\tval loss: 0.00031\n",
      "epoch 17996 / 20000\n",
      "gradient norm: 0.022762884676922113, minimum ratio: 2.46578947368421\n",
      "\ttrain loss: 0.00030\n",
      "\tval loss: 0.00031\n",
      "epoch 17997 / 20000\n",
      "gradient norm: 0.01388563826913014, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00030\n",
      "\tval loss: 0.00031\n",
      "epoch 17998 / 20000\n",
      "gradient norm: 0.028455574356485158, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00030\n",
      "\tval loss: 0.00031\n",
      "epoch 17999 / 20000\n",
      "gradient norm: 0.013534304540371522, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00030\n",
      "\tval loss: 0.00031\n",
      "epoch 18000 / 20000\n",
      "gradient norm: 0.014862017589621246, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00030\n",
      "\tval loss: 0.00031\n",
      "epoch 18001 / 20000\n",
      "gradient norm: 0.025609067175537348, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00030\n",
      "\tval loss: 0.00031\n",
      "epoch 18002 / 20000\n",
      "gradient norm: 0.022350475774146616, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00030\n",
      "\tval loss: 0.00031\n",
      "epoch 18003 / 20000\n",
      "gradient norm: 0.02442539611365646, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00030\n",
      "\tval loss: 0.00030\n",
      "epoch 18004 / 20000\n",
      "gradient norm: 0.02506333275232464, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00030\n",
      "\tval loss: 0.00030\n",
      "epoch 18005 / 20000\n",
      "gradient norm: 0.02883627964183688, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00030\n",
      "\tval loss: 0.00030\n",
      "epoch 18006 / 20000\n",
      "gradient norm: 0.014040771464351565, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00030\n",
      "\tval loss: 0.00030\n",
      "epoch 18007 / 20000\n",
      "gradient norm: 0.01991217234171927, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00030\n",
      "\tval loss: 0.00030\n",
      "epoch 18008 / 20000\n",
      "gradient norm: 0.02179894529399462, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00030\n",
      "\tval loss: 0.00030\n",
      "epoch 18009 / 20000\n",
      "gradient norm: 0.02667155201197602, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00030\n",
      "\tval loss: 0.00030\n",
      "epoch 18010 / 20000\n",
      "gradient norm: 0.028566711640451103, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00030\n",
      "\tval loss: 0.00030\n",
      "epoch 18011 / 20000\n",
      "gradient norm: 0.028806492977309972, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00030\n",
      "\tval loss: 0.00030\n",
      "epoch 18012 / 20000\n",
      "gradient norm: 0.024716321961022913, minimum ratio: 2.4421052631578943\n",
      "\ttrain loss: 0.00029\n",
      "\tval loss: 0.00030\n",
      "epoch 18013 / 20000\n",
      "gradient norm: 0.017981232987949625, minimum ratio: 2.452631578947368\n",
      "\ttrain loss: 0.00029\n",
      "\tval loss: 0.00030\n",
      "epoch 18014 / 20000\n",
      "gradient norm: 0.034229400858748704, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00030\n",
      "\tval loss: 0.00030\n",
      "epoch 18015 / 20000\n",
      "gradient norm: 0.021244400675641373, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00029\n",
      "\tval loss: 0.00030\n",
      "epoch 18016 / 20000\n",
      "gradient norm: 0.023182762961369008, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00029\n",
      "\tval loss: 0.00030\n",
      "epoch 18017 / 20000\n",
      "gradient norm: 0.015001162566477433, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00029\n",
      "\tval loss: 0.00030\n",
      "epoch 18018 / 20000\n",
      "gradient norm: 0.025361756386701018, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00029\n",
      "\tval loss: 0.00030\n",
      "epoch 18019 / 20000\n",
      "gradient norm: 0.028046948287737905, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00029\n",
      "\tval loss: 0.00030\n",
      "epoch 18020 / 20000\n",
      "gradient norm: 0.025979696365538985, minimum ratio: 2.460526315789474\n",
      "\ttrain loss: 0.00029\n",
      "\tval loss: 0.00030\n",
      "epoch 18021 / 20000\n",
      "gradient norm: 0.024665766366524622, minimum ratio: 2.436842105263158\n",
      "\ttrain loss: 0.00029\n",
      "\tval loss: 0.00030\n",
      "epoch 18022 / 20000\n",
      "gradient norm: 0.0388728363905102, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00029\n",
      "\tval loss: 0.00029\n",
      "epoch 18023 / 20000\n",
      "gradient norm: 0.03553573548560962, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00029\n",
      "\tval loss: 0.00030\n",
      "epoch 18024 / 20000\n",
      "gradient norm: 0.03264194226358086, minimum ratio: 2.4447368421052627\n",
      "\ttrain loss: 0.00029\n",
      "\tval loss: 0.00029\n",
      "epoch 18025 / 20000\n",
      "gradient norm: 0.025455638708081096, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00029\n",
      "\tval loss: 0.00030\n",
      "epoch 18026 / 20000\n",
      "gradient norm: 0.022675222193356603, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00029\n",
      "\tval loss: 0.00029\n",
      "epoch 18027 / 20000\n",
      "gradient norm: 0.016191882925340906, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00029\n",
      "\tval loss: 0.00029\n",
      "epoch 18028 / 20000\n",
      "gradient norm: 0.016068269324023277, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00029\n",
      "\tval loss: 0.00029\n",
      "epoch 18029 / 20000\n",
      "gradient norm: 0.013387692219112068, minimum ratio: 2.4499999999999997\n",
      "\ttrain loss: 0.00029\n",
      "\tval loss: 0.00029\n",
      "epoch 18030 / 20000\n",
      "gradient norm: 0.010202132471022196, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00028\n",
      "\tval loss: 0.00029\n",
      "epoch 18031 / 20000\n",
      "gradient norm: 0.013040246252785437, minimum ratio: 2.4447368421052635\n",
      "\ttrain loss: 0.00029\n",
      "\tval loss: 0.00029\n",
      "epoch 18032 / 20000\n",
      "gradient norm: 0.009115331318753306, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00028\n",
      "\tval loss: 0.00029\n",
      "epoch 18033 / 20000\n",
      "gradient norm: 0.018177061196183786, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00029\n",
      "\tval loss: 0.00029\n",
      "epoch 18034 / 20000\n",
      "gradient norm: 0.02416423213435337, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00028\n",
      "\tval loss: 0.00029\n",
      "epoch 18035 / 20000\n",
      "gradient norm: 0.018529373628553003, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00028\n",
      "\tval loss: 0.00029\n",
      "epoch 18036 / 20000\n",
      "gradient norm: 0.010023400885984302, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00028\n",
      "\tval loss: 0.00029\n",
      "epoch 18037 / 20000\n",
      "gradient norm: 0.014811562054092064, minimum ratio: 2.4447368421052635\n",
      "\ttrain loss: 0.00028\n",
      "\tval loss: 0.00029\n",
      "epoch 18038 / 20000\n",
      "gradient norm: 0.029030691832304, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00028\n",
      "\tval loss: 0.00029\n",
      "epoch 18039 / 20000\n",
      "gradient norm: 0.0378164853900671, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00028\n",
      "\tval loss: 0.00029\n",
      "epoch 18040 / 20000\n",
      "gradient norm: 0.03633643063949421, minimum ratio: 2.460526315789474\n",
      "\ttrain loss: 0.00028\n",
      "\tval loss: 0.00029\n",
      "epoch 18041 / 20000\n",
      "gradient norm: 0.030160648078890517, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00028\n",
      "\tval loss: 0.00029\n",
      "epoch 18042 / 20000\n",
      "gradient norm: 0.026342615339672193, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00028\n",
      "\tval loss: 0.00029\n",
      "epoch 18043 / 20000\n",
      "gradient norm: 0.02458645316073671, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00028\n",
      "\tval loss: 0.00029\n",
      "epoch 18044 / 20000\n",
      "gradient norm: 0.013763699680566788, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00028\n",
      "\tval loss: 0.00028\n",
      "epoch 18045 / 20000\n",
      "gradient norm: 0.022589913511183113, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00028\n",
      "\tval loss: 0.00029\n",
      "epoch 18046 / 20000\n",
      "gradient norm: 0.01133014986407943, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00028\n",
      "\tval loss: 0.00028\n",
      "epoch 18047 / 20000\n",
      "gradient norm: 0.016123469424201176, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00028\n",
      "\tval loss: 0.00028\n",
      "epoch 18048 / 20000\n",
      "gradient norm: 0.009907479703542776, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00028\n",
      "\tval loss: 0.00028\n",
      "epoch 18049 / 20000\n",
      "gradient norm: 0.01737761755066458, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00028\n",
      "\tval loss: 0.00028\n",
      "epoch 18050 / 20000\n",
      "gradient norm: 0.021387849643360823, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00028\n",
      "\tval loss: 0.00028\n",
      "epoch 18051 / 20000\n",
      "gradient norm: 0.032503942609764636, minimum ratio: 2.4894736842105267\n",
      "\ttrain loss: 0.00028\n",
      "\tval loss: 0.00028\n",
      "epoch 18052 / 20000\n",
      "gradient norm: 0.02490177465369925, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00028\n",
      "\tval loss: 0.00028\n",
      "epoch 18053 / 20000\n",
      "gradient norm: 0.02103251637890935, minimum ratio: 2.452631578947368\n",
      "\ttrain loss: 0.00028\n",
      "\tval loss: 0.00028\n",
      "epoch 18054 / 20000\n",
      "gradient norm: 0.018029566504992545, minimum ratio: 2.4499999999999997\n",
      "\ttrain loss: 0.00027\n",
      "\tval loss: 0.00028\n",
      "epoch 18055 / 20000\n",
      "gradient norm: 0.011812133627245203, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00027\n",
      "\tval loss: 0.00028\n",
      "epoch 18056 / 20000\n",
      "gradient norm: 0.018428857380058616, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00027\n",
      "\tval loss: 0.00028\n",
      "epoch 18057 / 20000\n",
      "gradient norm: 0.006226128476555459, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00027\n",
      "\tval loss: 0.00028\n",
      "epoch 18058 / 20000\n",
      "gradient norm: 0.012498791547841392, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00027\n",
      "\tval loss: 0.00028\n",
      "epoch 18059 / 20000\n",
      "gradient norm: 0.013378377290791832, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00027\n",
      "\tval loss: 0.00028\n",
      "epoch 18060 / 20000\n",
      "gradient norm: 0.009436273452593014, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00027\n",
      "\tval loss: 0.00028\n",
      "epoch 18061 / 20000\n",
      "gradient norm: 0.017407081264536828, minimum ratio: 2.465789473684211\n",
      "\ttrain loss: 0.00027\n",
      "\tval loss: 0.00028\n",
      "epoch 18062 / 20000\n",
      "gradient norm: 0.029308918048627675, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00027\n",
      "\tval loss: 0.00028\n",
      "epoch 18063 / 20000\n",
      "gradient norm: 0.026264437823556364, minimum ratio: 2.4842105263157896\n",
      "\ttrain loss: 0.00027\n",
      "\tval loss: 0.00028\n",
      "epoch 18064 / 20000\n",
      "gradient norm: 0.01309225952718407, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00027\n",
      "\tval loss: 0.00028\n",
      "epoch 18065 / 20000\n",
      "gradient norm: 0.032724246149882674, minimum ratio: 2.4499999999999997\n",
      "\ttrain loss: 0.00027\n",
      "\tval loss: 0.00028\n",
      "epoch 18066 / 20000\n",
      "gradient norm: 0.030676451919134706, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00027\n",
      "\tval loss: 0.00028\n",
      "epoch 18067 / 20000\n",
      "gradient norm: 0.029803016281221062, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00027\n",
      "\tval loss: 0.00028\n",
      "epoch 18068 / 20000\n",
      "gradient norm: 0.018604531709570438, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00027\n",
      "\tval loss: 0.00027\n",
      "epoch 18069 / 20000\n",
      "gradient norm: 0.015126657293876633, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00027\n",
      "\tval loss: 0.00028\n",
      "epoch 18070 / 20000\n",
      "gradient norm: 0.015993902838090435, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00027\n",
      "\tval loss: 0.00027\n",
      "epoch 18071 / 20000\n",
      "gradient norm: 0.016338147994247265, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00027\n",
      "\tval loss: 0.00028\n",
      "epoch 18072 / 20000\n",
      "gradient norm: 0.016867205122252926, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00027\n",
      "\tval loss: 0.00027\n",
      "epoch 18073 / 20000\n",
      "gradient norm: 0.016073026665253565, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00027\n",
      "\tval loss: 0.00027\n",
      "epoch 18074 / 20000\n",
      "gradient norm: 0.012948376170243137, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00027\n",
      "\tval loss: 0.00027\n",
      "epoch 18075 / 20000\n",
      "gradient norm: 0.019107419459032826, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00027\n",
      "\tval loss: 0.00027\n",
      "epoch 18076 / 20000\n",
      "gradient norm: 0.01727618122822605, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00027\n",
      "\tval loss: 0.00027\n",
      "epoch 18077 / 20000\n",
      "gradient norm: 0.013172024657251313, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00026\n",
      "\tval loss: 0.00027\n",
      "epoch 18078 / 20000\n",
      "gradient norm: 0.01148034434299916, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00026\n",
      "\tval loss: 0.00027\n",
      "epoch 18079 / 20000\n",
      "gradient norm: 0.02014085656264797, minimum ratio: 2.460526315789474\n",
      "\ttrain loss: 0.00026\n",
      "\tval loss: 0.00027\n",
      "epoch 18080 / 20000\n",
      "gradient norm: 0.024128874792950228, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00026\n",
      "\tval loss: 0.00027\n",
      "epoch 18081 / 20000\n",
      "gradient norm: 0.013976229325635359, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00026\n",
      "\tval loss: 0.00027\n",
      "epoch 18082 / 20000\n",
      "gradient norm: 0.013564659282565117, minimum ratio: 2.423684210526316\n",
      "\ttrain loss: 0.00026\n",
      "\tval loss: 0.00027\n",
      "epoch 18083 / 20000\n",
      "gradient norm: 0.01672014474752359, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00026\n",
      "\tval loss: 0.00027\n",
      "epoch 18084 / 20000\n",
      "gradient norm: 0.012282217532629147, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00026\n",
      "\tval loss: 0.00027\n",
      "epoch 18085 / 20000\n",
      "gradient norm: 0.006492015570984222, minimum ratio: 2.4684210526315784\n",
      "\ttrain loss: 0.00026\n",
      "\tval loss: 0.00027\n",
      "epoch 18086 / 20000\n",
      "gradient norm: 0.011877913115313277, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00026\n",
      "\tval loss: 0.00027\n",
      "epoch 18087 / 20000\n",
      "gradient norm: 0.02383870625635609, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00026\n",
      "\tval loss: 0.00027\n",
      "epoch 18088 / 20000\n",
      "gradient norm: 0.02852287798305042, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00026\n",
      "\tval loss: 0.00027\n",
      "epoch 18089 / 20000\n",
      "gradient norm: 0.03591348818736151, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00026\n",
      "\tval loss: 0.00027\n",
      "epoch 18090 / 20000\n",
      "gradient norm: 0.019711732180439867, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00026\n",
      "\tval loss: 0.00027\n",
      "epoch 18091 / 20000\n",
      "gradient norm: 0.016007559912395664, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00026\n",
      "\tval loss: 0.00026\n",
      "epoch 18092 / 20000\n",
      "gradient norm: 0.02010894619161263, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00026\n",
      "\tval loss: 0.00026\n",
      "epoch 18093 / 20000\n",
      "gradient norm: 0.017781483882572502, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00026\n",
      "\tval loss: 0.00026\n",
      "epoch 18094 / 20000\n",
      "gradient norm: 0.011139655005536042, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00026\n",
      "\tval loss: 0.00026\n",
      "epoch 18095 / 20000\n",
      "gradient norm: 0.011678466631565243, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00026\n",
      "\tval loss: 0.00026\n",
      "epoch 18096 / 20000\n",
      "gradient norm: 0.012839231756515801, minimum ratio: 2.436842105263158\n",
      "\ttrain loss: 0.00026\n",
      "\tval loss: 0.00026\n",
      "epoch 18097 / 20000\n",
      "gradient norm: 0.0075244274630676955, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00026\n",
      "\tval loss: 0.00026\n",
      "epoch 18098 / 20000\n",
      "gradient norm: 0.010592396662104875, minimum ratio: 2.4684210526315784\n",
      "\ttrain loss: 0.00025\n",
      "\tval loss: 0.00026\n",
      "epoch 18099 / 20000\n",
      "gradient norm: 0.013254123798105866, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00025\n",
      "\tval loss: 0.00026\n",
      "epoch 18100 / 20000\n",
      "gradient norm: 0.0170331078406889, minimum ratio: 2.4447368421052635\n",
      "\ttrain loss: 0.00025\n",
      "\tval loss: 0.00026\n",
      "epoch 18101 / 20000\n",
      "gradient norm: 0.015172074970905669, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00025\n",
      "\tval loss: 0.00026\n",
      "epoch 18102 / 20000\n",
      "gradient norm: 0.01681984303286299, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00025\n",
      "\tval loss: 0.00026\n",
      "epoch 18103 / 20000\n",
      "gradient norm: 0.020264118182240054, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.00025\n",
      "\tval loss: 0.00026\n",
      "epoch 18104 / 20000\n",
      "gradient norm: 0.03057192574487999, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00025\n",
      "\tval loss: 0.00026\n",
      "epoch 18105 / 20000\n",
      "gradient norm: 0.015367188228992745, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00025\n",
      "\tval loss: 0.00026\n",
      "epoch 18106 / 20000\n",
      "gradient norm: 0.01804821557016112, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00025\n",
      "\tval loss: 0.00026\n",
      "epoch 18107 / 20000\n",
      "gradient norm: 0.03478267171885818, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00026\n",
      "\tval loss: 0.00026\n",
      "epoch 18108 / 20000\n",
      "gradient norm: 0.04025016337982379, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00025\n",
      "\tval loss: 0.00026\n",
      "epoch 18109 / 20000\n",
      "gradient norm: 0.025635062309447676, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00025\n",
      "\tval loss: 0.00026\n",
      "epoch 18110 / 20000\n",
      "gradient norm: 0.021411639027064666, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00025\n",
      "\tval loss: 0.00026\n",
      "epoch 18111 / 20000\n",
      "gradient norm: 0.015321084443712607, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00025\n",
      "\tval loss: 0.00026\n",
      "epoch 18112 / 20000\n",
      "gradient norm: 0.014579010370653123, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00025\n",
      "\tval loss: 0.00026\n",
      "epoch 18113 / 20000\n",
      "gradient norm: 0.01438040989160072, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00025\n",
      "\tval loss: 0.00026\n",
      "epoch 18114 / 20000\n",
      "gradient norm: 0.01461107944487594, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00025\n",
      "\tval loss: 0.00025\n",
      "epoch 18115 / 20000\n",
      "gradient norm: 0.016247946565272287, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00025\n",
      "\tval loss: 0.00026\n",
      "epoch 18116 / 20000\n",
      "gradient norm: 0.021799798210849985, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00025\n",
      "\tval loss: 0.00025\n",
      "epoch 18117 / 20000\n",
      "gradient norm: 0.021360614395234734, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00025\n",
      "\tval loss: 0.00025\n",
      "epoch 18118 / 20000\n",
      "gradient norm: 0.017268105628318153, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00025\n",
      "\tval loss: 0.00025\n",
      "epoch 18119 / 20000\n",
      "gradient norm: 0.013801531109493226, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00025\n",
      "\tval loss: 0.00025\n",
      "epoch 18120 / 20000\n",
      "gradient norm: 0.013000434846617281, minimum ratio: 2.4394736842105265\n",
      "\ttrain loss: 0.00025\n",
      "\tval loss: 0.00025\n",
      "epoch 18121 / 20000\n",
      "gradient norm: 0.008566021744627506, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00025\n",
      "\tval loss: 0.00025\n",
      "epoch 18122 / 20000\n",
      "gradient norm: 0.014050693600438535, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00025\n",
      "\tval loss: 0.00025\n",
      "epoch 18123 / 20000\n",
      "gradient norm: 0.0285502215847373, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00025\n",
      "\tval loss: 0.00025\n",
      "epoch 18124 / 20000\n",
      "gradient norm: 0.009694708860479295, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00024\n",
      "\tval loss: 0.00025\n",
      "epoch 18125 / 20000\n",
      "gradient norm: 0.025211533211404458, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00024\n",
      "\tval loss: 0.00025\n",
      "epoch 18126 / 20000\n",
      "gradient norm: 0.01676931549445726, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00024\n",
      "\tval loss: 0.00025\n",
      "epoch 18127 / 20000\n",
      "gradient norm: 0.017373060749378055, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00024\n",
      "\tval loss: 0.00025\n",
      "epoch 18128 / 20000\n",
      "gradient norm: 0.022306891871267, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00024\n",
      "\tval loss: 0.00025\n",
      "epoch 18129 / 20000\n",
      "gradient norm: 0.026097989815752953, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00024\n",
      "\tval loss: 0.00025\n",
      "epoch 18130 / 20000\n",
      "gradient norm: 0.022161706583574414, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00024\n",
      "\tval loss: 0.00025\n",
      "epoch 18131 / 20000\n",
      "gradient norm: 0.027885070885531604, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00024\n",
      "\tval loss: 0.00025\n",
      "epoch 18132 / 20000\n",
      "gradient norm: 0.021537730586715043, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00024\n",
      "\tval loss: 0.00025\n",
      "epoch 18133 / 20000\n",
      "gradient norm: 0.01970794636872597, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00024\n",
      "\tval loss: 0.00025\n",
      "epoch 18134 / 20000\n",
      "gradient norm: 0.024608073726994917, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00024\n",
      "\tval loss: 0.00025\n",
      "epoch 18135 / 20000\n",
      "gradient norm: 0.019738510280149058, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00024\n",
      "\tval loss: 0.00025\n",
      "epoch 18136 / 20000\n",
      "gradient norm: 0.015612346265697852, minimum ratio: 2.460526315789474\n",
      "\ttrain loss: 0.00024\n",
      "\tval loss: 0.00025\n",
      "epoch 18137 / 20000\n",
      "gradient norm: 0.01699329595430754, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00024\n",
      "\tval loss: 0.00024\n",
      "epoch 18138 / 20000\n",
      "gradient norm: 0.011318169301375747, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00024\n",
      "\tval loss: 0.00025\n",
      "epoch 18139 / 20000\n",
      "gradient norm: 0.02658381780202035, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00024\n",
      "\tval loss: 0.00024\n",
      "epoch 18140 / 20000\n",
      "gradient norm: 0.02354335243580863, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00024\n",
      "\tval loss: 0.00025\n",
      "epoch 18141 / 20000\n",
      "gradient norm: 0.032712443731725216, minimum ratio: 2.4421052631578943\n",
      "\ttrain loss: 0.00024\n",
      "\tval loss: 0.00024\n",
      "epoch 18142 / 20000\n",
      "gradient norm: 0.02667416399344802, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00024\n",
      "\tval loss: 0.00024\n",
      "epoch 18143 / 20000\n",
      "gradient norm: 0.02666306385071948, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00024\n",
      "\tval loss: 0.00024\n",
      "epoch 18144 / 20000\n",
      "gradient norm: 0.02609342141658999, minimum ratio: 2.46578947368421\n",
      "\ttrain loss: 0.00024\n",
      "\tval loss: 0.00024\n",
      "epoch 18145 / 20000\n",
      "gradient norm: 0.014876346787787043, minimum ratio: 2.46578947368421\n",
      "\ttrain loss: 0.00023\n",
      "\tval loss: 0.00025\n",
      "epoch 18146 / 20000\n",
      "gradient norm: 0.02558464542380534, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00024\n",
      "\tval loss: 0.00024\n",
      "epoch 18147 / 20000\n",
      "gradient norm: 0.021118144009960815, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00024\n",
      "\tval loss: 0.00024\n",
      "epoch 18148 / 20000\n",
      "gradient norm: 0.020094905863516033, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00023\n",
      "\tval loss: 0.00024\n",
      "epoch 18149 / 20000\n",
      "gradient norm: 0.022663459414616227, minimum ratio: 2.46578947368421\n",
      "\ttrain loss: 0.00023\n",
      "\tval loss: 0.00024\n",
      "epoch 18150 / 20000\n",
      "gradient norm: 0.0135060814791359, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00023\n",
      "\tval loss: 0.00024\n",
      "epoch 18151 / 20000\n",
      "gradient norm: 0.022000485798344016, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00023\n",
      "\tval loss: 0.00024\n",
      "epoch 18152 / 20000\n",
      "gradient norm: 0.015499838162213564, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00023\n",
      "\tval loss: 0.00024\n",
      "epoch 18153 / 20000\n",
      "gradient norm: 0.02911569707794115, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00023\n",
      "\tval loss: 0.00024\n",
      "epoch 18154 / 20000\n",
      "gradient norm: 0.01761181154870428, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00023\n",
      "\tval loss: 0.00024\n",
      "epoch 18155 / 20000\n",
      "gradient norm: 0.026958950445987284, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00023\n",
      "\tval loss: 0.00024\n",
      "epoch 18156 / 20000\n",
      "gradient norm: 0.02757132740225643, minimum ratio: 2.4894736842105267\n",
      "\ttrain loss: 0.00023\n",
      "\tval loss: 0.00024\n",
      "epoch 18157 / 20000\n",
      "gradient norm: 0.017153053820948116, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00023\n",
      "\tval loss: 0.00024\n",
      "epoch 18158 / 20000\n",
      "gradient norm: 0.014615085936384276, minimum ratio: 2.4894736842105267\n",
      "\ttrain loss: 0.00023\n",
      "\tval loss: 0.00024\n",
      "epoch 18159 / 20000\n",
      "gradient norm: 0.008992847404442728, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00023\n",
      "\tval loss: 0.00024\n",
      "epoch 18160 / 20000\n",
      "gradient norm: 0.01026264413667377, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00023\n",
      "\tval loss: 0.00024\n",
      "epoch 18161 / 20000\n",
      "gradient norm: 0.015440294548170641, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00023\n",
      "\tval loss: 0.00024\n",
      "epoch 18162 / 20000\n",
      "gradient norm: 0.018119934597052634, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00023\n",
      "\tval loss: 0.00024\n",
      "epoch 18163 / 20000\n",
      "gradient norm: 0.008405486718402244, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00023\n",
      "\tval loss: 0.00024\n",
      "epoch 18164 / 20000\n",
      "gradient norm: 0.021143126534298062, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00023\n",
      "\tval loss: 0.00024\n",
      "epoch 18165 / 20000\n",
      "gradient norm: 0.020275870949262753, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00023\n",
      "\tval loss: 0.00023\n",
      "epoch 18166 / 20000\n",
      "gradient norm: 0.02328112709801644, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00023\n",
      "\tval loss: 0.00023\n",
      "epoch 18167 / 20000\n",
      "gradient norm: 0.011893418792169541, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00023\n",
      "\tval loss: 0.00023\n",
      "epoch 18168 / 20000\n",
      "gradient norm: 0.019457030051853508, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00023\n",
      "\tval loss: 0.00023\n",
      "epoch 18169 / 20000\n",
      "gradient norm: 0.018199528334662318, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00023\n",
      "\tval loss: 0.00023\n",
      "epoch 18170 / 20000\n",
      "gradient norm: 0.019310846517328173, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00023\n",
      "\tval loss: 0.00023\n",
      "epoch 18171 / 20000\n",
      "gradient norm: 0.013426683988654986, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00023\n",
      "\tval loss: 0.00023\n",
      "epoch 18172 / 20000\n",
      "gradient norm: 0.010032206278992817, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00022\n",
      "\tval loss: 0.00023\n",
      "epoch 18173 / 20000\n",
      "gradient norm: 0.006619296815188136, minimum ratio: 2.460526315789474\n",
      "\ttrain loss: 0.00022\n",
      "\tval loss: 0.00023\n",
      "epoch 18174 / 20000\n",
      "gradient norm: 0.008954521184932673, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00022\n",
      "\tval loss: 0.00023\n",
      "epoch 18175 / 20000\n",
      "gradient norm: 0.010929848358500749, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00022\n",
      "\tval loss: 0.00023\n",
      "epoch 18176 / 20000\n",
      "gradient norm: 0.024915172602050006, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00022\n",
      "\tval loss: 0.00023\n",
      "epoch 18177 / 20000\n",
      "gradient norm: 0.021816108579514548, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00022\n",
      "\tval loss: 0.00023\n",
      "epoch 18178 / 20000\n",
      "gradient norm: 0.009083366487175226, minimum ratio: 2.4894736842105267\n",
      "\ttrain loss: 0.00022\n",
      "\tval loss: 0.00023\n",
      "epoch 18179 / 20000\n",
      "gradient norm: 0.014293627551523969, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00022\n",
      "\tval loss: 0.00023\n",
      "epoch 18180 / 20000\n",
      "gradient norm: 0.019483117677737027, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00022\n",
      "\tval loss: 0.00023\n",
      "epoch 18181 / 20000\n",
      "gradient norm: 0.01119188970187679, minimum ratio: 2.4421052631578943\n",
      "\ttrain loss: 0.00022\n",
      "\tval loss: 0.00023\n",
      "epoch 18182 / 20000\n",
      "gradient norm: 0.02235449361614883, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00022\n",
      "\tval loss: 0.00023\n",
      "epoch 18183 / 20000\n",
      "gradient norm: 0.014410713134566322, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00022\n",
      "\tval loss: 0.00023\n",
      "epoch 18184 / 20000\n",
      "gradient norm: 0.020277260307921097, minimum ratio: 2.418421052631579\n",
      "\ttrain loss: 0.00022\n",
      "\tval loss: 0.00023\n",
      "epoch 18185 / 20000\n",
      "gradient norm: 0.014725563290994614, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00022\n",
      "\tval loss: 0.00023\n",
      "epoch 18186 / 20000\n",
      "gradient norm: 0.026386522134998813, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00022\n",
      "\tval loss: 0.00023\n",
      "epoch 18187 / 20000\n",
      "gradient norm: 0.02777976094512269, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00022\n",
      "\tval loss: 0.00023\n",
      "epoch 18188 / 20000\n",
      "gradient norm: 0.03081152547383681, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00022\n",
      "\tval loss: 0.00023\n",
      "epoch 18189 / 20000\n",
      "gradient norm: 0.03238495852565393, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00022\n",
      "\tval loss: 0.00023\n",
      "epoch 18190 / 20000\n",
      "gradient norm: 0.014721852116053924, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00022\n",
      "\tval loss: 0.00022\n",
      "epoch 18191 / 20000\n",
      "gradient norm: 0.01879278221167624, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00022\n",
      "\tval loss: 0.00023\n",
      "epoch 18192 / 20000\n",
      "gradient norm: 0.01717500318773091, minimum ratio: 2.460526315789474\n",
      "\ttrain loss: 0.00022\n",
      "\tval loss: 0.00022\n",
      "epoch 18193 / 20000\n",
      "gradient norm: 0.021585383859928697, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00022\n",
      "\tval loss: 0.00022\n",
      "epoch 18194 / 20000\n",
      "gradient norm: 0.019256653380580246, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00022\n",
      "\tval loss: 0.00022\n",
      "epoch 18195 / 20000\n",
      "gradient norm: 0.014829794003162533, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00022\n",
      "\tval loss: 0.00022\n",
      "epoch 18196 / 20000\n",
      "gradient norm: 0.00964416099304799, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00022\n",
      "\tval loss: 0.00022\n",
      "epoch 18197 / 20000\n",
      "gradient norm: 0.01005935890134424, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00022\n",
      "\tval loss: 0.00022\n",
      "epoch 18198 / 20000\n",
      "gradient norm: 0.008280632784590125, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00022\n",
      "\tval loss: 0.00022\n",
      "epoch 18199 / 20000\n",
      "gradient norm: 0.01618165339459665, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00022\n",
      "\tval loss: 0.00022\n",
      "epoch 18200 / 20000\n",
      "gradient norm: 0.02088397229090333, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00022\n",
      "\tval loss: 0.00022\n",
      "epoch 18201 / 20000\n",
      "gradient norm: 0.027708418696420267, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00021\n",
      "\tval loss: 0.00022\n",
      "epoch 18202 / 20000\n",
      "gradient norm: 0.0171818877588521, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00021\n",
      "\tval loss: 0.00022\n",
      "epoch 18203 / 20000\n",
      "gradient norm: 0.012506912491517141, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00021\n",
      "\tval loss: 0.00022\n",
      "epoch 18204 / 20000\n",
      "gradient norm: 0.012383438952383585, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00021\n",
      "\tval loss: 0.00022\n",
      "epoch 18205 / 20000\n",
      "gradient norm: 0.01604233100079, minimum ratio: 2.4394736842105265\n",
      "\ttrain loss: 0.00021\n",
      "\tval loss: 0.00022\n",
      "epoch 18206 / 20000\n",
      "gradient norm: 0.023654111137147993, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00021\n",
      "\tval loss: 0.00022\n",
      "epoch 18207 / 20000\n",
      "gradient norm: 0.025745876569999382, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00021\n",
      "\tval loss: 0.00022\n",
      "epoch 18208 / 20000\n",
      "gradient norm: 0.030493744532577693, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00021\n",
      "\tval loss: 0.00022\n",
      "epoch 18209 / 20000\n",
      "gradient norm: 0.021603665314614773, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00021\n",
      "\tval loss: 0.00022\n",
      "epoch 18210 / 20000\n",
      "gradient norm: 0.017500805828603916, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00021\n",
      "\tval loss: 0.00022\n",
      "epoch 18211 / 20000\n",
      "gradient norm: 0.014908434735843912, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00021\n",
      "\tval loss: 0.00022\n",
      "epoch 18212 / 20000\n",
      "gradient norm: 0.01852197370317299, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00021\n",
      "\tval loss: 0.00022\n",
      "epoch 18213 / 20000\n",
      "gradient norm: 0.01554349940852262, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00021\n",
      "\tval loss: 0.00022\n",
      "epoch 18214 / 20000\n",
      "gradient norm: 0.012866961274994537, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00021\n",
      "\tval loss: 0.00022\n",
      "epoch 18215 / 20000\n",
      "gradient norm: 0.026935201953165233, minimum ratio: 2.4421052631578943\n",
      "\ttrain loss: 0.00021\n",
      "\tval loss: 0.00022\n",
      "epoch 18216 / 20000\n",
      "gradient norm: 0.0244719969923608, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00021\n",
      "\tval loss: 0.00022\n",
      "epoch 18217 / 20000\n",
      "gradient norm: 0.02173865635995753, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00021\n",
      "\tval loss: 0.00022\n",
      "epoch 18218 / 20000\n",
      "gradient norm: 0.02262256742687896, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00021\n",
      "\tval loss: 0.00021\n",
      "epoch 18219 / 20000\n",
      "gradient norm: 0.022760978114092723, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00021\n",
      "\tval loss: 0.00022\n",
      "epoch 18220 / 20000\n",
      "gradient norm: 0.014331446960568428, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00021\n",
      "\tval loss: 0.00021\n",
      "epoch 18221 / 20000\n",
      "gradient norm: 0.024891291366657242, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00021\n",
      "\tval loss: 0.00021\n",
      "epoch 18222 / 20000\n",
      "gradient norm: 0.02989231754327193, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00021\n",
      "\tval loss: 0.00021\n",
      "epoch 18223 / 20000\n",
      "gradient norm: 0.01521307072835043, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00021\n",
      "\tval loss: 0.00021\n",
      "epoch 18224 / 20000\n",
      "gradient norm: 0.029877021312131546, minimum ratio: 2.465789473684211\n",
      "\ttrain loss: 0.00021\n",
      "\tval loss: 0.00021\n",
      "epoch 18225 / 20000\n",
      "gradient norm: 0.006769100946257822, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00021\n",
      "\tval loss: 0.00021\n",
      "epoch 18226 / 20000\n",
      "gradient norm: 0.008561260750866495, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00020\n",
      "\tval loss: 0.00021\n",
      "epoch 18227 / 20000\n",
      "gradient norm: 0.01034196381806396, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00020\n",
      "\tval loss: 0.00021\n",
      "epoch 18228 / 20000\n",
      "gradient norm: 0.021273229329381138, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00021\n",
      "\tval loss: 0.00021\n",
      "epoch 18229 / 20000\n",
      "gradient norm: 0.014019136200658977, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00020\n",
      "\tval loss: 0.00021\n",
      "epoch 18230 / 20000\n",
      "gradient norm: 0.02543136168969795, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00020\n",
      "\tval loss: 0.00021\n",
      "epoch 18231 / 20000\n",
      "gradient norm: 0.016225078055867925, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00020\n",
      "\tval loss: 0.00021\n",
      "epoch 18232 / 20000\n",
      "gradient norm: 0.018781020859023556, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00020\n",
      "\tval loss: 0.00021\n",
      "epoch 18233 / 20000\n",
      "gradient norm: 0.02166774493525736, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00020\n",
      "\tval loss: 0.00021\n",
      "epoch 18234 / 20000\n",
      "gradient norm: 0.02278794231824577, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00020\n",
      "\tval loss: 0.00021\n",
      "epoch 18235 / 20000\n",
      "gradient norm: 0.013821423257468268, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00020\n",
      "\tval loss: 0.00021\n",
      "epoch 18236 / 20000\n",
      "gradient norm: 0.012976245867321268, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00020\n",
      "\tval loss: 0.00021\n",
      "epoch 18237 / 20000\n",
      "gradient norm: 0.012113730103010312, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00020\n",
      "\tval loss: 0.00021\n",
      "epoch 18238 / 20000\n",
      "gradient norm: 0.018256703158840537, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00020\n",
      "\tval loss: 0.00021\n",
      "epoch 18239 / 20000\n",
      "gradient norm: 0.01703546367934905, minimum ratio: 2.46578947368421\n",
      "\ttrain loss: 0.00020\n",
      "\tval loss: 0.00021\n",
      "epoch 18240 / 20000\n",
      "gradient norm: 0.020629984079278074, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00020\n",
      "\tval loss: 0.00021\n",
      "epoch 18241 / 20000\n",
      "gradient norm: 0.012800822674762458, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00020\n",
      "\tval loss: 0.00021\n",
      "epoch 18242 / 20000\n",
      "gradient norm: 0.009379271476063877, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00020\n",
      "\tval loss: 0.00021\n",
      "epoch 18243 / 20000\n",
      "gradient norm: 0.008977197081549093, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00020\n",
      "\tval loss: 0.00021\n",
      "epoch 18244 / 20000\n",
      "gradient norm: 0.012198593089124188, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00020\n",
      "\tval loss: 0.00021\n",
      "epoch 18245 / 20000\n",
      "gradient norm: 0.013594932213891298, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00020\n",
      "\tval loss: 0.00021\n",
      "epoch 18246 / 20000\n",
      "gradient norm: 0.018271597306011245, minimum ratio: 2.4815789473684213\n",
      "\ttrain loss: 0.00020\n",
      "\tval loss: 0.00021\n",
      "epoch 18247 / 20000\n",
      "gradient norm: 0.011136555549455807, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00020\n",
      "\tval loss: 0.00020\n",
      "epoch 18248 / 20000\n",
      "gradient norm: 0.006761251876014285, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00020\n",
      "\tval loss: 0.00020\n",
      "epoch 18249 / 20000\n",
      "gradient norm: 0.012200988290715031, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00020\n",
      "\tval loss: 0.00020\n",
      "epoch 18250 / 20000\n",
      "gradient norm: 0.0152270735707134, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00020\n",
      "\tval loss: 0.00020\n",
      "epoch 18251 / 20000\n",
      "gradient norm: 0.012526319682365283, minimum ratio: 2.4499999999999997\n",
      "\ttrain loss: 0.00020\n",
      "\tval loss: 0.00020\n",
      "epoch 18252 / 20000\n",
      "gradient norm: 0.015567185240797698, minimum ratio: 2.460526315789474\n",
      "\ttrain loss: 0.00020\n",
      "\tval loss: 0.00020\n",
      "epoch 18253 / 20000\n",
      "gradient norm: 0.013550579402362928, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00020\n",
      "\tval loss: 0.00020\n",
      "epoch 18254 / 20000\n",
      "gradient norm: 0.006145272243884392, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00019\n",
      "\tval loss: 0.00020\n",
      "epoch 18255 / 20000\n",
      "gradient norm: 0.004257713422703091, minimum ratio: 2.4736842105263155\n",
      "\ttrain loss: 0.00020\n",
      "\tval loss: 0.00020\n",
      "epoch 18256 / 20000\n",
      "gradient norm: 0.009757961612194777, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00020\n",
      "\tval loss: 0.00020\n",
      "epoch 18257 / 20000\n",
      "gradient norm: 0.008349111303687096, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00019\n",
      "\tval loss: 0.00020\n",
      "epoch 18258 / 20000\n",
      "gradient norm: 0.006649698851106223, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00019\n",
      "\tval loss: 0.00020\n",
      "epoch 18259 / 20000\n",
      "gradient norm: 0.005599666706984863, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00019\n",
      "\tval loss: 0.00020\n",
      "epoch 18260 / 20000\n",
      "gradient norm: 0.010500173084437847, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00019\n",
      "\tval loss: 0.00020\n",
      "epoch 18261 / 20000\n",
      "gradient norm: 0.020398865730385296, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00019\n",
      "\tval loss: 0.00020\n",
      "epoch 18262 / 20000\n",
      "gradient norm: 0.026564621774014086, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00019\n",
      "\tval loss: 0.00020\n",
      "epoch 18263 / 20000\n",
      "gradient norm: 0.037425267189973965, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00020\n",
      "\tval loss: 0.00020\n",
      "epoch 18264 / 20000\n",
      "gradient norm: 0.03711520813521929, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00019\n",
      "\tval loss: 0.00020\n",
      "epoch 18265 / 20000\n",
      "gradient norm: 0.02790030656615272, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00019\n",
      "\tval loss: 0.00020\n",
      "epoch 18266 / 20000\n",
      "gradient norm: 0.039294396119657904, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00019\n",
      "\tval loss: 0.00020\n",
      "epoch 18267 / 20000\n",
      "gradient norm: 0.031855893510510214, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00019\n",
      "\tval loss: 0.00020\n",
      "epoch 18268 / 20000\n",
      "gradient norm: 0.026117785411770456, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00019\n",
      "\tval loss: 0.00020\n",
      "epoch 18269 / 20000\n",
      "gradient norm: 0.01683898500050418, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00019\n",
      "\tval loss: 0.00020\n",
      "epoch 18270 / 20000\n",
      "gradient norm: 0.012789123284164816, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00019\n",
      "\tval loss: 0.00020\n",
      "epoch 18271 / 20000\n",
      "gradient norm: 0.015611915150657296, minimum ratio: 2.492105263157895\n",
      "\ttrain loss: 0.00019\n",
      "\tval loss: 0.00020\n",
      "epoch 18272 / 20000\n",
      "gradient norm: 0.019123156584100798, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00019\n",
      "\tval loss: 0.00020\n",
      "epoch 18273 / 20000\n",
      "gradient norm: 0.02169492549728602, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00019\n",
      "\tval loss: 0.00020\n",
      "epoch 18274 / 20000\n",
      "gradient norm: 0.010994932366884314, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00019\n",
      "\tval loss: 0.00019\n",
      "epoch 18275 / 20000\n",
      "gradient norm: 0.017005492700263858, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00019\n",
      "\tval loss: 0.00020\n",
      "epoch 18276 / 20000\n",
      "gradient norm: 0.008857765817083418, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00019\n",
      "\tval loss: 0.00019\n",
      "epoch 18277 / 20000\n",
      "gradient norm: 0.007684388401685283, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00019\n",
      "\tval loss: 0.00019\n",
      "epoch 18278 / 20000\n",
      "gradient norm: 0.013106261365464889, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00019\n",
      "\tval loss: 0.00019\n",
      "epoch 18279 / 20000\n",
      "gradient norm: 0.025784342898987234, minimum ratio: 2.4868421052631575\n",
      "\ttrain loss: 0.00019\n",
      "\tval loss: 0.00019\n",
      "epoch 18280 / 20000\n",
      "gradient norm: 0.011145486787427217, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00019\n",
      "\tval loss: 0.00020\n",
      "epoch 18281 / 20000\n",
      "gradient norm: 0.014423733766307123, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00019\n",
      "\tval loss: 0.00019\n",
      "epoch 18282 / 20000\n",
      "gradient norm: 0.018987155141076073, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00019\n",
      "\tval loss: 0.00019\n",
      "epoch 18283 / 20000\n",
      "gradient norm: 0.01906365467584692, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00019\n",
      "\tval loss: 0.00019\n",
      "epoch 18284 / 20000\n",
      "gradient norm: 0.014035822096047923, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00019\n",
      "\tval loss: 0.00019\n",
      "epoch 18285 / 20000\n",
      "gradient norm: 0.006583466340089217, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00019\n",
      "\tval loss: 0.00019\n",
      "epoch 18286 / 20000\n",
      "gradient norm: 0.01967418476124294, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00019\n",
      "\tval loss: 0.00019\n",
      "epoch 18287 / 20000\n",
      "gradient norm: 0.008073564938968047, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00018\n",
      "\tval loss: 0.00019\n",
      "epoch 18288 / 20000\n",
      "gradient norm: 0.014581439027097076, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00018\n",
      "\tval loss: 0.00019\n",
      "epoch 18289 / 20000\n",
      "gradient norm: 0.024719174049096182, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00019\n",
      "\tval loss: 0.00019\n",
      "epoch 18290 / 20000\n",
      "gradient norm: 0.034870082046836615, minimum ratio: 2.492105263157895\n",
      "\ttrain loss: 0.00019\n",
      "\tval loss: 0.00019\n",
      "epoch 18291 / 20000\n",
      "gradient norm: 0.030259581690188497, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00018\n",
      "\tval loss: 0.00019\n",
      "epoch 18292 / 20000\n",
      "gradient norm: 0.021472873413586058, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00018\n",
      "\tval loss: 0.00019\n",
      "epoch 18293 / 20000\n",
      "gradient norm: 0.021896053018281236, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00018\n",
      "\tval loss: 0.00019\n",
      "epoch 18294 / 20000\n",
      "gradient norm: 0.019402880512643605, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00018\n",
      "\tval loss: 0.00019\n",
      "epoch 18295 / 20000\n",
      "gradient norm: 0.015074706898303702, minimum ratio: 2.4868421052631575\n",
      "\ttrain loss: 0.00018\n",
      "\tval loss: 0.00019\n",
      "epoch 18296 / 20000\n",
      "gradient norm: 0.01800787536194548, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00018\n",
      "\tval loss: 0.00019\n",
      "epoch 18297 / 20000\n",
      "gradient norm: 0.009700920403702185, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00018\n",
      "\tval loss: 0.00019\n",
      "epoch 18298 / 20000\n",
      "gradient norm: 0.01283549054642208, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00018\n",
      "\tval loss: 0.00019\n",
      "epoch 18299 / 20000\n",
      "gradient norm: 0.011015977914212272, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00018\n",
      "\tval loss: 0.00019\n",
      "epoch 18300 / 20000\n",
      "gradient norm: 0.022828898567240685, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00018\n",
      "\tval loss: 0.00019\n",
      "epoch 18301 / 20000\n",
      "gradient norm: 0.017288164788624272, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00018\n",
      "\tval loss: 0.00019\n",
      "epoch 18302 / 20000\n",
      "gradient norm: 0.01697513711405918, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00018\n",
      "\tval loss: 0.00019\n",
      "epoch 18303 / 20000\n",
      "gradient norm: 0.012752707378240302, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00018\n",
      "\tval loss: 0.00019\n",
      "epoch 18304 / 20000\n",
      "gradient norm: 0.009838243830017745, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00018\n",
      "\tval loss: 0.00019\n",
      "epoch 18305 / 20000\n",
      "gradient norm: 0.00975676128291525, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00018\n",
      "\tval loss: 0.00019\n",
      "epoch 18306 / 20000\n",
      "gradient norm: 0.010328803648008034, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00018\n",
      "\tval loss: 0.00019\n",
      "epoch 18307 / 20000\n",
      "gradient norm: 0.01905464213632513, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00018\n",
      "\tval loss: 0.00018\n",
      "epoch 18308 / 20000\n",
      "gradient norm: 0.02010423713363707, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00018\n",
      "\tval loss: 0.00019\n",
      "epoch 18309 / 20000\n",
      "gradient norm: 0.021740398195106536, minimum ratio: 2.436842105263158\n",
      "\ttrain loss: 0.00018\n",
      "\tval loss: 0.00018\n",
      "epoch 18310 / 20000\n",
      "gradient norm: 0.016349397352314554, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00018\n",
      "\tval loss: 0.00018\n",
      "epoch 18311 / 20000\n",
      "gradient norm: 0.0094564079772681, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00018\n",
      "\tval loss: 0.00018\n",
      "epoch 18312 / 20000\n",
      "gradient norm: 0.009917447052430362, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00018\n",
      "\tval loss: 0.00018\n",
      "epoch 18313 / 20000\n",
      "gradient norm: 0.01775748754153028, minimum ratio: 2.460526315789474\n",
      "\ttrain loss: 0.00018\n",
      "\tval loss: 0.00018\n",
      "epoch 18314 / 20000\n",
      "gradient norm: 0.024708260083571076, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00018\n",
      "\tval loss: 0.00018\n",
      "epoch 18315 / 20000\n",
      "gradient norm: 0.023670009395573288, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00018\n",
      "\tval loss: 0.00018\n",
      "epoch 18316 / 20000\n",
      "gradient norm: 0.02322955516865477, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00018\n",
      "\tval loss: 0.00018\n",
      "epoch 18317 / 20000\n",
      "gradient norm: 0.044250322214793414, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00018\n",
      "\tval loss: 0.00018\n",
      "epoch 18318 / 20000\n",
      "gradient norm: 0.03865085623692721, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00018\n",
      "\tval loss: 0.00018\n",
      "epoch 18319 / 20000\n",
      "gradient norm: 0.035290476254886016, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00018\n",
      "\tval loss: 0.00018\n",
      "epoch 18320 / 20000\n",
      "gradient norm: 0.022503684682305902, minimum ratio: 2.4499999999999997\n",
      "\ttrain loss: 0.00018\n",
      "\tval loss: 0.00018\n",
      "epoch 18321 / 20000\n",
      "gradient norm: 0.03463798339362256, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00018\n",
      "\tval loss: 0.00018\n",
      "epoch 18322 / 20000\n",
      "gradient norm: 0.024364812183193862, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00017\n",
      "\tval loss: 0.00018\n",
      "epoch 18323 / 20000\n",
      "gradient norm: 0.031042531365528703, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00017\n",
      "\tval loss: 0.00018\n",
      "epoch 18324 / 20000\n",
      "gradient norm: 0.03174272598698735, minimum ratio: 2.4447368421052635\n",
      "\ttrain loss: 0.00018\n",
      "\tval loss: 0.00018\n",
      "epoch 18325 / 20000\n",
      "gradient norm: 0.04692806309321895, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00018\n",
      "\tval loss: 0.00018\n",
      "epoch 18326 / 20000\n",
      "gradient norm: 0.021920499042607844, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00017\n",
      "\tval loss: 0.00018\n",
      "epoch 18327 / 20000\n",
      "gradient norm: 0.03618441231083125, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00017\n",
      "\tval loss: 0.00018\n",
      "epoch 18328 / 20000\n",
      "gradient norm: 0.012074955069692805, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00017\n",
      "\tval loss: 0.00018\n",
      "epoch 18329 / 20000\n",
      "gradient norm: 0.011969451501499861, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00017\n",
      "\tval loss: 0.00018\n",
      "epoch 18330 / 20000\n",
      "gradient norm: 0.018740286672255024, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00017\n",
      "\tval loss: 0.00018\n",
      "epoch 18331 / 20000\n",
      "gradient norm: 0.023268630931852385, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00017\n",
      "\tval loss: 0.00018\n",
      "epoch 18332 / 20000\n",
      "gradient norm: 0.016104539652587846, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00017\n",
      "\tval loss: 0.00018\n",
      "epoch 18333 / 20000\n",
      "gradient norm: 0.02905366406776011, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00017\n",
      "\tval loss: 0.00018\n",
      "epoch 18334 / 20000\n",
      "gradient norm: 0.021638767182594165, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00017\n",
      "\tval loss: 0.00018\n",
      "epoch 18335 / 20000\n",
      "gradient norm: 0.02791257348144427, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00017\n",
      "\tval loss: 0.00018\n",
      "epoch 18336 / 20000\n",
      "gradient norm: 0.021234145649941638, minimum ratio: 2.465789473684211\n",
      "\ttrain loss: 0.00017\n",
      "\tval loss: 0.00018\n",
      "epoch 18337 / 20000\n",
      "gradient norm: 0.026135162013815716, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00017\n",
      "\tval loss: 0.00018\n",
      "epoch 18338 / 20000\n",
      "gradient norm: 0.021791080420371145, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00017\n",
      "\tval loss: 0.00018\n",
      "epoch 18339 / 20000\n",
      "gradient norm: 0.022717958316206932, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00017\n",
      "\tval loss: 0.00018\n",
      "epoch 18340 / 20000\n",
      "gradient norm: 0.025065623311093077, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00017\n",
      "\tval loss: 0.00018\n",
      "epoch 18341 / 20000\n",
      "gradient norm: 0.025155391049338505, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00017\n",
      "\tval loss: 0.00017\n",
      "epoch 18342 / 20000\n",
      "gradient norm: 0.024240487269707955, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00017\n",
      "\tval loss: 0.00017\n",
      "epoch 18343 / 20000\n",
      "gradient norm: 0.027443204569863155, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00017\n",
      "\tval loss: 0.00017\n",
      "epoch 18344 / 20000\n",
      "gradient norm: 0.020728889998281375, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00017\n",
      "\tval loss: 0.00017\n",
      "epoch 18345 / 20000\n",
      "gradient norm: 0.01956296426942572, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00017\n",
      "\tval loss: 0.00017\n",
      "epoch 18346 / 20000\n",
      "gradient norm: 0.02429013219079934, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00017\n",
      "\tval loss: 0.00017\n",
      "epoch 18347 / 20000\n",
      "gradient norm: 0.008900438057025895, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00017\n",
      "\tval loss: 0.00017\n",
      "epoch 18348 / 20000\n",
      "gradient norm: 0.009963101678295061, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00017\n",
      "\tval loss: 0.00017\n",
      "epoch 18349 / 20000\n",
      "gradient norm: 0.010572727169346763, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00017\n",
      "\tval loss: 0.00017\n",
      "epoch 18350 / 20000\n",
      "gradient norm: 0.027210374013520777, minimum ratio: 2.46578947368421\n",
      "\ttrain loss: 0.00017\n",
      "\tval loss: 0.00017\n",
      "epoch 18351 / 20000\n",
      "gradient norm: 0.022600727214012295, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00017\n",
      "\tval loss: 0.00017\n",
      "epoch 18352 / 20000\n",
      "gradient norm: 0.024659653950948268, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00017\n",
      "\tval loss: 0.00017\n",
      "epoch 18353 / 20000\n",
      "gradient norm: 0.02922299801139161, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00017\n",
      "\tval loss: 0.00017\n",
      "epoch 18354 / 20000\n",
      "gradient norm: 0.014640873298048973, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00016\n",
      "\tval loss: 0.00017\n",
      "epoch 18355 / 20000\n",
      "gradient norm: 0.01259233060409315, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00016\n",
      "\tval loss: 0.00017\n",
      "epoch 18356 / 20000\n",
      "gradient norm: 0.021147278865100816, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00016\n",
      "\tval loss: 0.00017\n",
      "epoch 18357 / 20000\n",
      "gradient norm: 0.02051246864721179, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00016\n",
      "\tval loss: 0.00017\n",
      "epoch 18358 / 20000\n",
      "gradient norm: 0.022801858227467164, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00016\n",
      "\tval loss: 0.00017\n",
      "epoch 18359 / 20000\n",
      "gradient norm: 0.019200143819034565, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00016\n",
      "\tval loss: 0.00017\n",
      "epoch 18360 / 20000\n",
      "gradient norm: 0.016170648363186046, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00016\n",
      "\tval loss: 0.00017\n",
      "epoch 18361 / 20000\n",
      "gradient norm: 0.012163076869910583, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00016\n",
      "\tval loss: 0.00017\n",
      "epoch 18362 / 20000\n",
      "gradient norm: 0.010202857651165687, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00016\n",
      "\tval loss: 0.00017\n",
      "epoch 18363 / 20000\n",
      "gradient norm: 0.0111376415588893, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00016\n",
      "\tval loss: 0.00017\n",
      "epoch 18364 / 20000\n",
      "gradient norm: 0.013211645054980181, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00016\n",
      "\tval loss: 0.00017\n",
      "epoch 18365 / 20000\n",
      "gradient norm: 0.011899676435859874, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00016\n",
      "\tval loss: 0.00017\n",
      "epoch 18366 / 20000\n",
      "gradient norm: 0.012787424064299557, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00016\n",
      "\tval loss: 0.00017\n",
      "epoch 18367 / 20000\n",
      "gradient norm: 0.013924362632678822, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00016\n",
      "\tval loss: 0.00017\n",
      "epoch 18368 / 20000\n",
      "gradient norm: 0.007685249162022956, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00016\n",
      "\tval loss: 0.00017\n",
      "epoch 18369 / 20000\n",
      "gradient norm: 0.010767524770926684, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00016\n",
      "\tval loss: 0.00017\n",
      "epoch 18370 / 20000\n",
      "gradient norm: 0.013317249569809064, minimum ratio: 2.4815789473684213\n",
      "\ttrain loss: 0.00016\n",
      "\tval loss: 0.00017\n",
      "epoch 18371 / 20000\n",
      "gradient norm: 0.013687254715478048, minimum ratio: 2.465789473684211\n",
      "\ttrain loss: 0.00016\n",
      "\tval loss: 0.00017\n",
      "epoch 18372 / 20000\n",
      "gradient norm: 0.017165883880807087, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00016\n",
      "\tval loss: 0.00017\n",
      "epoch 18373 / 20000\n",
      "gradient norm: 0.014856921188766137, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00016\n",
      "\tval loss: 0.00017\n",
      "epoch 18374 / 20000\n",
      "gradient norm: 0.021132836904143915, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00016\n",
      "\tval loss: 0.00017\n",
      "epoch 18375 / 20000\n",
      "gradient norm: 0.01909045610227622, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00016\n",
      "\tval loss: 0.00017\n",
      "epoch 18376 / 20000\n",
      "gradient norm: 0.005857207208464388, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00016\n",
      "\tval loss: 0.00016\n",
      "epoch 18377 / 20000\n",
      "gradient norm: 0.008481961194775067, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00016\n",
      "\tval loss: 0.00017\n",
      "epoch 18378 / 20000\n",
      "gradient norm: 0.010026494390331209, minimum ratio: 2.4394736842105265\n",
      "\ttrain loss: 0.00016\n",
      "\tval loss: 0.00016\n",
      "epoch 18379 / 20000\n",
      "gradient norm: 0.008217212031013332, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00016\n",
      "\tval loss: 0.00016\n",
      "epoch 18380 / 20000\n",
      "gradient norm: 0.008650143427075818, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00016\n",
      "\tval loss: 0.00016\n",
      "epoch 18381 / 20000\n",
      "gradient norm: 0.01210077985888347, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00016\n",
      "\tval loss: 0.00016\n",
      "epoch 18382 / 20000\n",
      "gradient norm: 0.019860177708324045, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00016\n",
      "\tval loss: 0.00016\n",
      "epoch 18383 / 20000\n",
      "gradient norm: 0.02036837000923697, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00016\n",
      "\tval loss: 0.00016\n",
      "epoch 18384 / 20000\n",
      "gradient norm: 0.012178255987237208, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00016\n",
      "\tval loss: 0.00016\n",
      "epoch 18385 / 20000\n",
      "gradient norm: 0.01475886517437175, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00016\n",
      "\tval loss: 0.00016\n",
      "epoch 18386 / 20000\n",
      "gradient norm: 0.02227533928817138, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00016\n",
      "\tval loss: 0.00016\n",
      "epoch 18387 / 20000\n",
      "gradient norm: 0.011557990641449578, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00015\n",
      "\tval loss: 0.00016\n",
      "epoch 18388 / 20000\n",
      "gradient norm: 0.007239924190798774, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00015\n",
      "\tval loss: 0.00016\n",
      "epoch 18389 / 20000\n",
      "gradient norm: 0.010394509954494424, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00015\n",
      "\tval loss: 0.00016\n",
      "epoch 18390 / 20000\n",
      "gradient norm: 0.010018158936873078, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00015\n",
      "\tval loss: 0.00016\n",
      "epoch 18391 / 20000\n",
      "gradient norm: 0.016473237352329306, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00015\n",
      "\tval loss: 0.00016\n",
      "epoch 18392 / 20000\n",
      "gradient norm: 0.009019752920721658, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00015\n",
      "\tval loss: 0.00016\n",
      "epoch 18393 / 20000\n",
      "gradient norm: 0.016620470763882622, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00015\n",
      "\tval loss: 0.00016\n",
      "epoch 18394 / 20000\n",
      "gradient norm: 0.014100183208938688, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00015\n",
      "\tval loss: 0.00016\n",
      "epoch 18395 / 20000\n",
      "gradient norm: 0.011544087377842516, minimum ratio: 2.4894736842105267\n",
      "\ttrain loss: 0.00015\n",
      "\tval loss: 0.00016\n",
      "epoch 18396 / 20000\n",
      "gradient norm: 0.012676115526119247, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00015\n",
      "\tval loss: 0.00016\n",
      "epoch 18397 / 20000\n",
      "gradient norm: 0.023203135089715943, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00015\n",
      "\tval loss: 0.00016\n",
      "epoch 18398 / 20000\n",
      "gradient norm: 0.016150568728335202, minimum ratio: 2.4499999999999997\n",
      "\ttrain loss: 0.00015\n",
      "\tval loss: 0.00016\n",
      "epoch 18399 / 20000\n",
      "gradient norm: 0.015050564135890454, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00015\n",
      "\tval loss: 0.00016\n",
      "epoch 18400 / 20000\n",
      "gradient norm: 0.005775827761681285, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00015\n",
      "\tval loss: 0.00016\n",
      "epoch 18401 / 20000\n",
      "gradient norm: 0.011243216853472404, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00015\n",
      "\tval loss: 0.00016\n",
      "epoch 18402 / 20000\n",
      "gradient norm: 0.015487856755498797, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00015\n",
      "\tval loss: 0.00016\n",
      "epoch 18403 / 20000\n",
      "gradient norm: 0.023219747934490442, minimum ratio: 2.421052631578947\n",
      "\ttrain loss: 0.00015\n",
      "\tval loss: 0.00016\n",
      "epoch 18404 / 20000\n",
      "gradient norm: 0.013771521917078644, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00015\n",
      "\tval loss: 0.00016\n",
      "epoch 18405 / 20000\n",
      "gradient norm: 0.020844911923632026, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00015\n",
      "\tval loss: 0.00016\n",
      "epoch 18406 / 20000\n",
      "gradient norm: 0.0097222694021184, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00015\n",
      "\tval loss: 0.00016\n",
      "epoch 18407 / 20000\n",
      "gradient norm: 0.015087773819686845, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00015\n",
      "\tval loss: 0.00016\n",
      "epoch 18408 / 20000\n",
      "gradient norm: 0.020296783797675744, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00015\n",
      "\tval loss: 0.00016\n",
      "epoch 18409 / 20000\n",
      "gradient norm: 0.014340906796860509, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00015\n",
      "\tval loss: 0.00016\n",
      "epoch 18410 / 20000\n",
      "gradient norm: 0.00983534735860303, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00015\n",
      "\tval loss: 0.00016\n",
      "epoch 18411 / 20000\n",
      "gradient norm: 0.014640011766459793, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00015\n",
      "\tval loss: 0.00016\n",
      "epoch 18412 / 20000\n",
      "gradient norm: 0.013404466095380485, minimum ratio: 2.4447368421052627\n",
      "\ttrain loss: 0.00015\n",
      "\tval loss: 0.00015\n",
      "epoch 18413 / 20000\n",
      "gradient norm: 0.016294521410600282, minimum ratio: 2.4421052631578943\n",
      "\ttrain loss: 0.00015\n",
      "\tval loss: 0.00016\n",
      "epoch 18414 / 20000\n",
      "gradient norm: 0.020397707325173542, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00015\n",
      "\tval loss: 0.00015\n",
      "epoch 18415 / 20000\n",
      "gradient norm: 0.02221262910461519, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00015\n",
      "\tval loss: 0.00016\n",
      "epoch 18416 / 20000\n",
      "gradient norm: 0.02342152615892701, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00015\n",
      "\tval loss: 0.00015\n",
      "epoch 18417 / 20000\n",
      "gradient norm: 0.011983603908447549, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00015\n",
      "\tval loss: 0.00015\n",
      "epoch 18418 / 20000\n",
      "gradient norm: 0.012821761178201996, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00015\n",
      "\tval loss: 0.00015\n",
      "epoch 18419 / 20000\n",
      "gradient norm: 0.011874246556544676, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00015\n",
      "\tval loss: 0.00015\n",
      "epoch 18420 / 20000\n",
      "gradient norm: 0.013016101001994684, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00015\n",
      "\tval loss: 0.00015\n",
      "epoch 18421 / 20000\n",
      "gradient norm: 0.01069755625212565, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00015\n",
      "\tval loss: 0.00015\n",
      "epoch 18422 / 20000\n",
      "gradient norm: 0.015186720440397039, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00015\n",
      "\tval loss: 0.00015\n",
      "epoch 18423 / 20000\n",
      "gradient norm: 0.02133130154106766, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00015\n",
      "\tval loss: 0.00015\n",
      "epoch 18424 / 20000\n",
      "gradient norm: 0.015598649144521914, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00015\n",
      "\tval loss: 0.00015\n",
      "epoch 18425 / 20000\n",
      "gradient norm: 0.016556066111661494, minimum ratio: 2.460526315789474\n",
      "\ttrain loss: 0.00015\n",
      "\tval loss: 0.00015\n",
      "epoch 18426 / 20000\n",
      "gradient norm: 0.009266346256481484, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00014\n",
      "\tval loss: 0.00015\n",
      "epoch 18427 / 20000\n",
      "gradient norm: 0.01134602514503058, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00014\n",
      "\tval loss: 0.00015\n",
      "epoch 18428 / 20000\n",
      "gradient norm: 0.016932600876316428, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00015\n",
      "\tval loss: 0.00015\n",
      "epoch 18429 / 20000\n",
      "gradient norm: 0.011896619434992317, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00014\n",
      "\tval loss: 0.00015\n",
      "epoch 18430 / 20000\n",
      "gradient norm: 0.013482632086379454, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00014\n",
      "\tval loss: 0.00015\n",
      "epoch 18431 / 20000\n",
      "gradient norm: 0.006947514710191172, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00014\n",
      "\tval loss: 0.00015\n",
      "epoch 18432 / 20000\n",
      "gradient norm: 0.010617101313982857, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00014\n",
      "\tval loss: 0.00015\n",
      "epoch 18433 / 20000\n",
      "gradient norm: 0.0042052986536873505, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00014\n",
      "\tval loss: 0.00015\n",
      "epoch 18434 / 20000\n",
      "gradient norm: 0.00560248046531342, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00014\n",
      "\tval loss: 0.00015\n",
      "epoch 18435 / 20000\n",
      "gradient norm: 0.011168662342242897, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00014\n",
      "\tval loss: 0.00015\n",
      "epoch 18436 / 20000\n",
      "gradient norm: 0.01077370927669108, minimum ratio: 2.4394736842105265\n",
      "\ttrain loss: 0.00014\n",
      "\tval loss: 0.00015\n",
      "epoch 18437 / 20000\n",
      "gradient norm: 0.016708519047824666, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00014\n",
      "\tval loss: 0.00015\n",
      "epoch 18438 / 20000\n",
      "gradient norm: 0.02417003718437627, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00014\n",
      "\tval loss: 0.00015\n",
      "epoch 18439 / 20000\n",
      "gradient norm: 0.027164913626620546, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00014\n",
      "\tval loss: 0.00015\n",
      "epoch 18440 / 20000\n",
      "gradient norm: 0.030687547972775064, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00014\n",
      "\tval loss: 0.00015\n",
      "epoch 18441 / 20000\n",
      "gradient norm: 0.017752093059243634, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00014\n",
      "\tval loss: 0.00015\n",
      "epoch 18442 / 20000\n",
      "gradient norm: 0.01658965353271924, minimum ratio: 2.465789473684211\n",
      "\ttrain loss: 0.00014\n",
      "\tval loss: 0.00015\n",
      "epoch 18443 / 20000\n",
      "gradient norm: 0.017063836712623015, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00014\n",
      "\tval loss: 0.00015\n",
      "epoch 18444 / 20000\n",
      "gradient norm: 0.0140498909750022, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00014\n",
      "\tval loss: 0.00015\n",
      "epoch 18445 / 20000\n",
      "gradient norm: 0.017269718169700354, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00014\n",
      "\tval loss: 0.00015\n",
      "epoch 18446 / 20000\n",
      "gradient norm: 0.01402107093599625, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00014\n",
      "\tval loss: 0.00015\n",
      "epoch 18447 / 20000\n",
      "gradient norm: 0.010727490778663196, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00014\n",
      "\tval loss: 0.00015\n",
      "epoch 18448 / 20000\n",
      "gradient norm: 0.008622173598269, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00014\n",
      "\tval loss: 0.00015\n",
      "epoch 18449 / 20000\n",
      "gradient norm: 0.010566961078438908, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00014\n",
      "\tval loss: 0.00015\n",
      "epoch 18450 / 20000\n",
      "gradient norm: 0.011145032360218465, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00014\n",
      "\tval loss: 0.00015\n",
      "epoch 18451 / 20000\n",
      "gradient norm: 0.02031862220610492, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00014\n",
      "\tval loss: 0.00015\n",
      "epoch 18452 / 20000\n",
      "gradient norm: 0.020904969598632306, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00014\n",
      "\tval loss: 0.00014\n",
      "epoch 18453 / 20000\n",
      "gradient norm: 0.02335513918660581, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00014\n",
      "\tval loss: 0.00015\n",
      "epoch 18454 / 20000\n",
      "gradient norm: 0.037142174202017486, minimum ratio: 2.460526315789474\n",
      "\ttrain loss: 0.00014\n",
      "\tval loss: 0.00014\n",
      "epoch 18455 / 20000\n",
      "gradient norm: 0.027708761423127726, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00014\n",
      "\tval loss: 0.00015\n",
      "epoch 18456 / 20000\n",
      "gradient norm: 0.01755411679914687, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00014\n",
      "\tval loss: 0.00014\n",
      "epoch 18457 / 20000\n",
      "gradient norm: 0.019573865312850103, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00014\n",
      "\tval loss: 0.00015\n",
      "epoch 18458 / 20000\n",
      "gradient norm: 0.016595199384028092, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00014\n",
      "\tval loss: 0.00014\n",
      "epoch 18459 / 20000\n",
      "gradient norm: 0.02365784473659005, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00014\n",
      "\tval loss: 0.00015\n",
      "epoch 18460 / 20000\n",
      "gradient norm: 0.02095087300403975, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00014\n",
      "\tval loss: 0.00014\n",
      "epoch 18461 / 20000\n",
      "gradient norm: 0.021258928230963647, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00014\n",
      "\tval loss: 0.00014\n",
      "epoch 18462 / 20000\n",
      "gradient norm: 0.02111157777835615, minimum ratio: 2.46578947368421\n",
      "\ttrain loss: 0.00014\n",
      "\tval loss: 0.00014\n",
      "epoch 18463 / 20000\n",
      "gradient norm: 0.013243184177554213, minimum ratio: 2.460526315789474\n",
      "\ttrain loss: 0.00014\n",
      "\tval loss: 0.00014\n",
      "epoch 18464 / 20000\n",
      "gradient norm: 0.016019214584957808, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00014\n",
      "\tval loss: 0.00014\n",
      "epoch 18465 / 20000\n",
      "gradient norm: 0.02196038336842321, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00014\n",
      "\tval loss: 0.00014\n",
      "epoch 18466 / 20000\n",
      "gradient norm: 0.017209126031957567, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00014\n",
      "\tval loss: 0.00014\n",
      "epoch 18467 / 20000\n",
      "gradient norm: 0.015557397156953812, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00014\n",
      "\tval loss: 0.00014\n",
      "epoch 18468 / 20000\n",
      "gradient norm: 0.011310658097499982, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00013\n",
      "\tval loss: 0.00014\n",
      "epoch 18469 / 20000\n",
      "gradient norm: 0.015659671364119276, minimum ratio: 2.4684210526315784\n",
      "\ttrain loss: 0.00014\n",
      "\tval loss: 0.00014\n",
      "epoch 18470 / 20000\n",
      "gradient norm: 0.01278457313310355, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00013\n",
      "\tval loss: 0.00014\n",
      "epoch 18471 / 20000\n",
      "gradient norm: 0.01748378282354679, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00013\n",
      "\tval loss: 0.00014\n",
      "epoch 18472 / 20000\n",
      "gradient norm: 0.01911631357506849, minimum ratio: 2.4842105263157896\n",
      "\ttrain loss: 0.00013\n",
      "\tval loss: 0.00014\n",
      "epoch 18473 / 20000\n",
      "gradient norm: 0.025067136652069166, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00013\n",
      "\tval loss: 0.00014\n",
      "epoch 18474 / 20000\n",
      "gradient norm: 0.016806084662675858, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00013\n",
      "\tval loss: 0.00014\n",
      "epoch 18475 / 20000\n",
      "gradient norm: 0.01503284351201728, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00013\n",
      "\tval loss: 0.00014\n",
      "epoch 18476 / 20000\n",
      "gradient norm: 0.011648660045466386, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00013\n",
      "\tval loss: 0.00014\n",
      "epoch 18477 / 20000\n",
      "gradient norm: 0.004344142187619582, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00013\n",
      "\tval loss: 0.00014\n",
      "epoch 18478 / 20000\n",
      "gradient norm: 0.01786650888971053, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00013\n",
      "\tval loss: 0.00014\n",
      "epoch 18479 / 20000\n",
      "gradient norm: 0.013438010588288307, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00013\n",
      "\tval loss: 0.00014\n",
      "epoch 18480 / 20000\n",
      "gradient norm: 0.007315175811527297, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00013\n",
      "\tval loss: 0.00014\n",
      "epoch 18481 / 20000\n",
      "gradient norm: 0.007071370157063939, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00013\n",
      "\tval loss: 0.00014\n",
      "epoch 18482 / 20000\n",
      "gradient norm: 0.019637335499282926, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00013\n",
      "\tval loss: 0.00014\n",
      "epoch 18483 / 20000\n",
      "gradient norm: 0.012319368877797388, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00013\n",
      "\tval loss: 0.00014\n",
      "epoch 18484 / 20000\n",
      "gradient norm: 0.016169843991519883, minimum ratio: 2.4421052631578943\n",
      "\ttrain loss: 0.00013\n",
      "\tval loss: 0.00014\n",
      "epoch 18485 / 20000\n",
      "gradient norm: 0.006822580762673169, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00013\n",
      "\tval loss: 0.00014\n",
      "epoch 18486 / 20000\n",
      "gradient norm: 0.009228410475770943, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00013\n",
      "\tval loss: 0.00014\n",
      "epoch 18487 / 20000\n",
      "gradient norm: 0.013567618952947669, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00013\n",
      "\tval loss: 0.00014\n",
      "epoch 18488 / 20000\n",
      "gradient norm: 0.016305477038258687, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00013\n",
      "\tval loss: 0.00014\n",
      "epoch 18489 / 20000\n",
      "gradient norm: 0.013408708706265315, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00013\n",
      "\tval loss: 0.00014\n",
      "epoch 18490 / 20000\n",
      "gradient norm: 0.01801954340771772, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00013\n",
      "\tval loss: 0.00014\n",
      "epoch 18491 / 20000\n",
      "gradient norm: 0.009639401381718926, minimum ratio: 2.46578947368421\n",
      "\ttrain loss: 0.00013\n",
      "\tval loss: 0.00014\n",
      "epoch 18492 / 20000\n",
      "gradient norm: 0.014773418923141435, minimum ratio: 2.4447368421052627\n",
      "\ttrain loss: 0.00013\n",
      "\tval loss: 0.00014\n",
      "epoch 18493 / 20000\n",
      "gradient norm: 0.014128337323199958, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00013\n",
      "\tval loss: 0.00014\n",
      "epoch 18494 / 20000\n",
      "gradient norm: 0.009871896807453595, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00013\n",
      "\tval loss: 0.00014\n",
      "epoch 18495 / 20000\n",
      "gradient norm: 0.021134490365511738, minimum ratio: 2.4578947368421056\n",
      "\ttrain loss: 0.00013\n",
      "\tval loss: 0.00014\n",
      "epoch 18496 / 20000\n",
      "gradient norm: 0.01910437105107121, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00013\n",
      "\tval loss: 0.00014\n",
      "epoch 18497 / 20000\n",
      "gradient norm: 0.019298333820188418, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00013\n",
      "\tval loss: 0.00013\n",
      "epoch 18498 / 20000\n",
      "gradient norm: 0.017801723239244893, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00013\n",
      "\tval loss: 0.00014\n",
      "epoch 18499 / 20000\n",
      "gradient norm: 0.025627200375311077, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00013\n",
      "\tval loss: 0.00013\n",
      "epoch 18500 / 20000\n",
      "gradient norm: 0.012751272399327718, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00013\n",
      "\tval loss: 0.00014\n",
      "epoch 18501 / 20000\n",
      "gradient norm: 0.012976452620932832, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00013\n",
      "\tval loss: 0.00013\n",
      "epoch 18502 / 20000\n",
      "gradient norm: 0.02317284505261341, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00013\n",
      "\tval loss: 0.00013\n",
      "epoch 18503 / 20000\n",
      "gradient norm: 0.008729165332624689, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00013\n",
      "\tval loss: 0.00013\n",
      "epoch 18504 / 20000\n",
      "gradient norm: 0.009709812147775665, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00013\n",
      "\tval loss: 0.00013\n",
      "epoch 18505 / 20000\n",
      "gradient norm: 0.015347740103607066, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00013\n",
      "\tval loss: 0.00013\n",
      "epoch 18506 / 20000\n",
      "gradient norm: 0.017787831311579794, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00013\n",
      "\tval loss: 0.00013\n",
      "epoch 18507 / 20000\n",
      "gradient norm: 0.02310175052843988, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00013\n",
      "\tval loss: 0.00013\n",
      "epoch 18508 / 20000\n",
      "gradient norm: 0.009416488464921713, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00013\n",
      "\tval loss: 0.00013\n",
      "epoch 18509 / 20000\n",
      "gradient norm: 0.008349081210326403, minimum ratio: 2.4394736842105265\n",
      "\ttrain loss: 0.00013\n",
      "\tval loss: 0.00013\n",
      "epoch 18510 / 20000\n",
      "gradient norm: 0.008431587542872876, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00013\n",
      "\tval loss: 0.00013\n",
      "epoch 18511 / 20000\n",
      "gradient norm: 0.010993699746904895, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00013\n",
      "\tval loss: 0.00013\n",
      "epoch 18512 / 20000\n",
      "gradient norm: 0.01808386982884258, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00013\n",
      "\tval loss: 0.00013\n",
      "epoch 18513 / 20000\n",
      "gradient norm: 0.02686624156194739, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00013\n",
      "\tval loss: 0.00013\n",
      "epoch 18514 / 20000\n",
      "gradient norm: 0.024771804717602208, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00013\n",
      "\tval loss: 0.00013\n",
      "epoch 18515 / 20000\n",
      "gradient norm: 0.0203852248378098, minimum ratio: 2.460526315789474\n",
      "\ttrain loss: 0.00012\n",
      "\tval loss: 0.00013\n",
      "epoch 18516 / 20000\n",
      "gradient norm: 0.010253938002279028, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00012\n",
      "\tval loss: 0.00013\n",
      "epoch 18517 / 20000\n",
      "gradient norm: 0.012419138103723526, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00012\n",
      "\tval loss: 0.00013\n",
      "epoch 18518 / 20000\n",
      "gradient norm: 0.009865206113317981, minimum ratio: 2.4815789473684213\n",
      "\ttrain loss: 0.00012\n",
      "\tval loss: 0.00013\n",
      "epoch 18519 / 20000\n",
      "gradient norm: 0.01604002359090373, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00012\n",
      "\tval loss: 0.00013\n",
      "epoch 18520 / 20000\n",
      "gradient norm: 0.010243379074381664, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00012\n",
      "\tval loss: 0.00013\n",
      "epoch 18521 / 20000\n",
      "gradient norm: 0.0170786160742864, minimum ratio: 2.4894736842105267\n",
      "\ttrain loss: 0.00012\n",
      "\tval loss: 0.00013\n",
      "epoch 18522 / 20000\n",
      "gradient norm: 0.008582336573454086, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00012\n",
      "\tval loss: 0.00013\n",
      "epoch 18523 / 20000\n",
      "gradient norm: 0.017894204371259548, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00012\n",
      "\tval loss: 0.00013\n",
      "epoch 18524 / 20000\n",
      "gradient norm: 0.013425650089629926, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00012\n",
      "\tval loss: 0.00013\n",
      "epoch 18525 / 20000\n",
      "gradient norm: 0.016330933169228956, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00012\n",
      "\tval loss: 0.00013\n",
      "epoch 18526 / 20000\n",
      "gradient norm: 0.011830834278953262, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00012\n",
      "\tval loss: 0.00013\n",
      "epoch 18527 / 20000\n",
      "gradient norm: 0.01671839042683132, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00012\n",
      "\tval loss: 0.00013\n",
      "epoch 18528 / 20000\n",
      "gradient norm: 0.020966781608876772, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00012\n",
      "\tval loss: 0.00013\n",
      "epoch 18529 / 20000\n",
      "gradient norm: 0.018849730520742014, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00012\n",
      "\tval loss: 0.00013\n",
      "epoch 18530 / 20000\n",
      "gradient norm: 0.021561589237535372, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00012\n",
      "\tval loss: 0.00013\n",
      "epoch 18531 / 20000\n",
      "gradient norm: 0.00872760618221946, minimum ratio: 2.492105263157895\n",
      "\ttrain loss: 0.00012\n",
      "\tval loss: 0.00013\n",
      "epoch 18532 / 20000\n",
      "gradient norm: 0.007705846335738897, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00012\n",
      "\tval loss: 0.00013\n",
      "epoch 18533 / 20000\n",
      "gradient norm: 0.005585616934695281, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00012\n",
      "\tval loss: 0.00013\n",
      "epoch 18534 / 20000\n",
      "gradient norm: 0.006227044737897813, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00012\n",
      "\tval loss: 0.00013\n",
      "epoch 18535 / 20000\n",
      "gradient norm: 0.010402186017017812, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00012\n",
      "\tval loss: 0.00013\n",
      "epoch 18536 / 20000\n",
      "gradient norm: 0.009849446563748643, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00012\n",
      "\tval loss: 0.00013\n",
      "epoch 18537 / 20000\n",
      "gradient norm: 0.024887745559681207, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00012\n",
      "\tval loss: 0.00013\n",
      "epoch 18538 / 20000\n",
      "gradient norm: 0.01088937021268066, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00012\n",
      "\tval loss: 0.00013\n",
      "epoch 18539 / 20000\n",
      "gradient norm: 0.0072417308983858675, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00012\n",
      "\tval loss: 0.00013\n",
      "epoch 18540 / 20000\n",
      "gradient norm: 0.007075017943861894, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00012\n",
      "\tval loss: 0.00013\n",
      "epoch 18541 / 20000\n",
      "gradient norm: 0.008498945622704923, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00012\n",
      "\tval loss: 0.00013\n",
      "epoch 18542 / 20000\n",
      "gradient norm: 0.014764749445021152, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00012\n",
      "\tval loss: 0.00012\n",
      "epoch 18543 / 20000\n",
      "gradient norm: 0.007291641857591458, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00012\n",
      "\tval loss: 0.00013\n",
      "epoch 18544 / 20000\n",
      "gradient norm: 0.01085698016686365, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00012\n",
      "\tval loss: 0.00012\n",
      "epoch 18545 / 20000\n",
      "gradient norm: 0.015638655808288604, minimum ratio: 2.460526315789474\n",
      "\ttrain loss: 0.00012\n",
      "\tval loss: 0.00013\n",
      "epoch 18546 / 20000\n",
      "gradient norm: 0.023490135150495917, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00012\n",
      "\tval loss: 0.00012\n",
      "epoch 18547 / 20000\n",
      "gradient norm: 0.019944148691138253, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00012\n",
      "\tval loss: 0.00013\n",
      "epoch 18548 / 20000\n",
      "gradient norm: 0.017964995960937813, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00012\n",
      "\tval loss: 0.00012\n",
      "epoch 18549 / 20000\n",
      "gradient norm: 0.00930943718412891, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00012\n",
      "\tval loss: 0.00012\n",
      "epoch 18550 / 20000\n",
      "gradient norm: 0.015461564471479505, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00012\n",
      "\tval loss: 0.00012\n",
      "epoch 18551 / 20000\n",
      "gradient norm: 0.008830036356812343, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00012\n",
      "\tval loss: 0.00012\n",
      "epoch 18552 / 20000\n",
      "gradient norm: 0.010959963110508397, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00012\n",
      "\tval loss: 0.00012\n",
      "epoch 18553 / 20000\n",
      "gradient norm: 0.00934039440471679, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00012\n",
      "\tval loss: 0.00012\n",
      "epoch 18554 / 20000\n",
      "gradient norm: 0.021932216099230573, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00012\n",
      "\tval loss: 0.00012\n",
      "epoch 18555 / 20000\n",
      "gradient norm: 0.006799439273891039, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00012\n",
      "\tval loss: 0.00012\n",
      "epoch 18556 / 20000\n",
      "gradient norm: 0.012541325952042826, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00012\n",
      "\tval loss: 0.00012\n",
      "epoch 18557 / 20000\n",
      "gradient norm: 0.013991947984322906, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00012\n",
      "\tval loss: 0.00012\n",
      "epoch 18558 / 20000\n",
      "gradient norm: 0.02822499183821492, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00012\n",
      "\tval loss: 0.00012\n",
      "epoch 18559 / 20000\n",
      "gradient norm: 0.009809042909182608, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00012\n",
      "\tval loss: 0.00012\n",
      "epoch 18560 / 20000\n",
      "gradient norm: 0.0068150086008245125, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00012\n",
      "\tval loss: 0.00012\n",
      "epoch 18561 / 20000\n",
      "gradient norm: 0.008388787144212984, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00011\n",
      "\tval loss: 0.00012\n",
      "epoch 18562 / 20000\n",
      "gradient norm: 0.0069448365102289245, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00011\n",
      "\tval loss: 0.00012\n",
      "epoch 18563 / 20000\n",
      "gradient norm: 0.009513521596090868, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00011\n",
      "\tval loss: 0.00012\n",
      "epoch 18564 / 20000\n",
      "gradient norm: 0.014088563242694363, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00011\n",
      "\tval loss: 0.00012\n",
      "epoch 18565 / 20000\n",
      "gradient norm: 0.026323738449718803, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00012\n",
      "\tval loss: 0.00012\n",
      "epoch 18566 / 20000\n",
      "gradient norm: 0.03756730834720656, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00012\n",
      "\tval loss: 0.00012\n",
      "epoch 18567 / 20000\n",
      "gradient norm: 0.02142422486213036, minimum ratio: 2.46578947368421\n",
      "\ttrain loss: 0.00011\n",
      "\tval loss: 0.00013\n",
      "epoch 18568 / 20000\n",
      "gradient norm: 0.0307257923996076, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00012\n",
      "\tval loss: 0.00012\n",
      "epoch 18569 / 20000\n",
      "gradient norm: 0.03745698250713758, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00012\n",
      "\tval loss: 0.00012\n",
      "epoch 18570 / 20000\n",
      "gradient norm: 0.016883708303794265, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00011\n",
      "\tval loss: 0.00012\n",
      "epoch 18571 / 20000\n",
      "gradient norm: 0.01922208009636961, minimum ratio: 2.4447368421052627\n",
      "\ttrain loss: 0.00011\n",
      "\tval loss: 0.00012\n",
      "epoch 18572 / 20000\n",
      "gradient norm: 0.01536216150270775, minimum ratio: 2.460526315789474\n",
      "\ttrain loss: 0.00011\n",
      "\tval loss: 0.00012\n",
      "epoch 18573 / 20000\n",
      "gradient norm: 0.01718399379751645, minimum ratio: 2.436842105263158\n",
      "\ttrain loss: 0.00011\n",
      "\tval loss: 0.00012\n",
      "epoch 18574 / 20000\n",
      "gradient norm: 0.017598380625713617, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00011\n",
      "\tval loss: 0.00012\n",
      "epoch 18575 / 20000\n",
      "gradient norm: 0.01457638619467616, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00011\n",
      "\tval loss: 0.00012\n",
      "epoch 18576 / 20000\n",
      "gradient norm: 0.010111584640981164, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00011\n",
      "\tval loss: 0.00012\n",
      "epoch 18577 / 20000\n",
      "gradient norm: 0.009044672566233203, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00011\n",
      "\tval loss: 0.00012\n",
      "epoch 18578 / 20000\n",
      "gradient norm: 0.010360207787016407, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00011\n",
      "\tval loss: 0.00012\n",
      "epoch 18579 / 20000\n",
      "gradient norm: 0.021300246415194124, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00011\n",
      "\tval loss: 0.00012\n",
      "epoch 18580 / 20000\n",
      "gradient norm: 0.02010823049931787, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00011\n",
      "\tval loss: 0.00012\n",
      "epoch 18581 / 20000\n",
      "gradient norm: 0.03474872661172412, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00011\n",
      "\tval loss: 0.00012\n",
      "epoch 18582 / 20000\n",
      "gradient norm: 0.017709270410705358, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00011\n",
      "\tval loss: 0.00012\n",
      "epoch 18583 / 20000\n",
      "gradient norm: 0.03050715709105134, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00011\n",
      "\tval loss: 0.00012\n",
      "epoch 18584 / 20000\n",
      "gradient norm: 0.025017723150085658, minimum ratio: 2.4447368421052635\n",
      "\ttrain loss: 0.00011\n",
      "\tval loss: 0.00012\n",
      "epoch 18585 / 20000\n",
      "gradient norm: 0.022301379911368713, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00011\n",
      "\tval loss: 0.00012\n",
      "epoch 18586 / 20000\n",
      "gradient norm: 0.019296155543997884, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00011\n",
      "\tval loss: 0.00012\n",
      "epoch 18587 / 20000\n",
      "gradient norm: 0.026290224719559774, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00011\n",
      "\tval loss: 0.00012\n",
      "epoch 18588 / 20000\n",
      "gradient norm: 0.014726271067047492, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00011\n",
      "\tval loss: 0.00012\n",
      "epoch 18589 / 20000\n",
      "gradient norm: 0.015857787409913726, minimum ratio: 2.46578947368421\n",
      "\ttrain loss: 0.00011\n",
      "\tval loss: 0.00012\n",
      "epoch 18590 / 20000\n",
      "gradient norm: 0.02296248366474174, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00011\n",
      "\tval loss: 0.00012\n",
      "epoch 18591 / 20000\n",
      "gradient norm: 0.022255591495195404, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00011\n",
      "\tval loss: 0.00012\n",
      "epoch 18592 / 20000\n",
      "gradient norm: 0.031190297711873427, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00011\n",
      "\tval loss: 0.00012\n",
      "epoch 18593 / 20000\n",
      "gradient norm: 0.027317608939483762, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00011\n",
      "\tval loss: 0.00012\n",
      "epoch 18594 / 20000\n",
      "gradient norm: 0.025621714477892965, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00011\n",
      "\tval loss: 0.00012\n",
      "epoch 18595 / 20000\n",
      "gradient norm: 0.015206410229438916, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00011\n",
      "\tval loss: 0.00012\n",
      "epoch 18596 / 20000\n",
      "gradient norm: 0.02071471489034593, minimum ratio: 2.460526315789474\n",
      "\ttrain loss: 0.00011\n",
      "\tval loss: 0.00011\n",
      "epoch 18597 / 20000\n",
      "gradient norm: 0.01903822910389863, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00011\n",
      "\tval loss: 0.00012\n",
      "epoch 18598 / 20000\n",
      "gradient norm: 0.01684255403233692, minimum ratio: 2.4263157894736844\n",
      "\ttrain loss: 0.00011\n",
      "\tval loss: 0.00011\n",
      "epoch 18599 / 20000\n",
      "gradient norm: 0.020662984170485288, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00011\n",
      "\tval loss: 0.00011\n",
      "epoch 18600 / 20000\n",
      "gradient norm: 0.02447701504570432, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00011\n",
      "\tval loss: 0.00012\n",
      "epoch 18601 / 20000\n",
      "gradient norm: 0.027970379480393603, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00011\n",
      "\tval loss: 0.00011\n",
      "epoch 18602 / 20000\n",
      "gradient norm: 0.013090677399304695, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00011\n",
      "\tval loss: 0.00011\n",
      "epoch 18603 / 20000\n",
      "gradient norm: 0.00826429360313341, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00011\n",
      "\tval loss: 0.00011\n",
      "epoch 18604 / 20000\n",
      "gradient norm: 0.008598949760198593, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00011\n",
      "\tval loss: 0.00011\n",
      "epoch 18605 / 20000\n",
      "gradient norm: 0.011587726730795112, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00011\n",
      "\tval loss: 0.00011\n",
      "epoch 18606 / 20000\n",
      "gradient norm: 0.017983639176236466, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00011\n",
      "\tval loss: 0.00011\n",
      "epoch 18607 / 20000\n",
      "gradient norm: 0.008220103394705802, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00011\n",
      "\tval loss: 0.00011\n",
      "epoch 18608 / 20000\n",
      "gradient norm: 0.023852794605772942, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00011\n",
      "\tval loss: 0.00011\n",
      "epoch 18609 / 20000\n",
      "gradient norm: 0.013750652491580695, minimum ratio: 2.4868421052631575\n",
      "\ttrain loss: 0.00011\n",
      "\tval loss: 0.00011\n",
      "epoch 18610 / 20000\n",
      "gradient norm: 0.008617744650109671, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00011\n",
      "\tval loss: 0.00011\n",
      "epoch 18611 / 20000\n",
      "gradient norm: 0.009866561478702351, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00011\n",
      "\tval loss: 0.00011\n",
      "epoch 18612 / 20000\n",
      "gradient norm: 0.011372989596566185, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00011\n",
      "\tval loss: 0.00011\n",
      "epoch 18613 / 20000\n",
      "gradient norm: 0.019391358480788767, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00011\n",
      "\tval loss: 0.00011\n",
      "epoch 18614 / 20000\n",
      "gradient norm: 0.024356076173717156, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00011\n",
      "\tval loss: 0.00011\n",
      "epoch 18615 / 20000\n",
      "gradient norm: 0.021934317599516362, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00011\n",
      "\tval loss: 0.00011\n",
      "epoch 18616 / 20000\n",
      "gradient norm: 0.02810201421380043, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00011\n",
      "\tval loss: 0.00011\n",
      "epoch 18617 / 20000\n",
      "gradient norm: 0.018794210511259735, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00011\n",
      "\tval loss: 0.00011\n",
      "epoch 18618 / 20000\n",
      "gradient norm: 0.015816521510714665, minimum ratio: 2.4684210526315784\n",
      "\ttrain loss: 0.00010\n",
      "\tval loss: 0.00011\n",
      "epoch 18619 / 20000\n",
      "gradient norm: 0.02176439028698951, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00011\n",
      "\tval loss: 0.00011\n",
      "epoch 18620 / 20000\n",
      "gradient norm: 0.010836123168701306, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00010\n",
      "\tval loss: 0.00011\n",
      "epoch 18621 / 20000\n",
      "gradient norm: 0.022071497282013297, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00011\n",
      "\tval loss: 0.00011\n",
      "epoch 18622 / 20000\n",
      "gradient norm: 0.022850416891742498, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00011\n",
      "\tval loss: 0.00011\n",
      "epoch 18623 / 20000\n",
      "gradient norm: 0.01692929698037915, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00010\n",
      "\tval loss: 0.00011\n",
      "epoch 18624 / 20000\n",
      "gradient norm: 0.025897142360918224, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00010\n",
      "\tval loss: 0.00011\n",
      "epoch 18625 / 20000\n",
      "gradient norm: 0.023820046451874077, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00010\n",
      "\tval loss: 0.00011\n",
      "epoch 18626 / 20000\n",
      "gradient norm: 0.02176797913853079, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00010\n",
      "\tval loss: 0.00011\n",
      "epoch 18627 / 20000\n",
      "gradient norm: 0.019165219651767984, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00010\n",
      "\tval loss: 0.00011\n",
      "epoch 18628 / 20000\n",
      "gradient norm: 0.025917322520399466, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00010\n",
      "\tval loss: 0.00011\n",
      "epoch 18629 / 20000\n",
      "gradient norm: 0.025814347434788942, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00010\n",
      "\tval loss: 0.00011\n",
      "epoch 18630 / 20000\n",
      "gradient norm: 0.03317449166206643, minimum ratio: 2.4842105263157896\n",
      "\ttrain loss: 0.00010\n",
      "\tval loss: 0.00011\n",
      "epoch 18631 / 20000\n",
      "gradient norm: 0.023954820295330137, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00010\n",
      "\tval loss: 0.00011\n",
      "epoch 18632 / 20000\n",
      "gradient norm: 0.03665677603567019, minimum ratio: 2.460526315789474\n",
      "\ttrain loss: 0.00010\n",
      "\tval loss: 0.00011\n",
      "epoch 18633 / 20000\n",
      "gradient norm: 0.02959702513180673, minimum ratio: 2.4447368421052635\n",
      "\ttrain loss: 0.00010\n",
      "\tval loss: 0.00011\n",
      "epoch 18634 / 20000\n",
      "gradient norm: 0.017533071688376367, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00010\n",
      "\tval loss: 0.00011\n",
      "epoch 18635 / 20000\n",
      "gradient norm: 0.013503694455721416, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00010\n",
      "\tval loss: 0.00011\n",
      "epoch 18636 / 20000\n",
      "gradient norm: 0.013591209659352899, minimum ratio: 2.4447368421052627\n",
      "\ttrain loss: 0.00010\n",
      "\tval loss: 0.00011\n",
      "epoch 18637 / 20000\n",
      "gradient norm: 0.020716717786854133, minimum ratio: 2.4421052631578943\n",
      "\ttrain loss: 0.00010\n",
      "\tval loss: 0.00011\n",
      "epoch 18638 / 20000\n",
      "gradient norm: 0.014539907409925945, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00010\n",
      "\tval loss: 0.00011\n",
      "epoch 18639 / 20000\n",
      "gradient norm: 0.01999594148946926, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00010\n",
      "\tval loss: 0.00011\n",
      "epoch 18640 / 20000\n",
      "gradient norm: 0.0085443330463022, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00010\n",
      "\tval loss: 0.00011\n",
      "epoch 18641 / 20000\n",
      "gradient norm: 0.025004023249493912, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00010\n",
      "\tval loss: 0.00011\n",
      "epoch 18642 / 20000\n",
      "gradient norm: 0.0046719226957065985, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00010\n",
      "\tval loss: 0.00011\n",
      "epoch 18643 / 20000\n",
      "gradient norm: 0.00844365925877355, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00010\n",
      "\tval loss: 0.00011\n",
      "epoch 18644 / 20000\n",
      "gradient norm: 0.015850740601308644, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00010\n",
      "\tval loss: 0.00011\n",
      "epoch 18645 / 20000\n",
      "gradient norm: 0.012273873886442743, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00010\n",
      "\tval loss: 0.00011\n",
      "epoch 18646 / 20000\n",
      "gradient norm: 0.01917474772199057, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00010\n",
      "\tval loss: 0.00011\n",
      "epoch 18647 / 20000\n",
      "gradient norm: 0.023172133543994278, minimum ratio: 2.4894736842105267\n",
      "\ttrain loss: 0.00010\n",
      "\tval loss: 0.00011\n",
      "epoch 18648 / 20000\n",
      "gradient norm: 0.032319957128493115, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00010\n",
      "\tval loss: 0.00011\n",
      "epoch 18649 / 20000\n",
      "gradient norm: 0.030104113509878516, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00010\n",
      "\tval loss: 0.00011\n",
      "epoch 18650 / 20000\n",
      "gradient norm: 0.043075696390587837, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00010\n",
      "\tval loss: 0.00011\n",
      "epoch 18651 / 20000\n",
      "gradient norm: 0.03125468408688903, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00010\n",
      "\tval loss: 0.00011\n",
      "epoch 18652 / 20000\n",
      "gradient norm: 0.0329309071530588, minimum ratio: 2.460526315789474\n",
      "\ttrain loss: 0.00010\n",
      "\tval loss: 0.00011\n",
      "epoch 18653 / 20000\n",
      "gradient norm: 0.017473646483267657, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00010\n",
      "\tval loss: 0.00011\n",
      "epoch 18654 / 20000\n",
      "gradient norm: 0.019775303546339273, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00010\n",
      "\tval loss: 0.00010\n",
      "epoch 18655 / 20000\n",
      "gradient norm: 0.01612619817024097, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00010\n",
      "\tval loss: 0.00011\n",
      "epoch 18656 / 20000\n",
      "gradient norm: 0.013969246268970892, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00010\n",
      "\tval loss: 0.00010\n",
      "epoch 18657 / 20000\n",
      "gradient norm: 0.01386769357486628, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00010\n",
      "\tval loss: 0.00011\n",
      "epoch 18658 / 20000\n",
      "gradient norm: 0.007689867779845372, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00010\n",
      "\tval loss: 0.00010\n",
      "epoch 18659 / 20000\n",
      "gradient norm: 0.01341580506414175, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00010\n",
      "\tval loss: 0.00011\n",
      "epoch 18660 / 20000\n",
      "gradient norm: 0.012275478220544755, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00010\n",
      "\tval loss: 0.00010\n",
      "epoch 18661 / 20000\n",
      "gradient norm: 0.009479717933572829, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00010\n",
      "\tval loss: 0.00010\n",
      "epoch 18662 / 20000\n",
      "gradient norm: 0.009148219018243253, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00010\n",
      "\tval loss: 0.00010\n",
      "epoch 18663 / 20000\n",
      "gradient norm: 0.00889690149051603, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00010\n",
      "\tval loss: 0.00010\n",
      "epoch 18664 / 20000\n",
      "gradient norm: 0.016222892852965742, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00010\n",
      "\tval loss: 0.00010\n",
      "epoch 18665 / 20000\n",
      "gradient norm: 0.011347426523570903, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00010\n",
      "\tval loss: 0.00010\n",
      "epoch 18666 / 20000\n",
      "gradient norm: 0.013858217163942754, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00010\n",
      "\tval loss: 0.00010\n",
      "epoch 18667 / 20000\n",
      "gradient norm: 0.018487417430151254, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00010\n",
      "\tval loss: 0.00010\n",
      "epoch 18668 / 20000\n",
      "gradient norm: 0.019855241596815176, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00010\n",
      "\tval loss: 0.00010\n",
      "epoch 18669 / 20000\n",
      "gradient norm: 0.008168919681338593, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00010\n",
      "\tval loss: 0.00010\n",
      "epoch 18670 / 20000\n",
      "gradient norm: 0.007018528340267949, minimum ratio: 2.4447368421052627\n",
      "\ttrain loss: 0.00010\n",
      "\tval loss: 0.00010\n",
      "epoch 18671 / 20000\n",
      "gradient norm: 0.007938610171549954, minimum ratio: 2.4815789473684213\n",
      "\ttrain loss: 0.00010\n",
      "\tval loss: 0.00010\n",
      "epoch 18672 / 20000\n",
      "gradient norm: 0.012765026367560495, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00010\n",
      "\tval loss: 0.00010\n",
      "epoch 18673 / 20000\n",
      "gradient norm: 0.01952581707155332, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00010\n",
      "\tval loss: 0.00010\n",
      "epoch 18674 / 20000\n",
      "gradient norm: 0.028997078057727776, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00010\n",
      "\tval loss: 0.00010\n",
      "epoch 18675 / 20000\n",
      "gradient norm: 0.03021915757562965, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00010\n",
      "\tval loss: 0.00010\n",
      "epoch 18676 / 20000\n",
      "gradient norm: 0.012055496248649433, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00010\n",
      "\tval loss: 0.00010\n",
      "epoch 18677 / 20000\n",
      "gradient norm: 0.019959313794970512, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00010\n",
      "\tval loss: 0.00010\n",
      "epoch 18678 / 20000\n",
      "gradient norm: 0.009446533797017764, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00010\n",
      "\tval loss: 0.00010\n",
      "epoch 18679 / 20000\n",
      "gradient norm: 0.010422400118841324, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00010\n",
      "\tval loss: 0.00010\n",
      "epoch 18680 / 20000\n",
      "gradient norm: 0.015132780492422171, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00010\n",
      "\tval loss: 0.00010\n",
      "epoch 18681 / 20000\n",
      "gradient norm: 0.010071534299640916, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00010\n",
      "\tval loss: 0.00010\n",
      "epoch 18682 / 20000\n",
      "gradient norm: 0.008594689534220379, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00009\n",
      "\tval loss: 0.00010\n",
      "epoch 18683 / 20000\n",
      "gradient norm: 0.012176116535556503, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00009\n",
      "\tval loss: 0.00010\n",
      "epoch 18684 / 20000\n",
      "gradient norm: 0.009823259155382402, minimum ratio: 2.4421052631578943\n",
      "\ttrain loss: 0.00009\n",
      "\tval loss: 0.00010\n",
      "epoch 18685 / 20000\n",
      "gradient norm: 0.009608259162632748, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00009\n",
      "\tval loss: 0.00010\n",
      "epoch 18686 / 20000\n",
      "gradient norm: 0.012095351485186256, minimum ratio: 2.46578947368421\n",
      "\ttrain loss: 0.00009\n",
      "\tval loss: 0.00010\n",
      "epoch 18687 / 20000\n",
      "gradient norm: 0.0123300465347711, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00009\n",
      "\tval loss: 0.00010\n",
      "epoch 18688 / 20000\n",
      "gradient norm: 0.012490845212596469, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00009\n",
      "\tval loss: 0.00010\n",
      "epoch 18689 / 20000\n",
      "gradient norm: 0.012557473106426187, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00009\n",
      "\tval loss: 0.00010\n",
      "epoch 18690 / 20000\n",
      "gradient norm: 0.009054303911398165, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00009\n",
      "\tval loss: 0.00010\n",
      "epoch 18691 / 20000\n",
      "gradient norm: 0.010218606126727536, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00009\n",
      "\tval loss: 0.00010\n",
      "epoch 18692 / 20000\n",
      "gradient norm: 0.016601780662313104, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00009\n",
      "\tval loss: 0.00010\n",
      "epoch 18693 / 20000\n",
      "gradient norm: 0.02779678048682399, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00009\n",
      "\tval loss: 0.00010\n",
      "epoch 18694 / 20000\n",
      "gradient norm: 0.030362722493009642, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00009\n",
      "\tval loss: 0.00010\n",
      "epoch 18695 / 20000\n",
      "gradient norm: 0.03224143508123234, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00009\n",
      "\tval loss: 0.00010\n",
      "epoch 18696 / 20000\n",
      "gradient norm: 0.020116454557864927, minimum ratio: 2.4842105263157896\n",
      "\ttrain loss: 0.00009\n",
      "\tval loss: 0.00010\n",
      "epoch 18697 / 20000\n",
      "gradient norm: 0.013540324885980226, minimum ratio: 2.4421052631578943\n",
      "\ttrain loss: 0.00009\n",
      "\tval loss: 0.00010\n",
      "epoch 18698 / 20000\n",
      "gradient norm: 0.014162012943415903, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00009\n",
      "\tval loss: 0.00010\n",
      "epoch 18699 / 20000\n",
      "gradient norm: 0.01359866680286359, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00009\n",
      "\tval loss: 0.00010\n",
      "epoch 18700 / 20000\n",
      "gradient norm: 0.013934764647274278, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00009\n",
      "\tval loss: 0.00010\n",
      "epoch 18701 / 20000\n",
      "gradient norm: 0.02110780027578585, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00009\n",
      "\tval loss: 0.00010\n",
      "epoch 18702 / 20000\n",
      "gradient norm: 0.025729094573762268, minimum ratio: 2.4447368421052627\n",
      "\ttrain loss: 0.00009\n",
      "\tval loss: 0.00010\n",
      "epoch 18703 / 20000\n",
      "gradient norm: 0.02394981955876574, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00009\n",
      "\tval loss: 0.00010\n",
      "epoch 18704 / 20000\n",
      "gradient norm: 0.02088008396094665, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00009\n",
      "\tval loss: 0.00010\n",
      "epoch 18705 / 20000\n",
      "gradient norm: 0.013968809638754465, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00009\n",
      "\tval loss: 0.00010\n",
      "epoch 18706 / 20000\n",
      "gradient norm: 0.017860884021501988, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00009\n",
      "\tval loss: 0.00010\n",
      "epoch 18707 / 20000\n",
      "gradient norm: 0.012303894574870355, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00009\n",
      "\tval loss: 0.00010\n",
      "epoch 18708 / 20000\n",
      "gradient norm: 0.013786067574983463, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00009\n",
      "\tval loss: 0.00010\n",
      "epoch 18709 / 20000\n",
      "gradient norm: 0.018881574695114978, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00009\n",
      "\tval loss: 0.00010\n",
      "epoch 18710 / 20000\n",
      "gradient norm: 0.011302943239570595, minimum ratio: 2.4842105263157896\n",
      "\ttrain loss: 0.00009\n",
      "\tval loss: 0.00010\n",
      "epoch 18711 / 20000\n",
      "gradient norm: 0.013316723110619932, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00009\n",
      "\tval loss: 0.00010\n",
      "epoch 18712 / 20000\n",
      "gradient norm: 0.014121799256827217, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00009\n",
      "\tval loss: 0.00010\n",
      "epoch 18713 / 20000\n",
      "gradient norm: 0.01985938471625559, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00009\n",
      "\tval loss: 0.00010\n",
      "epoch 18714 / 20000\n",
      "gradient norm: 0.022833271592389792, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00009\n",
      "\tval loss: 0.00010\n",
      "epoch 18715 / 20000\n",
      "gradient norm: 0.02935126330703497, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00009\n",
      "\tval loss: 0.00010\n",
      "epoch 18716 / 20000\n",
      "gradient norm: 0.025433021859498695, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00009\n",
      "\tval loss: 0.00010\n",
      "epoch 18717 / 20000\n",
      "gradient norm: 0.023417787386279088, minimum ratio: 2.4447368421052635\n",
      "\ttrain loss: 0.00009\n",
      "\tval loss: 0.00010\n",
      "epoch 18718 / 20000\n",
      "gradient norm: 0.022063991375034675, minimum ratio: 2.460526315789474\n",
      "\ttrain loss: 0.00009\n",
      "\tval loss: 0.00010\n",
      "epoch 18719 / 20000\n",
      "gradient norm: 0.022380137670552358, minimum ratio: 2.4499999999999997\n",
      "\ttrain loss: 0.00009\n",
      "\tval loss: 0.00010\n",
      "epoch 18720 / 20000\n",
      "gradient norm: 0.023944088723510504, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00009\n",
      "\tval loss: 0.00010\n",
      "epoch 18721 / 20000\n",
      "gradient norm: 0.021329537237761542, minimum ratio: 2.46578947368421\n",
      "\ttrain loss: 0.00009\n",
      "\tval loss: 0.00010\n",
      "epoch 18722 / 20000\n",
      "gradient norm: 0.01409576136211399, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00009\n",
      "\tval loss: 0.00009\n",
      "epoch 18723 / 20000\n",
      "gradient norm: 0.00855047169898171, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00009\n",
      "\tval loss: 0.00009\n",
      "epoch 18724 / 20000\n",
      "gradient norm: 0.007290723675396293, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00009\n",
      "\tval loss: 0.00009\n",
      "epoch 18725 / 20000\n",
      "gradient norm: 0.007718778637354262, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00009\n",
      "\tval loss: 0.00009\n",
      "epoch 18726 / 20000\n",
      "gradient norm: 0.011531547919730656, minimum ratio: 2.46578947368421\n",
      "\ttrain loss: 0.00009\n",
      "\tval loss: 0.00009\n",
      "epoch 18727 / 20000\n",
      "gradient norm: 0.013795810373267159, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00009\n",
      "\tval loss: 0.00009\n",
      "epoch 18728 / 20000\n",
      "gradient norm: 0.010985952787450515, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00009\n",
      "\tval loss: 0.00009\n",
      "epoch 18729 / 20000\n",
      "gradient norm: 0.009837412682827562, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00009\n",
      "\tval loss: 0.00009\n",
      "epoch 18730 / 20000\n",
      "gradient norm: 0.013193532096920535, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00009\n",
      "\tval loss: 0.00010\n",
      "epoch 18731 / 20000\n",
      "gradient norm: 0.015206279058475047, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00009\n",
      "\tval loss: 0.00009\n",
      "epoch 18732 / 20000\n",
      "gradient norm: 0.02245303918607533, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00009\n",
      "\tval loss: 0.00009\n",
      "epoch 18733 / 20000\n",
      "gradient norm: 0.01897331402869895, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00009\n",
      "\tval loss: 0.00009\n",
      "epoch 18734 / 20000\n",
      "gradient norm: 0.022508720197947696, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00009\n",
      "\tval loss: 0.00009\n",
      "epoch 18735 / 20000\n",
      "gradient norm: 0.016301807743730024, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00009\n",
      "\tval loss: 0.00009\n",
      "epoch 18736 / 20000\n",
      "gradient norm: 0.010188323307374958, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00009\n",
      "\tval loss: 0.00009\n",
      "epoch 18737 / 20000\n",
      "gradient norm: 0.0075229788562865, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00009\n",
      "\tval loss: 0.00009\n",
      "epoch 18738 / 20000\n",
      "gradient norm: 0.011332657260936685, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00009\n",
      "\tval loss: 0.00009\n",
      "epoch 18739 / 20000\n",
      "gradient norm: 0.007985724994796328, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00009\n",
      "\tval loss: 0.00009\n",
      "epoch 18740 / 20000\n",
      "gradient norm: 0.007956048852065578, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00009\n",
      "\tval loss: 0.00009\n",
      "epoch 18741 / 20000\n",
      "gradient norm: 0.018208434048574418, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00009\n",
      "\tval loss: 0.00009\n",
      "epoch 18742 / 20000\n",
      "gradient norm: 0.022175126752699725, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00009\n",
      "\tval loss: 0.00009\n",
      "epoch 18743 / 20000\n",
      "gradient norm: 0.016245485210674815, minimum ratio: 2.460526315789474\n",
      "\ttrain loss: 0.00009\n",
      "\tval loss: 0.00009\n",
      "epoch 18744 / 20000\n",
      "gradient norm: 0.02110218914458528, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00009\n",
      "\tval loss: 0.00009\n",
      "epoch 18745 / 20000\n",
      "gradient norm: 0.011204529771930538, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00009\n",
      "\tval loss: 0.00009\n",
      "epoch 18746 / 20000\n",
      "gradient norm: 0.018857130664400756, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00009\n",
      "\tval loss: 0.00009\n",
      "epoch 18747 / 20000\n",
      "gradient norm: 0.01779188879299909, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00009\n",
      "\tval loss: 0.00009\n",
      "epoch 18748 / 20000\n",
      "gradient norm: 0.01981997706752736, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00009\n",
      "\tval loss: 0.00009\n",
      "epoch 18749 / 20000\n",
      "gradient norm: 0.014796215749811381, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00009\n",
      "\tval loss: 0.00009\n",
      "epoch 18750 / 20000\n",
      "gradient norm: 0.018719754210906103, minimum ratio: 2.4315789473684206\n",
      "\ttrain loss: 0.00009\n",
      "\tval loss: 0.00009\n",
      "epoch 18751 / 20000\n",
      "gradient norm: 0.014814045338425785, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00009\n",
      "\tval loss: 0.00009\n",
      "epoch 18752 / 20000\n",
      "gradient norm: 0.013957353017758578, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00009\n",
      "\tval loss: 0.00009\n",
      "epoch 18753 / 20000\n",
      "gradient norm: 0.010406099099782296, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00009\n",
      "\tval loss: 0.00009\n",
      "epoch 18754 / 20000\n",
      "gradient norm: 0.01840226468630135, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00009\n",
      "\tval loss: 0.00009\n",
      "epoch 18755 / 20000\n",
      "gradient norm: 0.014675734404590912, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00009\n",
      "\tval loss: 0.00009\n",
      "epoch 18756 / 20000\n",
      "gradient norm: 0.007582014164654538, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00008\n",
      "\tval loss: 0.00009\n",
      "epoch 18757 / 20000\n",
      "gradient norm: 0.005230002789176069, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00008\n",
      "\tval loss: 0.00009\n",
      "epoch 18758 / 20000\n",
      "gradient norm: 0.0062286453758133575, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00008\n",
      "\tval loss: 0.00009\n",
      "epoch 18759 / 20000\n",
      "gradient norm: 0.006493896529718768, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00008\n",
      "\tval loss: 0.00009\n",
      "epoch 18760 / 20000\n",
      "gradient norm: 0.009319881661213003, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00008\n",
      "\tval loss: 0.00009\n",
      "epoch 18761 / 20000\n",
      "gradient norm: 0.02183632191736251, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00008\n",
      "\tval loss: 0.00009\n",
      "epoch 18762 / 20000\n",
      "gradient norm: 0.0102772955870023, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00008\n",
      "\tval loss: 0.00009\n",
      "epoch 18763 / 20000\n",
      "gradient norm: 0.006442182042519562, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00008\n",
      "\tval loss: 0.00009\n",
      "epoch 18764 / 20000\n",
      "gradient norm: 0.013209534517955035, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00008\n",
      "\tval loss: 0.00009\n",
      "epoch 18765 / 20000\n",
      "gradient norm: 0.013190373225370422, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00008\n",
      "\tval loss: 0.00009\n",
      "epoch 18766 / 20000\n",
      "gradient norm: 0.016105905873700976, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00008\n",
      "\tval loss: 0.00009\n",
      "epoch 18767 / 20000\n",
      "gradient norm: 0.017769425321603194, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00008\n",
      "\tval loss: 0.00009\n",
      "epoch 18768 / 20000\n",
      "gradient norm: 0.017361896025249735, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00008\n",
      "\tval loss: 0.00009\n",
      "epoch 18769 / 20000\n",
      "gradient norm: 0.014539444586262107, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00008\n",
      "\tval loss: 0.00009\n",
      "epoch 18770 / 20000\n",
      "gradient norm: 0.011447894154116511, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00008\n",
      "\tval loss: 0.00009\n",
      "epoch 18771 / 20000\n",
      "gradient norm: 0.01141375170846004, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00008\n",
      "\tval loss: 0.00009\n",
      "epoch 18772 / 20000\n",
      "gradient norm: 0.007880833436502144, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00008\n",
      "\tval loss: 0.00009\n",
      "epoch 18773 / 20000\n",
      "gradient norm: 0.011472779428004287, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00008\n",
      "\tval loss: 0.00009\n",
      "epoch 18774 / 20000\n",
      "gradient norm: 0.01973225228721276, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00008\n",
      "\tval loss: 0.00009\n",
      "epoch 18775 / 20000\n",
      "gradient norm: 0.01163891502073966, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00008\n",
      "\tval loss: 0.00009\n",
      "epoch 18776 / 20000\n",
      "gradient norm: 0.010634752128680702, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00008\n",
      "\tval loss: 0.00009\n",
      "epoch 18777 / 20000\n",
      "gradient norm: 0.009270913855289109, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00008\n",
      "\tval loss: 0.00009\n",
      "epoch 18778 / 20000\n",
      "gradient norm: 0.013585195119958371, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00008\n",
      "\tval loss: 0.00009\n",
      "epoch 18779 / 20000\n",
      "gradient norm: 0.015491519763600081, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.00008\n",
      "\tval loss: 0.00009\n",
      "epoch 18780 / 20000\n",
      "gradient norm: 0.019947665830841288, minimum ratio: 2.46578947368421\n",
      "\ttrain loss: 0.00008\n",
      "\tval loss: 0.00009\n",
      "epoch 18781 / 20000\n",
      "gradient norm: 0.013114062749082223, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00008\n",
      "\tval loss: 0.00009\n",
      "epoch 18782 / 20000\n",
      "gradient norm: 0.00557226428645663, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00008\n",
      "\tval loss: 0.00009\n",
      "epoch 18783 / 20000\n",
      "gradient norm: 0.017061654085409828, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00008\n",
      "\tval loss: 0.00009\n",
      "epoch 18784 / 20000\n",
      "gradient norm: 0.02677395031787455, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00008\n",
      "\tval loss: 0.00009\n",
      "epoch 18785 / 20000\n",
      "gradient norm: 0.016894300875719637, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00008\n",
      "\tval loss: 0.00009\n",
      "epoch 18786 / 20000\n",
      "gradient norm: 0.01566225317947101, minimum ratio: 2.4842105263157896\n",
      "\ttrain loss: 0.00008\n",
      "\tval loss: 0.00009\n",
      "epoch 18787 / 20000\n",
      "gradient norm: 0.016364288341719657, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00008\n",
      "\tval loss: 0.00009\n",
      "epoch 18788 / 20000\n",
      "gradient norm: 0.017554597812704742, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00008\n",
      "\tval loss: 0.00009\n",
      "epoch 18789 / 20000\n",
      "gradient norm: 0.012573722779052332, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00008\n",
      "\tval loss: 0.00009\n",
      "epoch 18790 / 20000\n",
      "gradient norm: 0.011755372732295655, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00008\n",
      "\tval loss: 0.00009\n",
      "epoch 18791 / 20000\n",
      "gradient norm: 0.014576097732060589, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00008\n",
      "\tval loss: 0.00009\n",
      "epoch 18792 / 20000\n",
      "gradient norm: 0.012989158451091498, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00008\n",
      "\tval loss: 0.00009\n",
      "epoch 18793 / 20000\n",
      "gradient norm: 0.021742084209108725, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00008\n",
      "\tval loss: 0.00009\n",
      "epoch 18794 / 20000\n",
      "gradient norm: 0.006849434954347089, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00008\n",
      "\tval loss: 0.00009\n",
      "epoch 18795 / 20000\n",
      "gradient norm: 0.004974603198206751, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00008\n",
      "\tval loss: 0.00009\n",
      "epoch 18796 / 20000\n",
      "gradient norm: 0.00442097446648404, minimum ratio: 2.460526315789474\n",
      "\ttrain loss: 0.00008\n",
      "\tval loss: 0.00009\n",
      "epoch 18797 / 20000\n",
      "gradient norm: 0.006548416888108477, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00008\n",
      "\tval loss: 0.00009\n",
      "epoch 18798 / 20000\n",
      "gradient norm: 0.004726729741378222, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00008\n",
      "\tval loss: 0.00009\n",
      "epoch 18799 / 20000\n",
      "gradient norm: 0.006992114780587144, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00008\n",
      "\tval loss: 0.00009\n",
      "epoch 18800 / 20000\n",
      "gradient norm: 0.01315387216891395, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00008\n",
      "\tval loss: 0.00009\n",
      "epoch 18801 / 20000\n",
      "gradient norm: 0.010248022532323375, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00008\n",
      "\tval loss: 0.00008\n",
      "epoch 18802 / 20000\n",
      "gradient norm: 0.015036654513096437, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00008\n",
      "\tval loss: 0.00008\n",
      "epoch 18803 / 20000\n",
      "gradient norm: 0.023299777618376538, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00008\n",
      "\tval loss: 0.00009\n",
      "epoch 18804 / 20000\n",
      "gradient norm: 0.01628838901524432, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00008\n",
      "\tval loss: 0.00008\n",
      "epoch 18805 / 20000\n",
      "gradient norm: 0.03422575870354194, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00008\n",
      "\tval loss: 0.00009\n",
      "epoch 18806 / 20000\n",
      "gradient norm: 0.020449962976272218, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00008\n",
      "\tval loss: 0.00008\n",
      "epoch 18807 / 20000\n",
      "gradient norm: 0.015144567747483961, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00008\n",
      "\tval loss: 0.00009\n",
      "epoch 18808 / 20000\n",
      "gradient norm: 0.011923120080609806, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00008\n",
      "\tval loss: 0.00008\n",
      "epoch 18809 / 20000\n",
      "gradient norm: 0.008802262076642364, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00008\n",
      "\tval loss: 0.00008\n",
      "epoch 18810 / 20000\n",
      "gradient norm: 0.004301145963836461, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00008\n",
      "\tval loss: 0.00008\n",
      "epoch 18811 / 20000\n",
      "gradient norm: 0.008781618264038116, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00008\n",
      "\tval loss: 0.00009\n",
      "epoch 18812 / 20000\n",
      "gradient norm: 0.01507125879288651, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00008\n",
      "\tval loss: 0.00008\n",
      "epoch 18813 / 20000\n",
      "gradient norm: 0.012482137361075729, minimum ratio: 2.4499999999999997\n",
      "\ttrain loss: 0.00008\n",
      "\tval loss: 0.00009\n",
      "epoch 18814 / 20000\n",
      "gradient norm: 0.013201563124312088, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00008\n",
      "\tval loss: 0.00008\n",
      "epoch 18815 / 20000\n",
      "gradient norm: 0.005236812896328047, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00008\n",
      "\tval loss: 0.00008\n",
      "epoch 18816 / 20000\n",
      "gradient norm: 0.00782911201895331, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00008\n",
      "\tval loss: 0.00008\n",
      "epoch 18817 / 20000\n",
      "gradient norm: 0.008700540303834714, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00008\n",
      "\tval loss: 0.00008\n",
      "epoch 18818 / 20000\n",
      "gradient norm: 0.00740898096410092, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00008\n",
      "\tval loss: 0.00008\n",
      "epoch 18819 / 20000\n",
      "gradient norm: 0.016311391111230478, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00008\n",
      "\tval loss: 0.00008\n",
      "epoch 18820 / 20000\n",
      "gradient norm: 0.023989560373593122, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00008\n",
      "\tval loss: 0.00008\n",
      "epoch 18821 / 20000\n",
      "gradient norm: 0.011501474989927374, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00008\n",
      "\tval loss: 0.00008\n",
      "epoch 18822 / 20000\n",
      "gradient norm: 0.0165605811343994, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00008\n",
      "\tval loss: 0.00008\n",
      "epoch 18823 / 20000\n",
      "gradient norm: 0.015234337639412843, minimum ratio: 2.460526315789474\n",
      "\ttrain loss: 0.00008\n",
      "\tval loss: 0.00008\n",
      "epoch 18824 / 20000\n",
      "gradient norm: 0.019930415117414668, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00008\n",
      "\tval loss: 0.00008\n",
      "epoch 18825 / 20000\n",
      "gradient norm: 0.02500661270460114, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00008\n",
      "\tval loss: 0.00008\n",
      "epoch 18826 / 20000\n",
      "gradient norm: 0.01886635359551292, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00008\n",
      "\tval loss: 0.00008\n",
      "epoch 18827 / 20000\n",
      "gradient norm: 0.016010005172574893, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00008\n",
      "\tval loss: 0.00008\n",
      "epoch 18828 / 20000\n",
      "gradient norm: 0.006921256237546913, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00008\n",
      "\tval loss: 0.00008\n",
      "epoch 18829 / 20000\n",
      "gradient norm: 0.008162589932908304, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00008\n",
      "\tval loss: 0.00008\n",
      "epoch 18830 / 20000\n",
      "gradient norm: 0.015234472128213383, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00008\n",
      "\tval loss: 0.00008\n",
      "epoch 18831 / 20000\n",
      "gradient norm: 0.007368029357166961, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00008\n",
      "\tval loss: 0.00008\n",
      "epoch 18832 / 20000\n",
      "gradient norm: 0.011993681982858106, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00008\n",
      "\tval loss: 0.00008\n",
      "epoch 18833 / 20000\n",
      "gradient norm: 0.011896628930117004, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00008\n",
      "\tval loss: 0.00008\n",
      "epoch 18834 / 20000\n",
      "gradient norm: 0.015323832514695823, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00008\n",
      "\tval loss: 0.00008\n",
      "epoch 18835 / 20000\n",
      "gradient norm: 0.00490973076375667, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00008\n",
      "\tval loss: 0.00008\n",
      "epoch 18836 / 20000\n",
      "gradient norm: 0.004909115086775273, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00008\n",
      "\tval loss: 0.00008\n",
      "epoch 18837 / 20000\n",
      "gradient norm: 0.025765850819880143, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00008\n",
      "\tval loss: 0.00008\n",
      "epoch 18838 / 20000\n",
      "gradient norm: 0.027607924115727656, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00008\n",
      "\tval loss: 0.00008\n",
      "epoch 18839 / 20000\n",
      "gradient norm: 0.01315725632593967, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00008\n",
      "\tval loss: 0.00008\n",
      "epoch 18840 / 20000\n",
      "gradient norm: 0.01713450296665542, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00008\n",
      "\tval loss: 0.00008\n",
      "epoch 18841 / 20000\n",
      "gradient norm: 0.01950505402055569, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00008\n",
      "\tval loss: 0.00008\n",
      "epoch 18842 / 20000\n",
      "gradient norm: 0.011499036278109998, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00008\n",
      "\tval loss: 0.00008\n",
      "epoch 18843 / 20000\n",
      "gradient norm: 0.019365230720723048, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00008\n",
      "\tval loss: 0.00008\n",
      "epoch 18844 / 20000\n",
      "gradient norm: 0.02236053510569036, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00008\n",
      "\tval loss: 0.00008\n",
      "epoch 18845 / 20000\n",
      "gradient norm: 0.014826446102233604, minimum ratio: 2.4815789473684213\n",
      "\ttrain loss: 0.00008\n",
      "\tval loss: 0.00008\n",
      "epoch 18846 / 20000\n",
      "gradient norm: 0.015052420261781663, minimum ratio: 2.465789473684211\n",
      "\ttrain loss: 0.00008\n",
      "\tval loss: 0.00008\n",
      "epoch 18847 / 20000\n",
      "gradient norm: 0.013122514181304723, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00008\n",
      "\tval loss: 0.00008\n",
      "epoch 18848 / 20000\n",
      "gradient norm: 0.010093549615703523, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00008\n",
      "\tval loss: 0.00008\n",
      "epoch 18849 / 20000\n",
      "gradient norm: 0.008170943096047267, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00008\n",
      "\tval loss: 0.00008\n",
      "epoch 18850 / 20000\n",
      "gradient norm: 0.012827907674363814, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00007\n",
      "\tval loss: 0.00008\n",
      "epoch 18851 / 20000\n",
      "gradient norm: 0.020643228170229122, minimum ratio: 2.452631578947368\n",
      "\ttrain loss: 0.00008\n",
      "\tval loss: 0.00008\n",
      "epoch 18852 / 20000\n",
      "gradient norm: 0.01574487470497843, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00007\n",
      "\tval loss: 0.00008\n",
      "epoch 18853 / 20000\n",
      "gradient norm: 0.012645394046558067, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00008\n",
      "\tval loss: 0.00008\n",
      "epoch 18854 / 20000\n",
      "gradient norm: 0.009140437083260622, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00007\n",
      "\tval loss: 0.00008\n",
      "epoch 18855 / 20000\n",
      "gradient norm: 0.006200568917847704, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00007\n",
      "\tval loss: 0.00008\n",
      "epoch 18856 / 20000\n",
      "gradient norm: 0.008696087301359512, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00007\n",
      "\tval loss: 0.00008\n",
      "epoch 18857 / 20000\n",
      "gradient norm: 0.013683132565347478, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00007\n",
      "\tval loss: 0.00008\n",
      "epoch 18858 / 20000\n",
      "gradient norm: 0.008412743143708212, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00007\n",
      "\tval loss: 0.00008\n",
      "epoch 18859 / 20000\n",
      "gradient norm: 0.011562873594812118, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00007\n",
      "\tval loss: 0.00008\n",
      "epoch 18860 / 20000\n",
      "gradient norm: 0.010178550757700577, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00007\n",
      "\tval loss: 0.00008\n",
      "epoch 18861 / 20000\n",
      "gradient norm: 0.010897180749452673, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.00007\n",
      "\tval loss: 0.00008\n",
      "epoch 18862 / 20000\n",
      "gradient norm: 0.016723718057619408, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00007\n",
      "\tval loss: 0.00008\n",
      "epoch 18863 / 20000\n",
      "gradient norm: 0.011922132514882833, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00007\n",
      "\tval loss: 0.00008\n",
      "epoch 18864 / 20000\n",
      "gradient norm: 0.006217051384737715, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00007\n",
      "\tval loss: 0.00008\n",
      "epoch 18865 / 20000\n",
      "gradient norm: 0.02108911456889473, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00007\n",
      "\tval loss: 0.00008\n",
      "epoch 18866 / 20000\n",
      "gradient norm: 0.004887646005954593, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00007\n",
      "\tval loss: 0.00008\n",
      "epoch 18867 / 20000\n",
      "gradient norm: 0.01959775949944742, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00007\n",
      "\tval loss: 0.00008\n",
      "epoch 18868 / 20000\n",
      "gradient norm: 0.01470273724407889, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00007\n",
      "\tval loss: 0.00008\n",
      "epoch 18869 / 20000\n",
      "gradient norm: 0.02082937757950276, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00007\n",
      "\tval loss: 0.00008\n",
      "epoch 18870 / 20000\n",
      "gradient norm: 0.022447455616202205, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00007\n",
      "\tval loss: 0.00008\n",
      "epoch 18871 / 20000\n",
      "gradient norm: 0.011331622081343085, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00007\n",
      "\tval loss: 0.00008\n",
      "epoch 18872 / 20000\n",
      "gradient norm: 0.013178932349546812, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00007\n",
      "\tval loss: 0.00008\n",
      "epoch 18873 / 20000\n",
      "gradient norm: 0.007954903157951776, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00007\n",
      "\tval loss: 0.00008\n",
      "epoch 18874 / 20000\n",
      "gradient norm: 0.003130177028651815, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00007\n",
      "\tval loss: 0.00008\n",
      "epoch 18875 / 20000\n",
      "gradient norm: 0.008193034125724807, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00007\n",
      "\tval loss: 0.00008\n",
      "epoch 18876 / 20000\n",
      "gradient norm: 0.008874819890479557, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00007\n",
      "\tval loss: 0.00008\n",
      "epoch 18877 / 20000\n",
      "gradient norm: 0.007233659736812115, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00007\n",
      "\tval loss: 0.00008\n",
      "epoch 18878 / 20000\n",
      "gradient norm: 0.012113304430386052, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00007\n",
      "\tval loss: 0.00008\n",
      "epoch 18879 / 20000\n",
      "gradient norm: 0.01977730364887975, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00007\n",
      "\tval loss: 0.00008\n",
      "epoch 18880 / 20000\n",
      "gradient norm: 0.018651828926522285, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00007\n",
      "\tval loss: 0.00008\n",
      "epoch 18881 / 20000\n",
      "gradient norm: 0.010748272339696996, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00007\n",
      "\tval loss: 0.00008\n",
      "epoch 18882 / 20000\n",
      "gradient norm: 0.004772279709868599, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00007\n",
      "\tval loss: 0.00008\n",
      "epoch 18883 / 20000\n",
      "gradient norm: 0.006681726626993623, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00007\n",
      "\tval loss: 0.00008\n",
      "epoch 18884 / 20000\n",
      "gradient norm: 0.00868011816055514, minimum ratio: 2.4736842105263155\n",
      "\ttrain loss: 0.00007\n",
      "\tval loss: 0.00008\n",
      "epoch 18885 / 20000\n",
      "gradient norm: 0.008442890248261392, minimum ratio: 2.452631578947368\n",
      "\ttrain loss: 0.00007\n",
      "\tval loss: 0.00008\n",
      "epoch 18886 / 20000\n",
      "gradient norm: 0.009548870599246584, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00007\n",
      "\tval loss: 0.00008\n",
      "epoch 18887 / 20000\n",
      "gradient norm: 0.011254742756136693, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00007\n",
      "\tval loss: 0.00008\n",
      "epoch 18888 / 20000\n",
      "gradient norm: 0.009555437049129978, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00007\n",
      "\tval loss: 0.00008\n",
      "epoch 18889 / 20000\n",
      "gradient norm: 0.016042553987063002, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00007\n",
      "\tval loss: 0.00008\n",
      "epoch 18890 / 20000\n",
      "gradient norm: 0.012607858923729509, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00007\n",
      "\tval loss: 0.00008\n",
      "epoch 18891 / 20000\n",
      "gradient norm: 0.005129455115820747, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00007\n",
      "\tval loss: 0.00008\n",
      "epoch 18892 / 20000\n",
      "gradient norm: 0.008131151313136797, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00007\n",
      "\tval loss: 0.00008\n",
      "epoch 18893 / 20000\n",
      "gradient norm: 0.009051069224369712, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00007\n",
      "\tval loss: 0.00008\n",
      "epoch 18894 / 20000\n",
      "gradient norm: 0.007380887880572118, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00007\n",
      "\tval loss: 0.00008\n",
      "epoch 18895 / 20000\n",
      "gradient norm: 0.008795765475952066, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00007\n",
      "\tval loss: 0.00008\n",
      "epoch 18896 / 20000\n",
      "gradient norm: 0.0120838734874269, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00007\n",
      "\tval loss: 0.00008\n",
      "epoch 18897 / 20000\n",
      "gradient norm: 0.010915403894614428, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00007\n",
      "\tval loss: 0.00008\n",
      "epoch 18898 / 20000\n",
      "gradient norm: 0.014187445631250739, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00007\n",
      "\tval loss: 0.00008\n",
      "epoch 18899 / 20000\n",
      "gradient norm: 0.022847998305223882, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00007\n",
      "\tval loss: 0.00008\n",
      "epoch 18900 / 20000\n",
      "gradient norm: 0.021432415349408984, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00007\n",
      "\tval loss: 0.00008\n",
      "epoch 18901 / 20000\n",
      "gradient norm: 0.011725127376848832, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00007\n",
      "\tval loss: 0.00008\n",
      "epoch 18902 / 20000\n",
      "gradient norm: 0.007634762609086465, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00007\n",
      "\tval loss: 0.00008\n",
      "epoch 18903 / 20000\n",
      "gradient norm: 0.015904397296253592, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00007\n",
      "\tval loss: 0.00008\n",
      "epoch 18904 / 20000\n",
      "gradient norm: 0.012694039731286466, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00007\n",
      "\tval loss: 0.00007\n",
      "epoch 18905 / 20000\n",
      "gradient norm: 0.01053539224085398, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00007\n",
      "\tval loss: 0.00008\n",
      "epoch 18906 / 20000\n",
      "gradient norm: 0.02026067196857184, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00007\n",
      "\tval loss: 0.00007\n",
      "epoch 18907 / 20000\n",
      "gradient norm: 0.00798284835764207, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00007\n",
      "\tval loss: 0.00008\n",
      "epoch 18908 / 20000\n",
      "gradient norm: 0.011117545793240424, minimum ratio: 2.460526315789474\n",
      "\ttrain loss: 0.00007\n",
      "\tval loss: 0.00007\n",
      "epoch 18909 / 20000\n",
      "gradient norm: 0.007812427764292806, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00007\n",
      "\tval loss: 0.00007\n",
      "epoch 18910 / 20000\n",
      "gradient norm: 0.0068959290510974824, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00007\n",
      "\tval loss: 0.00007\n",
      "epoch 18911 / 20000\n",
      "gradient norm: 0.008206587270251475, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00007\n",
      "\tval loss: 0.00008\n",
      "epoch 18912 / 20000\n",
      "gradient norm: 0.015540151864115614, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00007\n",
      "\tval loss: 0.00007\n",
      "epoch 18913 / 20000\n",
      "gradient norm: 0.014249047788325697, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00007\n",
      "\tval loss: 0.00007\n",
      "epoch 18914 / 20000\n",
      "gradient norm: 0.008006268413737416, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00007\n",
      "\tval loss: 0.00007\n",
      "epoch 18915 / 20000\n",
      "gradient norm: 0.011755430925404653, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00007\n",
      "\tval loss: 0.00007\n",
      "epoch 18916 / 20000\n",
      "gradient norm: 0.019935531861847267, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00007\n",
      "\tval loss: 0.00007\n",
      "epoch 18917 / 20000\n",
      "gradient norm: 0.0113258499186486, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00007\n",
      "\tval loss: 0.00007\n",
      "epoch 18918 / 20000\n",
      "gradient norm: 0.009354010660899803, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00007\n",
      "\tval loss: 0.00007\n",
      "epoch 18919 / 20000\n",
      "gradient norm: 0.007725710209342651, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00007\n",
      "\tval loss: 0.00007\n",
      "epoch 18920 / 20000\n",
      "gradient norm: 0.008782046927080955, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00007\n",
      "\tval loss: 0.00007\n",
      "epoch 18921 / 20000\n",
      "gradient norm: 0.005893194262171164, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00007\n",
      "\tval loss: 0.00007\n",
      "epoch 18922 / 20000\n",
      "gradient norm: 0.00830323672562372, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00007\n",
      "\tval loss: 0.00007\n",
      "epoch 18923 / 20000\n",
      "gradient norm: 0.0176167894678656, minimum ratio: 2.460526315789474\n",
      "\ttrain loss: 0.00007\n",
      "\tval loss: 0.00007\n",
      "epoch 18924 / 20000\n",
      "gradient norm: 0.007900240467279218, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00007\n",
      "\tval loss: 0.00007\n",
      "epoch 18925 / 20000\n",
      "gradient norm: 0.007575000694487244, minimum ratio: 2.4394736842105265\n",
      "\ttrain loss: 0.00007\n",
      "\tval loss: 0.00007\n",
      "epoch 18926 / 20000\n",
      "gradient norm: 0.016147743997862563, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00007\n",
      "\tval loss: 0.00007\n",
      "epoch 18927 / 20000\n",
      "gradient norm: 0.009591981419362128, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00007\n",
      "\tval loss: 0.00007\n",
      "epoch 18928 / 20000\n",
      "gradient norm: 0.0076359059967217036, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00007\n",
      "\tval loss: 0.00007\n",
      "epoch 18929 / 20000\n",
      "gradient norm: 0.006218472906766692, minimum ratio: 2.46578947368421\n",
      "\ttrain loss: 0.00007\n",
      "\tval loss: 0.00007\n",
      "epoch 18930 / 20000\n",
      "gradient norm: 0.00917623154236935, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00007\n",
      "\tval loss: 0.00007\n",
      "epoch 18931 / 20000\n",
      "gradient norm: 0.0036921711143804714, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00007\n",
      "\tval loss: 0.00007\n",
      "epoch 18932 / 20000\n",
      "gradient norm: 0.009314763825386763, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00007\n",
      "\tval loss: 0.00007\n",
      "epoch 18933 / 20000\n",
      "gradient norm: 0.00891340005910024, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00007\n",
      "\tval loss: 0.00007\n",
      "epoch 18934 / 20000\n",
      "gradient norm: 0.019981385907158256, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00007\n",
      "\tval loss: 0.00007\n",
      "epoch 18935 / 20000\n",
      "gradient norm: 0.013643398327985778, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00007\n",
      "\tval loss: 0.00007\n",
      "epoch 18936 / 20000\n",
      "gradient norm: 0.007937435817439109, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00007\n",
      "\tval loss: 0.00007\n",
      "epoch 18937 / 20000\n",
      "gradient norm: 0.0051231738907517865, minimum ratio: 2.4868421052631575\n",
      "\ttrain loss: 0.00007\n",
      "\tval loss: 0.00007\n",
      "epoch 18938 / 20000\n",
      "gradient norm: 0.010658364757546224, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00007\n",
      "\tval loss: 0.00007\n",
      "epoch 18939 / 20000\n",
      "gradient norm: 0.0092179491330171, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00007\n",
      "\tval loss: 0.00007\n",
      "epoch 18940 / 20000\n",
      "gradient norm: 0.008864146075211465, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00007\n",
      "\tval loss: 0.00007\n",
      "epoch 18941 / 20000\n",
      "gradient norm: 0.017787645308999345, minimum ratio: 2.4736842105263155\n",
      "\ttrain loss: 0.00007\n",
      "\tval loss: 0.00007\n",
      "epoch 18942 / 20000\n",
      "gradient norm: 0.0163091073918622, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00007\n",
      "\tval loss: 0.00007\n",
      "epoch 18943 / 20000\n",
      "gradient norm: 0.027345053327735513, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00007\n",
      "\tval loss: 0.00007\n",
      "epoch 18944 / 20000\n",
      "gradient norm: 0.020014138441183604, minimum ratio: 2.494736842105263\n",
      "\ttrain loss: 0.00007\n",
      "\tval loss: 0.00007\n",
      "epoch 18945 / 20000\n",
      "gradient norm: 0.01582064233662095, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00007\n",
      "\tval loss: 0.00007\n",
      "epoch 18946 / 20000\n",
      "gradient norm: 0.013919009696110152, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00007\n",
      "\tval loss: 0.00007\n",
      "epoch 18947 / 20000\n",
      "gradient norm: 0.02152859402121976, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00007\n",
      "\tval loss: 0.00007\n",
      "epoch 18948 / 20000\n",
      "gradient norm: 0.018437682927469723, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00007\n",
      "\tval loss: 0.00007\n",
      "epoch 18949 / 20000\n",
      "gradient norm: 0.015534983918769285, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00007\n",
      "\tval loss: 0.00007\n",
      "epoch 18950 / 20000\n",
      "gradient norm: 0.012102134132874198, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00007\n",
      "\tval loss: 0.00007\n",
      "epoch 18951 / 20000\n",
      "gradient norm: 0.012000231290585361, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00007\n",
      "\tval loss: 0.00007\n",
      "epoch 18952 / 20000\n",
      "gradient norm: 0.008851919585140422, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00007\n",
      "\tval loss: 0.00007\n",
      "epoch 18953 / 20000\n",
      "gradient norm: 0.008471363369608298, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00007\n",
      "\tval loss: 0.00007\n",
      "epoch 18954 / 20000\n",
      "gradient norm: 0.012917545434902422, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00007\n",
      "\tval loss: 0.00007\n",
      "epoch 18955 / 20000\n",
      "gradient norm: 0.006096785633417312, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00007\n",
      "\tval loss: 0.00007\n",
      "epoch 18956 / 20000\n",
      "gradient norm: 0.015516247949562967, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00007\n",
      "\tval loss: 0.00007\n",
      "epoch 18957 / 20000\n",
      "gradient norm: 0.018944068753626198, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00007\n",
      "\tval loss: 0.00007\n",
      "epoch 18958 / 20000\n",
      "gradient norm: 0.013560775929363444, minimum ratio: 2.452631578947368\n",
      "\ttrain loss: 0.00007\n",
      "\tval loss: 0.00007\n",
      "epoch 18959 / 20000\n",
      "gradient norm: 0.02099941673805006, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00007\n",
      "\tval loss: 0.00007\n",
      "epoch 18960 / 20000\n",
      "gradient norm: 0.011618418415309861, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00007\n",
      "\tval loss: 0.00007\n",
      "epoch 18961 / 20000\n",
      "gradient norm: 0.010528024518862367, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00007\n",
      "\tval loss: 0.00007\n",
      "epoch 18962 / 20000\n",
      "gradient norm: 0.008315151892020367, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00007\n",
      "\tval loss: 0.00007\n",
      "epoch 18963 / 20000\n",
      "gradient norm: 0.008613517187768593, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00007\n",
      "\tval loss: 0.00007\n",
      "epoch 18964 / 20000\n",
      "gradient norm: 0.006395778109435923, minimum ratio: 2.4421052631578943\n",
      "\ttrain loss: 0.00007\n",
      "\tval loss: 0.00007\n",
      "epoch 18965 / 20000\n",
      "gradient norm: 0.009639187424909323, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00007\n",
      "\tval loss: 0.00007\n",
      "epoch 18966 / 20000\n",
      "gradient norm: 0.01699979926343076, minimum ratio: 2.4868421052631575\n",
      "\ttrain loss: 0.00007\n",
      "\tval loss: 0.00007\n",
      "epoch 18967 / 20000\n",
      "gradient norm: 0.018326265329960734, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00007\n",
      "\tval loss: 0.00007\n",
      "epoch 18968 / 20000\n",
      "gradient norm: 0.012679758772719651, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00007\n",
      "\tval loss: 0.00007\n",
      "epoch 18969 / 20000\n",
      "gradient norm: 0.015873279509833083, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00007\n",
      "\tval loss: 0.00007\n",
      "epoch 18970 / 20000\n",
      "gradient norm: 0.018149929819628596, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00007\n",
      "\tval loss: 0.00007\n",
      "epoch 18971 / 20000\n",
      "gradient norm: 0.013408520229859278, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00007\n",
      "\tval loss: 0.00007\n",
      "epoch 18972 / 20000\n",
      "gradient norm: 0.018074567866278812, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00007\n",
      "\tval loss: 0.00007\n",
      "epoch 18973 / 20000\n",
      "gradient norm: 0.02124095385079272, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00007\n",
      "\tval loss: 0.00007\n",
      "epoch 18974 / 20000\n",
      "gradient norm: 0.011826490517705679, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00006\n",
      "\tval loss: 0.00007\n",
      "epoch 18975 / 20000\n",
      "gradient norm: 0.013865829925634898, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00007\n",
      "\tval loss: 0.00007\n",
      "epoch 18976 / 20000\n",
      "gradient norm: 0.016572736378293484, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00007\n",
      "\tval loss: 0.00007\n",
      "epoch 18977 / 20000\n",
      "gradient norm: 0.014918238623067737, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00006\n",
      "\tval loss: 0.00007\n",
      "epoch 18978 / 20000\n",
      "gradient norm: 0.021760486299172044, minimum ratio: 2.4842105263157896\n",
      "\ttrain loss: 0.00007\n",
      "\tval loss: 0.00007\n",
      "epoch 18979 / 20000\n",
      "gradient norm: 0.017427487880922854, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00007\n",
      "\tval loss: 0.00007\n",
      "epoch 18980 / 20000\n",
      "gradient norm: 0.01869980347692035, minimum ratio: 2.4736842105263155\n",
      "\ttrain loss: 0.00007\n",
      "\tval loss: 0.00007\n",
      "epoch 18981 / 20000\n",
      "gradient norm: 0.02132405579322949, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00007\n",
      "\tval loss: 0.00007\n",
      "epoch 18982 / 20000\n",
      "gradient norm: 0.02080492995446548, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00006\n",
      "\tval loss: 0.00007\n",
      "epoch 18983 / 20000\n",
      "gradient norm: 0.020902334799757227, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00007\n",
      "\tval loss: 0.00007\n",
      "epoch 18984 / 20000\n",
      "gradient norm: 0.0139340568712214, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00006\n",
      "\tval loss: 0.00007\n",
      "epoch 18985 / 20000\n",
      "gradient norm: 0.016388272430049255, minimum ratio: 2.46578947368421\n",
      "\ttrain loss: 0.00006\n",
      "\tval loss: 0.00007\n",
      "epoch 18986 / 20000\n",
      "gradient norm: 0.01120073877973482, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00006\n",
      "\tval loss: 0.00007\n",
      "epoch 18987 / 20000\n",
      "gradient norm: 0.012668641487834975, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00006\n",
      "\tval loss: 0.00007\n",
      "epoch 18988 / 20000\n",
      "gradient norm: 0.023514755332143977, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00006\n",
      "\tval loss: 0.00007\n",
      "epoch 18989 / 20000\n",
      "gradient norm: 0.013793806283501908, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00006\n",
      "\tval loss: 0.00007\n",
      "epoch 18990 / 20000\n",
      "gradient norm: 0.013433152067591436, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00006\n",
      "\tval loss: 0.00007\n",
      "epoch 18991 / 20000\n",
      "gradient norm: 0.007242071907967329, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00006\n",
      "\tval loss: 0.00007\n",
      "epoch 18992 / 20000\n",
      "gradient norm: 0.005481994434376247, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00006\n",
      "\tval loss: 0.00007\n",
      "epoch 18993 / 20000\n",
      "gradient norm: 0.014382958761416376, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00006\n",
      "\tval loss: 0.00007\n",
      "epoch 18994 / 20000\n",
      "gradient norm: 0.016606714358204044, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00006\n",
      "\tval loss: 0.00007\n",
      "epoch 18995 / 20000\n",
      "gradient norm: 0.011719713016645983, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00006\n",
      "\tval loss: 0.00007\n",
      "epoch 18996 / 20000\n",
      "gradient norm: 0.01386040126089938, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00006\n",
      "\tval loss: 0.00007\n",
      "epoch 18997 / 20000\n",
      "gradient norm: 0.02723394336499041, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00006\n",
      "\tval loss: 0.00007\n",
      "epoch 18998 / 20000\n",
      "gradient norm: 0.02272864370024763, minimum ratio: 2.46578947368421\n",
      "\ttrain loss: 0.00006\n",
      "\tval loss: 0.00007\n",
      "epoch 18999 / 20000\n",
      "gradient norm: 0.019809874705970287, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00006\n",
      "\tval loss: 0.00007\n",
      "epoch 19000 / 20000\n",
      "gradient norm: 0.012219101932714693, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00006\n",
      "\tval loss: 0.00007\n",
      "epoch 19001 / 20000\n",
      "gradient norm: 0.01574110447836574, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00006\n",
      "\tval loss: 0.00007\n",
      "epoch 19002 / 20000\n",
      "gradient norm: 0.00983412962523289, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00006\n",
      "\tval loss: 0.00007\n",
      "epoch 19003 / 20000\n",
      "gradient norm: 0.004828396835364401, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00006\n",
      "\tval loss: 0.00007\n",
      "epoch 19004 / 20000\n",
      "gradient norm: 0.007872721238527447, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00006\n",
      "\tval loss: 0.00007\n",
      "epoch 19005 / 20000\n",
      "gradient norm: 0.007255634598550387, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00006\n",
      "\tval loss: 0.00007\n",
      "epoch 19006 / 20000\n",
      "gradient norm: 0.011534671124536544, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00006\n",
      "\tval loss: 0.00007\n",
      "epoch 19007 / 20000\n",
      "gradient norm: 0.0032406444079242647, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00006\n",
      "\tval loss: 0.00007\n",
      "epoch 19008 / 20000\n",
      "gradient norm: 0.005443430607556365, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00006\n",
      "\tval loss: 0.00007\n",
      "epoch 19009 / 20000\n",
      "gradient norm: 0.0045588317516376264, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00006\n",
      "\tval loss: 0.00007\n",
      "epoch 19010 / 20000\n",
      "gradient norm: 0.0031254155401256867, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00006\n",
      "\tval loss: 0.00007\n",
      "epoch 19011 / 20000\n",
      "gradient norm: 0.005717729960451834, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00006\n",
      "\tval loss: 0.00007\n",
      "epoch 19012 / 20000\n",
      "gradient norm: 0.007718755470705219, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00006\n",
      "\tval loss: 0.00007\n",
      "epoch 19013 / 20000\n",
      "gradient norm: 0.015078018885105848, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00006\n",
      "\tval loss: 0.00007\n",
      "epoch 19014 / 20000\n",
      "gradient norm: 0.015394891423056833, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00006\n",
      "\tval loss: 0.00007\n",
      "epoch 19015 / 20000\n",
      "gradient norm: 0.013209180760895833, minimum ratio: 2.4947368421052634\n",
      "\ttrain loss: 0.00006\n",
      "\tval loss: 0.00007\n",
      "epoch 19016 / 20000\n",
      "gradient norm: 0.011819958250271156, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00006\n",
      "\tval loss: 0.00007\n",
      "epoch 19017 / 20000\n",
      "gradient norm: 0.009734385486808605, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00006\n",
      "\tval loss: 0.00007\n",
      "epoch 19018 / 20000\n",
      "gradient norm: 0.004832919978071004, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00006\n",
      "\tval loss: 0.00007\n",
      "epoch 19019 / 20000\n",
      "gradient norm: 0.010589821853500325, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00006\n",
      "\tval loss: 0.00007\n",
      "epoch 19020 / 20000\n",
      "gradient norm: 0.00987792520027142, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00006\n",
      "\tval loss: 0.00007\n",
      "epoch 19021 / 20000\n",
      "gradient norm: 0.009175932325888425, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00006\n",
      "\tval loss: 0.00007\n",
      "epoch 19022 / 20000\n",
      "gradient norm: 0.0041545352432876825, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00006\n",
      "\tval loss: 0.00007\n",
      "epoch 19023 / 20000\n",
      "gradient norm: 0.011445843207184225, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00006\n",
      "\tval loss: 0.00007\n",
      "epoch 19024 / 20000\n",
      "gradient norm: 0.01819078763946891, minimum ratio: 2.460526315789474\n",
      "\ttrain loss: 0.00006\n",
      "\tval loss: 0.00007\n",
      "epoch 19025 / 20000\n",
      "gradient norm: 0.015446703881025314, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00006\n",
      "\tval loss: 0.00007\n",
      "epoch 19026 / 20000\n",
      "gradient norm: 0.012133549418649636, minimum ratio: 2.4736842105263155\n",
      "\ttrain loss: 0.00006\n",
      "\tval loss: 0.00007\n",
      "epoch 19027 / 20000\n",
      "gradient norm: 0.0037778451296617277, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00006\n",
      "\tval loss: 0.00007\n",
      "epoch 19028 / 20000\n",
      "gradient norm: 0.004797825400601141, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00006\n",
      "\tval loss: 0.00007\n",
      "epoch 19029 / 20000\n",
      "gradient norm: 0.005376256682211533, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00006\n",
      "\tval loss: 0.00007\n",
      "epoch 19030 / 20000\n",
      "gradient norm: 0.00573923415504396, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00006\n",
      "\tval loss: 0.00007\n",
      "epoch 19031 / 20000\n",
      "gradient norm: 0.010826948346220888, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00006\n",
      "\tval loss: 0.00007\n",
      "epoch 19032 / 20000\n",
      "gradient norm: 0.013736137261730619, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00006\n",
      "\tval loss: 0.00007\n",
      "epoch 19033 / 20000\n",
      "gradient norm: 0.009204394009429961, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00006\n",
      "\tval loss: 0.00007\n",
      "epoch 19034 / 20000\n",
      "gradient norm: 0.005043709257734008, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00006\n",
      "\tval loss: 0.00007\n",
      "epoch 19035 / 20000\n",
      "gradient norm: 0.004863027548708487, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00006\n",
      "\tval loss: 0.00007\n",
      "epoch 19036 / 20000\n",
      "gradient norm: 0.00860143137833802, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00006\n",
      "\tval loss: 0.00007\n",
      "epoch 19037 / 20000\n",
      "gradient norm: 0.01950306340586394, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00006\n",
      "\tval loss: 0.00007\n",
      "epoch 19038 / 20000\n",
      "gradient norm: 0.020706442301161587, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.00006\n",
      "\tval loss: 0.00007\n",
      "epoch 19039 / 20000\n",
      "gradient norm: 0.018123399335308932, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00006\n",
      "\tval loss: 0.00007\n",
      "epoch 19040 / 20000\n",
      "gradient norm: 0.017280303116422147, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00006\n",
      "\tval loss: 0.00007\n",
      "epoch 19041 / 20000\n",
      "gradient norm: 0.013208638920332305, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00006\n",
      "\tval loss: 0.00007\n",
      "epoch 19042 / 20000\n",
      "gradient norm: 0.0075244829640723765, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00006\n",
      "\tval loss: 0.00007\n",
      "epoch 19043 / 20000\n",
      "gradient norm: 0.024275729705550475, minimum ratio: 2.4447368421052635\n",
      "\ttrain loss: 0.00006\n",
      "\tval loss: 0.00007\n",
      "epoch 19044 / 20000\n",
      "gradient norm: 0.013048380395048298, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00006\n",
      "\tval loss: 0.00007\n",
      "epoch 19045 / 20000\n",
      "gradient norm: 0.012378190993331373, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00006\n",
      "\tval loss: 0.00007\n",
      "epoch 19046 / 20000\n",
      "gradient norm: 0.009389183047460392, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00006\n",
      "\tval loss: 0.00006\n",
      "epoch 19047 / 20000\n",
      "gradient norm: 0.008097838232060894, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00006\n",
      "\tval loss: 0.00006\n",
      "epoch 19048 / 20000\n",
      "gradient norm: 0.006642311185714789, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00006\n",
      "\tval loss: 0.00006\n",
      "epoch 19049 / 20000\n",
      "gradient norm: 0.0038357075245585293, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00006\n",
      "\tval loss: 0.00006\n",
      "epoch 19050 / 20000\n",
      "gradient norm: 0.004354021912149619, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00006\n",
      "\tval loss: 0.00006\n",
      "epoch 19051 / 20000\n",
      "gradient norm: 0.010748496380983852, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00006\n",
      "\tval loss: 0.00006\n",
      "epoch 19052 / 20000\n",
      "gradient norm: 0.01870500500081107, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00006\n",
      "\tval loss: 0.00007\n",
      "epoch 19053 / 20000\n",
      "gradient norm: 0.00916989722463768, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00006\n",
      "\tval loss: 0.00006\n",
      "epoch 19054 / 20000\n",
      "gradient norm: 0.00860875153739471, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00006\n",
      "\tval loss: 0.00006\n",
      "epoch 19055 / 20000\n",
      "gradient norm: 0.014439898484852165, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00006\n",
      "\tval loss: 0.00006\n",
      "epoch 19056 / 20000\n",
      "gradient norm: 0.012135315773775801, minimum ratio: 2.4499999999999997\n",
      "\ttrain loss: 0.00006\n",
      "\tval loss: 0.00006\n",
      "epoch 19057 / 20000\n",
      "gradient norm: 0.01595859503140673, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00006\n",
      "\tval loss: 0.00006\n",
      "epoch 19058 / 20000\n",
      "gradient norm: 0.013470130841596983, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00006\n",
      "\tval loss: 0.00006\n",
      "epoch 19059 / 20000\n",
      "gradient norm: 0.012727234949124977, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00006\n",
      "\tval loss: 0.00006\n",
      "epoch 19060 / 20000\n",
      "gradient norm: 0.007683077928959392, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00006\n",
      "\tval loss: 0.00006\n",
      "epoch 19061 / 20000\n",
      "gradient norm: 0.006184708719956689, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00006\n",
      "\tval loss: 0.00006\n",
      "epoch 19062 / 20000\n",
      "gradient norm: 0.01344431184406858, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00006\n",
      "\tval loss: 0.00006\n",
      "epoch 19063 / 20000\n",
      "gradient norm: 0.005111859325552359, minimum ratio: 2.4842105263157896\n",
      "\ttrain loss: 0.00006\n",
      "\tval loss: 0.00006\n",
      "epoch 19064 / 20000\n",
      "gradient norm: 0.01039909767860081, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00006\n",
      "\tval loss: 0.00006\n",
      "epoch 19065 / 20000\n",
      "gradient norm: 0.014394426572835073, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00006\n",
      "\tval loss: 0.00006\n",
      "epoch 19066 / 20000\n",
      "gradient norm: 0.011085071048000827, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00006\n",
      "\tval loss: 0.00006\n",
      "epoch 19067 / 20000\n",
      "gradient norm: 0.014364436967298388, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00006\n",
      "\tval loss: 0.00006\n",
      "epoch 19068 / 20000\n",
      "gradient norm: 0.014194132985721808, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00006\n",
      "\tval loss: 0.00007\n",
      "epoch 19069 / 20000\n",
      "gradient norm: 0.022057534428313375, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00006\n",
      "\tval loss: 0.00006\n",
      "epoch 19070 / 20000\n",
      "gradient norm: 0.021450932305015158, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00006\n",
      "\tval loss: 0.00007\n",
      "epoch 19071 / 20000\n",
      "gradient norm: 0.02208353838068433, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00006\n",
      "\tval loss: 0.00006\n",
      "epoch 19072 / 20000\n",
      "gradient norm: 0.016279528077575378, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00006\n",
      "\tval loss: 0.00006\n",
      "epoch 19073 / 20000\n",
      "gradient norm: 0.016785217623692006, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00006\n",
      "\tval loss: 0.00006\n",
      "epoch 19074 / 20000\n",
      "gradient norm: 0.0058915910485666245, minimum ratio: 2.465789473684211\n",
      "\ttrain loss: 0.00006\n",
      "\tval loss: 0.00006\n",
      "epoch 19075 / 20000\n",
      "gradient norm: 0.0071114427264546975, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00006\n",
      "\tval loss: 0.00006\n",
      "epoch 19076 / 20000\n",
      "gradient norm: 0.0031477942029596306, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00006\n",
      "\tval loss: 0.00006\n",
      "epoch 19077 / 20000\n",
      "gradient norm: 0.008511584048392251, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00006\n",
      "\tval loss: 0.00006\n",
      "epoch 19078 / 20000\n",
      "gradient norm: 0.005010552398744039, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00006\n",
      "\tval loss: 0.00006\n",
      "epoch 19079 / 20000\n",
      "gradient norm: 0.005206782283494249, minimum ratio: 2.4736842105263155\n",
      "\ttrain loss: 0.00006\n",
      "\tval loss: 0.00006\n",
      "epoch 19080 / 20000\n",
      "gradient norm: 0.005658953668898903, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.00006\n",
      "\tval loss: 0.00006\n",
      "epoch 19081 / 20000\n",
      "gradient norm: 0.011198978871107101, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00006\n",
      "\tval loss: 0.00006\n",
      "epoch 19082 / 20000\n",
      "gradient norm: 0.016151932650245726, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00006\n",
      "\tval loss: 0.00006\n",
      "epoch 19083 / 20000\n",
      "gradient norm: 0.011049441352952272, minimum ratio: 2.4578947368421056\n",
      "\ttrain loss: 0.00006\n",
      "\tval loss: 0.00006\n",
      "epoch 19084 / 20000\n",
      "gradient norm: 0.023246927303262055, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00006\n",
      "\tval loss: 0.00006\n",
      "epoch 19085 / 20000\n",
      "gradient norm: 0.016810571491078008, minimum ratio: 2.452631578947368\n",
      "\ttrain loss: 0.00006\n",
      "\tval loss: 0.00006\n",
      "epoch 19086 / 20000\n",
      "gradient norm: 0.010493810186744668, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00006\n",
      "\tval loss: 0.00006\n",
      "epoch 19087 / 20000\n",
      "gradient norm: 0.00899592113273684, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00006\n",
      "\tval loss: 0.00006\n",
      "epoch 19088 / 20000\n",
      "gradient norm: 0.008152750400768127, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00006\n",
      "\tval loss: 0.00006\n",
      "epoch 19089 / 20000\n",
      "gradient norm: 0.009621237084502354, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00006\n",
      "\tval loss: 0.00006\n",
      "epoch 19090 / 20000\n",
      "gradient norm: 0.012825588550185785, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00006\n",
      "\tval loss: 0.00006\n",
      "epoch 19091 / 20000\n",
      "gradient norm: 0.009534240438370034, minimum ratio: 2.460526315789474\n",
      "\ttrain loss: 0.00006\n",
      "\tval loss: 0.00006\n",
      "epoch 19092 / 20000\n",
      "gradient norm: 0.005982680275337771, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00006\n",
      "\tval loss: 0.00006\n",
      "epoch 19093 / 20000\n",
      "gradient norm: 0.00597100707818754, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00006\n",
      "\tval loss: 0.00006\n",
      "epoch 19094 / 20000\n",
      "gradient norm: 0.007252381521539064, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00006\n",
      "\tval loss: 0.00006\n",
      "epoch 19095 / 20000\n",
      "gradient norm: 0.01027624488051515, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00006\n",
      "\tval loss: 0.00006\n",
      "epoch 19096 / 20000\n",
      "gradient norm: 0.013886108383303508, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00006\n",
      "\tval loss: 0.00006\n",
      "epoch 19097 / 20000\n",
      "gradient norm: 0.019759501847147476, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.00006\n",
      "\tval loss: 0.00006\n",
      "epoch 19098 / 20000\n",
      "gradient norm: 0.01773013171623461, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00006\n",
      "\tval loss: 0.00006\n",
      "epoch 19099 / 20000\n",
      "gradient norm: 0.022422927955631167, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00006\n",
      "\tval loss: 0.00006\n",
      "epoch 19100 / 20000\n",
      "gradient norm: 0.015479451816645451, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00006\n",
      "\tval loss: 0.00006\n",
      "epoch 19101 / 20000\n",
      "gradient norm: 0.022420792985940352, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00006\n",
      "\tval loss: 0.00006\n",
      "epoch 19102 / 20000\n",
      "gradient norm: 0.01414639933500439, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00006\n",
      "\tval loss: 0.00006\n",
      "epoch 19103 / 20000\n",
      "gradient norm: 0.010972498042974621, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00006\n",
      "\tval loss: 0.00006\n",
      "epoch 19104 / 20000\n",
      "gradient norm: 0.012373666075291112, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00006\n",
      "\tval loss: 0.00006\n",
      "epoch 19105 / 20000\n",
      "gradient norm: 0.007600934972288087, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00006\n",
      "\tval loss: 0.00006\n",
      "epoch 19106 / 20000\n",
      "gradient norm: 0.010176377123571001, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00006\n",
      "\tval loss: 0.00006\n",
      "epoch 19107 / 20000\n",
      "gradient norm: 0.013623467995785177, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00006\n",
      "\tval loss: 0.00006\n",
      "epoch 19108 / 20000\n",
      "gradient norm: 0.013542143329686951, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00006\n",
      "\tval loss: 0.00006\n",
      "epoch 19109 / 20000\n",
      "gradient norm: 0.01441200626140926, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00006\n",
      "\tval loss: 0.00006\n",
      "epoch 19110 / 20000\n",
      "gradient norm: 0.015113522247702349, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00006\n",
      "\tval loss: 0.00006\n",
      "epoch 19111 / 20000\n",
      "gradient norm: 0.0066199267384945415, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00006\n",
      "\tval loss: 0.00006\n",
      "epoch 19112 / 20000\n",
      "gradient norm: 0.010989421047270298, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00006\n",
      "\tval loss: 0.00006\n",
      "epoch 19113 / 20000\n",
      "gradient norm: 0.01061861409834819, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00006\n",
      "\tval loss: 0.00006\n",
      "epoch 19114 / 20000\n",
      "gradient norm: 0.009762610134202987, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00006\n",
      "\tval loss: 0.00006\n",
      "epoch 19115 / 20000\n",
      "gradient norm: 0.014223066536942497, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00006\n",
      "\tval loss: 0.00006\n",
      "epoch 19116 / 20000\n",
      "gradient norm: 0.004542481605312787, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00006\n",
      "\tval loss: 0.00006\n",
      "epoch 19117 / 20000\n",
      "gradient norm: 0.0033732483643689193, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00006\n",
      "\tval loss: 0.00006\n",
      "epoch 19118 / 20000\n",
      "gradient norm: 0.00504550730693154, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00006\n",
      "\tval loss: 0.00006\n",
      "epoch 19119 / 20000\n",
      "gradient norm: 0.010463659884408116, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00006\n",
      "\tval loss: 0.00006\n",
      "epoch 19120 / 20000\n",
      "gradient norm: 0.015784357019583695, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00006\n",
      "\tval loss: 0.00006\n",
      "epoch 19121 / 20000\n",
      "gradient norm: 0.01864691308583133, minimum ratio: 2.46578947368421\n",
      "\ttrain loss: 0.00006\n",
      "\tval loss: 0.00006\n",
      "epoch 19122 / 20000\n",
      "gradient norm: 0.019220084504922852, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00006\n",
      "\tval loss: 0.00006\n",
      "epoch 19123 / 20000\n",
      "gradient norm: 0.017801329217036255, minimum ratio: 2.4815789473684213\n",
      "\ttrain loss: 0.00006\n",
      "\tval loss: 0.00006\n",
      "epoch 19124 / 20000\n",
      "gradient norm: 0.01952881160832476, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00006\n",
      "\tval loss: 0.00006\n",
      "epoch 19125 / 20000\n",
      "gradient norm: 0.014874047774355859, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00006\n",
      "\tval loss: 0.00006\n",
      "epoch 19126 / 20000\n",
      "gradient norm: 0.019324728491483256, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00006\n",
      "\tval loss: 0.00006\n",
      "epoch 19127 / 20000\n",
      "gradient norm: 0.015663535974454135, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00006\n",
      "\tval loss: 0.00006\n",
      "epoch 19128 / 20000\n",
      "gradient norm: 0.008867742762959097, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00006\n",
      "\tval loss: 0.00006\n",
      "epoch 19129 / 20000\n",
      "gradient norm: 0.006731603600201197, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00006\n",
      "\tval loss: 0.00006\n",
      "epoch 19130 / 20000\n",
      "gradient norm: 0.007316156406886876, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00006\n",
      "\tval loss: 0.00006\n",
      "epoch 19131 / 20000\n",
      "gradient norm: 0.008572550417738967, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00006\n",
      "\tval loss: 0.00006\n",
      "epoch 19132 / 20000\n",
      "gradient norm: 0.004010427568573505, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00006\n",
      "\tval loss: 0.00006\n",
      "epoch 19133 / 20000\n",
      "gradient norm: 0.011482700589112937, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00006\n",
      "\tval loss: 0.00006\n",
      "epoch 19134 / 20000\n",
      "gradient norm: 0.009838988509727642, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00006\n",
      "\tval loss: 0.00006\n",
      "epoch 19135 / 20000\n",
      "gradient norm: 0.009136149150435813, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00006\n",
      "\tval loss: 0.00006\n",
      "epoch 19136 / 20000\n",
      "gradient norm: 0.015009922091849148, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00006\n",
      "\tval loss: 0.00006\n",
      "epoch 19137 / 20000\n",
      "gradient norm: 0.00993790196662303, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00006\n",
      "\tval loss: 0.00006\n",
      "epoch 19138 / 20000\n",
      "gradient norm: 0.008013066981220618, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00006\n",
      "\tval loss: 0.00006\n",
      "epoch 19139 / 20000\n",
      "gradient norm: 0.01489102773484774, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00006\n",
      "\tval loss: 0.00006\n",
      "epoch 19140 / 20000\n",
      "gradient norm: 0.024059078481514007, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00006\n",
      "\tval loss: 0.00006\n",
      "epoch 19141 / 20000\n",
      "gradient norm: 0.014483266597380862, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00006\n",
      "\tval loss: 0.00006\n",
      "epoch 19142 / 20000\n",
      "gradient norm: 0.007803943266480928, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00006\n",
      "\tval loss: 0.00006\n",
      "epoch 19143 / 20000\n",
      "gradient norm: 0.008680718368850648, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00006\n",
      "\tval loss: 0.00006\n",
      "epoch 19144 / 20000\n",
      "gradient norm: 0.010707918379921466, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.00006\n",
      "\tval loss: 0.00006\n",
      "epoch 19145 / 20000\n",
      "gradient norm: 0.014824111334746704, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00006\n",
      "\tval loss: 0.00006\n",
      "epoch 19146 / 20000\n",
      "gradient norm: 0.01285550050670281, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00006\n",
      "\tval loss: 0.00006\n",
      "epoch 19147 / 20000\n",
      "gradient norm: 0.010076518403366208, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00006\n",
      "\tval loss: 0.00006\n",
      "epoch 19148 / 20000\n",
      "gradient norm: 0.009874402043351438, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00006\n",
      "\tval loss: 0.00006\n",
      "epoch 19149 / 20000\n",
      "gradient norm: 0.01574326609261334, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00006\n",
      "\tval loss: 0.00006\n",
      "epoch 19150 / 20000\n",
      "gradient norm: 0.01724092596123228, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00006\n",
      "\tval loss: 0.00006\n",
      "epoch 19151 / 20000\n",
      "gradient norm: 0.020796669865376316, minimum ratio: 2.4894736842105267\n",
      "\ttrain loss: 0.00006\n",
      "\tval loss: 0.00006\n",
      "epoch 19152 / 20000\n",
      "gradient norm: 0.013830722702550702, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00006\n",
      "\tval loss: 0.00006\n",
      "epoch 19153 / 20000\n",
      "gradient norm: 0.006971426060772501, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00006\n",
      "\tval loss: 0.00006\n",
      "epoch 19154 / 20000\n",
      "gradient norm: 0.004247271208441816, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00006\n",
      "\tval loss: 0.00006\n",
      "epoch 19155 / 20000\n",
      "gradient norm: 0.013193587292334996, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00006\n",
      "\tval loss: 0.00006\n",
      "epoch 19156 / 20000\n",
      "gradient norm: 0.010641309738275595, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00006\n",
      "\tval loss: 0.00006\n",
      "epoch 19157 / 20000\n",
      "gradient norm: 0.009164104791125283, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00006\n",
      "\tval loss: 0.00006\n",
      "epoch 19158 / 20000\n",
      "gradient norm: 0.007008244225289673, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00006\n",
      "\tval loss: 0.00006\n",
      "epoch 19159 / 20000\n",
      "gradient norm: 0.008219027484301478, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00006\n",
      "\tval loss: 0.00006\n",
      "epoch 19160 / 20000\n",
      "gradient norm: 0.01768758671823889, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00006\n",
      "\tval loss: 0.00006\n",
      "epoch 19161 / 20000\n",
      "gradient norm: 0.016143938264576718, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00006\n",
      "\tval loss: 0.00006\n",
      "epoch 19162 / 20000\n",
      "gradient norm: 0.010706944383855443, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00006\n",
      "\tval loss: 0.00006\n",
      "epoch 19163 / 20000\n",
      "gradient norm: 0.00875047707813792, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00006\n",
      "\tval loss: 0.00006\n",
      "epoch 19164 / 20000\n",
      "gradient norm: 0.011368686144123785, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00006\n",
      "\tval loss: 0.00006\n",
      "epoch 19165 / 20000\n",
      "gradient norm: 0.012532564258435741, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00006\n",
      "\tval loss: 0.00006\n",
      "epoch 19166 / 20000\n",
      "gradient norm: 0.00851284600503277, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00006\n",
      "\tval loss: 0.00006\n",
      "epoch 19167 / 20000\n",
      "gradient norm: 0.008970064416644163, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00006\n",
      "\tval loss: 0.00006\n",
      "epoch 19168 / 20000\n",
      "gradient norm: 0.007582940423162654, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00006\n",
      "\tval loss: 0.00006\n",
      "epoch 19169 / 20000\n",
      "gradient norm: 0.011040604425943457, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00006\n",
      "\tval loss: 0.00006\n",
      "epoch 19170 / 20000\n",
      "gradient norm: 0.024968184996396303, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00006\n",
      "\tval loss: 0.00006\n",
      "epoch 19171 / 20000\n",
      "gradient norm: 0.015064092265674844, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00006\n",
      "\tval loss: 0.00006\n",
      "epoch 19172 / 20000\n",
      "gradient norm: 0.011999931259197183, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00006\n",
      "\tval loss: 0.00006\n",
      "epoch 19173 / 20000\n",
      "gradient norm: 0.009451879319385625, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00006\n",
      "\tval loss: 0.00006\n",
      "epoch 19174 / 20000\n",
      "gradient norm: 0.005667305718816351, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00006\n",
      "epoch 19175 / 20000\n",
      "gradient norm: 0.00440983398584649, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00006\n",
      "epoch 19176 / 20000\n",
      "gradient norm: 0.006522217809106223, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00006\n",
      "\tval loss: 0.00006\n",
      "epoch 19177 / 20000\n",
      "gradient norm: 0.0015162824201979674, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00006\n",
      "epoch 19178 / 20000\n",
      "gradient norm: 0.00529448504676111, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00006\n",
      "epoch 19179 / 20000\n",
      "gradient norm: 0.010541912939515896, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00006\n",
      "\tval loss: 0.00006\n",
      "epoch 19180 / 20000\n",
      "gradient norm: 0.01619393503642641, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00006\n",
      "\tval loss: 0.00006\n",
      "epoch 19181 / 20000\n",
      "gradient norm: 0.031382914166897535, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00006\n",
      "\tval loss: 0.00006\n",
      "epoch 19182 / 20000\n",
      "gradient norm: 0.02903998458350543, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00006\n",
      "\tval loss: 0.00006\n",
      "epoch 19183 / 20000\n",
      "gradient norm: 0.031100942404009402, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00006\n",
      "\tval loss: 0.00006\n",
      "epoch 19184 / 20000\n",
      "gradient norm: 0.027075257647084072, minimum ratio: 2.4394736842105265\n",
      "\ttrain loss: 0.00006\n",
      "\tval loss: 0.00006\n",
      "epoch 19185 / 20000\n",
      "gradient norm: 0.016312251827912405, minimum ratio: 2.465789473684211\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00006\n",
      "epoch 19186 / 20000\n",
      "gradient norm: 0.0064021149155450985, minimum ratio: 2.4447368421052635\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00006\n",
      "epoch 19187 / 20000\n",
      "gradient norm: 0.005709994373319205, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00006\n",
      "epoch 19188 / 20000\n",
      "gradient norm: 0.0065748700726544484, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00006\n",
      "epoch 19189 / 20000\n",
      "gradient norm: 0.00887499679083703, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00006\n",
      "epoch 19190 / 20000\n",
      "gradient norm: 0.009158789369394071, minimum ratio: 2.4447368421052635\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00006\n",
      "epoch 19191 / 20000\n",
      "gradient norm: 0.01039929164107889, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00006\n",
      "epoch 19192 / 20000\n",
      "gradient norm: 0.008602626527135726, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00006\n",
      "epoch 19193 / 20000\n",
      "gradient norm: 0.0063182914891513065, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00006\n",
      "epoch 19194 / 20000\n",
      "gradient norm: 0.007081343253958039, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00006\n",
      "epoch 19195 / 20000\n",
      "gradient norm: 0.005603528668871149, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00006\n",
      "epoch 19196 / 20000\n",
      "gradient norm: 0.0063553437939845026, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00006\n",
      "epoch 19197 / 20000\n",
      "gradient norm: 0.013672813947778195, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00006\n",
      "epoch 19198 / 20000\n",
      "gradient norm: 0.013458117988193408, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00006\n",
      "epoch 19199 / 20000\n",
      "gradient norm: 0.016654859500704333, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00006\n",
      "epoch 19200 / 20000\n",
      "gradient norm: 0.016131094642332755, minimum ratio: 2.4842105263157896\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00006\n",
      "epoch 19201 / 20000\n",
      "gradient norm: 0.011807187838712707, minimum ratio: 2.4447368421052635\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00006\n",
      "epoch 19202 / 20000\n",
      "gradient norm: 0.005930436178459786, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00006\n",
      "epoch 19203 / 20000\n",
      "gradient norm: 0.0052033247957297135, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00006\n",
      "epoch 19204 / 20000\n",
      "gradient norm: 0.007554402785899583, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00006\n",
      "epoch 19205 / 20000\n",
      "gradient norm: 0.00991770753171295, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00006\n",
      "epoch 19206 / 20000\n",
      "gradient norm: 0.0033569938968867064, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00006\n",
      "epoch 19207 / 20000\n",
      "gradient norm: 0.004504164855461568, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00006\n",
      "epoch 19208 / 20000\n",
      "gradient norm: 0.007136902029742487, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00006\n",
      "epoch 19209 / 20000\n",
      "gradient norm: 0.007527876950916834, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00006\n",
      "epoch 19210 / 20000\n",
      "gradient norm: 0.00980417123355437, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00006\n",
      "epoch 19211 / 20000\n",
      "gradient norm: 0.012164343352196738, minimum ratio: 2.4842105263157896\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00006\n",
      "epoch 19212 / 20000\n",
      "gradient norm: 0.01538219086069148, minimum ratio: 2.4499999999999997\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00006\n",
      "epoch 19213 / 20000\n",
      "gradient norm: 0.007535977041698061, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00006\n",
      "epoch 19214 / 20000\n",
      "gradient norm: 0.011493364087073132, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00006\n",
      "epoch 19215 / 20000\n",
      "gradient norm: 0.00590647611534223, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00006\n",
      "epoch 19216 / 20000\n",
      "gradient norm: 0.003274476286605932, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00006\n",
      "epoch 19217 / 20000\n",
      "gradient norm: 0.008154186594765633, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00006\n",
      "epoch 19218 / 20000\n",
      "gradient norm: 0.010861802162253298, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00006\n",
      "epoch 19219 / 20000\n",
      "gradient norm: 0.01860883116023615, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00006\n",
      "epoch 19220 / 20000\n",
      "gradient norm: 0.01119638183445204, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00006\n",
      "epoch 19221 / 20000\n",
      "gradient norm: 0.006455116526922211, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00006\n",
      "epoch 19222 / 20000\n",
      "gradient norm: 0.003083654082729481, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00006\n",
      "epoch 19223 / 20000\n",
      "gradient norm: 0.0034626231317815837, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00006\n",
      "epoch 19224 / 20000\n",
      "gradient norm: 0.013519162515876815, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00006\n",
      "epoch 19225 / 20000\n",
      "gradient norm: 0.011383799457689747, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00006\n",
      "epoch 19226 / 20000\n",
      "gradient norm: 0.01918473478872329, minimum ratio: 2.492105263157895\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00006\n",
      "epoch 19227 / 20000\n",
      "gradient norm: 0.026457684172783047, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00006\n",
      "epoch 19228 / 20000\n",
      "gradient norm: 0.019673172530019656, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00006\n",
      "epoch 19229 / 20000\n",
      "gradient norm: 0.02480266717611812, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00006\n",
      "epoch 19230 / 20000\n",
      "gradient norm: 0.023567127500427887, minimum ratio: 2.460526315789474\n",
      "\ttrain loss: 0.00006\n",
      "\tval loss: 0.00006\n",
      "epoch 19231 / 20000\n",
      "gradient norm: 0.022069927596021444, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00006\n",
      "epoch 19232 / 20000\n",
      "gradient norm: 0.011272361931332853, minimum ratio: 2.4236842105263157\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00006\n",
      "epoch 19233 / 20000\n",
      "gradient norm: 0.00815571793646086, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00006\n",
      "epoch 19234 / 20000\n",
      "gradient norm: 0.011299327219603583, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00006\n",
      "epoch 19235 / 20000\n",
      "gradient norm: 0.020345811441075057, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00006\n",
      "epoch 19236 / 20000\n",
      "gradient norm: 0.018082911934470758, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00006\n",
      "epoch 19237 / 20000\n",
      "gradient norm: 0.01798515481641516, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00006\n",
      "epoch 19238 / 20000\n",
      "gradient norm: 0.005232330280705355, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00006\n",
      "epoch 19239 / 20000\n",
      "gradient norm: 0.011017656957847066, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00006\n",
      "epoch 19240 / 20000\n",
      "gradient norm: 0.014975258469348773, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00006\n",
      "epoch 19241 / 20000\n",
      "gradient norm: 0.011801748201833107, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00006\n",
      "epoch 19242 / 20000\n",
      "gradient norm: 0.011781218738178723, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00006\n",
      "epoch 19243 / 20000\n",
      "gradient norm: 0.005791438699816354, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00006\n",
      "epoch 19244 / 20000\n",
      "gradient norm: 0.008604350863606669, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00006\n",
      "epoch 19245 / 20000\n",
      "gradient norm: 0.010356507904361933, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00006\n",
      "epoch 19246 / 20000\n",
      "gradient norm: 0.017613782241824083, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00006\n",
      "epoch 19247 / 20000\n",
      "gradient norm: 0.011892261449247599, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00006\n",
      "epoch 19248 / 20000\n",
      "gradient norm: 0.011333945927617606, minimum ratio: 2.46578947368421\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00006\n",
      "epoch 19249 / 20000\n",
      "gradient norm: 0.010223656623566058, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00006\n",
      "epoch 19250 / 20000\n",
      "gradient norm: 0.005068373662652448, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00006\n",
      "epoch 19251 / 20000\n",
      "gradient norm: 0.007866425527026877, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00006\n",
      "epoch 19252 / 20000\n",
      "gradient norm: 0.00848555269476492, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00006\n",
      "epoch 19253 / 20000\n",
      "gradient norm: 0.00955963872547727, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00006\n",
      "epoch 19254 / 20000\n",
      "gradient norm: 0.004420550219947472, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00006\n",
      "epoch 19255 / 20000\n",
      "gradient norm: 0.010762222962512169, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00006\n",
      "epoch 19256 / 20000\n",
      "gradient norm: 0.009620723270927556, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00006\n",
      "epoch 19257 / 20000\n",
      "gradient norm: 0.008045493246754631, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00006\n",
      "epoch 19258 / 20000\n",
      "gradient norm: 0.013908586799516343, minimum ratio: 2.4842105263157896\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00006\n",
      "epoch 19259 / 20000\n",
      "gradient norm: 0.00409248037612997, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00006\n",
      "epoch 19260 / 20000\n",
      "gradient norm: 0.011607811364228837, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00006\n",
      "epoch 19261 / 20000\n",
      "gradient norm: 0.008459358272375539, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00006\n",
      "epoch 19262 / 20000\n",
      "gradient norm: 0.006008024916809518, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00006\n",
      "epoch 19263 / 20000\n",
      "gradient norm: 0.008915918835555203, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00006\n",
      "epoch 19264 / 20000\n",
      "gradient norm: 0.007372092892182991, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00006\n",
      "epoch 19265 / 20000\n",
      "gradient norm: 0.009621278150007129, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00006\n",
      "epoch 19266 / 20000\n",
      "gradient norm: 0.012494647147832438, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00006\n",
      "epoch 19267 / 20000\n",
      "gradient norm: 0.012956852777278982, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00006\n",
      "epoch 19268 / 20000\n",
      "gradient norm: 0.020102854177821428, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00006\n",
      "epoch 19269 / 20000\n",
      "gradient norm: 0.01827336872520391, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00006\n",
      "epoch 19270 / 20000\n",
      "gradient norm: 0.023985723120858893, minimum ratio: 2.4447368421052627\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00006\n",
      "epoch 19271 / 20000\n",
      "gradient norm: 0.01847555857966654, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00006\n",
      "epoch 19272 / 20000\n",
      "gradient norm: 0.019241556634369772, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00006\n",
      "epoch 19273 / 20000\n",
      "gradient norm: 0.022778522659791633, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00006\n",
      "epoch 19274 / 20000\n",
      "gradient norm: 0.020327820937382057, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00006\n",
      "epoch 19275 / 20000\n",
      "gradient norm: 0.013670494619873352, minimum ratio: 2.5052631578947366\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00006\n",
      "epoch 19276 / 20000\n",
      "gradient norm: 0.005450691780424677, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00006\n",
      "epoch 19277 / 20000\n",
      "gradient norm: 0.013748633646173403, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00006\n",
      "epoch 19278 / 20000\n",
      "gradient norm: 0.016055816391599365, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00006\n",
      "epoch 19279 / 20000\n",
      "gradient norm: 0.01640801876783371, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00006\n",
      "epoch 19280 / 20000\n",
      "gradient norm: 0.011010738860932179, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00006\n",
      "epoch 19281 / 20000\n",
      "gradient norm: 0.012654255813686177, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00006\n",
      "epoch 19282 / 20000\n",
      "gradient norm: 0.013805788767058402, minimum ratio: 2.4499999999999997\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00006\n",
      "epoch 19283 / 20000\n",
      "gradient norm: 0.012290534476051107, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00006\n",
      "epoch 19284 / 20000\n",
      "gradient norm: 0.009084873832762241, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00006\n",
      "epoch 19285 / 20000\n",
      "gradient norm: 0.009191197517793626, minimum ratio: 2.4421052631578943\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00006\n",
      "epoch 19286 / 20000\n",
      "gradient norm: 0.011489912663819268, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00006\n",
      "epoch 19287 / 20000\n",
      "gradient norm: 0.00799396687943954, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00006\n",
      "epoch 19288 / 20000\n",
      "gradient norm: 0.012297519380808808, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00006\n",
      "epoch 19289 / 20000\n",
      "gradient norm: 0.010503823250473943, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00006\n",
      "epoch 19290 / 20000\n",
      "gradient norm: 0.01076254149666056, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00006\n",
      "epoch 19291 / 20000\n",
      "gradient norm: 0.011519162406329997, minimum ratio: 2.4973684210526312\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00006\n",
      "epoch 19292 / 20000\n",
      "gradient norm: 0.012001388153294101, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00006\n",
      "epoch 19293 / 20000\n",
      "gradient norm: 0.009004415755043738, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00006\n",
      "epoch 19294 / 20000\n",
      "gradient norm: 0.013034506628173403, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00006\n",
      "epoch 19295 / 20000\n",
      "gradient norm: 0.014251858257921413, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00006\n",
      "epoch 19296 / 20000\n",
      "gradient norm: 0.013977757029351778, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00006\n",
      "epoch 19297 / 20000\n",
      "gradient norm: 0.007397447086987086, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00006\n",
      "epoch 19298 / 20000\n",
      "gradient norm: 0.006059683655621484, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00006\n",
      "epoch 19299 / 20000\n",
      "gradient norm: 0.01157718917238526, minimum ratio: 2.4289473684210523\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00006\n",
      "epoch 19300 / 20000\n",
      "gradient norm: 0.006017292158503551, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00006\n",
      "epoch 19301 / 20000\n",
      "gradient norm: 0.005445005888759624, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00006\n",
      "epoch 19302 / 20000\n",
      "gradient norm: 0.005899197160033509, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00006\n",
      "epoch 19303 / 20000\n",
      "gradient norm: 0.006538649897265714, minimum ratio: 2.4736842105263155\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00006\n",
      "epoch 19304 / 20000\n",
      "gradient norm: 0.009624353377148509, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00006\n",
      "epoch 19305 / 20000\n",
      "gradient norm: 0.006909217350766994, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00006\n",
      "epoch 19306 / 20000\n",
      "gradient norm: 0.009870860449154861, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00006\n",
      "epoch 19307 / 20000\n",
      "gradient norm: 0.010383318658568896, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00006\n",
      "epoch 19308 / 20000\n",
      "gradient norm: 0.011080331198172644, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00006\n",
      "epoch 19309 / 20000\n",
      "gradient norm: 0.022783076216001064, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00006\n",
      "epoch 19310 / 20000\n",
      "gradient norm: 0.015352194750448689, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00006\n",
      "epoch 19311 / 20000\n",
      "gradient norm: 0.011250469367951155, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00006\n",
      "epoch 19312 / 20000\n",
      "gradient norm: 0.00953547800600063, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19313 / 20000\n",
      "gradient norm: 0.00699367735433043, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00006\n",
      "epoch 19314 / 20000\n",
      "gradient norm: 0.014545405807439238, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00006\n",
      "epoch 19315 / 20000\n",
      "gradient norm: 0.016050826452556066, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19316 / 20000\n",
      "gradient norm: 0.019561531356885098, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00006\n",
      "epoch 19317 / 20000\n",
      "gradient norm: 0.014584203745471314, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00006\n",
      "epoch 19318 / 20000\n",
      "gradient norm: 0.015161881572566926, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00006\n",
      "epoch 19319 / 20000\n",
      "gradient norm: 0.017609366623219103, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00006\n",
      "epoch 19320 / 20000\n",
      "gradient norm: 0.013412140229775105, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19321 / 20000\n",
      "gradient norm: 0.015181199516518973, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00006\n",
      "epoch 19322 / 20000\n",
      "gradient norm: 0.018516603420721367, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19323 / 20000\n",
      "gradient norm: 0.007559529680293053, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00006\n",
      "epoch 19324 / 20000\n",
      "gradient norm: 0.009318369120592251, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19325 / 20000\n",
      "gradient norm: 0.011349117601639591, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19326 / 20000\n",
      "gradient norm: 0.0057167624836438335, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19327 / 20000\n",
      "gradient norm: 0.003955771848268341, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19328 / 20000\n",
      "gradient norm: 0.005636128509650007, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19329 / 20000\n",
      "gradient norm: 0.005210814255406149, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19330 / 20000\n",
      "gradient norm: 0.003934505708457436, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19331 / 20000\n",
      "gradient norm: 0.011412985128117725, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19332 / 20000\n",
      "gradient norm: 0.0058564219434629194, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19333 / 20000\n",
      "gradient norm: 0.013753967126831412, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00006\n",
      "epoch 19334 / 20000\n",
      "gradient norm: 0.014249700354412198, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19335 / 20000\n",
      "gradient norm: 0.004519470414379612, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19336 / 20000\n",
      "gradient norm: 0.010556912253377959, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19337 / 20000\n",
      "gradient norm: 0.0075109946192242205, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19338 / 20000\n",
      "gradient norm: 0.007684423675527796, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19339 / 20000\n",
      "gradient norm: 0.0054872451510163955, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19340 / 20000\n",
      "gradient norm: 0.004410442692460492, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19341 / 20000\n",
      "gradient norm: 0.006740543190971948, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19342 / 20000\n",
      "gradient norm: 0.013737835062784143, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19343 / 20000\n",
      "gradient norm: 0.015225856317556463, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00006\n",
      "epoch 19344 / 20000\n",
      "gradient norm: 0.01736746754613705, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00006\n",
      "epoch 19345 / 20000\n",
      "gradient norm: 0.011909921508049592, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19346 / 20000\n",
      "gradient norm: 0.014279915456427261, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19347 / 20000\n",
      "gradient norm: 0.02090707086608745, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00006\n",
      "epoch 19348 / 20000\n",
      "gradient norm: 0.020101667410926893, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19349 / 20000\n",
      "gradient norm: 0.0190252190514002, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19350 / 20000\n",
      "gradient norm: 0.023204298689961433, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19351 / 20000\n",
      "gradient norm: 0.010623240646964405, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19352 / 20000\n",
      "gradient norm: 0.009319028511526994, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19353 / 20000\n",
      "gradient norm: 0.0034892552794190124, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19354 / 20000\n",
      "gradient norm: 0.006433265531086363, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19355 / 20000\n",
      "gradient norm: 0.005078177502582548, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19356 / 20000\n",
      "gradient norm: 0.003673112907563336, minimum ratio: 2.4421052631578943\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19357 / 20000\n",
      "gradient norm: 0.005067139230959583, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19358 / 20000\n",
      "gradient norm: 0.016274956782581285, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19359 / 20000\n",
      "gradient norm: 0.011475812178105116, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19360 / 20000\n",
      "gradient norm: 0.02184946820489131, minimum ratio: 2.4499999999999997\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19361 / 20000\n",
      "gradient norm: 0.010848591671674512, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19362 / 20000\n",
      "gradient norm: 0.004734229980385862, minimum ratio: 2.4394736842105265\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19363 / 20000\n",
      "gradient norm: 0.0061249528953339905, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19364 / 20000\n",
      "gradient norm: 0.006273449514992535, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19365 / 20000\n",
      "gradient norm: 0.0120037954475265, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19366 / 20000\n",
      "gradient norm: 0.0116056028418825, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19367 / 20000\n",
      "gradient norm: 0.016488434746861458, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00006\n",
      "epoch 19368 / 20000\n",
      "gradient norm: 0.023278602107893676, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19369 / 20000\n",
      "gradient norm: 0.013800124259432778, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19370 / 20000\n",
      "gradient norm: 0.022453568992204964, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19371 / 20000\n",
      "gradient norm: 0.013228238836745732, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19372 / 20000\n",
      "gradient norm: 0.00844040135780233, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19373 / 20000\n",
      "gradient norm: 0.013850473915226758, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19374 / 20000\n",
      "gradient norm: 0.012746566178975627, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19375 / 20000\n",
      "gradient norm: 0.01610619350685738, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19376 / 20000\n",
      "gradient norm: 0.01141616638051346, minimum ratio: 2.460526315789474\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19377 / 20000\n",
      "gradient norm: 0.011890232068253681, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19378 / 20000\n",
      "gradient norm: 0.013319423524080776, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19379 / 20000\n",
      "gradient norm: 0.021001561573939398, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19380 / 20000\n",
      "gradient norm: 0.01842462774948217, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00006\n",
      "epoch 19381 / 20000\n",
      "gradient norm: 0.023368711466901004, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19382 / 20000\n",
      "gradient norm: 0.024655197892570868, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19383 / 20000\n",
      "gradient norm: 0.011026015126844868, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19384 / 20000\n",
      "gradient norm: 0.009963744727429003, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19385 / 20000\n",
      "gradient norm: 0.00686636395403184, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19386 / 20000\n",
      "gradient norm: 0.007347255610511638, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19387 / 20000\n",
      "gradient norm: 0.015561247608275153, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19388 / 20000\n",
      "gradient norm: 0.01861748768715188, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19389 / 20000\n",
      "gradient norm: 0.009674763765360694, minimum ratio: 2.4394736842105265\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19390 / 20000\n",
      "gradient norm: 0.013004715438000858, minimum ratio: 2.4684210526315784\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19391 / 20000\n",
      "gradient norm: 0.006554229898029007, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19392 / 20000\n",
      "gradient norm: 0.007497949598473497, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19393 / 20000\n",
      "gradient norm: 0.017817228304920718, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19394 / 20000\n",
      "gradient norm: 0.013241278335044626, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19395 / 20000\n",
      "gradient norm: 0.014260443625971675, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19396 / 20000\n",
      "gradient norm: 0.021744289610069245, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19397 / 20000\n",
      "gradient norm: 0.009847929220995866, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19398 / 20000\n",
      "gradient norm: 0.008100448139884975, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19399 / 20000\n",
      "gradient norm: 0.016598728427197784, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19400 / 20000\n",
      "gradient norm: 0.023894636426120996, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19401 / 20000\n",
      "gradient norm: 0.017113333611632697, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19402 / 20000\n",
      "gradient norm: 0.0262019556685118, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19403 / 20000\n",
      "gradient norm: 0.021122769539942965, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19404 / 20000\n",
      "gradient norm: 0.01383872568840161, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19405 / 20000\n",
      "gradient norm: 0.012412530952133238, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19406 / 20000\n",
      "gradient norm: 0.011621590063441545, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19407 / 20000\n",
      "gradient norm: 0.012771654299285728, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19408 / 20000\n",
      "gradient norm: 0.009823139160289429, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19409 / 20000\n",
      "gradient norm: 0.008791024010861292, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19410 / 20000\n",
      "gradient norm: 0.012651135097257793, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19411 / 20000\n",
      "gradient norm: 0.009185237024212256, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19412 / 20000\n",
      "gradient norm: 0.00794761098222807, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19413 / 20000\n",
      "gradient norm: 0.009240252446033992, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19414 / 20000\n",
      "gradient norm: 0.006993481772951782, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19415 / 20000\n",
      "gradient norm: 0.008464827405987307, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19416 / 20000\n",
      "gradient norm: 0.009598339267540723, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19417 / 20000\n",
      "gradient norm: 0.007787203241605312, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19418 / 20000\n",
      "gradient norm: 0.01514635724015534, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19419 / 20000\n",
      "gradient norm: 0.007290068126167171, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19420 / 20000\n",
      "gradient norm: 0.008299363107653335, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19421 / 20000\n",
      "gradient norm: 0.012444280000636354, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19422 / 20000\n",
      "gradient norm: 0.007918486167909577, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19423 / 20000\n",
      "gradient norm: 0.003766067713513621, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19424 / 20000\n",
      "gradient norm: 0.003390994908841094, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19425 / 20000\n",
      "gradient norm: 0.006044033565558493, minimum ratio: 2.4421052631578943\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19426 / 20000\n",
      "gradient norm: 0.010198952630162239, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19427 / 20000\n",
      "gradient norm: 0.006004077527904883, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19428 / 20000\n",
      "gradient norm: 0.007099484340869822, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19429 / 20000\n",
      "gradient norm: 0.0036994344409322366, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19430 / 20000\n",
      "gradient norm: 0.005519804537470918, minimum ratio: 2.4394736842105265\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19431 / 20000\n",
      "gradient norm: 0.00632230487826746, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19432 / 20000\n",
      "gradient norm: 0.021294841630151495, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19433 / 20000\n",
      "gradient norm: 0.019440003583440557, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19434 / 20000\n",
      "gradient norm: 0.01996805620728992, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19435 / 20000\n",
      "gradient norm: 0.014354092054418288, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19436 / 20000\n",
      "gradient norm: 0.011440441085142083, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19437 / 20000\n",
      "gradient norm: 0.01680781165487133, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19438 / 20000\n",
      "gradient norm: 0.018863388686440885, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19439 / 20000\n",
      "gradient norm: 0.016538200550712645, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19440 / 20000\n",
      "gradient norm: 0.011980861629126593, minimum ratio: 2.4736842105263155\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19441 / 20000\n",
      "gradient norm: 0.0025369439863425214, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19442 / 20000\n",
      "gradient norm: 0.005359793001844082, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19443 / 20000\n",
      "gradient norm: 0.013905816012993455, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19444 / 20000\n",
      "gradient norm: 0.015720207651611418, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19445 / 20000\n",
      "gradient norm: 0.013506284158211201, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19446 / 20000\n",
      "gradient norm: 0.015617029333952814, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19447 / 20000\n",
      "gradient norm: 0.01562331520835869, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19448 / 20000\n",
      "gradient norm: 0.01422200191882439, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19449 / 20000\n",
      "gradient norm: 0.006520741997519508, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19450 / 20000\n",
      "gradient norm: 0.00919501794851385, minimum ratio: 2.4921052631578946\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19451 / 20000\n",
      "gradient norm: 0.007110660968464799, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19452 / 20000\n",
      "gradient norm: 0.005441330838948488, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19453 / 20000\n",
      "gradient norm: 0.010035067010903731, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19454 / 20000\n",
      "gradient norm: 0.01617461774731055, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19455 / 20000\n",
      "gradient norm: 0.012917577289044857, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19456 / 20000\n",
      "gradient norm: 0.018934526437078603, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19457 / 20000\n",
      "gradient norm: 0.006006260933645535, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19458 / 20000\n",
      "gradient norm: 0.007246507244417444, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19459 / 20000\n",
      "gradient norm: 0.006090510345529765, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19460 / 20000\n",
      "gradient norm: 0.015791926853125915, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19461 / 20000\n",
      "gradient norm: 0.012852888030465692, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19462 / 20000\n",
      "gradient norm: 0.01215155467070872, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19463 / 20000\n",
      "gradient norm: 0.012095037352992222, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19464 / 20000\n",
      "gradient norm: 0.017839544743765146, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19465 / 20000\n",
      "gradient norm: 0.0033161620376631618, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19466 / 20000\n",
      "gradient norm: 0.008437837212113664, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19467 / 20000\n",
      "gradient norm: 0.009261366532882676, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19468 / 20000\n",
      "gradient norm: 0.006829523372289259, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19469 / 20000\n",
      "gradient norm: 0.006766504680854268, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19470 / 20000\n",
      "gradient norm: 0.005846378247952089, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19471 / 20000\n",
      "gradient norm: 0.017541204317240044, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19472 / 20000\n",
      "gradient norm: 0.0062372626416618004, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19473 / 20000\n",
      "gradient norm: 0.007015267226961441, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19474 / 20000\n",
      "gradient norm: 0.0026013745882664807, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19475 / 20000\n",
      "gradient norm: 0.006616087979637086, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19476 / 20000\n",
      "gradient norm: 0.00292785104829818, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19477 / 20000\n",
      "gradient norm: 0.006318492683931254, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19478 / 20000\n",
      "gradient norm: 0.00886476197047159, minimum ratio: 2.46578947368421\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19479 / 20000\n",
      "gradient norm: 0.01732946460833773, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19480 / 20000\n",
      "gradient norm: 0.01165894053701777, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19481 / 20000\n",
      "gradient norm: 0.012386607835651375, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19482 / 20000\n",
      "gradient norm: 0.013637301221024245, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19483 / 20000\n",
      "gradient norm: 0.010710184462368488, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19484 / 20000\n",
      "gradient norm: 0.012340301211224869, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19485 / 20000\n",
      "gradient norm: 0.025441599893383682, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00006\n",
      "epoch 19486 / 20000\n",
      "gradient norm: 0.027029747565393336, minimum ratio: 2.486842105263158\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19487 / 20000\n",
      "gradient norm: 0.017517757762107067, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19488 / 20000\n",
      "gradient norm: 0.025924626766936854, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19489 / 20000\n",
      "gradient norm: 0.021008279698435217, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19490 / 20000\n",
      "gradient norm: 0.019834087579511106, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19491 / 20000\n",
      "gradient norm: 0.026869178749620914, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19492 / 20000\n",
      "gradient norm: 0.013084225982311182, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19493 / 20000\n",
      "gradient norm: 0.012347924828645773, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19494 / 20000\n",
      "gradient norm: 0.011012603077688254, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19495 / 20000\n",
      "gradient norm: 0.01044337495113723, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19496 / 20000\n",
      "gradient norm: 0.01153016957687214, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19497 / 20000\n",
      "gradient norm: 0.009094056513276882, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19498 / 20000\n",
      "gradient norm: 0.0127311193064088, minimum ratio: 2.4868421052631575\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19499 / 20000\n",
      "gradient norm: 0.0052229901775717735, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19500 / 20000\n",
      "gradient norm: 0.008866707183187827, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19501 / 20000\n",
      "gradient norm: 0.013265765344840474, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19502 / 20000\n",
      "gradient norm: 0.0155791942961514, minimum ratio: 2.4421052631578943\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19503 / 20000\n",
      "gradient norm: 0.014131178613752127, minimum ratio: 2.452631578947368\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19504 / 20000\n",
      "gradient norm: 0.01063617602630984, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19505 / 20000\n",
      "gradient norm: 0.01010635556303896, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19506 / 20000\n",
      "gradient norm: 0.016751870280131698, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19507 / 20000\n",
      "gradient norm: 0.01630098748137243, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19508 / 20000\n",
      "gradient norm: 0.01104412977292668, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19509 / 20000\n",
      "gradient norm: 0.010457019146997482, minimum ratio: 2.46578947368421\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19510 / 20000\n",
      "gradient norm: 0.011146150878630579, minimum ratio: 2.46578947368421\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19511 / 20000\n",
      "gradient norm: 0.014358511456521228, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19512 / 20000\n",
      "gradient norm: 0.009562114035361446, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19513 / 20000\n",
      "gradient norm: 0.014009808422997594, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19514 / 20000\n",
      "gradient norm: 0.00625787958415458, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19515 / 20000\n",
      "gradient norm: 0.004672369883337524, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19516 / 20000\n",
      "gradient norm: 0.018022230331553146, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19517 / 20000\n",
      "gradient norm: 0.017858189974504057, minimum ratio: 2.4499999999999997\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19518 / 20000\n",
      "gradient norm: 0.014579448965378106, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19519 / 20000\n",
      "gradient norm: 0.015466989338165149, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19520 / 20000\n",
      "gradient norm: 0.023819647467462346, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19521 / 20000\n",
      "gradient norm: 0.02089662750950083, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19522 / 20000\n",
      "gradient norm: 0.014176204160321504, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19523 / 20000\n",
      "gradient norm: 0.008798377093626186, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19524 / 20000\n",
      "gradient norm: 0.008282921291538514, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19525 / 20000\n",
      "gradient norm: 0.01792694817413576, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19526 / 20000\n",
      "gradient norm: 0.016187401313800365, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19527 / 20000\n",
      "gradient norm: 0.014754639836610295, minimum ratio: 2.46578947368421\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19528 / 20000\n",
      "gradient norm: 0.02082382507796865, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19529 / 20000\n",
      "gradient norm: 0.015158388603595085, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19530 / 20000\n",
      "gradient norm: 0.018987965493579395, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19531 / 20000\n",
      "gradient norm: 0.01621371954388451, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19532 / 20000\n",
      "gradient norm: 0.024082835792796686, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19533 / 20000\n",
      "gradient norm: 0.01543751050485298, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19534 / 20000\n",
      "gradient norm: 0.01048251663451083, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19535 / 20000\n",
      "gradient norm: 0.007515170247643255, minimum ratio: 2.4263157894736844\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19536 / 20000\n",
      "gradient norm: 0.008917151935747825, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19537 / 20000\n",
      "gradient norm: 0.016023917036363855, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19538 / 20000\n",
      "gradient norm: 0.02061414736090228, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19539 / 20000\n",
      "gradient norm: 0.027085331414127722, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19540 / 20000\n",
      "gradient norm: 0.02592128750984557, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19541 / 20000\n",
      "gradient norm: 0.024137374333804473, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19542 / 20000\n",
      "gradient norm: 0.02405205712420866, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19543 / 20000\n",
      "gradient norm: 0.016523463476914912, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19544 / 20000\n",
      "gradient norm: 0.00927058018714888, minimum ratio: 2.465789473684211\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19545 / 20000\n",
      "gradient norm: 0.019092944770818576, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19546 / 20000\n",
      "gradient norm: 0.018925533280707896, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19547 / 20000\n",
      "gradient norm: 0.011222206143429503, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19548 / 20000\n",
      "gradient norm: 0.0173437311896123, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19549 / 20000\n",
      "gradient norm: 0.015597378092934377, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19550 / 20000\n",
      "gradient norm: 0.00988479534862563, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19551 / 20000\n",
      "gradient norm: 0.01114452048932435, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19552 / 20000\n",
      "gradient norm: 0.014246317412471399, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19553 / 20000\n",
      "gradient norm: 0.005607673330814578, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19554 / 20000\n",
      "gradient norm: 0.007996529391675722, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19555 / 20000\n",
      "gradient norm: 0.005942593095824122, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19556 / 20000\n",
      "gradient norm: 0.006411823589587584, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19557 / 20000\n",
      "gradient norm: 0.00740563943691086, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19558 / 20000\n",
      "gradient norm: 0.012356574297882617, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19559 / 20000\n",
      "gradient norm: 0.014161226252326742, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19560 / 20000\n",
      "gradient norm: 0.009338093565020245, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19561 / 20000\n",
      "gradient norm: 0.009460829660383752, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19562 / 20000\n",
      "gradient norm: 0.014661458117188886, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19563 / 20000\n",
      "gradient norm: 0.016467460111016408, minimum ratio: 2.4499999999999997\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19564 / 20000\n",
      "gradient norm: 0.010907423988101073, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19565 / 20000\n",
      "gradient norm: 0.015017643236205913, minimum ratio: 2.489473684210526\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19566 / 20000\n",
      "gradient norm: 0.014127843096503057, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19567 / 20000\n",
      "gradient norm: 0.009651669810409658, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19568 / 20000\n",
      "gradient norm: 0.012979599807295017, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19569 / 20000\n",
      "gradient norm: 0.007317629984754603, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19570 / 20000\n",
      "gradient norm: 0.008754284936003387, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19571 / 20000\n",
      "gradient norm: 0.006359767852700315, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19572 / 20000\n",
      "gradient norm: 0.005420463778136764, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19573 / 20000\n",
      "gradient norm: 0.008455112460069358, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19574 / 20000\n",
      "gradient norm: 0.004441883385879919, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19575 / 20000\n",
      "gradient norm: 0.01490167248994112, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19576 / 20000\n",
      "gradient norm: 0.011321810714434832, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19577 / 20000\n",
      "gradient norm: 0.012425573622749653, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19578 / 20000\n",
      "gradient norm: 0.006751213775714859, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19579 / 20000\n",
      "gradient norm: 0.008887545147445053, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19580 / 20000\n",
      "gradient norm: 0.011754356004530564, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19581 / 20000\n",
      "gradient norm: 0.019710798049345613, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19582 / 20000\n",
      "gradient norm: 0.016525856539374217, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19583 / 20000\n",
      "gradient norm: 0.015061638012412004, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19584 / 20000\n",
      "gradient norm: 0.014882014482282102, minimum ratio: 2.4394736842105265\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19585 / 20000\n",
      "gradient norm: 0.006803098294767551, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19586 / 20000\n",
      "gradient norm: 0.004582836641930044, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19587 / 20000\n",
      "gradient norm: 0.00767784799245419, minimum ratio: 2.4815789473684213\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19588 / 20000\n",
      "gradient norm: 0.009850342816207558, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19589 / 20000\n",
      "gradient norm: 0.02001030309475027, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19590 / 20000\n",
      "gradient norm: 0.016589568927884102, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19591 / 20000\n",
      "gradient norm: 0.01835431146901101, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19592 / 20000\n",
      "gradient norm: 0.017900934457429685, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19593 / 20000\n",
      "gradient norm: 0.02190479077398777, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19594 / 20000\n",
      "gradient norm: 0.021857355546671897, minimum ratio: 2.4499999999999997\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19595 / 20000\n",
      "gradient norm: 0.01633850418147631, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19596 / 20000\n",
      "gradient norm: 0.01869137230096385, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19597 / 20000\n",
      "gradient norm: 0.017154751083580777, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19598 / 20000\n",
      "gradient norm: 0.012556370900711045, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19599 / 20000\n",
      "gradient norm: 0.015409708896186203, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19600 / 20000\n",
      "gradient norm: 0.009754262340720743, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19601 / 20000\n",
      "gradient norm: 0.009544422791805118, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19602 / 20000\n",
      "gradient norm: 0.007293139104149304, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19603 / 20000\n",
      "gradient norm: 0.009404312921105884, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19604 / 20000\n",
      "gradient norm: 0.016435639874543995, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19605 / 20000\n",
      "gradient norm: 0.014435627483180724, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19606 / 20000\n",
      "gradient norm: 0.025524513272102922, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19607 / 20000\n",
      "gradient norm: 0.0172281987615861, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19608 / 20000\n",
      "gradient norm: 0.014710341427417006, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19609 / 20000\n",
      "gradient norm: 0.0040634720789967105, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19610 / 20000\n",
      "gradient norm: 0.013930162313045003, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19611 / 20000\n",
      "gradient norm: 0.007538446370745078, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19612 / 20000\n",
      "gradient norm: 0.01346287308842875, minimum ratio: 2.484210526315789\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19613 / 20000\n",
      "gradient norm: 0.009244096887414344, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19614 / 20000\n",
      "gradient norm: 0.020520938793197274, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19615 / 20000\n",
      "gradient norm: 0.01625341732869856, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19616 / 20000\n",
      "gradient norm: 0.009956401219824329, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19617 / 20000\n",
      "gradient norm: 0.012605566589627415, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19618 / 20000\n",
      "gradient norm: 0.011944505415158346, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19619 / 20000\n",
      "gradient norm: 0.010618604341289029, minimum ratio: 2.460526315789474\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19620 / 20000\n",
      "gradient norm: 0.021773614585981704, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19621 / 20000\n",
      "gradient norm: 0.03035934010404162, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19622 / 20000\n",
      "gradient norm: 0.02343846412259154, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19623 / 20000\n",
      "gradient norm: 0.024583867052569985, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19624 / 20000\n",
      "gradient norm: 0.034216337895486504, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19625 / 20000\n",
      "gradient norm: 0.05227224651025608, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00006\n",
      "epoch 19626 / 20000\n",
      "gradient norm: 0.03929627261823043, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19627 / 20000\n",
      "gradient norm: 0.024424082330369856, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19628 / 20000\n",
      "gradient norm: 0.024148328928276896, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19629 / 20000\n",
      "gradient norm: 0.024489311734214425, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19630 / 20000\n",
      "gradient norm: 0.015559085659333505, minimum ratio: 2.4842105263157896\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19631 / 20000\n",
      "gradient norm: 0.008417551245656796, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19632 / 20000\n",
      "gradient norm: 0.006751697168510873, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19633 / 20000\n",
      "gradient norm: 0.009884314640657976, minimum ratio: 2.46578947368421\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19634 / 20000\n",
      "gradient norm: 0.012587934412294999, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19635 / 20000\n",
      "gradient norm: 0.01695376995485276, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19636 / 20000\n",
      "gradient norm: 0.015402308432385325, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19637 / 20000\n",
      "gradient norm: 0.014676974067697302, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19638 / 20000\n",
      "gradient norm: 0.01581023057224229, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19639 / 20000\n",
      "gradient norm: 0.013651387678692117, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19640 / 20000\n",
      "gradient norm: 0.014862190844723955, minimum ratio: 2.46578947368421\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19641 / 20000\n",
      "gradient norm: 0.007893956761108711, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19642 / 20000\n",
      "gradient norm: 0.007043671481369529, minimum ratio: 2.46578947368421\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19643 / 20000\n",
      "gradient norm: 0.006854820472653955, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19644 / 20000\n",
      "gradient norm: 0.004237386252498254, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19645 / 20000\n",
      "gradient norm: 0.008566407719627023, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19646 / 20000\n",
      "gradient norm: 0.01710073671711143, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19647 / 20000\n",
      "gradient norm: 0.016336150583811104, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19648 / 20000\n",
      "gradient norm: 0.011708096571965143, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19649 / 20000\n",
      "gradient norm: 0.014673272613435984, minimum ratio: 2.4578947368421056\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19650 / 20000\n",
      "gradient norm: 0.009768461757630575, minimum ratio: 2.436842105263158\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19651 / 20000\n",
      "gradient norm: 0.008407868503127247, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19652 / 20000\n",
      "gradient norm: 0.009356730879517272, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19653 / 20000\n",
      "gradient norm: 0.01594374980777502, minimum ratio: 2.46578947368421\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19654 / 20000\n",
      "gradient norm: 0.01422046341758687, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19655 / 20000\n",
      "gradient norm: 0.013501213601557538, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19656 / 20000\n",
      "gradient norm: 0.012505662205512635, minimum ratio: 2.4578947368421056\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19657 / 20000\n",
      "gradient norm: 0.025976710603572428, minimum ratio: 2.4736842105263155\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19658 / 20000\n",
      "gradient norm: 0.02093226990837138, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19659 / 20000\n",
      "gradient norm: 0.01653016684576869, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19660 / 20000\n",
      "gradient norm: 0.014999264996731654, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19661 / 20000\n",
      "gradient norm: 0.016653240396408364, minimum ratio: 2.460526315789474\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19662 / 20000\n",
      "gradient norm: 0.007171537959948182, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19663 / 20000\n",
      "gradient norm: 0.006076935795135796, minimum ratio: 2.4973684210526317\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19664 / 20000\n",
      "gradient norm: 0.007817507736035623, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19665 / 20000\n",
      "gradient norm: 0.008249413484008983, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19666 / 20000\n",
      "gradient norm: 0.0047335338313132524, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19667 / 20000\n",
      "gradient norm: 0.007090126338880509, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19668 / 20000\n",
      "gradient norm: 0.008433194059762172, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19669 / 20000\n",
      "gradient norm: 0.004291487690352369, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19670 / 20000\n",
      "gradient norm: 0.0039030567204463296, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19671 / 20000\n",
      "gradient norm: 0.005874786540516652, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19672 / 20000\n",
      "gradient norm: 0.009679904585937038, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19673 / 20000\n",
      "gradient norm: 0.007512377815146465, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19674 / 20000\n",
      "gradient norm: 0.013744385287282057, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19675 / 20000\n",
      "gradient norm: 0.007365646837570239, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19676 / 20000\n",
      "gradient norm: 0.0069356879976112396, minimum ratio: 2.436842105263158\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19677 / 20000\n",
      "gradient norm: 0.011638343203230761, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19678 / 20000\n",
      "gradient norm: 0.01062154961982742, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19679 / 20000\n",
      "gradient norm: 0.005593433175818063, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19680 / 20000\n",
      "gradient norm: 0.005293746828101575, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19681 / 20000\n",
      "gradient norm: 0.004907679918687791, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19682 / 20000\n",
      "gradient norm: 0.0065000990362023, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19683 / 20000\n",
      "gradient norm: 0.00507182432920672, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19684 / 20000\n",
      "gradient norm: 0.008507440114044584, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19685 / 20000\n",
      "gradient norm: 0.014638685330282897, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19686 / 20000\n",
      "gradient norm: 0.01715334175969474, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19687 / 20000\n",
      "gradient norm: 0.012039772685966454, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19688 / 20000\n",
      "gradient norm: 0.010608872493321542, minimum ratio: 2.423684210526316\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19689 / 20000\n",
      "gradient norm: 0.0025322978872281965, minimum ratio: 2.4394736842105265\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19690 / 20000\n",
      "gradient norm: 0.006152647445560433, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19691 / 20000\n",
      "gradient norm: 0.010090213356306776, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19692 / 20000\n",
      "gradient norm: 0.01280466333264485, minimum ratio: 2.46578947368421\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19693 / 20000\n",
      "gradient norm: 0.007961744297062978, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19694 / 20000\n",
      "gradient norm: 0.012325244621024467, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19695 / 20000\n",
      "gradient norm: 0.010205127502558753, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19696 / 20000\n",
      "gradient norm: 0.007499570303480141, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19697 / 20000\n",
      "gradient norm: 0.011343701626174152, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19698 / 20000\n",
      "gradient norm: 0.009343784200609662, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19699 / 20000\n",
      "gradient norm: 0.015120283103897236, minimum ratio: 2.4157894736842103\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19700 / 20000\n",
      "gradient norm: 0.006546180724399164, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19701 / 20000\n",
      "gradient norm: 0.011988606027443893, minimum ratio: 2.4447368421052627\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19702 / 20000\n",
      "gradient norm: 0.010117258527316153, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19703 / 20000\n",
      "gradient norm: 0.019701036653714254, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19704 / 20000\n",
      "gradient norm: 0.009840175378485583, minimum ratio: 2.4447368421052627\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19705 / 20000\n",
      "gradient norm: 0.008170146109478083, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19706 / 20000\n",
      "gradient norm: 0.015373915783129632, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19707 / 20000\n",
      "gradient norm: 0.021259987610392272, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19708 / 20000\n",
      "gradient norm: 0.01437053782865405, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19709 / 20000\n",
      "gradient norm: 0.014135918609099463, minimum ratio: 2.4394736842105265\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19710 / 20000\n",
      "gradient norm: 0.015408797829877585, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19711 / 20000\n",
      "gradient norm: 0.014048859622562304, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19712 / 20000\n",
      "gradient norm: 0.017080822901334614, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19713 / 20000\n",
      "gradient norm: 0.012060096429195255, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19714 / 20000\n",
      "gradient norm: 0.00667020225955639, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19715 / 20000\n",
      "gradient norm: 0.01006424633669667, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19716 / 20000\n",
      "gradient norm: 0.013807895404170267, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19717 / 20000\n",
      "gradient norm: 0.005520790626178496, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19718 / 20000\n",
      "gradient norm: 0.011016281670890749, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19719 / 20000\n",
      "gradient norm: 0.012920945358928293, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19720 / 20000\n",
      "gradient norm: 0.018228154891403392, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19721 / 20000\n",
      "gradient norm: 0.011937720511923544, minimum ratio: 2.4447368421052635\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19722 / 20000\n",
      "gradient norm: 0.01255307504470693, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19723 / 20000\n",
      "gradient norm: 0.013275028977659531, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19724 / 20000\n",
      "gradient norm: 0.013796623650705442, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19725 / 20000\n",
      "gradient norm: 0.0136607813910814, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19726 / 20000\n",
      "gradient norm: 0.01186491805856349, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19727 / 20000\n",
      "gradient norm: 0.013081260869512334, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19728 / 20000\n",
      "gradient norm: 0.006269094279559795, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19729 / 20000\n",
      "gradient norm: 0.004993223410565406, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19730 / 20000\n",
      "gradient norm: 0.016943240829277784, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19731 / 20000\n",
      "gradient norm: 0.015381517456262372, minimum ratio: 2.4736842105263155\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19732 / 20000\n",
      "gradient norm: 0.013270150739117526, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19733 / 20000\n",
      "gradient norm: 0.011061218392569572, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19734 / 20000\n",
      "gradient norm: 0.016245411432464607, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19735 / 20000\n",
      "gradient norm: 0.02668380760587752, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19736 / 20000\n",
      "gradient norm: 0.027592125232331455, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19737 / 20000\n",
      "gradient norm: 0.016999114450300112, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19738 / 20000\n",
      "gradient norm: 0.017888968635816127, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19739 / 20000\n",
      "gradient norm: 0.025982316787121817, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19740 / 20000\n",
      "gradient norm: 0.01649599091615528, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19741 / 20000\n",
      "gradient norm: 0.01620669156545773, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19742 / 20000\n",
      "gradient norm: 0.01901235803961754, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19743 / 20000\n",
      "gradient norm: 0.017983568308409303, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19744 / 20000\n",
      "gradient norm: 0.012633589707547799, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19745 / 20000\n",
      "gradient norm: 0.016170678107300773, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19746 / 20000\n",
      "gradient norm: 0.013989316881634295, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19747 / 20000\n",
      "gradient norm: 0.005688989876944106, minimum ratio: 2.465789473684211\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19748 / 20000\n",
      "gradient norm: 0.00810437637846917, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19749 / 20000\n",
      "gradient norm: 0.010825499004567973, minimum ratio: 2.4447368421052627\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19750 / 20000\n",
      "gradient norm: 0.011913568218005821, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19751 / 20000\n",
      "gradient norm: 0.018335303699132055, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19752 / 20000\n",
      "gradient norm: 0.010217845134320669, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19753 / 20000\n",
      "gradient norm: 0.01003931816740078, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19754 / 20000\n",
      "gradient norm: 0.01523440532037057, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19755 / 20000\n",
      "gradient norm: 0.011605646985117346, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19756 / 20000\n",
      "gradient norm: 0.012250569896423258, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19757 / 20000\n",
      "gradient norm: 0.007510047231335193, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19758 / 20000\n",
      "gradient norm: 0.011291793096461333, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19759 / 20000\n",
      "gradient norm: 0.013653217538376339, minimum ratio: 2.4868421052631575\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19760 / 20000\n",
      "gradient norm: 0.01835282740648836, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19761 / 20000\n",
      "gradient norm: 0.018173846940044314, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19762 / 20000\n",
      "gradient norm: 0.022841618745587766, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19763 / 20000\n",
      "gradient norm: 0.015061301106470637, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19764 / 20000\n",
      "gradient norm: 0.018318399947020225, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19765 / 20000\n",
      "gradient norm: 0.011060093478590716, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19766 / 20000\n",
      "gradient norm: 0.0072952443806570955, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19767 / 20000\n",
      "gradient norm: 0.014819099524174817, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19768 / 20000\n",
      "gradient norm: 0.016849875944899395, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19769 / 20000\n",
      "gradient norm: 0.01358854936552234, minimum ratio: 2.4736842105263155\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19770 / 20000\n",
      "gradient norm: 0.019541301677236333, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19771 / 20000\n",
      "gradient norm: 0.018299040726560634, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19772 / 20000\n",
      "gradient norm: 0.01575006518396549, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19773 / 20000\n",
      "gradient norm: 0.011973958113230765, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19774 / 20000\n",
      "gradient norm: 0.008461777615593746, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19775 / 20000\n",
      "gradient norm: 0.0069920529931550846, minimum ratio: 2.4236842105263157\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19776 / 20000\n",
      "gradient norm: 0.012898477696580812, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19777 / 20000\n",
      "gradient norm: 0.005679573510860791, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19778 / 20000\n",
      "gradient norm: 0.00495657765713986, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19779 / 20000\n",
      "gradient norm: 0.004864692247792846, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19780 / 20000\n",
      "gradient norm: 0.005580249264312442, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19781 / 20000\n",
      "gradient norm: 0.007345910569711123, minimum ratio: 2.4842105263157896\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19782 / 20000\n",
      "gradient norm: 0.00808550204965286, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19783 / 20000\n",
      "gradient norm: 0.013797880645142868, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19784 / 20000\n",
      "gradient norm: 0.015934903211018536, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19785 / 20000\n",
      "gradient norm: 0.017512722581159323, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19786 / 20000\n",
      "gradient norm: 0.022050914543797262, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19787 / 20000\n",
      "gradient norm: 0.015080590907018632, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19788 / 20000\n",
      "gradient norm: 0.019938774152251426, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19789 / 20000\n",
      "gradient norm: 0.027293316728901118, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19790 / 20000\n",
      "gradient norm: 0.020663809904363006, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19791 / 20000\n",
      "gradient norm: 0.013779437998891808, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19792 / 20000\n",
      "gradient norm: 0.0131023387220921, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19793 / 20000\n",
      "gradient norm: 0.01261186878400622, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19794 / 20000\n",
      "gradient norm: 0.011835803976282477, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19795 / 20000\n",
      "gradient norm: 0.013841858541127294, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19796 / 20000\n",
      "gradient norm: 0.02006642791093327, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19797 / 20000\n",
      "gradient norm: 0.018719325336860493, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19798 / 20000\n",
      "gradient norm: 0.014664667076431215, minimum ratio: 2.46578947368421\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19799 / 20000\n",
      "gradient norm: 0.010594545834464952, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19800 / 20000\n",
      "gradient norm: 0.00804999542015139, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19801 / 20000\n",
      "gradient norm: 0.016572345193708315, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19802 / 20000\n",
      "gradient norm: 0.018696703074965626, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19803 / 20000\n",
      "gradient norm: 0.019327176138176583, minimum ratio: 2.4894736842105263\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19804 / 20000\n",
      "gradient norm: 0.02058055019006133, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19805 / 20000\n",
      "gradient norm: 0.027691820811014622, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19806 / 20000\n",
      "gradient norm: 0.024339044583030045, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19807 / 20000\n",
      "gradient norm: 0.021025589725468308, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19808 / 20000\n",
      "gradient norm: 0.02264224262034986, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19809 / 20000\n",
      "gradient norm: 0.016254518668574747, minimum ratio: 2.4499999999999997\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19810 / 20000\n",
      "gradient norm: 0.013359460557694547, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19811 / 20000\n",
      "gradient norm: 0.014880154914862942, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19812 / 20000\n",
      "gradient norm: 0.023089484573574737, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19813 / 20000\n",
      "gradient norm: 0.011059566131734755, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19814 / 20000\n",
      "gradient norm: 0.012780496152117848, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19815 / 20000\n",
      "gradient norm: 0.00517145347839687, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19816 / 20000\n",
      "gradient norm: 0.01719437110295985, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19817 / 20000\n",
      "gradient norm: 0.014487862266832963, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19818 / 20000\n",
      "gradient norm: 0.011177630920428783, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19819 / 20000\n",
      "gradient norm: 0.019133644644171, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19820 / 20000\n",
      "gradient norm: 0.013465068659570534, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19821 / 20000\n",
      "gradient norm: 0.010408796893898398, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19822 / 20000\n",
      "gradient norm: 0.015234449398121797, minimum ratio: 2.4499999999999997\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19823 / 20000\n",
      "gradient norm: 0.012663009663810953, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19824 / 20000\n",
      "gradient norm: 0.014833385357633233, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19825 / 20000\n",
      "gradient norm: 0.014643436123151332, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19826 / 20000\n",
      "gradient norm: 0.005552285598241724, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19827 / 20000\n",
      "gradient norm: 0.00839347062719753, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19828 / 20000\n",
      "gradient norm: 0.014652069832663983, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19829 / 20000\n",
      "gradient norm: 0.01634772605029866, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19830 / 20000\n",
      "gradient norm: 0.020873407600447536, minimum ratio: 2.4499999999999997\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19831 / 20000\n",
      "gradient norm: 0.03106317255878821, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19832 / 20000\n",
      "gradient norm: 0.027867510623764247, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19833 / 20000\n",
      "gradient norm: 0.01717233496310655, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19834 / 20000\n",
      "gradient norm: 0.012269224389456213, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19835 / 20000\n",
      "gradient norm: 0.013380043834331445, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19836 / 20000\n",
      "gradient norm: 0.004723125224700198, minimum ratio: 2.4447368421052627\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19837 / 20000\n",
      "gradient norm: 0.004514378324529389, minimum ratio: 2.4236842105263157\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19838 / 20000\n",
      "gradient norm: 0.006159567397844512, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19839 / 20000\n",
      "gradient norm: 0.013402139215031639, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19840 / 20000\n",
      "gradient norm: 0.011607755077420734, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19841 / 20000\n",
      "gradient norm: 0.014964704576414078, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19842 / 20000\n",
      "gradient norm: 0.010428640263853595, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19843 / 20000\n",
      "gradient norm: 0.013215855258749798, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19844 / 20000\n",
      "gradient norm: 0.010606819691020064, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19845 / 20000\n",
      "gradient norm: 0.007955999375553802, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19846 / 20000\n",
      "gradient norm: 0.011491467714222381, minimum ratio: 2.4447368421052635\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19847 / 20000\n",
      "gradient norm: 0.008598193438956514, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19848 / 20000\n",
      "gradient norm: 0.01130196217854973, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19849 / 20000\n",
      "gradient norm: 0.009096245114051271, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19850 / 20000\n",
      "gradient norm: 0.010491043591173366, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19851 / 20000\n",
      "gradient norm: 0.007425303308991715, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19852 / 20000\n",
      "gradient norm: 0.010771694593131542, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19853 / 20000\n",
      "gradient norm: 0.01071264673373662, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19854 / 20000\n",
      "gradient norm: 0.007041247925371863, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19855 / 20000\n",
      "gradient norm: 0.005572052192292176, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19856 / 20000\n",
      "gradient norm: 0.011902074154932052, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19857 / 20000\n",
      "gradient norm: 0.010265293924021535, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19858 / 20000\n",
      "gradient norm: 0.00902487087296322, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19859 / 20000\n",
      "gradient norm: 0.005624311903375201, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19860 / 20000\n",
      "gradient norm: 0.00804731909011025, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19861 / 20000\n",
      "gradient norm: 0.007004530794802122, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19862 / 20000\n",
      "gradient norm: 0.006835611864516977, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19863 / 20000\n",
      "gradient norm: 0.004823508483241312, minimum ratio: 2.452631578947368\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19864 / 20000\n",
      "gradient norm: 0.007076618465362117, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19865 / 20000\n",
      "gradient norm: 0.011221555527299643, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19866 / 20000\n",
      "gradient norm: 0.015178951754933223, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19867 / 20000\n",
      "gradient norm: 0.013625563209643587, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19868 / 20000\n",
      "gradient norm: 0.009467253486945992, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19869 / 20000\n",
      "gradient norm: 0.009913856913044583, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19870 / 20000\n",
      "gradient norm: 0.003931674858904444, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19871 / 20000\n",
      "gradient norm: 0.009614597875042818, minimum ratio: 2.460526315789474\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19872 / 20000\n",
      "gradient norm: 0.009322400190285407, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19873 / 20000\n",
      "gradient norm: 0.008945435620262288, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19874 / 20000\n",
      "gradient norm: 0.010594682760711294, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19875 / 20000\n",
      "gradient norm: 0.014027123776031658, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19876 / 20000\n",
      "gradient norm: 0.00868185271974653, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19877 / 20000\n",
      "gradient norm: 0.0034727170786936767, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19878 / 20000\n",
      "gradient norm: 0.0067431110655888915, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19879 / 20000\n",
      "gradient norm: 0.009051793123944663, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19880 / 20000\n",
      "gradient norm: 0.006293301470577717, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19881 / 20000\n",
      "gradient norm: 0.010847687808563933, minimum ratio: 2.46578947368421\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19882 / 20000\n",
      "gradient norm: 0.008338010295119602, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19883 / 20000\n",
      "gradient norm: 0.00880987815617118, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19884 / 20000\n",
      "gradient norm: 0.025232040032278746, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19885 / 20000\n",
      "gradient norm: 0.02151948190294206, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19886 / 20000\n",
      "gradient norm: 0.01565068665149738, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19887 / 20000\n",
      "gradient norm: 0.03227059720666148, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19888 / 20000\n",
      "gradient norm: 0.044987359549850225, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19889 / 20000\n",
      "gradient norm: 0.030478969958494417, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19890 / 20000\n",
      "gradient norm: 0.030074630078161135, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19891 / 20000\n",
      "gradient norm: 0.030166486627422273, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19892 / 20000\n",
      "gradient norm: 0.022064717675675638, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19893 / 20000\n",
      "gradient norm: 0.022561505349585786, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19894 / 20000\n",
      "gradient norm: 0.025000502573675476, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19895 / 20000\n",
      "gradient norm: 0.01765859455917962, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19896 / 20000\n",
      "gradient norm: 0.01264018562505953, minimum ratio: 2.460526315789474\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19897 / 20000\n",
      "gradient norm: 0.010480847413418815, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19898 / 20000\n",
      "gradient norm: 0.008762885132455267, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19899 / 20000\n",
      "gradient norm: 0.004911590556730516, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19900 / 20000\n",
      "gradient norm: 0.008061901811743155, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19901 / 20000\n",
      "gradient norm: 0.018370209785643965, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19902 / 20000\n",
      "gradient norm: 0.026578863202303182, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19903 / 20000\n",
      "gradient norm: 0.015926208507153206, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19904 / 20000\n",
      "gradient norm: 0.02233222292852588, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19905 / 20000\n",
      "gradient norm: 0.017381790472427383, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19906 / 20000\n",
      "gradient norm: 0.015060572972288355, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19907 / 20000\n",
      "gradient norm: 0.011393142049200833, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19908 / 20000\n",
      "gradient norm: 0.009531435687677003, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19909 / 20000\n",
      "gradient norm: 0.007989111341885291, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19910 / 20000\n",
      "gradient norm: 0.004022338689537719, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19911 / 20000\n",
      "gradient norm: 0.01025617587583838, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19912 / 20000\n",
      "gradient norm: 0.00813538367219735, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19913 / 20000\n",
      "gradient norm: 0.01068254336132668, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19914 / 20000\n",
      "gradient norm: 0.012365489412331954, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19915 / 20000\n",
      "gradient norm: 0.018790071975672618, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19916 / 20000\n",
      "gradient norm: 0.01287008864164818, minimum ratio: 2.4499999999999997\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19917 / 20000\n",
      "gradient norm: 0.008267632671049796, minimum ratio: 2.471052631578947\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19918 / 20000\n",
      "gradient norm: 0.007051164750009775, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19919 / 20000\n",
      "gradient norm: 0.006541703751281602, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19920 / 20000\n",
      "gradient norm: 0.005939104063145351, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19921 / 20000\n",
      "gradient norm: 0.01423042081296444, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19922 / 20000\n",
      "gradient norm: 0.01944229427317623, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19923 / 20000\n",
      "gradient norm: 0.012901001362479292, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19924 / 20000\n",
      "gradient norm: 0.010387303787865676, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19925 / 20000\n",
      "gradient norm: 0.008949256502091885, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19926 / 20000\n",
      "gradient norm: 0.008680866783834063, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19927 / 20000\n",
      "gradient norm: 0.008714929921552539, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19928 / 20000\n",
      "gradient norm: 0.0034554854355519637, minimum ratio: 2.444736842105263\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19929 / 20000\n",
      "gradient norm: 0.008540879120118916, minimum ratio: 2.431578947368421\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19930 / 20000\n",
      "gradient norm: 0.01634015448507853, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19931 / 20000\n",
      "gradient norm: 0.011487782438052818, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19932 / 20000\n",
      "gradient norm: 0.010578817164059728, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19933 / 20000\n",
      "gradient norm: 0.007276789452589583, minimum ratio: 2.4289473684210523\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19934 / 20000\n",
      "gradient norm: 0.006956643584999256, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19935 / 20000\n",
      "gradient norm: 0.00867820628627669, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19936 / 20000\n",
      "gradient norm: 0.010815957255545072, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19937 / 20000\n",
      "gradient norm: 0.010173208051128313, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19938 / 20000\n",
      "gradient norm: 0.010545288867433555, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19939 / 20000\n",
      "gradient norm: 0.0056513084782636724, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19940 / 20000\n",
      "gradient norm: 0.007678235764615238, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19941 / 20000\n",
      "gradient norm: 0.01302311947074486, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19942 / 20000\n",
      "gradient norm: 0.01277184190985281, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19943 / 20000\n",
      "gradient norm: 0.009123501280555502, minimum ratio: 2.4789473684210526\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19944 / 20000\n",
      "gradient norm: 0.008616136430646293, minimum ratio: 2.439473684210526\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19945 / 20000\n",
      "gradient norm: 0.011686359808663838, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19946 / 20000\n",
      "gradient norm: 0.005592376648564823, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19947 / 20000\n",
      "gradient norm: 0.0046965369110694155, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19948 / 20000\n",
      "gradient norm: 0.004449849482625723, minimum ratio: 2.4684210526315793\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19949 / 20000\n",
      "gradient norm: 0.0061663801316171885, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19950 / 20000\n",
      "gradient norm: 0.014919205117621459, minimum ratio: 2.463157894736842\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19951 / 20000\n",
      "gradient norm: 0.009236710495315492, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19952 / 20000\n",
      "gradient norm: 0.012852912652306259, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19953 / 20000\n",
      "gradient norm: 0.01449909784423653, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19954 / 20000\n",
      "gradient norm: 0.014174641401041299, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19955 / 20000\n",
      "gradient norm: 0.021133183123311028, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19956 / 20000\n",
      "gradient norm: 0.01810416128137149, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19957 / 20000\n",
      "gradient norm: 0.020651364713557996, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19958 / 20000\n",
      "gradient norm: 0.016430584917543456, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19959 / 20000\n",
      "gradient norm: 0.018784714106004685, minimum ratio: 2.447368421052632\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19960 / 20000\n",
      "gradient norm: 0.012043766113492893, minimum ratio: 2.4473684210526314\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19961 / 20000\n",
      "gradient norm: 0.0056847562664188445, minimum ratio: 2.4499999999999997\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19962 / 20000\n",
      "gradient norm: 0.003724383503140416, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19963 / 20000\n",
      "gradient norm: 0.00566391961183399, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19964 / 20000\n",
      "gradient norm: 0.010403054329799488, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19965 / 20000\n",
      "gradient norm: 0.009345339611172676, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19966 / 20000\n",
      "gradient norm: 0.00642498772504041, minimum ratio: 2.460526315789474\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19967 / 20000\n",
      "gradient norm: 0.015335132571635768, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19968 / 20000\n",
      "gradient norm: 0.0081634980160743, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19969 / 20000\n",
      "gradient norm: 0.005678241330315359, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19970 / 20000\n",
      "gradient norm: 0.009061295306310058, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19971 / 20000\n",
      "gradient norm: 0.006132214461104013, minimum ratio: 2.481578947368421\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19972 / 20000\n",
      "gradient norm: 0.010918738262262195, minimum ratio: 2.4289473684210527\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19973 / 20000\n",
      "gradient norm: 0.014118201841483824, minimum ratio: 2.473684210526316\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19974 / 20000\n",
      "gradient norm: 0.011198527325177565, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19975 / 20000\n",
      "gradient norm: 0.01855035644257441, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19976 / 20000\n",
      "gradient norm: 0.021574686688836664, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19977 / 20000\n",
      "gradient norm: 0.028426573262549937, minimum ratio: 2.4710526315789476\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19978 / 20000\n",
      "gradient norm: 0.02127677072712686, minimum ratio: 2.4499999999999997\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19979 / 20000\n",
      "gradient norm: 0.01660703757079318, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19980 / 20000\n",
      "gradient norm: 0.006034252044628374, minimum ratio: 2.4368421052631577\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19981 / 20000\n",
      "gradient norm: 0.005864689170266502, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19982 / 20000\n",
      "gradient norm: 0.010244162753224373, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19983 / 20000\n",
      "gradient norm: 0.002733672554313671, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19984 / 20000\n",
      "gradient norm: 0.005418937689682934, minimum ratio: 2.492105263157895\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19985 / 20000\n",
      "gradient norm: 0.008437299686193, minimum ratio: 2.4631578947368418\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19986 / 20000\n",
      "gradient norm: 0.0033642559428699315, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19987 / 20000\n",
      "gradient norm: 0.0051033276176895015, minimum ratio: 2.4342105263157894\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19988 / 20000\n",
      "gradient norm: 0.004269922159437556, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19989 / 20000\n",
      "gradient norm: 0.00926360372977797, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19990 / 20000\n",
      "gradient norm: 0.009475933940848336, minimum ratio: 2.468421052631579\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19991 / 20000\n",
      "gradient norm: 0.008973630465334281, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19992 / 20000\n",
      "gradient norm: 0.01578332102508284, minimum ratio: 2.455263157894737\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19993 / 20000\n",
      "gradient norm: 0.013622419166495092, minimum ratio: 2.4657894736842105\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19994 / 20000\n",
      "gradient norm: 0.014212233538273722, minimum ratio: 2.4526315789473685\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19995 / 20000\n",
      "gradient norm: 0.017158772141556256, minimum ratio: 2.45\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19996 / 20000\n",
      "gradient norm: 0.03126869976404123, minimum ratio: 2.4763157894736842\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19997 / 20000\n",
      "gradient norm: 0.021844792005140334, minimum ratio: 2.442105263157895\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19998 / 20000\n",
      "gradient norm: 0.02441941686993232, minimum ratio: 2.457894736842105\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 19999 / 20000\n",
      "gradient norm: 0.026384056895039976, minimum ratio: 2.5\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n",
      "epoch 20000 / 20000\n",
      "gradient norm: 0.020663054601754993, minimum ratio: 2.4605263157894735\n",
      "\ttrain loss: 0.00005\n",
      "\tval loss: 0.00005\n"
     ]
    }
   ],
   "source": [
    "activations = defaultdict(int)\n",
    "hess = defaultdict(float)\n",
    "model = SineApproximator().to(device)\n",
    "autograd_lib.register(model)\n",
    "t_ls_1, v_ls_1, gradient_norm, minimal_ratio = returnLossPredictedOp(model, train_dataloader, val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6b32066f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt_1 = plt.figure(figsize=(10, 6))\n",
    "plt.title(\"Loss vs Minimal Ratio\")\n",
    "plt.scatter(minimal_ratio, t_ls_1, alpha=0.3)\n",
    "plt.xlabel('Minimum Ratio')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6792211a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
